{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "n7MBDuPasy-s",
        "e7-_jqRw3cRa",
        "QinQ4hWStzHt",
        "boZqFQNlraCh"
      ],
      "authorship_tag": "ABX9TyP0X9d88S89LbBIhgVJ0glF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "19ee2f90-3b66-4f4d-a5e7-c623b5311031"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a6e318-b59c-4fa1-def7-3118198adcb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "oVLI86qK9J_9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "D4BClPwS9KAB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f27f2a-9a60-458b-b5a2-c857110e6960",
        "id": "Zfs5m8Xs9KAC"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "c36470d4-7263-496f-c8fe-40d36fac47d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "98d1784d-86de-4718-9b40-f9db17159013"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "onw4pCwZy-1s",
        "outputId": "72e6f886-4559-4b4e-9664-16aac33649e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lmFKjQaeip1b",
        "outputId": "db260dd4-3e9c-40c7-b590-f4feb27e9313"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "ad403651-394d-47bb-e557-a638c31cd3a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "26hK4VWkx1R7",
        "outputId": "9a083ee1-8e71-416d-875a-03688e6054c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "RXluaxXx9KAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "pXrknAaH9KAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "PWPu36179KAO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "Zt00Gp3h9KAO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "s5FGWUO39KAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "1YVpDJMZ9KAP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "kuJmsPFz9KAP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "2wQw__yZ9KAQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "Yxeph5PR9KAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "Y6osQMX29KAS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "CaAspZtt9KAS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "aGe9ksS69KAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "gRSH3tdyf8yc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor2(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        data = data.drop(self.feature_cols, axis=1)\n",
        "        \n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        print(all(data.index==transf.index))\n",
        "        data = pd.concat([data,transf], axis=1)\n",
        "        # data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        transf = self.scaler.fit_transform(data[self.feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.scaler.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        data = data.drop(self.feature_cols, axis=1)\n",
        "        data = pd.concat([data,transf], axis=1)\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Kfvjdak-9KAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "3aXzwlaw9KAU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "wulPSyfF9KAU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "hKDJOCJf9KAV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "Vd0hQpw-U_ch"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "5aqms6jMFKti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.7965826139501325  \n",
        "Test: 0.706\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.10771222326909816),\n",
        "('basemodel__model__layer1', 505),\n",
        "('basemodel__model__learning_rate', 0.0032806529941975817),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 70)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "oGlT7ajZFKtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=70\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.10771222326909816, \n",
        "                           model__layer1=505, \n",
        "                           model__learning_rate=0.0032806529941975817,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fceefe0-59b0-4c3b-d0f8-2e8ae8182306",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "(13731, 70, 22) (13731, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 70, 22)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 505)               1066560   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 505)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 506       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,067,066\n",
            "Trainable params: 1,067,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2122.902, rmse=46.075, r2=0.214; v_loss=3661.737, v_rmse=60.512, v_r2=0.016; \n",
            "E 2\t: loss=1572.519, rmse=39.655, r2=0.418; v_loss=2669.167, v_rmse=51.664, v_r2=0.283; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000017901CA9D00>, <keras.callbacks.LambdaCallback object at 0x0000017903001040>], epochs=2, model=<function create_model at 0x000001790303C9D0>, model__activation1='tanh', model__dropout1=0.10771222326909816, model__layer1=505, model__learning_rate=0.0032806529941975817, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000179030136A0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000179035D7D30>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     scaler=MinMaxScaler(), seq_length=70)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c55b4f-b71b-40e2-d082-8d0d1eb34014",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.641,RMSE=-24.886\n",
            "Finished: 2022-10-16 08:11:55.591639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.9430289602358563  \n",
        "Test: 0.857\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 105),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 68)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36P-gmRD6QM",
        "outputId": "2f3b0316-0061-40f5-edd6-fb8a571d462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_3 (Masking)         (None, 68, 22)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,096,193\n",
            "Trainable params: 1,096,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2982.448, rmse=54.612, r2=-1.419; v_loss=2215.075, v_rmse=47.065, v_r2=-0.774; \n",
            "E 2\t: loss=1623.784, rmse=40.296, r2=-0.317; v_loss=1706.530, v_rmse=41.310, v_r2=-0.367; \n",
            "E 3\t: loss=1197.737, rmse=34.608, r2=0.029; v_loss=1497.697, v_rmse=38.700, v_r2=-0.199; \n",
            "E 4\t: loss=958.397, rmse=30.958, r2=0.223; v_loss=1343.810, v_rmse=36.658, v_r2=-0.076; \n",
            "E 5\t: loss=774.233, rmse=27.825, r2=0.372; v_loss=984.936, v_rmse=31.384, v_r2=0.211; \n",
            "E 6\t: loss=472.650, rmse=21.741, r2=0.617; v_loss=546.742, v_rmse=23.383, v_r2=0.562; \n",
            "E 7\t: loss=302.671, rmse=17.397, r2=0.755; v_loss=322.965, v_rmse=17.971, v_r2=0.741; \n",
            "E 8\t: loss=210.265, rmse=14.501, r2=0.829; v_loss=244.289, v_rmse=15.630, v_r2=0.804; \n",
            "E 9\t: loss=163.712, rmse=12.795, r2=0.867; v_loss=161.370, v_rmse=12.703, v_r2=0.871; \n",
            "E 10\t: loss=119.954, rmse=10.952, r2=0.903; v_loss=134.003, v_rmse=11.576, v_r2=0.893; \n",
            "E 11\t: loss=122.557, rmse=11.071, r2=0.901; v_loss=133.849, v_rmse=11.569, v_r2=0.893; \n",
            "E 12\t: loss=92.088, rmse=9.596, r2=0.925; v_loss=88.262, v_rmse=9.395, v_r2=0.929; \n",
            "E 13\t: loss=81.347, rmse=9.019, r2=0.934; v_loss=77.839, v_rmse=8.823, v_r2=0.938; \n",
            "E 14\t: loss=75.310, rmse=8.678, r2=0.939; v_loss=65.134, v_rmse=8.071, v_r2=0.948; \n",
            "E 15\t: loss=69.507, rmse=8.337, r2=0.944; v_loss=68.467, v_rmse=8.274, v_r2=0.945; \n",
            "E 16\t: loss=66.176, rmse=8.135, r2=0.946; v_loss=89.575, v_rmse=9.464, v_r2=0.928; \n",
            "E 17\t: loss=65.656, rmse=8.103, r2=0.947; v_loss=70.496, v_rmse=8.396, v_r2=0.944; \n",
            "E 18\t: loss=61.586, rmse=7.848, r2=0.950; v_loss=51.289, v_rmse=7.162, v_r2=0.959; \n",
            "E 19\t: loss=59.908, rmse=7.740, r2=0.951; v_loss=58.295, v_rmse=7.635, v_r2=0.953; \n",
            "E 20\t: loss=55.930, rmse=7.479, r2=0.955; v_loss=50.215, v_rmse=7.086, v_r2=0.960; \n",
            "E 21\t: loss=57.646, rmse=7.593, r2=0.953; v_loss=53.539, v_rmse=7.317, v_r2=0.957; \n",
            "E 22\t: loss=55.984, rmse=7.482, r2=0.955; v_loss=47.239, v_rmse=6.873, v_r2=0.962; \n",
            "E 23\t: loss=54.576, rmse=7.388, r2=0.956; v_loss=62.975, v_rmse=7.936, v_r2=0.950; \n",
            "E 24\t: loss=54.185, rmse=7.361, r2=0.956; v_loss=55.870, v_rmse=7.475, v_r2=0.955; \n",
            "E 25\t: loss=56.578, rmse=7.522, r2=0.954; v_loss=54.440, v_rmse=7.378, v_r2=0.956; \n",
            "E 26\t: loss=52.954, rmse=7.277, r2=0.957; v_loss=49.817, v_rmse=7.058, v_r2=0.960; \n",
            "E 27\t: loss=50.986, rmse=7.140, r2=0.959; v_loss=63.619, v_rmse=7.976, v_r2=0.949; \n",
            "E 28\t: loss=53.836, rmse=7.337, r2=0.956; v_loss=65.039, v_rmse=8.065, v_r2=0.948; \n",
            "E 29\t: loss=51.266, rmse=7.160, r2=0.958; v_loss=49.043, v_rmse=7.003, v_r2=0.961; \n",
            "E 30\t: loss=50.529, rmse=7.108, r2=0.959; v_loss=49.954, v_rmse=7.068, v_r2=0.960; \n",
            "E 31\t: loss=51.051, rmse=7.145, r2=0.959; v_loss=67.456, v_rmse=8.213, v_r2=0.946; \n",
            "E 32\t: loss=49.074, rmse=7.005, r2=0.960; v_loss=80.333, v_rmse=8.963, v_r2=0.936; \n",
            "E 33\t: loss=50.404, rmse=7.100, r2=0.959; v_loss=77.496, v_rmse=8.803, v_r2=0.938; \n",
            "E 34\t: loss=49.055, rmse=7.004, r2=0.960; v_loss=50.703, v_rmse=7.121, v_r2=0.959; \n",
            "E 35\t: loss=47.616, rmse=6.900, r2=0.961; v_loss=59.109, v_rmse=7.688, v_r2=0.953; \n",
            "E 36\t: loss=48.214, rmse=6.944, r2=0.961; v_loss=43.517, v_rmse=6.597, v_r2=0.965; \n",
            "E 37\t: loss=49.488, rmse=7.035, r2=0.960; v_loss=52.871, v_rmse=7.271, v_r2=0.958; \n",
            "E 38\t: loss=48.587, rmse=6.970, r2=0.961; v_loss=47.855, v_rmse=6.918, v_r2=0.962; \n",
            "E 39\t: loss=48.213, rmse=6.944, r2=0.961; v_loss=44.330, v_rmse=6.658, v_r2=0.964; \n",
            "E 40\t: loss=48.061, rmse=6.933, r2=0.961; v_loss=56.976, v_rmse=7.548, v_r2=0.954; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000247B9A42760>, <keras.callbacks.LambdaCallback object at 0x00000247B9AC3D00>], epochs=50, model=<function create_model at 0x00000247B9B5CB80>, model__activation1='tanh', model__dropout1=0.1, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000247CA9147C0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000248EA003AC0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     clip_y=105, scaler=MinMaxScaler(), seq_length=68)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "02417a5a-662e-4369-f4e5-8a8cf3f3c413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.869,RMSE=-12.909\n",
            "Finished: 2022-10-16 07:46:45.185856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1"
      ],
      "metadata": {
        "id": "SvWawqOFYvO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "bWDbtK4RYvPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.8521617501513421  \n",
        "Test: 0.793\n",
        "```\n",
        "('basemodel__batch_size', 239),\n",
        "('basemodel__epochs', 45),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__dropout1', 0.8360008606718795),\n",
        "('basemodel__model__dropout2', 0.8326359552620336),\n",
        "('basemodel__model__layer1', 493),\n",
        "('basemodel__model__layer2', 469),\n",
        "('basemodel__model__learning_rate', 0.0013568819509124186),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1967801723709445),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 74)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "18mXMMo2YvPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=74\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=239,\n",
        "                           epochs=45,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__dropout1=0.8360008606718795, \n",
        "                           model__dropout2=0.8326359552620336, \n",
        "                           model__layer1=493, \n",
        "                           model__layer2=469, \n",
        "                           model__learning_rate=0.0013568819509124186,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1967801723709445, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "2EKUQXh0YvPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52946ea0-d3d5-4eee-b6ea-94f635e6a707",
        "id": "5uHgjmJZYvPC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 74, 22)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 493)               1017552   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 493)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 469)               231686    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 469)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 470       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,249,708\n",
            "Trainable params: 1,249,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2721.398, rmse=52.167, r2=-0.111; v_loss=3049.229, v_rmse=55.220, v_r2=0.184; \n",
            "E 2\t: loss=1426.339, rmse=37.767, r2=0.418; v_loss=2281.288, v_rmse=47.763, v_r2=0.389; \n",
            "E 3\t: loss=1187.548, rmse=34.461, r2=0.515; v_loss=1950.685, v_rmse=44.167, v_r2=0.478; \n",
            "E 4\t: loss=1101.703, rmse=33.192, r2=0.550; v_loss=1748.322, v_rmse=41.813, v_r2=0.532; \n",
            "E 5\t: loss=984.472, rmse=31.376, r2=0.598; v_loss=1444.184, v_rmse=38.002, v_r2=0.613; \n",
            "E 6\t: loss=844.556, rmse=29.061, r2=0.655; v_loss=1110.438, v_rmse=33.323, v_r2=0.703; \n",
            "E 7\t: loss=738.586, rmse=27.177, r2=0.698; v_loss=808.535, v_rmse=28.435, v_r2=0.784; \n",
            "E 8\t: loss=731.587, rmse=27.048, r2=0.701; v_loss=739.132, v_rmse=27.187, v_r2=0.802; \n",
            "E 9\t: loss=686.618, rmse=26.203, r2=0.720; v_loss=603.122, v_rmse=24.559, v_r2=0.839; \n",
            "E 10\t: loss=625.926, rmse=25.019, r2=0.744; v_loss=428.100, v_rmse=20.691, v_r2=0.885; \n",
            "E 11\t: loss=593.926, rmse=24.371, r2=0.757; v_loss=500.614, v_rmse=22.374, v_r2=0.866; \n",
            "E 12\t: loss=629.177, rmse=25.083, r2=0.743; v_loss=497.126, v_rmse=22.296, v_r2=0.867; \n",
            "E 13\t: loss=580.272, rmse=24.089, r2=0.763; v_loss=718.226, v_rmse=26.800, v_r2=0.808; \n",
            "E 14\t: loss=570.658, rmse=23.888, r2=0.767; v_loss=378.745, v_rmse=19.461, v_r2=0.899; \n",
            "E 15\t: loss=550.960, rmse=23.473, r2=0.775; v_loss=435.865, v_rmse=20.877, v_r2=0.883; \n",
            "E 16\t: loss=560.576, rmse=23.676, r2=0.771; v_loss=948.325, v_rmse=30.795, v_r2=0.746; \n",
            "E 17\t: loss=595.176, rmse=24.396, r2=0.757; v_loss=547.284, v_rmse=23.394, v_r2=0.854; \n",
            "E 18\t: loss=523.061, rmse=22.871, r2=0.786; v_loss=810.776, v_rmse=28.474, v_r2=0.783; \n",
            "E 19\t: loss=535.381, rmse=23.138, r2=0.781; v_loss=427.783, v_rmse=20.683, v_r2=0.885; \n",
            "E 20\t: loss=487.960, rmse=22.090, r2=0.801; v_loss=314.580, v_rmse=17.736, v_r2=0.916; \n",
            "E 21\t: loss=481.336, rmse=21.939, r2=0.803; v_loss=353.945, v_rmse=18.813, v_r2=0.905; \n",
            "E 22\t: loss=475.789, rmse=21.813, r2=0.806; v_loss=324.817, v_rmse=18.023, v_r2=0.913; \n",
            "E 23\t: loss=454.765, rmse=21.325, r2=0.814; v_loss=293.180, v_rmse=17.123, v_r2=0.922; \n",
            "E 24\t: loss=468.520, rmse=21.645, r2=0.809; v_loss=373.612, v_rmse=19.329, v_r2=0.900; \n",
            "E 25\t: loss=479.419, rmse=21.896, r2=0.804; v_loss=377.195, v_rmse=19.422, v_r2=0.899; \n",
            "E 26\t: loss=455.310, rmse=21.338, r2=0.814; v_loss=300.542, v_rmse=17.336, v_r2=0.920; \n",
            "E 27\t: loss=469.611, rmse=21.671, r2=0.808; v_loss=387.978, v_rmse=19.697, v_r2=0.896; \n",
            "E 28\t: loss=435.679, rmse=20.873, r2=0.822; v_loss=330.940, v_rmse=18.192, v_r2=0.911; \n",
            "E 29\t: loss=439.870, rmse=20.973, r2=0.820; v_loss=365.294, v_rmse=19.113, v_r2=0.902; \n",
            "E 30\t: loss=458.431, rmse=21.411, r2=0.813; v_loss=387.967, v_rmse=19.697, v_r2=0.896; \n",
            "E 31\t: loss=449.871, rmse=21.210, r2=0.816; v_loss=385.490, v_rmse=19.634, v_r2=0.897; \n",
            "E 32\t: loss=437.567, rmse=20.918, r2=0.821; v_loss=301.145, v_rmse=17.354, v_r2=0.919; \n",
            "E 33\t: loss=403.795, rmse=20.095, r2=0.835; v_loss=341.337, v_rmse=18.475, v_r2=0.909; \n",
            "E 34\t: loss=431.613, rmse=20.775, r2=0.824; v_loss=407.754, v_rmse=20.193, v_r2=0.891; \n",
            "E 35\t: loss=415.093, rmse=20.374, r2=0.830; v_loss=328.591, v_rmse=18.127, v_r2=0.912; \n",
            "E 36\t: loss=403.548, rmse=20.089, r2=0.835; v_loss=358.622, v_rmse=18.937, v_r2=0.904; \n",
            "E 37\t: loss=419.594, rmse=20.484, r2=0.829; v_loss=301.316, v_rmse=17.358, v_r2=0.919; \n",
            "E 38\t: loss=417.036, rmse=20.421, r2=0.830; v_loss=559.979, v_rmse=23.664, v_r2=0.850; \n",
            "E 39\t: loss=435.395, rmse=20.866, r2=0.822; v_loss=332.459, v_rmse=18.233, v_r2=0.911; \n",
            "E 40\t: loss=419.385, rmse=20.479, r2=0.829; v_loss=313.870, v_rmse=17.716, v_r2=0.916; \n",
            "E 41\t: loss=409.252, rmse=20.230, r2=0.833; v_loss=517.277, v_rmse=22.744, v_r2=0.862; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=239, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000197C771EB80>, <keras.callbacks.LambdaCallback object at 0x00000197C7753BE0>], epochs=45, model=<function create_model at 0x00000197C90B6EE0>, model__activation1='tanh', model__activation2='relu', model__dropout1=0.8360008606718795, model__dropout...r2=469, model__learning_rate=0.0013568819509124186, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000197C7AAFC40>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000197C92950D0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1967801723709445, verbose=0),\n",
              "                     seq_length=74)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d429112-803d-4c55-fc1d-c4e2e00a0843",
        "id": "svjWhd4FYvPD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.793,RMSE=-18.928\n",
            "Finished: 2022-10-16 08:19:44.587007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "6LznVkFxYvPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.917847894602053  \n",
        "Test: 0.883\n",
        "```\n",
        "('basemodel__batch_size', 174),\n",
        "('basemodel__epochs', 21),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__dropout1', 0.5157104351784535),\n",
        "('basemodel__model__dropout2', 0.7126675967759073),\n",
        "('basemodel__model__layer1', 125),\n",
        "('basemodel__model__layer2', 386),\n",
        "('basemodel__model__learning_rate', 0.0017804516876459917),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.23205313885059345),\n",
        "('clip_y', 140),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 80)\n",
        "```\n"
      ],
      "metadata": {
        "id": "KiL-gZkZYvPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=80\n",
        "CLIP=140\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=174,\n",
        "                           epochs=21,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout1=0.5157104351784535, \n",
        "                           model__dropout2=0.7126675967759073, \n",
        "                           model__layer1=125, \n",
        "                           model__layer2=386, \n",
        "                           model__learning_rate=0.0017804516876459917,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.23205313885059345, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "tEwHSsUCYvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1c0e28-c509-46cc-d4d9-50112003f55d",
        "id": "AMEzooPSYvPF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 80, 22)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 125)               74000     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 125)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 386)               48636     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 386)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,023\n",
            "Trainable params: 123,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2039.539, rmse=45.161, r2=-0.199; v_loss=1358.758, v_rmse=36.861, v_r2=0.365; \n",
            "E 2\t: loss=703.401, rmse=26.522, r2=0.586; v_loss=799.613, v_rmse=28.277, v_r2=0.626; \n",
            "E 3\t: loss=557.290, rmse=23.607, r2=0.672; v_loss=764.354, v_rmse=27.647, v_r2=0.643; \n",
            "E 4\t: loss=499.155, rmse=22.342, r2=0.706; v_loss=712.040, v_rmse=26.684, v_r2=0.667; \n",
            "E 5\t: loss=472.438, rmse=21.736, r2=0.722; v_loss=540.095, v_rmse=23.240, v_r2=0.748; \n",
            "E 6\t: loss=408.930, rmse=20.222, r2=0.760; v_loss=433.801, v_rmse=20.828, v_r2=0.797; \n",
            "E 7\t: loss=327.316, rmse=18.092, r2=0.808; v_loss=234.598, v_rmse=15.317, v_r2=0.890; \n",
            "E 8\t: loss=290.886, rmse=17.055, r2=0.829; v_loss=233.447, v_rmse=15.279, v_r2=0.891; \n",
            "E 9\t: loss=259.619, rmse=16.113, r2=0.847; v_loss=241.909, v_rmse=15.553, v_r2=0.887; \n",
            "E 10\t: loss=229.232, rmse=15.140, r2=0.865; v_loss=179.287, v_rmse=13.390, v_r2=0.916; \n",
            "E 11\t: loss=204.551, rmse=14.302, r2=0.880; v_loss=152.195, v_rmse=12.337, v_r2=0.929; \n",
            "E 12\t: loss=201.773, rmse=14.205, r2=0.881; v_loss=192.834, v_rmse=13.886, v_r2=0.910; \n",
            "E 13\t: loss=183.495, rmse=13.546, r2=0.892; v_loss=149.442, v_rmse=12.225, v_r2=0.930; \n",
            "E 14\t: loss=167.473, rmse=12.941, r2=0.902; v_loss=138.964, v_rmse=11.788, v_r2=0.935; \n",
            "E 15\t: loss=171.544, rmse=13.097, r2=0.899; v_loss=146.008, v_rmse=12.083, v_r2=0.932; \n",
            "E 16\t: loss=192.886, rmse=13.888, r2=0.887; v_loss=134.393, v_rmse=11.593, v_r2=0.937; \n",
            "E 17\t: loss=162.054, rmse=12.730, r2=0.905; v_loss=135.225, v_rmse=11.629, v_r2=0.937; \n",
            "E 18\t: loss=150.156, rmse=12.254, r2=0.912; v_loss=123.085, v_rmse=11.094, v_r2=0.942; \n",
            "E 19\t: loss=159.084, rmse=12.613, r2=0.906; v_loss=103.725, v_rmse=10.185, v_r2=0.952; \n",
            "E 20\t: loss=145.855, rmse=12.077, r2=0.914; v_loss=117.418, v_rmse=10.836, v_r2=0.945; \n",
            "E 21\t: loss=137.448, rmse=11.724, r2=0.919; v_loss=115.687, v_rmse=10.756, v_r2=0.946; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=174, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000197C771EB80>, <keras.callbacks.LambdaCallback object at 0x00000197C7753BE0>], epochs=21, model=<function create_model at 0x00000197C90B6EE0>, model__activation1='tanh', model__activation2='selu', model__dropout1=0.5157104351784535, model__dropout...__learning_rate=0.0017804516876459917, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000197D6A3C430>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000019787C863A0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.23205313885059345, verbose=0),\n",
              "                     clip_y=140, seq_length=80)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4e97fa-2c54-4b34-ce8f-aad0202e4172",
        "id": "WU1dYRTwYvPG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.883,RMSE=-14.201\n",
            "Finished: 2022-10-16 08:20:41.062244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2"
      ],
      "metadata": {
        "id": "y28M-FK8zDq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "9Zl5AM1czDq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.7968129295270682  \n",
        "Test: 0.767\n",
        "```\n",
        "('basemodel__batch_size', 33),\n",
        "('basemodel__epochs', 32),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.22285374911306066),\n",
        "('basemodel__model__dropout2', 0.7374780395679955),\n",
        "('basemodel__model__dropout3', 0.3869949529630097),\n",
        "('basemodel__model__layer1', 224),\n",
        "('basemodel__model__layer2', 512),\n",
        "('basemodel__model__layer3', 396),\n",
        "('basemodel__model__learning_rate', 0.0006807885804241826),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.6313983549045777),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 95)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y5_j9VhBzDq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=95\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=33,\n",
        "                           epochs=32,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.22285374911306066, \n",
        "                           model__dropout2=0.7374780395679955,\n",
        "                           model__dropout3=0.3869949529630097, \n",
        "                           model__layer1=224, \n",
        "                           model__layer2=512, \n",
        "                           model__layer3=396, \n",
        "                           model__learning_rate=0.0006807885804241826,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.6313983549045777, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "yP84kQK2zDq5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017057cd-1c86-4c7f-8126-c53bed1d7106",
        "id": "dpx_rNVCzDq6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 95, 22)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 224)               221312    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 224)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               115200    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 396)               203148    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 396)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 397       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 540,057\n",
            "Trainable params: 540,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1405.871, rmse=37.495, r2=0.100; v_loss=2284.027, v_rmse=47.791, v_r2=0.155; \n",
            "E 2\t: loss=998.887, rmse=31.605, r2=0.361; v_loss=2177.207, v_rmse=46.661, v_r2=0.195; \n",
            "E 3\t: loss=820.525, rmse=28.645, r2=0.475; v_loss=1842.546, v_rmse=42.925, v_r2=0.318; \n",
            "E 4\t: loss=558.836, rmse=23.640, r2=0.642; v_loss=2085.063, v_rmse=45.662, v_r2=0.229; \n",
            "E 5\t: loss=471.286, rmse=21.709, r2=0.698; v_loss=1351.481, v_rmse=36.762, v_r2=0.500; \n",
            "E 6\t: loss=438.484, rmse=20.940, r2=0.719; v_loss=1337.982, v_rmse=36.578, v_r2=0.505; \n",
            "E 7\t: loss=376.254, rmse=19.397, r2=0.759; v_loss=1400.497, v_rmse=37.423, v_r2=0.482; \n",
            "E 8\t: loss=354.505, rmse=18.828, r2=0.773; v_loss=1232.157, v_rmse=35.102, v_r2=0.544; \n",
            "E 9\t: loss=290.536, rmse=17.045, r2=0.814; v_loss=1470.038, v_rmse=38.341, v_r2=0.456; \n",
            "E 10\t: loss=250.063, rmse=15.813, r2=0.840; v_loss=899.396, v_rmse=29.990, v_r2=0.667; \n",
            "E 11\t: loss=220.384, rmse=14.845, r2=0.859; v_loss=878.398, v_rmse=29.638, v_r2=0.675; \n",
            "E 12\t: loss=229.901, rmse=15.163, r2=0.853; v_loss=753.394, v_rmse=27.448, v_r2=0.721; \n",
            "E 13\t: loss=228.520, rmse=15.117, r2=0.854; v_loss=748.150, v_rmse=27.352, v_r2=0.723; \n",
            "E 14\t: loss=187.853, rmse=13.706, r2=0.880; v_loss=780.725, v_rmse=27.941, v_r2=0.711; \n",
            "E 15\t: loss=165.999, rmse=12.884, r2=0.894; v_loss=743.714, v_rmse=27.271, v_r2=0.725; \n",
            "E 16\t: loss=144.119, rmse=12.005, r2=0.908; v_loss=828.699, v_rmse=28.787, v_r2=0.693; \n",
            "E 17\t: loss=186.504, rmse=13.657, r2=0.881; v_loss=913.914, v_rmse=30.231, v_r2=0.662; \n",
            "E 18\t: loss=169.094, rmse=13.004, r2=0.892; v_loss=1080.849, v_rmse=32.876, v_r2=0.600; \n",
            "E 19\t: loss=166.898, rmse=12.919, r2=0.893; v_loss=973.230, v_rmse=31.197, v_r2=0.640; \n",
            "E 20\t: loss=141.032, rmse=11.876, r2=0.910; v_loss=961.654, v_rmse=31.011, v_r2=0.644; \n",
            "E 21\t: loss=164.205, rmse=12.814, r2=0.895; v_loss=717.128, v_rmse=26.779, v_r2=0.735; \n",
            "E 22\t: loss=143.733, rmse=11.989, r2=0.908; v_loss=992.340, v_rmse=31.501, v_r2=0.633; \n",
            "E 23\t: loss=139.622, rmse=11.816, r2=0.911; v_loss=800.118, v_rmse=28.286, v_r2=0.704; \n",
            "E 24\t: loss=131.650, rmse=11.474, r2=0.916; v_loss=651.280, v_rmse=25.520, v_r2=0.759; \n",
            "E 25\t: loss=141.530, rmse=11.897, r2=0.909; v_loss=948.171, v_rmse=30.792, v_r2=0.649; \n",
            "E 26\t: loss=132.959, rmse=11.531, r2=0.915; v_loss=585.781, v_rmse=24.203, v_r2=0.783; \n",
            "E 27\t: loss=111.870, rmse=10.577, r2=0.928; v_loss=662.985, v_rmse=25.749, v_r2=0.755; \n",
            "E 28\t: loss=162.991, rmse=12.767, r2=0.896; v_loss=625.365, v_rmse=25.007, v_r2=0.769; \n",
            "E 29\t: loss=119.508, rmse=10.932, r2=0.923; v_loss=623.233, v_rmse=24.965, v_r2=0.769; \n",
            "E 30\t: loss=111.481, rmse=10.558, r2=0.929; v_loss=645.536, v_rmse=25.407, v_r2=0.761; \n",
            "E 31\t: loss=118.313, rmse=10.877, r2=0.924; v_loss=928.797, v_rmse=30.476, v_r2=0.656; \n",
            "E 32\t: loss=133.694, rmse=11.563, r2=0.914; v_loss=730.894, v_rmse=27.035, v_r2=0.730; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=33, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=32, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='relu', model__activation3='selu', model__dropout1=0.222853..._rate=0.0006807885804241826, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000021373F822E0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000021373FA2B50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.6313983549045777, verbose=0),\n",
              "                     scaler=MinMaxScaler(), seq_length=95)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a15d68-75fb-49d4-f004-4faf037bbe9f",
        "id": "qzoIZZmlzDq7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.767,RMSE=-20.064\n",
            "Finished: 2022-10-17 13:42:24.798953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "wrpte1WXzDq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.8303738924314298  \n",
        "Test: 0.724\n",
        "```\n",
        "('basemodel__batch_size', 70),\n",
        "('basemodel__epochs', 45),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.677716159846799),\n",
        "('basemodel__model__dropout2', 0.2905479330833355),\n",
        "('basemodel__model__dropout3', 0.25279167191355223),\n",
        "('basemodel__model__layer1', 177),\n",
        "('basemodel__model__layer2', 470),\n",
        "('basemodel__model__layer3', 221),\n",
        "('basemodel__model__learning_rate', 0.009128147835708741),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.643380976472796),\n",
        "('clip_y', 98),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 58)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-RCr6qz8zDq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=58\n",
        "CLIP=98\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=70,\n",
        "                           epochs=45,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='tanh',\n",
        "                           model__dropout1=0.677716159846799, \n",
        "                           model__dropout2=0.2905479330833355,\n",
        "                           model__dropout3=0.25279167191355223, \n",
        "                           model__layer1=177, \n",
        "                           model__layer2=470, \n",
        "                           model__layer3=221, \n",
        "                           model__learning_rate=0.009128147835708741,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.643380976472796, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "TCGZ2Pr4zDq8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc10519-28fc-4955-e157-c832971be1fd",
        "id": "Fd65WHLTzDq9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_2 (Masking)         (None, 58, 22)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 177)               141600    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 177)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 470)               83660     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 470)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 221)               104091    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 221)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 222       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 329,573\n",
            "Trainable params: 329,573\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=916.736, rmse=30.278, r2=0.142; v_loss=636.404, v_rmse=25.227, v_r2=0.414; \n",
            "E 2\t: loss=289.095, rmse=17.003, r2=0.730; v_loss=328.619, v_rmse=18.128, v_r2=0.697; \n",
            "E 3\t: loss=236.314, rmse=15.373, r2=0.779; v_loss=286.056, v_rmse=16.913, v_r2=0.736; \n",
            "E 4\t: loss=206.042, rmse=14.354, r2=0.807; v_loss=599.695, v_rmse=24.489, v_r2=0.447; \n",
            "E 5\t: loss=190.136, rmse=13.789, r2=0.822; v_loss=458.307, v_rmse=21.408, v_r2=0.578; \n",
            "E 6\t: loss=175.191, rmse=13.236, r2=0.836; v_loss=202.988, v_rmse=14.247, v_r2=0.813; \n",
            "E 7\t: loss=172.022, rmse=13.116, r2=0.839; v_loss=219.702, v_rmse=14.822, v_r2=0.798; \n",
            "E 8\t: loss=161.633, rmse=12.713, r2=0.849; v_loss=188.178, v_rmse=13.718, v_r2=0.827; \n",
            "E 9\t: loss=150.945, rmse=12.286, r2=0.859; v_loss=158.764, v_rmse=12.600, v_r2=0.854; \n",
            "E 10\t: loss=146.535, rmse=12.105, r2=0.863; v_loss=240.224, v_rmse=15.499, v_r2=0.779; \n",
            "E 11\t: loss=151.835, rmse=12.322, r2=0.858; v_loss=225.860, v_rmse=15.029, v_r2=0.792; \n",
            "E 12\t: loss=156.146, rmse=12.496, r2=0.854; v_loss=392.014, v_rmse=19.799, v_r2=0.639; \n",
            "E 13\t: loss=143.312, rmse=11.971, r2=0.866; v_loss=522.510, v_rmse=22.858, v_r2=0.519; \n",
            "E 14\t: loss=144.943, rmse=12.039, r2=0.864; v_loss=230.998, v_rmse=15.199, v_r2=0.787; \n",
            "E 15\t: loss=133.207, rmse=11.542, r2=0.875; v_loss=266.659, v_rmse=16.330, v_r2=0.754; \n",
            "E 16\t: loss=133.587, rmse=11.558, r2=0.875; v_loss=206.270, v_rmse=14.362, v_r2=0.810; \n",
            "E 17\t: loss=138.282, rmse=11.759, r2=0.871; v_loss=195.867, v_rmse=13.995, v_r2=0.820; \n",
            "E 18\t: loss=144.583, rmse=12.024, r2=0.865; v_loss=234.814, v_rmse=15.324, v_r2=0.784; \n",
            "E 19\t: loss=148.964, rmse=12.205, r2=0.861; v_loss=249.625, v_rmse=15.800, v_r2=0.770; \n",
            "E 20\t: loss=133.826, rmse=11.568, r2=0.875; v_loss=207.715, v_rmse=14.412, v_r2=0.809; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=70, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=45, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='relu', model__activation3='tanh', model__dropout1=0.677716...learning_rate=0.009128147835708741, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000212181858E0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000021373F82880>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.643380976472796, verbose=0),\n",
              "                     clip_y=98, seq_length=58)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM3mTOqS2Hsb",
        "outputId": "fbb151df-6c30-4531-e170-806f74e5cd56"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8099047216294826"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b3f08b-230e-4387-db6f-2b8414cfb4bf",
        "id": "O8csd7JVzDq-"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.724,RMSE=-17.624\n",
            "Finished: 2022-10-17 13:48:04.292748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense"
      ],
      "metadata": {
        "id": "5z_LZWx32lXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pu0gM_uE2lXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.8491646332519348  \n",
        "Test: 0.705\n",
        "```\n",
        "('basemodel__batch_size', 325),\n",
        "             ('basemodel__epochs', 37),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.5999695396702547),\n",
        "             ('basemodel__model__dropout2', 0.2824705080924561),\n",
        "             ('basemodel__model__dropout3', 0.5749415465530767),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 58),\n",
        "             ('basemodel__model__layer3', 438),\n",
        "             ('basemodel__model__learning_rate', 0.007448084633524131),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.10991019995076438),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 93)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRabKU0p2lXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=93\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           model__second_dense=False,\n",
        "                           batch_size=325,\n",
        "                           epochs=37,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__dropout1=0.5999695396702547, \n",
        "                           model__dropout2=0.2824705080924561,\n",
        "                           model__dropout3=0.5749415465530767, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=58, \n",
        "                           model__layer3=438, \n",
        "                           model__learning_rate=0.007448084633524131,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.10991019995076438, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "6BGiwksX2lXG"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0d1ae9-94f1-4f39-da7a-94979f9f11ed",
        "id": "Yert7PMH2lXI"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_8 (Masking)         (None, 93, 22)            0         \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 93, 512)           1095680   \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 93, 512)           0         \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 58)                132472    \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 58)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 438)               25842     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 438)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 439       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,254,433\n",
            "Trainable params: 1,254,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2807.316, rmse=52.984, r2=-0.302; v_loss=3517.981, v_rmse=59.313, v_r2=0.026; \n",
            "E 2\t: loss=1385.642, rmse=37.224, r2=0.358; v_loss=1867.645, v_rmse=43.216, v_r2=0.483; \n",
            "E 3\t: loss=975.712, rmse=31.236, r2=0.548; v_loss=1779.694, v_rmse=42.186, v_r2=0.508; \n",
            "E 4\t: loss=834.461, rmse=28.887, r2=0.613; v_loss=1448.393, v_rmse=38.058, v_r2=0.599; \n",
            "E 5\t: loss=741.195, rmse=27.225, r2=0.656; v_loss=1122.174, v_rmse=33.499, v_r2=0.689; \n",
            "E 6\t: loss=657.656, rmse=25.645, r2=0.695; v_loss=1694.724, v_rmse=41.167, v_r2=0.531; \n",
            "E 7\t: loss=623.385, rmse=24.968, r2=0.711; v_loss=709.365, v_rmse=26.634, v_r2=0.804; \n",
            "E 8\t: loss=596.513, rmse=24.424, r2=0.723; v_loss=781.477, v_rmse=27.955, v_r2=0.784; \n",
            "E 9\t: loss=537.879, rmse=23.192, r2=0.751; v_loss=1161.276, v_rmse=34.078, v_r2=0.679; \n",
            "E 10\t: loss=513.603, rmse=22.663, r2=0.762; v_loss=1118.741, v_rmse=33.448, v_r2=0.690; \n",
            "E 11\t: loss=466.271, rmse=21.593, r2=0.784; v_loss=950.272, v_rmse=30.826, v_r2=0.737; \n",
            "E 12\t: loss=425.988, rmse=20.639, r2=0.803; v_loss=1787.936, v_rmse=42.284, v_r2=0.505; \n",
            "E 13\t: loss=427.324, rmse=20.672, r2=0.802; v_loss=816.878, v_rmse=28.581, v_r2=0.774; \n",
            "E 14\t: loss=467.038, rmse=21.611, r2=0.783; v_loss=729.066, v_rmse=27.001, v_r2=0.798; \n",
            "E 15\t: loss=437.541, rmse=20.917, r2=0.797; v_loss=881.551, v_rmse=29.691, v_r2=0.756; \n",
            "E 16\t: loss=398.014, rmse=19.950, r2=0.815; v_loss=855.057, v_rmse=29.241, v_r2=0.763; \n",
            "E 17\t: loss=384.389, rmse=19.606, r2=0.822; v_loss=598.662, v_rmse=24.468, v_r2=0.834; \n",
            "E 18\t: loss=326.881, rmse=18.080, r2=0.848; v_loss=1029.435, v_rmse=32.085, v_r2=0.715; \n",
            "E 19\t: loss=342.175, rmse=18.498, r2=0.841; v_loss=1002.506, v_rmse=31.662, v_r2=0.723; \n",
            "E 20\t: loss=317.253, rmse=17.812, r2=0.853; v_loss=671.528, v_rmse=25.914, v_r2=0.814; \n",
            "E 21\t: loss=329.527, rmse=18.153, r2=0.847; v_loss=1071.577, v_rmse=32.735, v_r2=0.703; \n",
            "E 22\t: loss=356.319, rmse=18.876, r2=0.835; v_loss=583.818, v_rmse=24.162, v_r2=0.838; \n",
            "E 23\t: loss=275.118, rmse=16.587, r2=0.872; v_loss=525.210, v_rmse=22.917, v_r2=0.855; \n",
            "E 24\t: loss=298.974, rmse=17.291, r2=0.861; v_loss=838.278, v_rmse=28.953, v_r2=0.768; \n",
            "E 25\t: loss=308.042, rmse=17.551, r2=0.857; v_loss=538.931, v_rmse=23.215, v_r2=0.851; \n",
            "E 26\t: loss=266.831, rmse=16.335, r2=0.876; v_loss=922.865, v_rmse=30.379, v_r2=0.745; \n",
            "E 27\t: loss=244.347, rmse=15.632, r2=0.887; v_loss=525.512, v_rmse=22.924, v_r2=0.855; \n",
            "E 28\t: loss=249.774, rmse=15.804, r2=0.884; v_loss=897.180, v_rmse=29.953, v_r2=0.752; \n",
            "E 29\t: loss=267.788, rmse=16.364, r2=0.876; v_loss=1162.617, v_rmse=34.097, v_r2=0.678; \n",
            "E 30\t: loss=218.741, rmse=14.790, r2=0.899; v_loss=821.009, v_rmse=28.653, v_r2=0.773; \n",
            "E 31\t: loss=225.054, rmse=15.002, r2=0.896; v_loss=764.591, v_rmse=27.651, v_r2=0.788; \n",
            "E 32\t: loss=231.028, rmse=15.200, r2=0.893; v_loss=1057.670, v_rmse=32.522, v_r2=0.707; \n",
            "E 33\t: loss=217.949, rmse=14.763, r2=0.899; v_loss=965.400, v_rmse=31.071, v_r2=0.733; \n",
            "E 34\t: loss=257.527, rmse=16.048, r2=0.881; v_loss=524.350, v_rmse=22.899, v_r2=0.855; \n",
            "E 35\t: loss=212.463, rmse=14.576, r2=0.901; v_loss=680.080, v_rmse=26.078, v_r2=0.812; \n",
            "E 36\t: loss=192.307, rmse=13.867, r2=0.911; v_loss=408.608, v_rmse=20.214, v_r2=0.887; \n",
            "E 37\t: loss=196.740, rmse=14.026, r2=0.909; v_loss=606.670, v_rmse=24.631, v_r2=0.832; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=325, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=37, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='tanh', model__activation3='sigmoid', model__dropout1=0.59...7448084633524131, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000213739BBC10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000213739BBAF0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__second_dense=False, print_summary=True, validation_split=0.10991019995076438, verbose=0),\n",
              "                     seq_length=93)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00304993-034a-464d-b99d-17616868d173",
        "id": "rqyVHO5n2lXK"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.708,RMSE=-22.445\n",
            "Finished: 2022-10-17 14:12:13.939541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "DZEmsy2m2lXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.9505741887137583  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 491),\n",
        "             ('basemodel__epochs', 35),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.269131429819357),\n",
        "             ('basemodel__model__dropout2', 0.1000488406021388),\n",
        "             ('basemodel__model__dropout3', 0.3965483901301635),\n",
        "             ('basemodel__model__layer1', 311),\n",
        "             ('basemodel__model__layer2', 103),\n",
        "             ('basemodel__model__layer3', 397),\n",
        "             ('basemodel__model__learning_rate', 0.004499578015509351),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.24810164977060487),\n",
        "             ('clip_y', 102),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 82)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5340ZcMG2lXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=82\n",
        "CLIP=102\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=491,\n",
        "                           epochs=35,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.269131429819357, \n",
        "                           model__dropout2=0.1000488406021388,\n",
        "                           model__dropout3=0.3965483901301635, \n",
        "                           model__layer1=311, \n",
        "                           model__layer2=103, \n",
        "                           model__layer3=397, \n",
        "                           model__learning_rate=0.004499578015509351,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.24810164977060487, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "njy3V5mz2lXL"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32f7530-c817-4944-ca2e-104be6a6adab",
        "id": "0ZDq9Rf-2lXM"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_9 (Masking)         (None, 82, 22)            0         \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 311)               415496    \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 311)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 103)               32136     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 103)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 397)               41288     \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 397)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 398       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 489,318\n",
            "Trainable params: 489,318\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1682.850, rmse=41.023, r2=-0.479; v_loss=1393.571, v_rmse=37.331, v_r2=-0.156; \n",
            "E 2\t: loss=1028.738, rmse=32.074, r2=0.096; v_loss=1035.901, v_rmse=32.185, v_r2=0.141; \n",
            "E 3\t: loss=758.774, rmse=27.546, r2=0.333; v_loss=994.018, v_rmse=31.528, v_r2=0.175; \n",
            "E 4\t: loss=665.094, rmse=25.789, r2=0.415; v_loss=970.422, v_rmse=31.152, v_r2=0.195; \n",
            "E 5\t: loss=602.499, rmse=24.546, r2=0.470; v_loss=686.694, v_rmse=26.205, v_r2=0.430; \n",
            "E 6\t: loss=477.888, rmse=21.861, r2=0.580; v_loss=418.688, v_rmse=20.462, v_r2=0.653; \n",
            "E 7\t: loss=477.010, rmse=21.841, r2=0.581; v_loss=439.795, v_rmse=20.971, v_r2=0.635; \n",
            "E 8\t: loss=316.579, rmse=17.793, r2=0.722; v_loss=370.316, v_rmse=19.244, v_r2=0.693; \n",
            "E 9\t: loss=299.797, rmse=17.315, r2=0.736; v_loss=272.600, v_rmse=16.511, v_r2=0.774; \n",
            "E 10\t: loss=245.415, rmse=15.666, r2=0.784; v_loss=372.088, v_rmse=19.290, v_r2=0.691; \n",
            "E 11\t: loss=225.698, rmse=15.023, r2=0.802; v_loss=138.170, v_rmse=11.755, v_r2=0.885; \n",
            "E 12\t: loss=146.544, rmse=12.106, r2=0.871; v_loss=99.422, v_rmse=9.971, v_r2=0.918; \n",
            "E 13\t: loss=117.072, rmse=10.820, r2=0.897; v_loss=135.228, v_rmse=11.629, v_r2=0.888; \n",
            "E 14\t: loss=116.232, rmse=10.781, r2=0.898; v_loss=81.250, v_rmse=9.014, v_r2=0.933; \n",
            "E 15\t: loss=112.376, rmse=10.601, r2=0.901; v_loss=65.725, v_rmse=8.107, v_r2=0.945; \n",
            "E 16\t: loss=88.214, rmse=9.392, r2=0.922; v_loss=87.062, v_rmse=9.331, v_r2=0.928; \n",
            "E 17\t: loss=85.532, rmse=9.248, r2=0.925; v_loss=67.491, v_rmse=8.215, v_r2=0.944; \n",
            "E 18\t: loss=79.031, rmse=8.890, r2=0.931; v_loss=62.114, v_rmse=7.881, v_r2=0.948; \n",
            "E 19\t: loss=75.328, rmse=8.679, r2=0.934; v_loss=155.161, v_rmse=12.456, v_r2=0.871; \n",
            "E 20\t: loss=109.320, rmse=10.456, r2=0.904; v_loss=117.289, v_rmse=10.830, v_r2=0.903; \n",
            "E 21\t: loss=81.849, rmse=9.047, r2=0.928; v_loss=58.464, v_rmse=7.646, v_r2=0.951; \n",
            "E 22\t: loss=73.203, rmse=8.556, r2=0.936; v_loss=68.396, v_rmse=8.270, v_r2=0.943; \n",
            "E 23\t: loss=77.473, rmse=8.802, r2=0.932; v_loss=54.737, v_rmse=7.398, v_r2=0.955; \n",
            "E 24\t: loss=68.804, rmse=8.295, r2=0.940; v_loss=76.373, v_rmse=8.739, v_r2=0.937; \n",
            "E 25\t: loss=63.349, rmse=7.959, r2=0.944; v_loss=68.134, v_rmse=8.254, v_r2=0.943; \n",
            "E 26\t: loss=70.083, rmse=8.372, r2=0.938; v_loss=57.773, v_rmse=7.601, v_r2=0.952; \n",
            "E 27\t: loss=75.839, rmse=8.709, r2=0.933; v_loss=70.285, v_rmse=8.384, v_r2=0.942; \n",
            "E 28\t: loss=67.045, rmse=8.188, r2=0.941; v_loss=66.680, v_rmse=8.166, v_r2=0.945; \n",
            "E 29\t: loss=71.246, rmse=8.441, r2=0.937; v_loss=53.289, v_rmse=7.300, v_r2=0.956; \n",
            "E 30\t: loss=63.621, rmse=7.976, r2=0.944; v_loss=78.664, v_rmse=8.869, v_r2=0.935; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=491, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=35, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='tanh', model__activation3='selu', model__dropout1=0.26913...499578015509351, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000021373BFC0D0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000213E382EE50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.24810164977060487, verbose=0),\n",
              "                     clip_y=102, scaler=MinMaxScaler(), seq_length=82)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b33db2-72bd-4216-e0cb-813e6293cb66",
        "id": "GsrsS-Ga2lXO"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.930,RMSE=-9.209\n",
            "Finished: 2022-10-17 14:13:38.475811\n"
          ]
        }
      ]
    }
  ]
}