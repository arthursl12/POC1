{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf",
        "nTPBH5fg_sFd"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOD7eRubQrZUSv4JBLFuYDv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD003_LSTMv2_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "f0e65cb9-68fc-4311-acbd-77b8ec3724e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afaf122f-c1f8-4e16-cfe8-e0a6caa7d163"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "id": "tlp572nXopEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb236c6-64d5-4f93-b014-7d850eb6a615"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(3, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "id": "-yRYxz2hh4xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "b9a0cde6-e025-4cd5-d08e-02c4512e381a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0005  0.0004  100.0  518.67  642.36  1583.23   \n",
              "1                1     2  0.0008 -0.0003  100.0  518.67  642.50  1584.69   \n",
              "2                1     3 -0.0014 -0.0002  100.0  518.67  642.18  1582.35   \n",
              "3                1     4 -0.0020  0.0001  100.0  518.67  642.92  1585.61   \n",
              "4                1     5  0.0016  0.0000  100.0  518.67  641.68  1588.63   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "24715          100   148 -0.0016 -0.0003  100.0  518.67  643.78  1596.01   \n",
              "24716          100   149  0.0034 -0.0003  100.0  518.67  643.29  1596.38   \n",
              "24717          100   150 -0.0016  0.0004  100.0  518.67  643.84  1604.53   \n",
              "24718          100   151 -0.0023  0.0004  100.0  518.67  643.94  1597.56   \n",
              "24719          100   152  0.0000  0.0003  100.0  518.67  643.64  1599.04   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1396.84  14.62  ...  522.31  2388.01  8145.32  8.4246  0.03   391   \n",
              "1      1396.89  14.62  ...  522.42  2388.03  8152.85  8.4403  0.03   392   \n",
              "2      1405.61  14.62  ...  522.03  2388.00  8150.17  8.3901  0.03   391   \n",
              "3      1392.27  14.62  ...  522.49  2388.08  8146.56  8.3878  0.03   392   \n",
              "4      1397.65  14.62  ...  522.58  2388.03  8147.80  8.3869  0.03   392   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "24715  1424.11  14.62  ...  519.66  2388.30  8138.08  8.5036  0.03   394   \n",
              "24716  1429.14  14.62  ...  519.91  2388.28  8144.36  8.5174  0.03   395   \n",
              "24717  1431.41  14.62  ...  519.44  2388.24  8135.95  8.5223  0.03   396   \n",
              "24718  1426.57  14.62  ...  520.01  2388.26  8141.24  8.5148  0.03   395   \n",
              "24719  1436.06  14.62  ...  519.48  2388.24  8136.98  8.5150  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.11  23.3537  \n",
              "1      2388  100.0  38.99  23.4491  \n",
              "2      2388  100.0  38.85  23.3669  \n",
              "3      2388  100.0  38.96  23.2951  \n",
              "4      2388  100.0  39.14  23.4583  \n",
              "...     ...    ...    ...      ...  \n",
              "24715  2388  100.0  38.44  22.9631  \n",
              "24716  2388  100.0  38.50  22.9746  \n",
              "24717  2388  100.0  38.39  23.0682  \n",
              "24718  2388  100.0  38.31  23.0753  \n",
              "24719  2388  100.0  38.56  23.0847  \n",
              "\n",
              "[24720 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.36</td>\n",
              "      <td>1583.23</td>\n",
              "      <td>1396.84</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.31</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>8145.32</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.11</td>\n",
              "      <td>23.3537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.50</td>\n",
              "      <td>1584.69</td>\n",
              "      <td>1396.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8152.85</td>\n",
              "      <td>8.4403</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.18</td>\n",
              "      <td>1582.35</td>\n",
              "      <td>1405.61</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.03</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8150.17</td>\n",
              "      <td>8.3901</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.85</td>\n",
              "      <td>23.3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1585.61</td>\n",
              "      <td>1392.27</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.49</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8146.56</td>\n",
              "      <td>8.3878</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.96</td>\n",
              "      <td>23.2951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.68</td>\n",
              "      <td>1588.63</td>\n",
              "      <td>1397.65</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.58</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8147.80</td>\n",
              "      <td>8.3869</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.14</td>\n",
              "      <td>23.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24715</th>\n",
              "      <td>100</td>\n",
              "      <td>148</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.78</td>\n",
              "      <td>1596.01</td>\n",
              "      <td>1424.11</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.66</td>\n",
              "      <td>2388.30</td>\n",
              "      <td>8138.08</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24716</th>\n",
              "      <td>100</td>\n",
              "      <td>149</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.29</td>\n",
              "      <td>1596.38</td>\n",
              "      <td>1429.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.91</td>\n",
              "      <td>2388.28</td>\n",
              "      <td>8144.36</td>\n",
              "      <td>8.5174</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.50</td>\n",
              "      <td>22.9746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24717</th>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.84</td>\n",
              "      <td>1604.53</td>\n",
              "      <td>1431.41</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.44</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8135.95</td>\n",
              "      <td>8.5223</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.39</td>\n",
              "      <td>23.0682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24718</th>\n",
              "      <td>100</td>\n",
              "      <td>151</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.94</td>\n",
              "      <td>1597.56</td>\n",
              "      <td>1426.57</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8141.24</td>\n",
              "      <td>8.5148</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.31</td>\n",
              "      <td>23.0753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24719</th>\n",
              "      <td>100</td>\n",
              "      <td>152</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.64</td>\n",
              "      <td>1599.04</td>\n",
              "      <td>1436.06</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.48</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8136.98</td>\n",
              "      <td>8.5150</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.56</td>\n",
              "      <td>23.0847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24720 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "4wtvRNsfuUwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacee9ce-2285-4117-b689-e79e02ea49db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16596, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "id": "onw4pCwZy-1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "fa27bb4c-f28a-45d9-91d3-fdb18a6199a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.59  1592.40  1409.87  14.62  21.58  560.53  2388.22  9085.50   \n",
              "1  518.67  642.56  1587.42  1409.69  14.62  21.61  553.33  2388.18  9050.97   \n",
              "2  518.67  642.75  1591.93  1417.66  14.62  21.60  563.61  2388.31  9091.69   \n",
              "3  518.67  642.28  1584.68  1406.56  14.62  21.61  552.75  2388.07  9048.23   \n",
              "4  518.67  642.15  1580.59  1397.26  14.62  21.58  553.82  2387.96  9050.89   \n",
              "\n",
              "    s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0  1.31  ...  528.05  2388.23  8158.77  8.2966  0.03   393  2388  100.0   \n",
              "1  1.30  ...  520.90  2388.17  8128.04  8.4514  0.03   392  2388  100.0   \n",
              "2  1.31  ...  531.36  2388.33  8173.56  8.3057  0.03   395  2388  100.0   \n",
              "3  1.30  ...  521.27  2388.09  8133.78  8.4337  0.03   392  2388  100.0   \n",
              "4  1.30  ...  521.74  2387.96  8132.51  8.3900  0.03   390  2388  100.0   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  39.43  23.5679  \n",
              "1  38.83  23.2821  \n",
              "2  39.27  23.6440  \n",
              "3  38.70  23.3804  \n",
              "4  38.89  23.4463  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.59</td>\n",
              "      <td>1592.40</td>\n",
              "      <td>1409.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.58</td>\n",
              "      <td>560.53</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>9085.50</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>528.05</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8158.77</td>\n",
              "      <td>8.2966</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.43</td>\n",
              "      <td>23.5679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.56</td>\n",
              "      <td>1587.42</td>\n",
              "      <td>1409.69</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.33</td>\n",
              "      <td>2388.18</td>\n",
              "      <td>9050.97</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>520.90</td>\n",
              "      <td>2388.17</td>\n",
              "      <td>8128.04</td>\n",
              "      <td>8.4514</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.83</td>\n",
              "      <td>23.2821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.75</td>\n",
              "      <td>1591.93</td>\n",
              "      <td>1417.66</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.60</td>\n",
              "      <td>563.61</td>\n",
              "      <td>2388.31</td>\n",
              "      <td>9091.69</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>531.36</td>\n",
              "      <td>2388.33</td>\n",
              "      <td>8173.56</td>\n",
              "      <td>8.3057</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.27</td>\n",
              "      <td>23.6440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.28</td>\n",
              "      <td>1584.68</td>\n",
              "      <td>1406.56</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.75</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>9048.23</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>521.27</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8133.78</td>\n",
              "      <td>8.4337</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.70</td>\n",
              "      <td>23.3804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1580.59</td>\n",
              "      <td>1397.26</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.58</td>\n",
              "      <td>553.82</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>9050.89</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>8132.51</td>\n",
              "      <td>8.3900</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.89</td>\n",
              "      <td>23.4463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "id": "lmFKjQaeip1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "3171e3c4-379c-4bdd-a8e1-d282412a7852"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  258\n",
              "1            1     2  257\n",
              "2            1     3  256\n",
              "3            1     4  255\n",
              "4            1     5  254"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "fuAnHn4GxzwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "6e6c04a1-95cc-4be4-9a8c-ccc4ef2dcee3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  258\n",
              "1  257\n",
              "2  256\n",
              "3  255\n",
              "4  254"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "26hK4VWkx1R7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "4f540989-e8a5-4ba5-dc50-06e5556c58c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.36  1583.23  1396.84  14.62  21.61  553.97  2387.96  9062.17   \n",
              "1  518.67  642.50  1584.69  1396.89  14.62  21.61  554.55  2388.00  9061.78   \n",
              "2  518.67  642.18  1582.35  1405.61  14.62  21.61  554.43  2388.03  9070.23   \n",
              "3  518.67  642.92  1585.61  1392.27  14.62  21.61  555.21  2388.00  9064.57   \n",
              "4  518.67  641.68  1588.63  1397.65  14.62  21.61  554.74  2388.04  9076.14   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  522.31  2388.01  8145.32  8.4246  0.03   391  2388  100.0  39.11   \n",
              "1  1.3  ...  522.42  2388.03  8152.85  8.4403  0.03   392  2388  100.0  38.99   \n",
              "2  1.3  ...  522.03  2388.00  8150.17  8.3901  0.03   391  2388  100.0  38.85   \n",
              "3  1.3  ...  522.49  2388.08  8146.56  8.3878  0.03   392  2388  100.0  38.96   \n",
              "4  1.3  ...  522.58  2388.03  8147.80  8.3869  0.03   392  2388  100.0  39.14   \n",
              "\n",
              "      s_20  \n",
              "0  23.3537  \n",
              "1  23.4491  \n",
              "2  23.3669  \n",
              "3  23.2951  \n",
              "4  23.4583  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.36</td>\n",
              "      <td>1583.23</td>\n",
              "      <td>1396.84</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.97</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>9062.17</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.31</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>8145.32</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.11</td>\n",
              "      <td>23.3537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.50</td>\n",
              "      <td>1584.69</td>\n",
              "      <td>1396.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.55</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>9061.78</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8152.85</td>\n",
              "      <td>8.4403</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.18</td>\n",
              "      <td>1582.35</td>\n",
              "      <td>1405.61</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.43</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>9070.23</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.03</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8150.17</td>\n",
              "      <td>8.3901</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.85</td>\n",
              "      <td>23.3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1585.61</td>\n",
              "      <td>1392.27</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>555.21</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>9064.57</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.49</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8146.56</td>\n",
              "      <td>8.3878</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.96</td>\n",
              "      <td>23.2951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.68</td>\n",
              "      <td>1588.63</td>\n",
              "      <td>1397.65</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.74</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9076.14</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.58</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8147.80</td>\n",
              "      <td>8.3869</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.14</td>\n",
              "      <td>23.4583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "0DRGYnNZE8Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=126\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                        #    model__activation2='tanh',\n",
        "                        #    model__dropout2=0.30649418903936865,\n",
        "                           model__layer3=64,\n",
        "                        #    model__activation3='tanh',\n",
        "                        #    model__dropout3=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__second_dense=False,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "esVl2LWkE8Ro"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h LSTM-1\n",
        "# ~1h30min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"basemodel__model__second_dense\": Categorical([False]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        # \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__activation2\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer3\": Integer(16,512),\n",
        "        \"basemodel__model__activation3\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46eb4941-eee4-4224-b6ff-c59790a2e819",
        "id": "NYC7FiqAE8Ro"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=229, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.4312949059884308, basemodel__model__dropout2=0.3807450679193153, basemodel__model__dropout3=0.6916033873523364, basemodel__model__layer1=167, basemodel__model__layer2=337, basemodel__model__layer3=289, basemodel__model__learning_rate=0.0013556548021189216, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.16231298330980526, clip_y=120, scaler=StandardScaler(), seq_length=84;, score=-0.002 total time= 1.3min\n",
            "[CV 2/3] END basemodel__batch_size=229, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.4312949059884308, basemodel__model__dropout2=0.3807450679193153, basemodel__model__dropout3=0.6916033873523364, basemodel__model__layer1=167, basemodel__model__layer2=337, basemodel__model__layer3=289, basemodel__model__learning_rate=0.0013556548021189216, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.16231298330980526, clip_y=120, scaler=StandardScaler(), seq_length=84;, score=0.898 total time= 2.1min\n",
            "[CV 3/3] END basemodel__batch_size=229, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.4312949059884308, basemodel__model__dropout2=0.3807450679193153, basemodel__model__dropout3=0.6916033873523364, basemodel__model__layer1=167, basemodel__model__layer2=337, basemodel__model__layer3=289, basemodel__model__learning_rate=0.0013556548021189216, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.16231298330980526, clip_y=120, scaler=StandardScaler(), seq_length=84;, score=0.908 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=434, basemodel__epochs=44, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.1498503526752572, basemodel__model__dropout2=0.21064683062286016, basemodel__model__dropout3=0.3828699181027345, basemodel__model__layer1=331, basemodel__model__layer2=489, basemodel__model__layer3=328, basemodel__model__learning_rate=0.009923710598637135, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5858567863797266, clip_y=88, scaler=MinMaxScaler(), seq_length=77;, score=-0.002 total time=  60.0s\n",
            "[CV 2/3] END basemodel__batch_size=434, basemodel__epochs=44, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.1498503526752572, basemodel__model__dropout2=0.21064683062286016, basemodel__model__dropout3=0.3828699181027345, basemodel__model__layer1=331, basemodel__model__layer2=489, basemodel__model__layer3=328, basemodel__model__learning_rate=0.009923710598637135, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5858567863797266, clip_y=88, scaler=MinMaxScaler(), seq_length=77;, score=0.215 total time= 2.9min\n",
            "[CV 3/3] END basemodel__batch_size=434, basemodel__epochs=44, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.1498503526752572, basemodel__model__dropout2=0.21064683062286016, basemodel__model__dropout3=0.3828699181027345, basemodel__model__layer1=331, basemodel__model__layer2=489, basemodel__model__layer3=328, basemodel__model__learning_rate=0.009923710598637135, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5858567863797266, clip_y=88, scaler=MinMaxScaler(), seq_length=77;, score=0.159 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=246, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4629322750450392, basemodel__model__dropout2=0.22435844324043466, basemodel__model__dropout3=0.7012420250723972, basemodel__model__layer1=292, basemodel__model__layer2=499, basemodel__model__layer3=365, basemodel__model__learning_rate=0.0038765850056252703, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.45627712334627846, clip_y=102, scaler=StandardScaler(), seq_length=46;, score=0.906 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=246, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4629322750450392, basemodel__model__dropout2=0.22435844324043466, basemodel__model__dropout3=0.7012420250723972, basemodel__model__layer1=292, basemodel__model__layer2=499, basemodel__model__layer3=365, basemodel__model__learning_rate=0.0038765850056252703, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.45627712334627846, clip_y=102, scaler=StandardScaler(), seq_length=46;, score=0.935 total time= 2.8min\n",
            "[CV 3/3] END basemodel__batch_size=246, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4629322750450392, basemodel__model__dropout2=0.22435844324043466, basemodel__model__dropout3=0.7012420250723972, basemodel__model__layer1=292, basemodel__model__layer2=499, basemodel__model__layer3=365, basemodel__model__learning_rate=0.0038765850056252703, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.45627712334627846, clip_y=102, scaler=StandardScaler(), seq_length=46;, score=0.905 total time= 2.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=422, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.17636403137199477, basemodel__model__dropout2=0.7046404262687053, basemodel__model__dropout3=0.7981042826479537, basemodel__model__layer1=468, basemodel__model__layer2=208, basemodel__model__layer3=185, basemodel__model__learning_rate=0.008391548832503206, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8717604725696007, clip_y=107, scaler=MinMaxScaler(), seq_length=34;, score=0.202 total time=  25.6s\n",
            "[CV 2/3] END basemodel__batch_size=422, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.17636403137199477, basemodel__model__dropout2=0.7046404262687053, basemodel__model__dropout3=0.7981042826479537, basemodel__model__layer1=468, basemodel__model__layer2=208, basemodel__model__layer3=185, basemodel__model__learning_rate=0.008391548832503206, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8717604725696007, clip_y=107, scaler=MinMaxScaler(), seq_length=34;, score=0.167 total time=  24.6s\n",
            "[CV 3/3] END basemodel__batch_size=422, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.17636403137199477, basemodel__model__dropout2=0.7046404262687053, basemodel__model__dropout3=0.7981042826479537, basemodel__model__layer1=468, basemodel__model__layer2=208, basemodel__model__layer3=185, basemodel__model__learning_rate=0.008391548832503206, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8717604725696007, clip_y=107, scaler=MinMaxScaler(), seq_length=34;, score=0.141 total time=  23.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=416, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6736249209278695, basemodel__model__dropout2=0.43934245796854565, basemodel__model__dropout3=0.6202272813982102, basemodel__model__layer1=191, basemodel__model__layer2=343, basemodel__model__layer3=270, basemodel__model__learning_rate=0.008835665823899178, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3143091025989634, clip_y=139, scaler=MinMaxScaler(), seq_length=64;, score=-0.001 total time=  35.8s\n",
            "[CV 2/3] END basemodel__batch_size=416, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6736249209278695, basemodel__model__dropout2=0.43934245796854565, basemodel__model__dropout3=0.6202272813982102, basemodel__model__layer1=191, basemodel__model__layer2=343, basemodel__model__layer3=270, basemodel__model__learning_rate=0.008835665823899178, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3143091025989634, clip_y=139, scaler=MinMaxScaler(), seq_length=64;, score=-0.000 total time=  38.4s\n",
            "[CV 3/3] END basemodel__batch_size=416, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6736249209278695, basemodel__model__dropout2=0.43934245796854565, basemodel__model__dropout3=0.6202272813982102, basemodel__model__layer1=191, basemodel__model__layer2=343, basemodel__model__layer3=270, basemodel__model__learning_rate=0.008835665823899178, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3143091025989634, clip_y=139, scaler=MinMaxScaler(), seq_length=64;, score=-0.000 total time=  51.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=384, basemodel__epochs=47, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3980638223866063, basemodel__model__dropout2=0.4672196113206446, basemodel__model__dropout3=0.5278121280969085, basemodel__model__layer1=406, basemodel__model__layer2=292, basemodel__model__layer3=308, basemodel__model__learning_rate=0.005689543694097537, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8745393391925862, clip_y=96, scaler=StandardScaler(), seq_length=96;, score=-0.089 total time= 1.6min\n",
            "[CV 2/3] END basemodel__batch_size=384, basemodel__epochs=47, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3980638223866063, basemodel__model__dropout2=0.4672196113206446, basemodel__model__dropout3=0.5278121280969085, basemodel__model__layer1=406, basemodel__model__layer2=292, basemodel__model__layer3=308, basemodel__model__learning_rate=0.005689543694097537, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8745393391925862, clip_y=96, scaler=StandardScaler(), seq_length=96;, score=-0.053 total time= 1.7min\n",
            "[CV 3/3] END basemodel__batch_size=384, basemodel__epochs=47, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3980638223866063, basemodel__model__dropout2=0.4672196113206446, basemodel__model__dropout3=0.5278121280969085, basemodel__model__layer1=406, basemodel__model__layer2=292, basemodel__model__layer3=308, basemodel__model__learning_rate=0.005689543694097537, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8745393391925862, clip_y=96, scaler=StandardScaler(), seq_length=96;, score=-0.000 total time= 1.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=328, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5756960280694708, basemodel__model__dropout2=0.6190220077629807, basemodel__model__dropout3=0.4376660687605579, basemodel__model__layer1=380, basemodel__model__layer2=331, basemodel__model__layer3=474, basemodel__model__learning_rate=0.006612742297240572, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.47481245138496375, clip_y=129, scaler=MinMaxScaler(), seq_length=58;, score=0.388 total time= 2.2min\n",
            "[CV 2/3] END basemodel__batch_size=328, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5756960280694708, basemodel__model__dropout2=0.6190220077629807, basemodel__model__dropout3=0.4376660687605579, basemodel__model__layer1=380, basemodel__model__layer2=331, basemodel__model__layer3=474, basemodel__model__learning_rate=0.006612742297240572, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.47481245138496375, clip_y=129, scaler=MinMaxScaler(), seq_length=58;, score=0.522 total time= 2.0min\n",
            "[CV 3/3] END basemodel__batch_size=328, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5756960280694708, basemodel__model__dropout2=0.6190220077629807, basemodel__model__dropout3=0.4376660687605579, basemodel__model__layer1=380, basemodel__model__layer2=331, basemodel__model__layer3=474, basemodel__model__learning_rate=0.006612742297240572, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.47481245138496375, clip_y=129, scaler=MinMaxScaler(), seq_length=58;, score=0.268 total time= 1.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=293, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.14090764294164143, basemodel__model__dropout2=0.5566222421431186, basemodel__model__dropout3=0.12064086804281687, basemodel__model__layer1=207, basemodel__model__layer2=426, basemodel__model__layer3=198, basemodel__model__learning_rate=0.005770288608722241, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3195931918414323, clip_y=113, scaler=StandardScaler(), seq_length=33;, score=0.850 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=293, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.14090764294164143, basemodel__model__dropout2=0.5566222421431186, basemodel__model__dropout3=0.12064086804281687, basemodel__model__layer1=207, basemodel__model__layer2=426, basemodel__model__layer3=198, basemodel__model__learning_rate=0.005770288608722241, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3195931918414323, clip_y=113, scaler=StandardScaler(), seq_length=33;, score=0.826 total time= 1.9min\n",
            "[CV 3/3] END basemodel__batch_size=293, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.14090764294164143, basemodel__model__dropout2=0.5566222421431186, basemodel__model__dropout3=0.12064086804281687, basemodel__model__layer1=207, basemodel__model__layer2=426, basemodel__model__layer3=198, basemodel__model__learning_rate=0.005770288608722241, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3195931918414323, clip_y=113, scaler=StandardScaler(), seq_length=33;, score=0.709 total time= 1.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=491, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.269131429819357, basemodel__model__dropout2=0.1000488406021388, basemodel__model__dropout3=0.3965483901301635, basemodel__model__layer1=311, basemodel__model__layer2=103, basemodel__model__layer3=397, basemodel__model__learning_rate=0.004499578015509351, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3941085696997352, clip_y=104, scaler=StandardScaler(), seq_length=97;, score=0.932 total time= 1.4min\n",
            "[CV 2/3] END basemodel__batch_size=491, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.269131429819357, basemodel__model__dropout2=0.1000488406021388, basemodel__model__dropout3=0.3965483901301635, basemodel__model__layer1=311, basemodel__model__layer2=103, basemodel__model__layer3=397, basemodel__model__learning_rate=0.004499578015509351, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3941085696997352, clip_y=104, scaler=StandardScaler(), seq_length=97;, score=0.952 total time= 1.4min\n",
            "[CV 3/3] END basemodel__batch_size=491, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.269131429819357, basemodel__model__dropout2=0.1000488406021388, basemodel__model__dropout3=0.3965483901301635, basemodel__model__layer1=311, basemodel__model__layer2=103, basemodel__model__layer3=397, basemodel__model__learning_rate=0.004499578015509351, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3941085696997352, clip_y=104, scaler=StandardScaler(), seq_length=97;, score=0.935 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=34, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.319771879068334, basemodel__model__dropout2=0.3502714449877026, basemodel__model__dropout3=0.22207566947075547, basemodel__model__layer1=459, basemodel__model__layer2=419, basemodel__model__layer3=390, basemodel__model__learning_rate=0.0002964907893683558, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4619134126084652, clip_y=125, scaler=MinMaxScaler(), seq_length=73;, score=0.916 total time= 4.8min\n",
            "[CV 2/3] END basemodel__batch_size=34, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.319771879068334, basemodel__model__dropout2=0.3502714449877026, basemodel__model__dropout3=0.22207566947075547, basemodel__model__layer1=459, basemodel__model__layer2=419, basemodel__model__layer3=390, basemodel__model__learning_rate=0.0002964907893683558, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4619134126084652, clip_y=125, scaler=MinMaxScaler(), seq_length=73;, score=0.923 total time= 4.7min\n",
            "[CV 3/3] END basemodel__batch_size=34, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.319771879068334, basemodel__model__dropout2=0.3502714449877026, basemodel__model__dropout3=0.22207566947075547, basemodel__model__layer1=459, basemodel__model__layer2=419, basemodel__model__layer3=390, basemodel__model__learning_rate=0.0002964907893683558, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4619134126084652, clip_y=125, scaler=MinMaxScaler(), seq_length=73;, score=0.921 total time= 5.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=389, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2670146050221951, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.36701636911986, basemodel__model__layer1=338, basemodel__model__layer2=123, basemodel__model__layer3=357, basemodel__model__learning_rate=0.0033469590294062453, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3683166695797505, clip_y=109, scaler=StandardScaler(), seq_length=92;, score=0.927 total time= 1.4min\n",
            "[CV 2/3] END basemodel__batch_size=389, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2670146050221951, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.36701636911986, basemodel__model__layer1=338, basemodel__model__layer2=123, basemodel__model__layer3=357, basemodel__model__learning_rate=0.0033469590294062453, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3683166695797505, clip_y=109, scaler=StandardScaler(), seq_length=92;, score=0.953 total time= 1.4min\n",
            "[CV 3/3] END basemodel__batch_size=389, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2670146050221951, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.36701636911986, basemodel__model__layer1=338, basemodel__model__layer2=123, basemodel__model__layer3=357, basemodel__model__learning_rate=0.0033469590294062453, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3683166695797505, clip_y=109, scaler=StandardScaler(), seq_length=92;, score=0.939 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2784317558709969, basemodel__model__dropout2=0.33629730315978534, basemodel__model__dropout3=0.1, basemodel__model__layer1=512, basemodel__model__layer2=445, basemodel__model__layer3=426, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5741296089544387, clip_y=126, scaler=MinMaxScaler(), seq_length=69;, score=0.900 total time= 5.4min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2784317558709969, basemodel__model__dropout2=0.33629730315978534, basemodel__model__dropout3=0.1, basemodel__model__layer1=512, basemodel__model__layer2=445, basemodel__model__layer3=426, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5741296089544387, clip_y=126, scaler=MinMaxScaler(), seq_length=69;, score=0.895 total time= 6.5min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2784317558709969, basemodel__model__dropout2=0.33629730315978534, basemodel__model__dropout3=0.1, basemodel__model__layer1=512, basemodel__model__layer2=445, basemodel__model__layer3=426, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5741296089544387, clip_y=126, scaler=MinMaxScaler(), seq_length=69;, score=0.886 total time= 6.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.10906809395528963, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__layer3=512, basemodel__model__learning_rate=0.005568870652268104, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=105, scaler=MinMaxScaler(), seq_length=100;, score=0.953 total time=  37.0s\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.10906809395528963, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__layer3=512, basemodel__model__learning_rate=0.005568870652268104, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=105, scaler=MinMaxScaler(), seq_length=100;, score=0.924 total time=  36.2s\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.10906809395528963, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__layer3=512, basemodel__model__learning_rate=0.005568870652268104, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=105, scaler=MinMaxScaler(), seq_length=100;, score=0.928 total time=  36.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.37859479466938384, basemodel__model__dropout2=0.3526169944660619, basemodel__model__dropout3=0.35877822410813887, basemodel__model__layer1=479, basemodel__model__layer2=407, basemodel__model__layer3=340, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.2993847440746512, clip_y=125, scaler=MinMaxScaler(), seq_length=77;, score=0.902 total time= 6.9min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.37859479466938384, basemodel__model__dropout2=0.3526169944660619, basemodel__model__dropout3=0.35877822410813887, basemodel__model__layer1=479, basemodel__model__layer2=407, basemodel__model__layer3=340, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.2993847440746512, clip_y=125, scaler=MinMaxScaler(), seq_length=77;, score=0.916 total time= 7.5min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.37859479466938384, basemodel__model__dropout2=0.3526169944660619, basemodel__model__dropout3=0.35877822410813887, basemodel__model__layer1=479, basemodel__model__layer2=407, basemodel__model__layer3=340, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.2993847440746512, clip_y=125, scaler=MinMaxScaler(), seq_length=77;, score=0.921 total time= 7.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=414, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.11369957885947174, basemodel__model__dropout3=0.9, basemodel__model__layer1=512, basemodel__model__layer2=371, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0027369918640646716, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=88, scaler=StandardScaler(), seq_length=97;, score=-4.141 total time=  17.6s\n",
            "[CV 2/3] END basemodel__batch_size=414, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.11369957885947174, basemodel__model__dropout3=0.9, basemodel__model__layer1=512, basemodel__model__layer2=371, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0027369918640646716, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=88, scaler=StandardScaler(), seq_length=97;, score=-4.250 total time=  17.7s\n",
            "[CV 3/3] END basemodel__batch_size=414, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.11369957885947174, basemodel__model__dropout3=0.9, basemodel__model__layer1=512, basemodel__model__layer2=371, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0027369918640646716, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=88, scaler=StandardScaler(), seq_length=97;, score=-4.207 total time=  17.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "WARNING:tensorflow:5 out of the last 9799 calls to <function Model.make_train_function.<locals>.train_function at 0x00000187F3642430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, scaler=StandardScaler(), seq_length=100;, score=0.510 total time= 7.9min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, scaler=StandardScaler(), seq_length=100;, score=0.805 total time= 8.1min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, scaler=StandardScaler(), seq_length=100;, score=0.308 total time= 8.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.2903967124769285, basemodel__model__dropout2=0.1205166040817387, basemodel__model__dropout3=0.9, basemodel__model__layer1=21, basemodel__model__layer2=512, basemodel__model__layer3=399, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=99, scaler=StandardScaler(), seq_length=30;, score=0.904 total time= 7.6min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.2903967124769285, basemodel__model__dropout2=0.1205166040817387, basemodel__model__dropout3=0.9, basemodel__model__layer1=21, basemodel__model__layer2=512, basemodel__model__layer3=399, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=99, scaler=StandardScaler(), seq_length=30;, score=0.918 total time= 7.8min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.2903967124769285, basemodel__model__dropout2=0.1205166040817387, basemodel__model__dropout3=0.9, basemodel__model__layer1=21, basemodel__model__layer2=512, basemodel__model__layer3=399, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=99, scaler=StandardScaler(), seq_length=30;, score=0.890 total time= 7.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=274, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.14038150471990501, basemodel__model__dropout2=0.12123369961697092, basemodel__model__dropout3=0.4797693945100455, basemodel__model__layer1=264, basemodel__model__layer2=78, basemodel__model__layer3=348, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.16440695796711308, clip_y=100, scaler=StandardScaler(), seq_length=100;, score=0.940 total time= 1.7min\n",
            "[CV 2/3] END basemodel__batch_size=274, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.14038150471990501, basemodel__model__dropout2=0.12123369961697092, basemodel__model__dropout3=0.4797693945100455, basemodel__model__layer1=264, basemodel__model__layer2=78, basemodel__model__layer3=348, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.16440695796711308, clip_y=100, scaler=StandardScaler(), seq_length=100;, score=0.948 total time= 1.7min\n",
            "[CV 3/3] END basemodel__batch_size=274, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.14038150471990501, basemodel__model__dropout2=0.12123369961697092, basemodel__model__dropout3=0.4797693945100455, basemodel__model__layer1=264, basemodel__model__layer2=78, basemodel__model__layer3=348, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.16440695796711308, clip_y=100, scaler=StandardScaler(), seq_length=100;, score=0.920 total time= 1.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=325, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.27757892223900893, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.4354575777156703, basemodel__model__layer1=309, basemodel__model__layer2=209, basemodel__model__layer3=368, basemodel__model__learning_rate=0.0025015411421478242, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.30558915072721615, clip_y=110, scaler=StandardScaler(), seq_length=79;, score=0.940 total time= 1.8min\n",
            "[CV 2/3] END basemodel__batch_size=325, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.27757892223900893, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.4354575777156703, basemodel__model__layer1=309, basemodel__model__layer2=209, basemodel__model__layer3=368, basemodel__model__learning_rate=0.0025015411421478242, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.30558915072721615, clip_y=110, scaler=StandardScaler(), seq_length=79;, score=0.945 total time= 1.8min\n",
            "[CV 3/3] END basemodel__batch_size=325, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.27757892223900893, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.4354575777156703, basemodel__model__layer1=309, basemodel__model__layer2=209, basemodel__model__layer3=368, basemodel__model__learning_rate=0.0025015411421478242, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.30558915072721615, clip_y=110, scaler=StandardScaler(), seq_length=79;, score=0.923 total time= 1.8min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.10000000000000005, basemodel__model__dropout3=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__layer3=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=30;, score=-0.004 total time=  15.7s\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.10000000000000005, basemodel__model__dropout3=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__layer3=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=30;, score=-0.001 total time=  16.7s\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.10000000000000005, basemodel__model__dropout3=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__layer3=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=30;, score=-0.001 total time=  17.0s\n",
            "Finished: 2022-10-24 10:06:07.886202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "h22vRW-9E8Rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6eea2ac-78f3-4546-982b-a64017385c62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9399516883374335\n",
            "OrderedDict([('basemodel__batch_size', 491), ('basemodel__epochs', 35), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'tanh'), ('basemodel__model__activation3', 'selu'), ('basemodel__model__dropout1', 0.269131429819357), ('basemodel__model__dropout2', 0.1000488406021388), ('basemodel__model__dropout3', 0.3965483901301635), ('basemodel__model__layer1', 311), ('basemodel__model__layer2', 103), ('basemodel__model__layer3', 397), ('basemodel__model__learning_rate', 0.004499578015509351), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__model__second_dense', False), ('basemodel__validation_split', 0.3941085696997352), ('clip_y', 104), ('scaler', StandardScaler()), ('seq_length', 97)])\n",
            "Finished: 2022-10-24 10:06:07.893176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "QN2L5lVTE8Rq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "4f527075-afef-49dc-e866-d29d1ac2b183"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-24 10:06:08.137639\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "id": "-fETrk6iE8Rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1151ced-2df7-4fcd-a293-3f808ce3d358"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 491),\n",
              "             ('basemodel__epochs', 35),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'tanh'),\n",
              "             ('basemodel__model__activation3', 'selu'),\n",
              "             ('basemodel__model__dropout1', 0.269131429819357),\n",
              "             ('basemodel__model__dropout2', 0.1000488406021388),\n",
              "             ('basemodel__model__dropout3', 0.3965483901301635),\n",
              "             ('basemodel__model__layer1', 311),\n",
              "             ('basemodel__model__layer2', 103),\n",
              "             ('basemodel__model__layer3', 397),\n",
              "             ('basemodel__model__learning_rate', 0.004499578015509351),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__model__second_dense', False),\n",
              "             ('basemodel__validation_split', 0.3941085696997352),\n",
              "             ('clip_y', 104),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 97)])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer \n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7960749287247998  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 53),\n",
        "             ('basemodel__epochs', 40),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.2519865793617908),\n",
        "             ('basemodel__model__layer1', 254),\n",
        "             ('basemodel__model__learning_rate', 0.0026310480233180064),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.268645350331565),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 96)\n",
        "```\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.9405557989097725  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 320),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__layer1', 171),\n",
        "             ('basemodel__model__learning_rate', 0.003956355423514566),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.1402058641858904),\n",
        "             ('clip_y', 81),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 65)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ESr-SWV1Dy3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1 \n"
      ],
      "metadata": {
        "id": "zSnh2UONQb4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7565845071829033  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 83),\n",
        "             ('basemodel__epochs', 31),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.24854411808808108),\n",
        "             ('basemodel__model__dropout2', 0.42830600210145653),\n",
        "             ('basemodel__model__layer1', 220),\n",
        "             ('basemodel__model__layer2', 164),\n",
        "             ('basemodel__model__learning_rate', 0.001141928043462988),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.23166030850146868),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 73)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vL2GlZ8KQb4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.888684501987752  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 118),\n",
        "             ('basemodel__epochs', 30),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.8430541193967747),\n",
        "             ('basemodel__model__dropout2', 0.5945240280760793),\n",
        "             ('basemodel__model__layer1', 162),\n",
        "             ('basemodel__model__layer2', 142),\n",
        "             ('basemodel__model__learning_rate', 0.002503870405609483),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.6441614026771669),\n",
        "             ('clip_y', 83),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 86)\n",
        "```\n"
      ],
      "metadata": {
        "id": "B3F5zD55D9Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2\n"
      ],
      "metadata": {
        "id": "Jygcz0fjrzEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.6493310087734959  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 199),\n",
        "             ('basemodel__epochs', 35),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.25434586961869254),\n",
        "             ('basemodel__model__dropout2', 0.16002400441910994),\n",
        "             ('basemodel__model__dropout3', 0.35413824342558264),\n",
        "             ('basemodel__model__layer1', 425),\n",
        "             ('basemodel__model__layer2', 66),\n",
        "             ('basemodel__model__layer3', 470),\n",
        "             ('basemodel__model__learning_rate', 0.0032857714954219377),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.26624246496701254),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 81)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ywnov-HvrzEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.9051346719630059  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 123),\n",
        "             ('basemodel__epochs', 33),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__dropout2', 0.5621274317662914),\n",
        "             ('basemodel__model__dropout3', 0.20153570533706447),\n",
        "             ('basemodel__model__layer1', 497),\n",
        "             ('basemodel__model__layer2', 256),\n",
        "             ('basemodel__model__layer3', 485),\n",
        "             ('basemodel__model__learning_rate', 0.00056680506717284),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.6912604506849247),\n",
        "             ('clip_y', 88),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 61)\n",
        "```\n"
      ],
      "metadata": {
        "id": "W98etTHQrzEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense\n"
      ],
      "metadata": {
        "id": "z2vaL6nDDYF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.8175456691305407  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.9),\n",
        "             ('basemodel__model__dropout2', 0.4884546283869159),\n",
        "             ('basemodel__model__dropout3', 0.1),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 41),\n",
        "             ('basemodel__model__layer3', 154),\n",
        "             ('basemodel__model__learning_rate', 0.0001),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 100)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YD0XcCDuDYF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL \n",
        "Score: 0.9399516883374335  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 491),\n",
        "             ('basemodel__epochs', 35),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.269131429819357),\n",
        "             ('basemodel__model__dropout2', 0.1000488406021388),\n",
        "             ('basemodel__model__dropout3', 0.3965483901301635),\n",
        "             ('basemodel__model__layer1', 311),\n",
        "             ('basemodel__model__layer2', 103),\n",
        "             ('basemodel__model__layer3', 397),\n",
        "             ('basemodel__model__learning_rate', 0.004499578015509351),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.3941085696997352),\n",
        "             ('clip_y', 104),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 97)\n",
        "```\n"
      ],
      "metadata": {
        "id": "L5Sg97mcDYF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "outputId": "10771aed-b881-4a8f-84bc-279c86183fd4",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-58-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# Data checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfeature_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_build_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: create_model() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QFBtaiz2Ckgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           \n",
        "                           \n",
        "                           model__layer1=512, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer2=400,\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "\n",
        "                        \n",
        "                           \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_36P-gmRD6QM",
        "outputId": "04f7f7d7-28d1-40ba-97ee-4fd9aa120787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_65 (Masking)        (None, 79, 22)            0         \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 400)               205200    \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 400)               0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301,281\n",
            "Trainable params: 1,301,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=288.566, rmse=16.987, r2=0.735; v_loss=171.738, v_rmse=13.105, v_r2=0.847; \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-62-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         self._fit_keras_model(\n\u001b[0m\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m   1222\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "83699a7e-1744-455e-c836-906b8dc33bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.918,RMSE=-9.668\n",
            "Finished: 2022-10-13 13:15:58.111062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee8uwFhF-E6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}