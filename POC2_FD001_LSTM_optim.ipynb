{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "Q4QwyfhXs_hv",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf",
        "fQA-YtFMM81M",
        "nTPBH5fg_sFd",
        "t18eQ8H3EfGV"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN49RA83xPWY3A7cWS3HiR9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_LSTM_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "b7d64306-5e66-463c-fe5e-2b16b0c00605"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.9.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (5.0.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 26.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlp572nXopEO",
        "outputId": "ede0c1fe-6412-4b6e-8530-f5fe89ed4326"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "354bca06-5861-4f9f-fb9a-70bfe39488d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50352526-7067-4370-b04c-7c204808848b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50352526-7067-4370-b04c-7c204808848b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50352526-7067-4370-b04c-7c204808848b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50352526-7067-4370-b04c-7c204808848b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "5a1e3107-bbfd-4e48-abd9-567242f74a3e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "onw4pCwZy-1s",
        "outputId": "e5f65d71-701b-4d82-869b-e3d64f121cc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19b03868-ac39-4128-9baa-5ab181d92b40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19b03868-ac39-4128-9baa-5ab181d92b40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19b03868-ac39-4128-9baa-5ab181d92b40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19b03868-ac39-4128-9baa-5ab181d92b40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "lmFKjQaeip1b",
        "outputId": "dd91f0ca-2247-4817-f687-f24fea1569ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea1b5e4b-51ee-4ac9-b30f-9a5fe31a8711\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea1b5e4b-51ee-4ac9-b30f-9a5fe31a8711')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea1b5e4b-51ee-4ac9-b30f-9a5fe31a8711 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea1b5e4b-51ee-4ac9-b30f-9a5fe31a8711');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "5438be71-8aa5-40ab-944d-bd22076195b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d4426c4-03e6-4a24-babf-a819a0a4b03e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d4426c4-03e6-4a24-babf-a819a0a4b03e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d4426c4-03e6-4a24-babf-a819a0a4b03e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d4426c4-03e6-4a24-babf-a819a0a4b03e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "26hK4VWkx1R7",
        "outputId": "8e360fea-6cba-4a18-c06e-3a3598ecd6a4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cc38f23-3acc-4a0e-b2ec-e8972c979eac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cc38f23-3acc-4a0e-b2ec-e8972c979eac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cc38f23-3acc-4a0e-b2ec-e8972c979eac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cc38f23-3acc-4a0e-b2ec-e8972c979eac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "t18eQ8H3EfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "Ex7mZbQNEfGW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "SPE41-R2EfGX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "a2kynIDbEfGZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_cols = [index_cols[1]]+sensors_cols\n",
        "SEQ_COLS = seq_cols"
      ],
      "metadata": {
        "id": "BAfnrm9Hwnua"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_SEQ_COLS = [index_cols[1]]+sensors_cols"
      ],
      "metadata": {
        "id": "NglteguEMJFm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    # LSTM layer\n",
        "    model.add(LSTM(layer1, activation=activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # Additional LSTM layers\n",
        "    if(layer2 is not None):\n",
        "        model.add(LSTM(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        if (layer3 is not None):\n",
        "            model.add(LSTM(layer3, activation=activation))\n",
        "            model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "Jowfppg9HG3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=135\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "cxz0nz9mHJ2v"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~3h\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([1,2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__model__activation\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "        \"basemodel__model__dropout\": Real(0.1,0.9),\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        # \"basemodel__model__layer2\": Integer(16,512),\n",
        "        # \"basemodel__model__layer3\": Integer(16,512)\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, verbose=3, n_jobs=1,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI-MbGPrHsB0",
        "outputId": "6b643664-1bc0-4544-e2f6-3e57da974fbf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=337, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.11033303670431432, basemodel__model__layer1=145, basemodel__model__learning_rate=0.004549649830092163, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.20207154249632364, clip_y=103, scaler=StandardScaler(), seq_length=58;, score=0.919 total time=  26.0s\n",
            "[CV 2/3] END basemodel__batch_size=337, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.11033303670431432, basemodel__model__layer1=145, basemodel__model__learning_rate=0.004549649830092163, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.20207154249632364, clip_y=103, scaler=StandardScaler(), seq_length=58;, score=0.907 total time=  27.3s\n",
            "[CV 3/3] END basemodel__batch_size=337, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.11033303670431432, basemodel__model__layer1=145, basemodel__model__learning_rate=0.004549649830092163, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.20207154249632364, clip_y=103, scaler=StandardScaler(), seq_length=58;, score=0.916 total time=  26.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=268, basemodel__epochs=7, basemodel__model__activation=tanh, basemodel__model__dropout=0.1319925861024741, basemodel__model__layer1=387, basemodel__model__learning_rate=0.009076825769855775, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8480475230773895, clip_y=85, scaler=MinMaxScaler(), seq_length=48;, score=0.188 total time=  16.2s\n",
            "[CV 2/3] END basemodel__batch_size=268, basemodel__epochs=7, basemodel__model__activation=tanh, basemodel__model__dropout=0.1319925861024741, basemodel__model__layer1=387, basemodel__model__learning_rate=0.009076825769855775, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8480475230773895, clip_y=85, scaler=MinMaxScaler(), seq_length=48;, score=0.236 total time=  11.3s\n",
            "[CV 3/3] END basemodel__batch_size=268, basemodel__epochs=7, basemodel__model__activation=tanh, basemodel__model__dropout=0.1319925861024741, basemodel__model__layer1=387, basemodel__model__learning_rate=0.009076825769855775, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8480475230773895, clip_y=85, scaler=MinMaxScaler(), seq_length=48;, score=0.392 total time=  11.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=298, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.17804690883386365, basemodel__model__layer1=351, basemodel__model__learning_rate=0.008313367125353617, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.25499203198477116, clip_y=138, scaler=MinMaxScaler(), seq_length=74;, score=-0.016 total time=  11.4s\n",
            "[CV 2/3] END basemodel__batch_size=298, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.17804690883386365, basemodel__model__layer1=351, basemodel__model__learning_rate=0.008313367125353617, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.25499203198477116, clip_y=138, scaler=MinMaxScaler(), seq_length=74;, score=0.001 total time=  11.3s\n",
            "[CV 3/3] END basemodel__batch_size=298, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.17804690883386365, basemodel__model__layer1=351, basemodel__model__learning_rate=0.008313367125353617, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.25499203198477116, clip_y=138, scaler=MinMaxScaler(), seq_length=74;, score=0.004 total time=  10.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=292, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.4824940369648728, basemodel__model__layer1=424, basemodel__model__learning_rate=0.0038858780995957264, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3682135421475964, clip_y=140, scaler=MinMaxScaler(), seq_length=65;, score=0.895 total time=  56.6s\n",
            "[CV 2/3] END basemodel__batch_size=292, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.4824940369648728, basemodel__model__layer1=424, basemodel__model__learning_rate=0.0038858780995957264, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3682135421475964, clip_y=140, scaler=MinMaxScaler(), seq_length=65;, score=0.837 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=292, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.4824940369648728, basemodel__model__layer1=424, basemodel__model__learning_rate=0.0038858780995957264, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3682135421475964, clip_y=140, scaler=MinMaxScaler(), seq_length=65;, score=0.756 total time=  56.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=377, basemodel__epochs=20, basemodel__model__activation=tanh, basemodel__model__dropout=0.4339055075427346, basemodel__model__layer1=495, basemodel__model__learning_rate=0.007470307552003795, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8545279771111064, clip_y=116, scaler=StandardScaler(), seq_length=74;, score=0.632 total time=  24.6s\n",
            "[CV 2/3] END basemodel__batch_size=377, basemodel__epochs=20, basemodel__model__activation=tanh, basemodel__model__dropout=0.4339055075427346, basemodel__model__layer1=495, basemodel__model__learning_rate=0.007470307552003795, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8545279771111064, clip_y=116, scaler=StandardScaler(), seq_length=74;, score=0.710 total time=  24.5s\n",
            "[CV 3/3] END basemodel__batch_size=377, basemodel__epochs=20, basemodel__model__activation=tanh, basemodel__model__dropout=0.4339055075427346, basemodel__model__layer1=495, basemodel__model__learning_rate=0.007470307552003795, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8545279771111064, clip_y=116, scaler=StandardScaler(), seq_length=74;, score=0.522 total time=  27.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=74, basemodel__epochs=27, basemodel__model__activation=tanh, basemodel__model__dropout=0.20735476545564197, basemodel__model__layer1=304, basemodel__model__learning_rate=0.003368193925588218, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.6601339640486347, clip_y=86, scaler=MinMaxScaler(), seq_length=79;, score=0.712 total time=  47.7s\n",
            "[CV 2/3] END basemodel__batch_size=74, basemodel__epochs=27, basemodel__model__activation=tanh, basemodel__model__dropout=0.20735476545564197, basemodel__model__layer1=304, basemodel__model__learning_rate=0.003368193925588218, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.6601339640486347, clip_y=86, scaler=MinMaxScaler(), seq_length=79;, score=0.877 total time=  36.4s\n",
            "[CV 3/3] END basemodel__batch_size=74, basemodel__epochs=27, basemodel__model__activation=tanh, basemodel__model__dropout=0.20735476545564197, basemodel__model__layer1=304, basemodel__model__learning_rate=0.003368193925588218, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.6601339640486347, clip_y=86, scaler=MinMaxScaler(), seq_length=79;, score=0.713 total time=  48.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=368, basemodel__epochs=44, basemodel__model__activation=tanh, basemodel__model__dropout=0.7394367207851371, basemodel__model__layer1=262, basemodel__model__learning_rate=0.001993991232834018, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.33152506246146723, clip_y=126, scaler=MinMaxScaler(), seq_length=32;, score=0.805 total time=  27.8s\n",
            "[CV 2/3] END basemodel__batch_size=368, basemodel__epochs=44, basemodel__model__activation=tanh, basemodel__model__dropout=0.7394367207851371, basemodel__model__layer1=262, basemodel__model__learning_rate=0.001993991232834018, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.33152506246146723, clip_y=126, scaler=MinMaxScaler(), seq_length=32;, score=0.840 total time=  47.6s\n",
            "[CV 3/3] END basemodel__batch_size=368, basemodel__epochs=44, basemodel__model__activation=tanh, basemodel__model__dropout=0.7394367207851371, basemodel__model__layer1=262, basemodel__model__learning_rate=0.001993991232834018, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.33152506246146723, clip_y=126, scaler=MinMaxScaler(), seq_length=32;, score=0.734 total time=  27.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=266, basemodel__epochs=23, basemodel__model__activation=tanh, basemodel__model__dropout=0.7832641745833667, basemodel__model__layer1=438, basemodel__model__learning_rate=0.0015502558637825975, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2280751038600814, clip_y=90, scaler=MinMaxScaler(), seq_length=71;, score=0.802 total time=  47.8s\n",
            "[CV 2/3] END basemodel__batch_size=266, basemodel__epochs=23, basemodel__model__activation=tanh, basemodel__model__dropout=0.7832641745833667, basemodel__model__layer1=438, basemodel__model__learning_rate=0.0015502558637825975, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2280751038600814, clip_y=90, scaler=MinMaxScaler(), seq_length=71;, score=0.766 total time=  48.1s\n",
            "[CV 3/3] END basemodel__batch_size=266, basemodel__epochs=23, basemodel__model__activation=tanh, basemodel__model__dropout=0.7832641745833667, basemodel__model__layer1=438, basemodel__model__learning_rate=0.0015502558637825975, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2280751038600814, clip_y=90, scaler=MinMaxScaler(), seq_length=71;, score=0.393 total time=  47.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=315, basemodel__epochs=24, basemodel__model__activation=tanh, basemodel__model__dropout=0.34655159702210536, basemodel__model__layer1=219, basemodel__model__learning_rate=0.005211201095160258, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.7212007708649436, clip_y=115, scaler=MinMaxScaler(), seq_length=95;, score=-0.008 total time=  17.2s\n",
            "[CV 2/3] END basemodel__batch_size=315, basemodel__epochs=24, basemodel__model__activation=tanh, basemodel__model__dropout=0.34655159702210536, basemodel__model__layer1=219, basemodel__model__learning_rate=0.005211201095160258, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.7212007708649436, clip_y=115, scaler=MinMaxScaler(), seq_length=95;, score=0.085 total time=  27.0s\n",
            "[CV 3/3] END basemodel__batch_size=315, basemodel__epochs=24, basemodel__model__activation=tanh, basemodel__model__dropout=0.34655159702210536, basemodel__model__layer1=219, basemodel__model__learning_rate=0.005211201095160258, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.7212007708649436, clip_y=115, scaler=MinMaxScaler(), seq_length=95;, score=0.055 total time=  26.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=40, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.4694995164949902, basemodel__model__layer1=279, basemodel__model__learning_rate=0.0014698501278068929, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2912996626921576, clip_y=109, scaler=MinMaxScaler(), seq_length=38;, score=0.531 total time=  12.0s\n",
            "[CV 2/3] END basemodel__batch_size=40, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.4694995164949902, basemodel__model__layer1=279, basemodel__model__learning_rate=0.0014698501278068929, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2912996626921576, clip_y=109, scaler=MinMaxScaler(), seq_length=38;, score=0.506 total time=  12.7s\n",
            "[CV 3/3] END basemodel__batch_size=40, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.4694995164949902, basemodel__model__layer1=279, basemodel__model__learning_rate=0.0014698501278068929, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2912996626921576, clip_y=109, scaler=MinMaxScaler(), seq_length=38;, score=0.568 total time=  16.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=250, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=94, basemodel__model__learning_rate=0.005660421686236487, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.29645866032893003, clip_y=92, scaler=StandardScaler(), seq_length=73;, score=0.930 total time=  25.2s\n",
            "[CV 2/3] END basemodel__batch_size=250, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=94, basemodel__model__learning_rate=0.005660421686236487, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.29645866032893003, clip_y=92, scaler=StandardScaler(), seq_length=73;, score=0.922 total time=  24.6s\n",
            "[CV 3/3] END basemodel__batch_size=250, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=94, basemodel__model__learning_rate=0.005660421686236487, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.29645866032893003, clip_y=92, scaler=StandardScaler(), seq_length=73;, score=0.894 total time=  26.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.20881940602976956, basemodel__model__layer1=16, basemodel__model__learning_rate=0.009675630521205496, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8432221361539157, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.778 total time=  57.3s\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.20881940602976956, basemodel__model__layer1=16, basemodel__model__learning_rate=0.009675630521205496, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8432221361539157, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.524 total time=  52.9s\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.20881940602976956, basemodel__model__layer1=16, basemodel__model__learning_rate=0.009675630521205496, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8432221361539157, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.744 total time=  37.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=229, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=178, basemodel__model__learning_rate=0.005039502455208682, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.21302363367210556, clip_y=90, scaler=StandardScaler(), seq_length=90;, score=0.887 total time=  33.5s\n",
            "[CV 2/3] END basemodel__batch_size=229, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=178, basemodel__model__learning_rate=0.005039502455208682, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.21302363367210556, clip_y=90, scaler=StandardScaler(), seq_length=90;, score=0.954 total time=  33.7s\n",
            "[CV 3/3] END basemodel__batch_size=229, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=178, basemodel__model__learning_rate=0.005039502455208682, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.21302363367210556, clip_y=90, scaler=StandardScaler(), seq_length=90;, score=0.947 total time=  46.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=45, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.7139639654276233, basemodel__model__layer1=319, basemodel__model__learning_rate=0.004879196386397446, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8334986593889752, clip_y=87, scaler=MinMaxScaler(), seq_length=100;, score=0.698 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=45, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.7139639654276233, basemodel__model__layer1=319, basemodel__model__learning_rate=0.004879196386397446, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8334986593889752, clip_y=87, scaler=MinMaxScaler(), seq_length=100;, score=0.285 total time=  38.8s\n",
            "[CV 3/3] END basemodel__batch_size=45, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.7139639654276233, basemodel__model__layer1=319, basemodel__model__learning_rate=0.004879196386397446, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8334986593889752, clip_y=87, scaler=MinMaxScaler(), seq_length=100;, score=0.047 total time= 1.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.10345185676563456, basemodel__model__layer1=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.941 total time= 1.6min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.10345185676563456, basemodel__model__layer1=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.940 total time= 2.5min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.10345185676563456, basemodel__model__layer1=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.910 total time=  43.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.227 total time= 2.5min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=-0.001 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.002 total time= 2.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=490, basemodel__epochs=40, basemodel__model__activation=tanh, basemodel__model__dropout=0.7494651604032851, basemodel__model__layer1=349, basemodel__model__learning_rate=0.0009512427520844479, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.25974518257445584, clip_y=123, scaler=MinMaxScaler(), seq_length=63;, score=0.753 total time=  47.7s\n",
            "[CV 2/3] END basemodel__batch_size=490, basemodel__epochs=40, basemodel__model__activation=tanh, basemodel__model__dropout=0.7494651604032851, basemodel__model__layer1=349, basemodel__model__learning_rate=0.0009512427520844479, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.25974518257445584, clip_y=123, scaler=MinMaxScaler(), seq_length=63;, score=0.549 total time=  47.8s\n",
            "[CV 3/3] END basemodel__batch_size=490, basemodel__epochs=40, basemodel__model__activation=tanh, basemodel__model__dropout=0.7494651604032851, basemodel__model__layer1=349, basemodel__model__learning_rate=0.0009512427520844479, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.25974518257445584, clip_y=123, scaler=MinMaxScaler(), seq_length=63;, score=0.662 total time=  39.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=105, scaler=MinMaxScaler(), seq_length=68;, score=0.943 total time= 3.5min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=105, scaler=MinMaxScaler(), seq_length=68;, score=0.943 total time= 2.1min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=105, scaler=MinMaxScaler(), seq_length=68;, score=0.943 total time= 3.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=283, basemodel__epochs=45, basemodel__model__activation=tanh, basemodel__model__dropout=0.37248928783223867, basemodel__model__layer1=403, basemodel__model__learning_rate=0.0024170953011910614, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=108, scaler=MinMaxScaler(), seq_length=45;, score=0.892 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=283, basemodel__epochs=45, basemodel__model__activation=tanh, basemodel__model__dropout=0.37248928783223867, basemodel__model__layer1=403, basemodel__model__learning_rate=0.0024170953011910614, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=108, scaler=MinMaxScaler(), seq_length=45;, score=0.912 total time=  53.7s\n",
            "[CV 3/3] END basemodel__batch_size=283, basemodel__epochs=45, basemodel__model__activation=tanh, basemodel__model__dropout=0.37248928783223867, basemodel__model__layer1=403, basemodel__model__learning_rate=0.0024170953011910614, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=108, scaler=MinMaxScaler(), seq_length=45;, score=0.890 total time= 1.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=352, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=325, basemodel__model__learning_rate=0.00154969400346632, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=125, scaler=StandardScaler(), seq_length=84;, score=0.907 total time=  53.5s\n",
            "[CV 2/3] END basemodel__batch_size=352, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=325, basemodel__model__learning_rate=0.00154969400346632, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=125, scaler=StandardScaler(), seq_length=84;, score=0.938 total time=  52.5s\n",
            "[CV 3/3] END basemodel__batch_size=352, basemodel__epochs=49, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=325, basemodel__model__learning_rate=0.00154969400346632, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=125, scaler=StandardScaler(), seq_length=84;, score=0.882 total time=  52.5s\n",
            "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f21449b0550>], epochs=50, model=<function create_model at 0x7f21b1128440>, model__activation='tanh', model__dropout=0.1, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f2147586d50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f21361ce6d0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=False, validation_split=0.1, verbose=0),\n",
            "                     clip_y=105, scaler=MinMaxScaler(), seq_length=68)\n",
            "Finished: 2022-10-10 12:32:43.322518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SSmZxJKlUNFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35d61da-195a-47b0-bb1b-469adc7b79f2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f21449b0550>], epochs=50, model=<function create_model at 0x7f21b1128440>, model__activation='tanh', model__dropout=0.1, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f2147586d50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f21361ce6d0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=False, validation_split=0.1, verbose=0),\n",
            "                     clip_y=105, scaler=MinMaxScaler(), seq_length=68)\n",
            "0.9430289602358563\n",
            "OrderedDict([('basemodel__batch_size', 32), ('basemodel__epochs', 50), ('basemodel__model__activation', 'tanh'), ('basemodel__model__dropout', 0.1), ('basemodel__model__layer1', 512), ('basemodel__model__learning_rate', 0.0001), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__validation_split', 0.1), ('clip_y', 105), ('scaler', MinMaxScaler()), ('seq_length', 68)])\n",
            "Finished: 2022-10-10 12:32:55.561581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "0HUnMESRVitn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "309d32ee-2b80-4e33-cce1-2fae018ad663"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-10 12:32:59.508007\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8QiZ9pWmSb0",
        "outputId": "118c82da-c29e-444e-83ff-e9e068b58978"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 32),\n",
              "             ('basemodel__epochs', 50),\n",
              "             ('basemodel__model__activation', 'tanh'),\n",
              "             ('basemodel__model__dropout', 0.1),\n",
              "             ('basemodel__model__layer1', 512),\n",
              "             ('basemodel__model__learning_rate', 0.0001),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__validation_split', 0.1),\n",
              "             ('clip_y', 105),\n",
              "             ('scaler', MinMaxScaler()),\n",
              "             ('seq_length', 68)])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer\n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7965826139501325  \n",
        "Test: 0.706\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.10771222326909816),\n",
        "('basemodel__model__layer1', 505),\n",
        "('basemodel__model__learning_rate', 0.0032806529941975817),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 70)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.9430289602358563  \n",
        "Test: 0.857\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 105),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 68)\n",
        "```\n",
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.  \n",
        "Test: 0.\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.  \n",
        "Test: 0.\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c328dea-1974-4b93-9966-69c39d8fcbcd",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_123\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_123 (Masking)       (None, 68, 22)            0         \n",
            "                                                                 \n",
            " lstm_123 (LSTM)             (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_123 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,096,193\n",
            "Trainable params: 1,096,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3093.311, rmse=55.618, r2=-1.509; v_loss=2320.318, v_rmse=48.170, v_r2=-0.858; \n",
            "E 2\t: loss=1687.357, rmse=41.077, r2=-0.368; v_loss=1733.833, v_rmse=41.639, v_r2=-0.389; \n",
            "E 3\t: loss=1225.183, rmse=35.003, r2=0.006; v_loss=1506.114, v_rmse=38.809, v_r2=-0.206; \n",
            "E 4\t: loss=971.241, rmse=31.165, r2=0.212; v_loss=1341.068, v_rmse=36.621, v_r2=-0.074; \n",
            "E 5\t: loss=753.771, rmse=27.455, r2=0.389; v_loss=1110.392, v_rmse=33.323, v_r2=0.111; \n",
            "E 6\t: loss=503.171, rmse=22.431, r2=0.592; v_loss=723.938, v_rmse=26.906, v_r2=0.420; \n",
            "E 7\t: loss=318.956, rmse=17.859, r2=0.741; v_loss=368.611, v_rmse=19.199, v_r2=0.705; \n",
            "E 8\t: loss=245.013, rmse=15.653, r2=0.801; v_loss=303.443, v_rmse=17.420, v_r2=0.757; \n",
            "E 9\t: loss=169.560, rmse=13.022, r2=0.862; v_loss=161.770, v_rmse=12.719, v_r2=0.870; \n",
            "E 10\t: loss=136.067, rmse=11.665, r2=0.890; v_loss=190.953, v_rmse=13.819, v_r2=0.847; \n",
            "E 11\t: loss=113.465, rmse=10.652, r2=0.908; v_loss=110.131, v_rmse=10.494, v_r2=0.912; \n",
            "E 12\t: loss=94.913, rmse=9.742, r2=0.923; v_loss=94.722, v_rmse=9.733, v_r2=0.924; \n",
            "E 13\t: loss=78.853, rmse=8.880, r2=0.936; v_loss=86.811, v_rmse=9.317, v_r2=0.930; \n",
            "E 14\t: loss=75.178, rmse=8.671, r2=0.939; v_loss=67.101, v_rmse=8.191, v_r2=0.946; \n",
            "E 15\t: loss=74.498, rmse=8.631, r2=0.940; v_loss=61.738, v_rmse=7.857, v_r2=0.951; \n",
            "E 16\t: loss=66.403, rmse=8.149, r2=0.946; v_loss=68.740, v_rmse=8.291, v_r2=0.945; \n",
            "E 17\t: loss=66.094, rmse=8.130, r2=0.946; v_loss=78.619, v_rmse=8.867, v_r2=0.937; \n",
            "E 18\t: loss=63.507, rmse=7.969, r2=0.948; v_loss=76.269, v_rmse=8.733, v_r2=0.939; \n",
            "E 19\t: loss=63.382, rmse=7.961, r2=0.949; v_loss=71.621, v_rmse=8.463, v_r2=0.943; \n",
            "E 20\t: loss=61.176, rmse=7.822, r2=0.950; v_loss=59.250, v_rmse=7.697, v_r2=0.953; \n",
            "E 21\t: loss=58.685, rmse=7.661, r2=0.952; v_loss=62.495, v_rmse=7.905, v_r2=0.950; \n",
            "E 22\t: loss=56.002, rmse=7.483, r2=0.955; v_loss=65.636, v_rmse=8.102, v_r2=0.947; \n",
            "E 23\t: loss=56.947, rmse=7.546, r2=0.954; v_loss=50.946, v_rmse=7.138, v_r2=0.959; \n",
            "E 24\t: loss=55.418, rmse=7.444, r2=0.955; v_loss=63.005, v_rmse=7.938, v_r2=0.950; \n",
            "E 25\t: loss=55.466, rmse=7.448, r2=0.955; v_loss=40.258, v_rmse=6.345, v_r2=0.968; \n",
            "E 26\t: loss=53.890, rmse=7.341, r2=0.956; v_loss=45.980, v_rmse=6.781, v_r2=0.963; \n",
            "E 27\t: loss=52.762, rmse=7.264, r2=0.957; v_loss=60.230, v_rmse=7.761, v_r2=0.952; \n",
            "E 28\t: loss=53.046, rmse=7.283, r2=0.957; v_loss=67.385, v_rmse=8.209, v_r2=0.946; \n",
            "E 29\t: loss=51.204, rmse=7.156, r2=0.958; v_loss=44.971, v_rmse=6.706, v_r2=0.964; \n",
            "E 30\t: loss=49.192, rmse=7.014, r2=0.960; v_loss=75.231, v_rmse=8.674, v_r2=0.940; \n",
            "E 31\t: loss=51.305, rmse=7.163, r2=0.958; v_loss=46.056, v_rmse=6.786, v_r2=0.963; \n",
            "E 32\t: loss=49.618, rmse=7.044, r2=0.960; v_loss=108.537, v_rmse=10.418, v_r2=0.913; \n",
            "E 33\t: loss=52.357, rmse=7.236, r2=0.958; v_loss=62.280, v_rmse=7.892, v_r2=0.950; \n",
            "E 34\t: loss=47.261, rmse=6.875, r2=0.962; v_loss=76.116, v_rmse=8.724, v_r2=0.939; \n",
            "E 35\t: loss=47.317, rmse=6.879, r2=0.962; v_loss=47.726, v_rmse=6.908, v_r2=0.962; \n",
            "E 36\t: loss=47.693, rmse=6.906, r2=0.961; v_loss=44.381, v_rmse=6.662, v_r2=0.964; \n",
            "E 37\t: loss=49.889, rmse=7.063, r2=0.960; v_loss=64.151, v_rmse=8.009, v_r2=0.949; \n",
            "E 38\t: loss=49.542, rmse=7.039, r2=0.960; v_loss=54.096, v_rmse=7.355, v_r2=0.957; \n",
            "E 39\t: loss=47.585, rmse=6.898, r2=0.961; v_loss=56.595, v_rmse=7.523, v_r2=0.955; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f21b11a6410>, <keras.callbacks.LambdaCallback object at 0x7f21b1212c90>], epochs=50, model=<function create_model at 0x7f21b1128440>, model__activation='tanh', model__dropout=0.1, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f211c3243d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f211c3245d0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     clip_y=105, scaler=MinMaxScaler(), seq_length=68)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36P-gmRD6QM",
        "outputId": "55451c3d-7c41-4347-b50c-5dfea4f0c7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[k1] = value[k2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 79, 253)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512)               1568768   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,569,281\n",
            "Trainable params: 1,569,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=578.149, rmse=24.045, r2=0.469; v_loss=144.199, v_rmse=12.008, v_r2=0.872; \n",
            "E 2\t: loss=100.144, rmse=10.007, r2=0.908; v_loss=65.974, v_rmse=8.122, v_r2=0.941; \n",
            "E 3\t: loss=76.217, rmse=8.730, r2=0.930; v_loss=74.162, v_rmse=8.612, v_r2=0.934; \n",
            "E 4\t: loss=65.670, rmse=8.104, r2=0.940; v_loss=72.952, v_rmse=8.541, v_r2=0.935; \n",
            "E 5\t: loss=57.321, rmse=7.571, r2=0.947; v_loss=63.162, v_rmse=7.947, v_r2=0.944; \n",
            "E 6\t: loss=50.718, rmse=7.122, r2=0.953; v_loss=64.987, v_rmse=8.061, v_r2=0.942; \n",
            "E 7\t: loss=44.037, rmse=6.636, r2=0.960; v_loss=56.251, v_rmse=7.500, v_r2=0.950; \n",
            "E 8\t: loss=38.944, rmse=6.241, r2=0.964; v_loss=64.878, v_rmse=8.055, v_r2=0.942; \n",
            "E 9\t: loss=34.945, rmse=5.911, r2=0.968; v_loss=44.270, v_rmse=6.654, v_r2=0.961; \n",
            "E 10\t: loss=30.951, rmse=5.563, r2=0.972; v_loss=48.802, v_rmse=6.986, v_r2=0.957; \n",
            "E 11\t: loss=29.114, rmse=5.396, r2=0.973; v_loss=53.417, v_rmse=7.309, v_r2=0.953; \n",
            "E 12\t: loss=27.563, rmse=5.250, r2=0.975; v_loss=56.601, v_rmse=7.523, v_r2=0.950; \n",
            "E 13\t: loss=25.555, rmse=5.055, r2=0.977; v_loss=44.062, v_rmse=6.638, v_r2=0.961; \n",
            "E 14\t: loss=24.727, rmse=4.973, r2=0.977; v_loss=58.766, v_rmse=7.666, v_r2=0.948; \n",
            "E 15\t: loss=24.022, rmse=4.901, r2=0.978; v_loss=58.903, v_rmse=7.675, v_r2=0.948; \n",
            "E 16\t: loss=23.202, rmse=4.817, r2=0.979; v_loss=53.948, v_rmse=7.345, v_r2=0.952; \n",
            "E 17\t: loss=21.782, rmse=4.667, r2=0.980; v_loss=50.976, v_rmse=7.140, v_r2=0.955; \n",
            "E 18\t: loss=20.798, rmse=4.560, r2=0.981; v_loss=56.699, v_rmse=7.530, v_r2=0.950; \n",
            "E 19\t: loss=20.299, rmse=4.505, r2=0.981; v_loss=53.961, v_rmse=7.346, v_r2=0.952; \n",
            "E 20\t: loss=19.917, rmse=4.463, r2=0.982; v_loss=56.383, v_rmse=7.509, v_r2=0.950; \n",
            "E 21\t: loss=19.888, rmse=4.460, r2=0.982; v_loss=67.227, v_rmse=8.199, v_r2=0.940; \n",
            "E 22\t: loss=19.086, rmse=4.369, r2=0.982; v_loss=62.636, v_rmse=7.914, v_r2=0.944; \n",
            "E 23\t: loss=19.312, rmse=4.395, r2=0.982; v_loss=64.261, v_rmse=8.016, v_r2=0.943; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fb131c18910>, <keras.callbacks.LambdaCallback object at 0x7fb131c27090>], epochs=23, model=<function create_model at 0x7fb192fe6c20>, model__activation='tanh', model__dropout=0.30649418903936865, model__layer1=512, model__learning_rate=0.0010472789501880123, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fb120413a50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fb131c34c10>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.23542211183603107, verbose=0),\n",
              "                     clip_y=99, poly_degree=2, seq_length=79)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "d1417190-46b2-42c9-f4e1-e5315ce0127f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[k1] = value[k2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.932,RMSE=-8.833\n",
            "Finished: 2022-09-29 11:29:46.568952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFqepk2KeacA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}