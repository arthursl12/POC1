{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "Q4QwyfhXs_hv",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf",
        "fQA-YtFMM81M",
        "t18eQ8H3EfGV",
        "ppByl3wN_W05"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHFdvF2Qd9nAJpjFstlpex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_LSTM_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "c3bf914d-a3f1-4e66-c50a-564750d0da5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b702948-33d5-45a4-b846-efacd708d116"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlp572nXopEO",
        "outputId": "7c3df761-16d0-488f-dcfd-436b71ef45e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "213067ac-840d-438a-fd71-12d08b8463b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "02aeebd3-e944-4abe-9ea0-10c12c9d769a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onw4pCwZy-1s",
        "outputId": "1465a59e-de3d-41e2-ea02-0d1e5a6b6e8f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmFKjQaeip1b",
        "outputId": "789d57bc-34f6-4b39-efb6-3ff00371d380"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "b00b4768-5690-4508-b652-b7f114b752e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26hK4VWkx1R7",
        "outputId": "0a88ad2b-80e9-439c-b19f-87ba5a2553eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "t18eQ8H3EfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "Ex7mZbQNEfGW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "SPE41-R2EfGX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "a2kynIDbEfGZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_cols = [index_cols[1]]+sensors_cols\n",
        "SEQ_COLS = seq_cols"
      ],
      "metadata": {
        "id": "BAfnrm9Hwnua"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_SEQ_COLS = [index_cols[1]]+sensors_cols"
      ],
      "metadata": {
        "id": "NglteguEMJFm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(LSTM(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(LSTM(layer2, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(LSTM(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "Jowfppg9HG3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=126\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "cxz0nz9mHJ2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h\n",
        "# ~1h30min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__model__activation\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "        \"basemodel__model__dropout\": Real(0.1,0.9),\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__layer2\": Integer(16,512)\n",
        "        # \"basemodel__model__layer3\": Integer(16,512)\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI-MbGPrHsB0",
        "outputId": "11582f0a-4827-4e0c-a013-7e4ab5eab24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=328, basemodel__epochs=27, basemodel__model__activation=tanh, basemodel__model__dropout=0.16501122046577185, basemodel__model__layer1=179, basemodel__model__layer2=428, basemodel__model__learning_rate=0.004066181653163268, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.46735773608305464, clip_y=122, scaler=StandardScaler(), seq_length=98;, score=0.893 total time= 1.2min\n",
            "[CV 2/3] END basemodel__batch_size=328, basemodel__epochs=27, basemodel__model__activation=tanh, basemodel__model__dropout=0.16501122046577185, basemodel__model__layer1=179, basemodel__model__layer2=428, basemodel__model__learning_rate=0.004066181653163268, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.46735773608305464, clip_y=122, scaler=StandardScaler(), seq_length=98;, score=0.302 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=328, basemodel__epochs=27, basemodel__model__activation=tanh, basemodel__model__dropout=0.16501122046577185, basemodel__model__layer1=179, basemodel__model__layer2=428, basemodel__model__learning_rate=0.004066181653163268, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.46735773608305464, clip_y=122, scaler=StandardScaler(), seq_length=98;, score=-0.020 total time= 1.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=336, basemodel__epochs=21, basemodel__model__activation=tanh, basemodel__model__dropout=0.7198881182018468, basemodel__model__layer1=148, basemodel__model__layer2=356, basemodel__model__learning_rate=0.008595611957594864, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7203938615536978, clip_y=84, scaler=MinMaxScaler(), seq_length=52;, score=0.453 total time=  35.6s\n",
            "[CV 2/3] END basemodel__batch_size=336, basemodel__epochs=21, basemodel__model__activation=tanh, basemodel__model__dropout=0.7198881182018468, basemodel__model__layer1=148, basemodel__model__layer2=356, basemodel__model__learning_rate=0.008595611957594864, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7203938615536978, clip_y=84, scaler=MinMaxScaler(), seq_length=52;, score=-0.392 total time=  19.3s\n",
            "[CV 3/3] END basemodel__batch_size=336, basemodel__epochs=21, basemodel__model__activation=tanh, basemodel__model__dropout=0.7198881182018468, basemodel__model__layer1=148, basemodel__model__layer2=356, basemodel__model__learning_rate=0.008595611957594864, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7203938615536978, clip_y=84, scaler=MinMaxScaler(), seq_length=52;, score=0.279 total time=  36.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=263, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.6664665715357432, basemodel__model__layer1=119, basemodel__model__layer2=161, basemodel__model__learning_rate=0.006451144037722768, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23140061699995373, clip_y=80, scaler=MinMaxScaler(), seq_length=92;, score=-0.009 total time=  15.3s\n",
            "[CV 2/3] END basemodel__batch_size=263, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.6664665715357432, basemodel__model__layer1=119, basemodel__model__layer2=161, basemodel__model__learning_rate=0.006451144037722768, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23140061699995373, clip_y=80, scaler=MinMaxScaler(), seq_length=92;, score=-0.005 total time=  14.7s\n",
            "[CV 3/3] END basemodel__batch_size=263, basemodel__epochs=2, basemodel__model__activation=tanh, basemodel__model__dropout=0.6664665715357432, basemodel__model__layer1=119, basemodel__model__layer2=161, basemodel__model__learning_rate=0.006451144037722768, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23140061699995373, clip_y=80, scaler=MinMaxScaler(), seq_length=92;, score=-0.016 total time=  14.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=51, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.684728557432887, basemodel__model__layer1=138, basemodel__model__layer2=66, basemodel__model__learning_rate=0.0069781868051007594, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7494654880561378, clip_y=94, scaler=StandardScaler(), seq_length=55;, score=0.910 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=51, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.684728557432887, basemodel__model__layer1=138, basemodel__model__layer2=66, basemodel__model__learning_rate=0.0069781868051007594, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7494654880561378, clip_y=94, scaler=StandardScaler(), seq_length=55;, score=0.824 total time= 1.9min\n",
            "[CV 3/3] END basemodel__batch_size=51, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.684728557432887, basemodel__model__layer1=138, basemodel__model__layer2=66, basemodel__model__learning_rate=0.0069781868051007594, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7494654880561378, clip_y=94, scaler=StandardScaler(), seq_length=55;, score=0.776 total time=  55.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=159, basemodel__epochs=4, basemodel__model__activation=tanh, basemodel__model__dropout=0.8639662984200317, basemodel__model__layer1=217, basemodel__model__layer2=44, basemodel__model__learning_rate=0.0019098114088857963, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.638869916051507, clip_y=138, scaler=MinMaxScaler(), seq_length=63;, score=-1.783 total time=  17.5s\n",
            "[CV 2/3] END basemodel__batch_size=159, basemodel__epochs=4, basemodel__model__activation=tanh, basemodel__model__dropout=0.8639662984200317, basemodel__model__layer1=217, basemodel__model__layer2=44, basemodel__model__learning_rate=0.0019098114088857963, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.638869916051507, clip_y=138, scaler=MinMaxScaler(), seq_length=63;, score=-1.778 total time=  17.6s\n",
            "[CV 3/3] END basemodel__batch_size=159, basemodel__epochs=4, basemodel__model__activation=tanh, basemodel__model__dropout=0.8639662984200317, basemodel__model__layer1=217, basemodel__model__layer2=44, basemodel__model__learning_rate=0.0019098114088857963, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.638869916051507, clip_y=138, scaler=MinMaxScaler(), seq_length=63;, score=-1.687 total time=  17.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=115, basemodel__epochs=7, basemodel__model__activation=tanh, basemodel__model__dropout=0.4180947212787276, basemodel__model__layer1=110, basemodel__model__layer2=475, basemodel__model__learning_rate=0.0098946629394394, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2584788743945746, clip_y=126, scaler=MinMaxScaler(), seq_length=33;, score=0.550 total time=  31.1s\n",
            "[CV 2/3] END basemodel__batch_size=115, basemodel__epochs=7, basemodel__model__activation=tanh, basemodel__model__dropout=0.4180947212787276, basemodel__model__layer1=110, basemodel__model__layer2=475, basemodel__model__learning_rate=0.0098946629394394, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2584788743945746, clip_y=126, scaler=MinMaxScaler(), seq_length=33;, score=0.551 total time=  31.4s\n",
            "[CV 3/3] END basemodel__batch_size=115, basemodel__epochs=7, basemodel__model__activation=tanh, basemodel__model__dropout=0.4180947212787276, basemodel__model__layer1=110, basemodel__model__layer2=475, basemodel__model__learning_rate=0.0098946629394394, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2584788743945746, clip_y=126, scaler=MinMaxScaler(), seq_length=33;, score=0.525 total time=  31.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=456, basemodel__epochs=45, basemodel__model__activation=tanh, basemodel__model__dropout=0.5351856891133079, basemodel__model__layer1=192, basemodel__model__layer2=90, basemodel__model__learning_rate=0.001956919272204245, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5478628959264611, clip_y=138, scaler=MinMaxScaler(), seq_length=49;, score=0.017 total time=  44.0s\n",
            "[CV 2/3] END basemodel__batch_size=456, basemodel__epochs=45, basemodel__model__activation=tanh, basemodel__model__dropout=0.5351856891133079, basemodel__model__layer1=192, basemodel__model__layer2=90, basemodel__model__learning_rate=0.001956919272204245, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5478628959264611, clip_y=138, scaler=MinMaxScaler(), seq_length=49;, score=-0.055 total time=  42.6s\n",
            "[CV 3/3] END basemodel__batch_size=456, basemodel__epochs=45, basemodel__model__activation=tanh, basemodel__model__dropout=0.5351856891133079, basemodel__model__layer1=192, basemodel__model__layer2=90, basemodel__model__learning_rate=0.001956919272204245, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5478628959264611, clip_y=138, scaler=MinMaxScaler(), seq_length=49;, score=0.016 total time=  43.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=202, basemodel__epochs=11, basemodel__model__activation=tanh, basemodel__model__dropout=0.48273651699175635, basemodel__model__layer1=148, basemodel__model__layer2=51, basemodel__model__learning_rate=0.008504270135675843, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5191949202155761, clip_y=114, scaler=MinMaxScaler(), seq_length=52;, score=-0.020 total time=  23.0s\n",
            "[CV 2/3] END basemodel__batch_size=202, basemodel__epochs=11, basemodel__model__activation=tanh, basemodel__model__dropout=0.48273651699175635, basemodel__model__layer1=148, basemodel__model__layer2=51, basemodel__model__learning_rate=0.008504270135675843, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5191949202155761, clip_y=114, scaler=MinMaxScaler(), seq_length=52;, score=-0.007 total time=  22.0s\n",
            "[CV 3/3] END basemodel__batch_size=202, basemodel__epochs=11, basemodel__model__activation=tanh, basemodel__model__dropout=0.48273651699175635, basemodel__model__layer1=148, basemodel__model__layer2=51, basemodel__model__learning_rate=0.008504270135675843, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5191949202155761, clip_y=114, scaler=MinMaxScaler(), seq_length=52;, score=-0.019 total time=  22.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=210, basemodel__epochs=47, basemodel__model__activation=tanh, basemodel__model__dropout=0.5029216361161006, basemodel__model__layer1=389, basemodel__model__layer2=103, basemodel__model__learning_rate=0.008913774854989004, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.14162221816854245, clip_y=135, scaler=MinMaxScaler(), seq_length=68;, score=0.376 total time= 1.7min\n",
            "[CV 2/3] END basemodel__batch_size=210, basemodel__epochs=47, basemodel__model__activation=tanh, basemodel__model__dropout=0.5029216361161006, basemodel__model__layer1=389, basemodel__model__layer2=103, basemodel__model__learning_rate=0.008913774854989004, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.14162221816854245, clip_y=135, scaler=MinMaxScaler(), seq_length=68;, score=0.808 total time= 2.1min\n",
            "[CV 3/3] END basemodel__batch_size=210, basemodel__epochs=47, basemodel__model__activation=tanh, basemodel__model__dropout=0.5029216361161006, basemodel__model__layer1=389, basemodel__model__layer2=103, basemodel__model__learning_rate=0.008913774854989004, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.14162221816854245, clip_y=135, scaler=MinMaxScaler(), seq_length=68;, score=0.805 total time= 1.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=120, basemodel__epochs=29, basemodel__model__activation=tanh, basemodel__model__dropout=0.2312711011778615, basemodel__model__layer1=461, basemodel__model__layer2=509, basemodel__model__learning_rate=0.006578493761541917, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.12553440347950443, clip_y=117, scaler=MinMaxScaler(), seq_length=43;, score=-0.003 total time=  48.4s\n",
            "[CV 2/3] END basemodel__batch_size=120, basemodel__epochs=29, basemodel__model__activation=tanh, basemodel__model__dropout=0.2312711011778615, basemodel__model__layer1=461, basemodel__model__layer2=509, basemodel__model__learning_rate=0.006578493761541917, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.12553440347950443, clip_y=117, scaler=MinMaxScaler(), seq_length=43;, score=-0.002 total time= 1.1min\n",
            "[CV 3/3] END basemodel__batch_size=120, basemodel__epochs=29, basemodel__model__activation=tanh, basemodel__model__dropout=0.2312711011778615, basemodel__model__layer1=461, basemodel__model__layer2=509, basemodel__model__learning_rate=0.006578493761541917, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.12553440347950443, clip_y=117, scaler=MinMaxScaler(), seq_length=43;, score=0.708 total time= 2.6min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=293, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.24549947734371755, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__learning_rate=0.005298615229857347, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4260127796569797, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.771 total time= 2.0min\n",
            "[CV 2/3] END basemodel__batch_size=293, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.24549947734371755, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__learning_rate=0.005298615229857347, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4260127796569797, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=-0.210 total time=  49.3s\n",
            "[CV 3/3] END basemodel__batch_size=293, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.24549947734371755, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__learning_rate=0.005298615229857347, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4260127796569797, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.756 total time= 2.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=30;, score=-4.982 total time= 2.6min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=30;, score=-4.906 total time= 2.7min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=30;, score=-4.698 total time= 2.6min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation=tanh, basemodel__model__dropout=0.6279700950679261, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0038404202753947714, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=140, scaler=MinMaxScaler(), seq_length=63;, score=-2.375 total time=  15.3s\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation=tanh, basemodel__model__dropout=0.6279700950679261, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0038404202753947714, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=140, scaler=MinMaxScaler(), seq_length=63;, score=-2.329 total time=  15.4s\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation=tanh, basemodel__model__dropout=0.6279700950679261, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0038404202753947714, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=140, scaler=MinMaxScaler(), seq_length=63;, score=-2.314 total time=  15.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "WARNING:tensorflow:5 out of the last 16707 calls to <function Model.make_test_function.<locals>.test_function at 0x00000280E33F5CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 1/3] END basemodel__batch_size=47, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.7632316641399991, basemodel__model__layer1=124, basemodel__model__layer2=21, basemodel__model__learning_rate=0.007217647323678346, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7729366553996238, clip_y=98, scaler=StandardScaler(), seq_length=60;, score=0.796 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=47, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.7632316641399991, basemodel__model__layer1=124, basemodel__model__layer2=21, basemodel__model__learning_rate=0.007217647323678346, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7729366553996238, clip_y=98, scaler=StandardScaler(), seq_length=60;, score=0.765 total time= 1.8min\n",
            "[CV 3/3] END basemodel__batch_size=47, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.7632316641399991, basemodel__model__layer1=124, basemodel__model__layer2=21, basemodel__model__learning_rate=0.007217647323678346, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7729366553996238, clip_y=98, scaler=StandardScaler(), seq_length=60;, score=0.680 total time= 2.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=92, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=266, basemodel__model__layer2=512, basemodel__model__learning_rate=0.006819440939875017, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8232219618420618, clip_y=80, scaler=StandardScaler(), seq_length=35;, score=0.920 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=92, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=266, basemodel__model__layer2=512, basemodel__model__learning_rate=0.006819440939875017, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8232219618420618, clip_y=80, scaler=StandardScaler(), seq_length=35;, score=0.826 total time= 1.1min\n",
            "[CV 3/3] END basemodel__batch_size=92, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.1, basemodel__model__layer1=266, basemodel__model__layer2=512, basemodel__model__learning_rate=0.006819440939875017, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8232219618420618, clip_y=80, scaler=StandardScaler(), seq_length=35;, score=0.769 total time= 2.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=78, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.12372135135129216, basemodel__model__layer1=187, basemodel__model__layer2=409, basemodel__model__learning_rate=0.006602021548991071, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8148543149632173, clip_y=80, scaler=StandardScaler(), seq_length=43;, score=0.876 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=78, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.12372135135129216, basemodel__model__layer1=187, basemodel__model__layer2=409, basemodel__model__learning_rate=0.006602021548991071, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8148543149632173, clip_y=80, scaler=StandardScaler(), seq_length=43;, score=0.806 total time= 1.6min\n",
            "[CV 3/3] END basemodel__batch_size=78, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.12372135135129216, basemodel__model__layer1=187, basemodel__model__layer2=409, basemodel__model__learning_rate=0.006602021548991071, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8148543149632173, clip_y=80, scaler=StandardScaler(), seq_length=43;, score=0.822 total time= 2.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=107, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.10823253673260416, basemodel__model__layer1=322, basemodel__model__layer2=512, basemodel__model__learning_rate=0.006814930635417383, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7240717441584384, clip_y=82, scaler=StandardScaler(), seq_length=31;, score=0.890 total time= 2.0min\n",
            "[CV 2/3] END basemodel__batch_size=107, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.10823253673260416, basemodel__model__layer1=322, basemodel__model__layer2=512, basemodel__model__learning_rate=0.006814930635417383, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7240717441584384, clip_y=82, scaler=StandardScaler(), seq_length=31;, score=0.854 total time= 2.2min\n",
            "[CV 3/3] END basemodel__batch_size=107, basemodel__epochs=48, basemodel__model__activation=tanh, basemodel__model__dropout=0.10823253673260416, basemodel__model__layer1=322, basemodel__model__layer2=512, basemodel__model__learning_rate=0.006814930635417383, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7240717441584384, clip_y=82, scaler=StandardScaler(), seq_length=31;, score=0.857 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=124, basemodel__epochs=42, basemodel__model__activation=tanh, basemodel__model__dropout=0.36325643292778165, basemodel__model__layer1=405, basemodel__model__layer2=313, basemodel__model__learning_rate=0.006786656514894841, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.43731520125606826, clip_y=93, scaler=StandardScaler(), seq_length=30;, score=0.921 total time= 2.1min\n",
            "[CV 2/3] END basemodel__batch_size=124, basemodel__epochs=42, basemodel__model__activation=tanh, basemodel__model__dropout=0.36325643292778165, basemodel__model__layer1=405, basemodel__model__layer2=313, basemodel__model__learning_rate=0.006786656514894841, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.43731520125606826, clip_y=93, scaler=StandardScaler(), seq_length=30;, score=0.886 total time= 1.6min\n",
            "[CV 3/3] END basemodel__batch_size=124, basemodel__epochs=42, basemodel__model__activation=tanh, basemodel__model__dropout=0.36325643292778165, basemodel__model__layer1=405, basemodel__model__layer2=313, basemodel__model__learning_rate=0.006786656514894841, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.43731520125606826, clip_y=93, scaler=StandardScaler(), seq_length=30;, score=0.836 total time= 1.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.17024609878937963, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__learning_rate=0.009914975588642449, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=140, scaler=MinMaxScaler(), seq_length=71;, score=0.719 total time= 4.0min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.17024609878937963, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__learning_rate=0.009914975588642449, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=140, scaler=MinMaxScaler(), seq_length=71;, score=0.674 total time= 4.9min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation=tanh, basemodel__model__dropout=0.17024609878937963, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__learning_rate=0.009914975588642449, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=140, scaler=MinMaxScaler(), seq_length=71;, score=0.470 total time= 2.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=245, basemodel__epochs=17, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=279, basemodel__model__layer2=201, basemodel__model__learning_rate=0.00671934598653267, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5205117148271099, clip_y=80, scaler=StandardScaler(), seq_length=56;, score=0.787 total time=  36.1s\n",
            "[CV 2/3] END basemodel__batch_size=245, basemodel__epochs=17, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=279, basemodel__model__layer2=201, basemodel__model__learning_rate=0.00671934598653267, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5205117148271099, clip_y=80, scaler=StandardScaler(), seq_length=56;, score=0.845 total time=  36.0s\n",
            "[CV 3/3] END basemodel__batch_size=245, basemodel__epochs=17, basemodel__model__activation=tanh, basemodel__model__dropout=0.9, basemodel__model__layer1=279, basemodel__model__layer2=201, basemodel__model__learning_rate=0.00671934598653267, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5205117148271099, clip_y=80, scaler=StandardScaler(), seq_length=56;, score=0.760 total time=  36.4s\n",
            "Finished: 2022-10-13 12:43:47.706293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SSmZxJKlUNFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786eae92-988b-4cd5-ad5c-2c5b74a339fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8811232847407394\n",
            "OrderedDict([('basemodel__batch_size', 124), ('basemodel__epochs', 42), ('basemodel__model__activation', 'tanh'), ('basemodel__model__dropout', 0.36325643292778165), ('basemodel__model__layer1', 405), ('basemodel__model__layer2', 313), ('basemodel__model__learning_rate', 0.006786656514894841), ('basemodel__model__optim', <class 'keras.optimizer_v2.rmsprop.RMSprop'>), ('basemodel__validation_split', 0.43731520125606826), ('clip_y', 93), ('scaler', StandardScaler()), ('seq_length', 30)])\n",
            "Finished: 2022-10-13 12:45:04.037125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "0HUnMESRVitn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "6d979819-a8e6-4cfb-9bf4-c2dd5790d5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-13 12:45:04.692111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8QiZ9pWmSb0",
        "outputId": "9bdb1e17-ffa3-492e-ac54-a3c164361e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 124),\n",
              "             ('basemodel__epochs', 42),\n",
              "             ('basemodel__model__activation', 'tanh'),\n",
              "             ('basemodel__model__dropout', 0.36325643292778165),\n",
              "             ('basemodel__model__layer1', 405),\n",
              "             ('basemodel__model__layer2', 313),\n",
              "             ('basemodel__model__learning_rate', 0.006786656514894841),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
              "             ('basemodel__validation_split', 0.43731520125606826),\n",
              "             ('clip_y', 93),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 30)])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer\n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7965826139501325  \n",
        "Test: 0.706\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.10771222326909816),\n",
        "('basemodel__model__layer1', 505),\n",
        "('basemodel__model__learning_rate', 0.0032806529941975817),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 70)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.9430289602358563  \n",
        "Test: 0.857\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 105),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 68)\n",
        "```\n",
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.8254078138058109  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 43),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.12031183587891998),\n",
        "('basemodel__model__layer1', 291),\n",
        "('basemodel__model__learning_rate', 0.0005169281218693581),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 61)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.8183215542558463  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 118),\n",
        "             ('basemodel__epochs', 32),\n",
        "             ('basemodel__model__activation', 'tanh'),\n",
        "             ('basemodel__model__dropout', 0.3795770073881617),\n",
        "             ('basemodel__model__layer1', 432),\n",
        "             ('basemodel__model__learning_rate', 0.00806882152030281),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.7235243202098837),\n",
        "             ('clip_y', 105),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 79)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 2-layer\n"
      ],
      "metadata": {
        "id": "zSnh2UONQb4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7036942110742231  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 29),\n",
        "             ('basemodel__model__activation', 'tanh'),\n",
        "             ('basemodel__model__dropout', 0.23530299114462505),\n",
        "             ('basemodel__model__layer1', 162),\n",
        "             ('basemodel__model__layer2', 487),\n",
        "             ('basemodel__model__learning_rate', 0.004875393938118097),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.19866467635377297),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 49)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.8811232847407394  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 124),\n",
        "             ('basemodel__epochs', 42),\n",
        "             ('basemodel__model__activation', 'tanh'),\n",
        "             ('basemodel__model__dropout', 0.36325643292778165),\n",
        "             ('basemodel__model__layer1', 405),\n",
        "             ('basemodel__model__layer2', 313),\n",
        "             ('basemodel__model__learning_rate', 0.006786656514894841),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.43731520125606826),\n",
        "             ('clip_y', 93),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 30)\n",
        "```\n",
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.  \n",
        "Test: 0.\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.  \n",
        "Test: 0.\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vL2GlZ8KQb4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c328dea-1974-4b93-9966-69c39d8fcbcd",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_123\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_123 (Masking)       (None, 68, 22)            0         \n",
            "                                                                 \n",
            " lstm_123 (LSTM)             (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_123 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,096,193\n",
            "Trainable params: 1,096,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3093.311, rmse=55.618, r2=-1.509; v_loss=2320.318, v_rmse=48.170, v_r2=-0.858; \n",
            "E 2\t: loss=1687.357, rmse=41.077, r2=-0.368; v_loss=1733.833, v_rmse=41.639, v_r2=-0.389; \n",
            "E 3\t: loss=1225.183, rmse=35.003, r2=0.006; v_loss=1506.114, v_rmse=38.809, v_r2=-0.206; \n",
            "E 4\t: loss=971.241, rmse=31.165, r2=0.212; v_loss=1341.068, v_rmse=36.621, v_r2=-0.074; \n",
            "E 5\t: loss=753.771, rmse=27.455, r2=0.389; v_loss=1110.392, v_rmse=33.323, v_r2=0.111; \n",
            "E 6\t: loss=503.171, rmse=22.431, r2=0.592; v_loss=723.938, v_rmse=26.906, v_r2=0.420; \n",
            "E 7\t: loss=318.956, rmse=17.859, r2=0.741; v_loss=368.611, v_rmse=19.199, v_r2=0.705; \n",
            "E 8\t: loss=245.013, rmse=15.653, r2=0.801; v_loss=303.443, v_rmse=17.420, v_r2=0.757; \n",
            "E 9\t: loss=169.560, rmse=13.022, r2=0.862; v_loss=161.770, v_rmse=12.719, v_r2=0.870; \n",
            "E 10\t: loss=136.067, rmse=11.665, r2=0.890; v_loss=190.953, v_rmse=13.819, v_r2=0.847; \n",
            "E 11\t: loss=113.465, rmse=10.652, r2=0.908; v_loss=110.131, v_rmse=10.494, v_r2=0.912; \n",
            "E 12\t: loss=94.913, rmse=9.742, r2=0.923; v_loss=94.722, v_rmse=9.733, v_r2=0.924; \n",
            "E 13\t: loss=78.853, rmse=8.880, r2=0.936; v_loss=86.811, v_rmse=9.317, v_r2=0.930; \n",
            "E 14\t: loss=75.178, rmse=8.671, r2=0.939; v_loss=67.101, v_rmse=8.191, v_r2=0.946; \n",
            "E 15\t: loss=74.498, rmse=8.631, r2=0.940; v_loss=61.738, v_rmse=7.857, v_r2=0.951; \n",
            "E 16\t: loss=66.403, rmse=8.149, r2=0.946; v_loss=68.740, v_rmse=8.291, v_r2=0.945; \n",
            "E 17\t: loss=66.094, rmse=8.130, r2=0.946; v_loss=78.619, v_rmse=8.867, v_r2=0.937; \n",
            "E 18\t: loss=63.507, rmse=7.969, r2=0.948; v_loss=76.269, v_rmse=8.733, v_r2=0.939; \n",
            "E 19\t: loss=63.382, rmse=7.961, r2=0.949; v_loss=71.621, v_rmse=8.463, v_r2=0.943; \n",
            "E 20\t: loss=61.176, rmse=7.822, r2=0.950; v_loss=59.250, v_rmse=7.697, v_r2=0.953; \n",
            "E 21\t: loss=58.685, rmse=7.661, r2=0.952; v_loss=62.495, v_rmse=7.905, v_r2=0.950; \n",
            "E 22\t: loss=56.002, rmse=7.483, r2=0.955; v_loss=65.636, v_rmse=8.102, v_r2=0.947; \n",
            "E 23\t: loss=56.947, rmse=7.546, r2=0.954; v_loss=50.946, v_rmse=7.138, v_r2=0.959; \n",
            "E 24\t: loss=55.418, rmse=7.444, r2=0.955; v_loss=63.005, v_rmse=7.938, v_r2=0.950; \n",
            "E 25\t: loss=55.466, rmse=7.448, r2=0.955; v_loss=40.258, v_rmse=6.345, v_r2=0.968; \n",
            "E 26\t: loss=53.890, rmse=7.341, r2=0.956; v_loss=45.980, v_rmse=6.781, v_r2=0.963; \n",
            "E 27\t: loss=52.762, rmse=7.264, r2=0.957; v_loss=60.230, v_rmse=7.761, v_r2=0.952; \n",
            "E 28\t: loss=53.046, rmse=7.283, r2=0.957; v_loss=67.385, v_rmse=8.209, v_r2=0.946; \n",
            "E 29\t: loss=51.204, rmse=7.156, r2=0.958; v_loss=44.971, v_rmse=6.706, v_r2=0.964; \n",
            "E 30\t: loss=49.192, rmse=7.014, r2=0.960; v_loss=75.231, v_rmse=8.674, v_r2=0.940; \n",
            "E 31\t: loss=51.305, rmse=7.163, r2=0.958; v_loss=46.056, v_rmse=6.786, v_r2=0.963; \n",
            "E 32\t: loss=49.618, rmse=7.044, r2=0.960; v_loss=108.537, v_rmse=10.418, v_r2=0.913; \n",
            "E 33\t: loss=52.357, rmse=7.236, r2=0.958; v_loss=62.280, v_rmse=7.892, v_r2=0.950; \n",
            "E 34\t: loss=47.261, rmse=6.875, r2=0.962; v_loss=76.116, v_rmse=8.724, v_r2=0.939; \n",
            "E 35\t: loss=47.317, rmse=6.879, r2=0.962; v_loss=47.726, v_rmse=6.908, v_r2=0.962; \n",
            "E 36\t: loss=47.693, rmse=6.906, r2=0.961; v_loss=44.381, v_rmse=6.662, v_r2=0.964; \n",
            "E 37\t: loss=49.889, rmse=7.063, r2=0.960; v_loss=64.151, v_rmse=8.009, v_r2=0.949; \n",
            "E 38\t: loss=49.542, rmse=7.039, r2=0.960; v_loss=54.096, v_rmse=7.355, v_r2=0.957; \n",
            "E 39\t: loss=47.585, rmse=6.898, r2=0.961; v_loss=56.595, v_rmse=7.523, v_r2=0.955; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f21b11a6410>, <keras.callbacks.LambdaCallback object at 0x7f21b1212c90>], epochs=50, model=<function create_model at 0x7f21b1128440>, model__activation='tanh', model__dropout=0.1, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f211c3243d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f211c3245d0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     clip_y=105, scaler=MinMaxScaler(), seq_length=68)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QFBtaiz2Ckgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model2,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=400,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36P-gmRD6QM",
        "outputId": "bcf08e0c-4c85-421d-cca1-0a15446fac58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_259\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_259 (Masking)       (None, 79, 253)           0         \n",
            "                                                                 \n",
            " lstm_397 (LSTM)             (None, 512)               1568768   \n",
            "                                                                 \n",
            " dropout_398 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_260 (Dense)           (None, 400)               205200    \n",
            "                                                                 \n",
            " dropout_399 (Dropout)       (None, 400)               0         \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,774,369\n",
            "Trainable params: 1,774,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=496.805, rmse=22.289, r2=0.544; v_loss=100.148, v_rmse=10.007, v_r2=0.911; \n",
            "E 2\t: loss=79.204, rmse=8.900, r2=0.927; v_loss=75.247, v_rmse=8.675, v_r2=0.933; \n",
            "E 3\t: loss=57.412, rmse=7.577, r2=0.947; v_loss=73.200, v_rmse=8.556, v_r2=0.935; \n",
            "E 4\t: loss=47.545, rmse=6.895, r2=0.956; v_loss=95.379, v_rmse=9.766, v_r2=0.915; \n",
            "E 5\t: loss=38.321, rmse=6.190, r2=0.965; v_loss=64.979, v_rmse=8.061, v_r2=0.942; \n",
            "E 6\t: loss=34.381, rmse=5.864, r2=0.968; v_loss=57.869, v_rmse=7.607, v_r2=0.949; \n",
            "E 7\t: loss=30.205, rmse=5.496, r2=0.972; v_loss=65.517, v_rmse=8.094, v_r2=0.942; \n",
            "E 8\t: loss=27.004, rmse=5.196, r2=0.975; v_loss=66.354, v_rmse=8.146, v_r2=0.941; \n",
            "E 9\t: loss=25.285, rmse=5.028, r2=0.977; v_loss=48.890, v_rmse=6.992, v_r2=0.957; \n",
            "E 10\t: loss=24.191, rmse=4.918, r2=0.978; v_loss=53.082, v_rmse=7.286, v_r2=0.953; \n",
            "E 11\t: loss=22.787, rmse=4.774, r2=0.979; v_loss=56.550, v_rmse=7.520, v_r2=0.950; \n",
            "E 12\t: loss=21.923, rmse=4.682, r2=0.980; v_loss=45.025, v_rmse=6.710, v_r2=0.960; \n",
            "E 13\t: loss=20.876, rmse=4.569, r2=0.981; v_loss=65.768, v_rmse=8.110, v_r2=0.942; \n",
            "E 14\t: loss=20.571, rmse=4.536, r2=0.981; v_loss=63.161, v_rmse=7.947, v_r2=0.944; \n",
            "E 15\t: loss=20.353, rmse=4.511, r2=0.981; v_loss=44.512, v_rmse=6.672, v_r2=0.960; \n",
            "E 16\t: loss=19.896, rmse=4.461, r2=0.982; v_loss=60.162, v_rmse=7.756, v_r2=0.947; \n",
            "E 17\t: loss=19.829, rmse=4.453, r2=0.982; v_loss=61.609, v_rmse=7.849, v_r2=0.945; \n",
            "E 18\t: loss=18.712, rmse=4.326, r2=0.983; v_loss=69.991, v_rmse=8.366, v_r2=0.938; \n",
            "E 19\t: loss=18.688, rmse=4.323, r2=0.983; v_loss=79.855, v_rmse=8.936, v_r2=0.929; \n",
            "E 20\t: loss=18.247, rmse=4.272, r2=0.983; v_loss=54.772, v_rmse=7.401, v_r2=0.951; \n",
            "E 21\t: loss=17.255, rmse=4.154, r2=0.984; v_loss=102.921, v_rmse=10.145, v_r2=0.909; \n",
            "E 22\t: loss=17.164, rmse=4.143, r2=0.984; v_loss=61.826, v_rmse=7.863, v_r2=0.945; \n",
            "E 23\t: loss=17.193, rmse=4.146, r2=0.984; v_loss=55.217, v_rmse=7.431, v_r2=0.951; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027F52FFEE50>, <keras.callbacks.LambdaCallback object at 0x0000027F53033D00>], epochs=23, model=<function create_model2 at 0x0000028102FA18B0>, model__activation='tanh', model__dropout=0.30649418903936865, model__layer1=512, model__layer2=400, model...010472789501880123, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000280AE770FD0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000280ED328B20>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.23542211183603107, verbose=0),\n",
              "                     clip_y=99, poly_degree=2, seq_length=79)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "83699a7e-1744-455e-c836-906b8dc33bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.918,RMSE=-9.668\n",
            "Finished: 2022-10-13 13:15:58.111062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee8uwFhF-E6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}