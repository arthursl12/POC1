{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "n7MBDuPasy-s",
        "e7-_jqRw3cRa",
        "QinQ4hWStzHt",
        "boZqFQNlraCh",
        "IIXnBTkfxpCf",
        "SL1dv6EX4NUk"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxF6RU+Efv/41qxkodEELx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD003_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "2d84dc53-c375-4fed-ed5e-d1e5ca75933a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ba183a-e6b5-414c-c298-19927ab6c710"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/CMaps/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgkQUCfsWAGK",
        "outputId": "1b3782c6-bbce-42e2-9d7b-2ac7dd26fc92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(3,folder=folder)\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "aeb49bc1-46d9-474e-aae1-242ccbc9d3d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0005  0.0004  100.0  518.67  642.36  1583.23   \n",
              "1                1     2  0.0008 -0.0003  100.0  518.67  642.50  1584.69   \n",
              "2                1     3 -0.0014 -0.0002  100.0  518.67  642.18  1582.35   \n",
              "3                1     4 -0.0020  0.0001  100.0  518.67  642.92  1585.61   \n",
              "4                1     5  0.0016  0.0000  100.0  518.67  641.68  1588.63   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "24715          100   148 -0.0016 -0.0003  100.0  518.67  643.78  1596.01   \n",
              "24716          100   149  0.0034 -0.0003  100.0  518.67  643.29  1596.38   \n",
              "24717          100   150 -0.0016  0.0004  100.0  518.67  643.84  1604.53   \n",
              "24718          100   151 -0.0023  0.0004  100.0  518.67  643.94  1597.56   \n",
              "24719          100   152  0.0000  0.0003  100.0  518.67  643.64  1599.04   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1396.84  14.62  ...  522.31  2388.01  8145.32  8.4246  0.03   391   \n",
              "1      1396.89  14.62  ...  522.42  2388.03  8152.85  8.4403  0.03   392   \n",
              "2      1405.61  14.62  ...  522.03  2388.00  8150.17  8.3901  0.03   391   \n",
              "3      1392.27  14.62  ...  522.49  2388.08  8146.56  8.3878  0.03   392   \n",
              "4      1397.65  14.62  ...  522.58  2388.03  8147.80  8.3869  0.03   392   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "24715  1424.11  14.62  ...  519.66  2388.30  8138.08  8.5036  0.03   394   \n",
              "24716  1429.14  14.62  ...  519.91  2388.28  8144.36  8.5174  0.03   395   \n",
              "24717  1431.41  14.62  ...  519.44  2388.24  8135.95  8.5223  0.03   396   \n",
              "24718  1426.57  14.62  ...  520.01  2388.26  8141.24  8.5148  0.03   395   \n",
              "24719  1436.06  14.62  ...  519.48  2388.24  8136.98  8.5150  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.11  23.3537  \n",
              "1      2388  100.0  38.99  23.4491  \n",
              "2      2388  100.0  38.85  23.3669  \n",
              "3      2388  100.0  38.96  23.2951  \n",
              "4      2388  100.0  39.14  23.4583  \n",
              "...     ...    ...    ...      ...  \n",
              "24715  2388  100.0  38.44  22.9631  \n",
              "24716  2388  100.0  38.50  22.9746  \n",
              "24717  2388  100.0  38.39  23.0682  \n",
              "24718  2388  100.0  38.31  23.0753  \n",
              "24719  2388  100.0  38.56  23.0847  \n",
              "\n",
              "[24720 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.36</td>\n",
              "      <td>1583.23</td>\n",
              "      <td>1396.84</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.31</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>8145.32</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.11</td>\n",
              "      <td>23.3537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.50</td>\n",
              "      <td>1584.69</td>\n",
              "      <td>1396.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8152.85</td>\n",
              "      <td>8.4403</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.18</td>\n",
              "      <td>1582.35</td>\n",
              "      <td>1405.61</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.03</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8150.17</td>\n",
              "      <td>8.3901</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.85</td>\n",
              "      <td>23.3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1585.61</td>\n",
              "      <td>1392.27</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.49</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8146.56</td>\n",
              "      <td>8.3878</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.96</td>\n",
              "      <td>23.2951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.68</td>\n",
              "      <td>1588.63</td>\n",
              "      <td>1397.65</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.58</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8147.80</td>\n",
              "      <td>8.3869</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.14</td>\n",
              "      <td>23.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24715</th>\n",
              "      <td>100</td>\n",
              "      <td>148</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.78</td>\n",
              "      <td>1596.01</td>\n",
              "      <td>1424.11</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.66</td>\n",
              "      <td>2388.30</td>\n",
              "      <td>8138.08</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24716</th>\n",
              "      <td>100</td>\n",
              "      <td>149</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.29</td>\n",
              "      <td>1596.38</td>\n",
              "      <td>1429.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.91</td>\n",
              "      <td>2388.28</td>\n",
              "      <td>8144.36</td>\n",
              "      <td>8.5174</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.50</td>\n",
              "      <td>22.9746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24717</th>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.84</td>\n",
              "      <td>1604.53</td>\n",
              "      <td>1431.41</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.44</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8135.95</td>\n",
              "      <td>8.5223</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.39</td>\n",
              "      <td>23.0682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24718</th>\n",
              "      <td>100</td>\n",
              "      <td>151</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.94</td>\n",
              "      <td>1597.56</td>\n",
              "      <td>1426.57</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8141.24</td>\n",
              "      <td>8.5148</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.31</td>\n",
              "      <td>23.0753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24719</th>\n",
              "      <td>100</td>\n",
              "      <td>152</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.64</td>\n",
              "      <td>1599.04</td>\n",
              "      <td>1436.06</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.48</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8136.98</td>\n",
              "      <td>8.5150</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.56</td>\n",
              "      <td>23.0847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24720 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "60ac9ced-fd1a-49b4-e444-3f9afe6249d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16596, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "onw4pCwZy-1s",
        "outputId": "67628ee8-e834-438a-a49f-d93b46a89654"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.59  1592.40  1409.87  14.62  21.58  560.53  2388.22  9085.50   \n",
              "1  518.67  642.56  1587.42  1409.69  14.62  21.61  553.33  2388.18  9050.97   \n",
              "2  518.67  642.75  1591.93  1417.66  14.62  21.60  563.61  2388.31  9091.69   \n",
              "3  518.67  642.28  1584.68  1406.56  14.62  21.61  552.75  2388.07  9048.23   \n",
              "4  518.67  642.15  1580.59  1397.26  14.62  21.58  553.82  2387.96  9050.89   \n",
              "\n",
              "    s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0  1.31  ...  528.05  2388.23  8158.77  8.2966  0.03   393  2388  100.0   \n",
              "1  1.30  ...  520.90  2388.17  8128.04  8.4514  0.03   392  2388  100.0   \n",
              "2  1.31  ...  531.36  2388.33  8173.56  8.3057  0.03   395  2388  100.0   \n",
              "3  1.30  ...  521.27  2388.09  8133.78  8.4337  0.03   392  2388  100.0   \n",
              "4  1.30  ...  521.74  2387.96  8132.51  8.3900  0.03   390  2388  100.0   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  39.43  23.5679  \n",
              "1  38.83  23.2821  \n",
              "2  39.27  23.6440  \n",
              "3  38.70  23.3804  \n",
              "4  38.89  23.4463  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.59</td>\n",
              "      <td>1592.40</td>\n",
              "      <td>1409.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.58</td>\n",
              "      <td>560.53</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>9085.50</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>528.05</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8158.77</td>\n",
              "      <td>8.2966</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.43</td>\n",
              "      <td>23.5679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.56</td>\n",
              "      <td>1587.42</td>\n",
              "      <td>1409.69</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.33</td>\n",
              "      <td>2388.18</td>\n",
              "      <td>9050.97</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>520.90</td>\n",
              "      <td>2388.17</td>\n",
              "      <td>8128.04</td>\n",
              "      <td>8.4514</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.83</td>\n",
              "      <td>23.2821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.75</td>\n",
              "      <td>1591.93</td>\n",
              "      <td>1417.66</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.60</td>\n",
              "      <td>563.61</td>\n",
              "      <td>2388.31</td>\n",
              "      <td>9091.69</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>531.36</td>\n",
              "      <td>2388.33</td>\n",
              "      <td>8173.56</td>\n",
              "      <td>8.3057</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.27</td>\n",
              "      <td>23.6440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.28</td>\n",
              "      <td>1584.68</td>\n",
              "      <td>1406.56</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.75</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>9048.23</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>521.27</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8133.78</td>\n",
              "      <td>8.4337</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.70</td>\n",
              "      <td>23.3804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1580.59</td>\n",
              "      <td>1397.26</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.58</td>\n",
              "      <td>553.82</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>9050.89</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>8132.51</td>\n",
              "      <td>8.3900</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.89</td>\n",
              "      <td>23.4463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lmFKjQaeip1b",
        "outputId": "c6b53fbe-3a2e-42a4-b67f-a479b6839e94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  258\n",
              "1            1     2  257\n",
              "2            1     3  256\n",
              "3            1     4  255\n",
              "4            1     5  254"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "691d6a52-4156-45da-d46c-217c5861f5e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  258\n",
              "1  257\n",
              "2  256\n",
              "3  255\n",
              "4  254"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "26hK4VWkx1R7",
        "outputId": "8370579e-ea05-468a-e925-f2332242f686"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.36  1583.23  1396.84  14.62  21.61  553.97  2387.96  9062.17   \n",
              "1  518.67  642.50  1584.69  1396.89  14.62  21.61  554.55  2388.00  9061.78   \n",
              "2  518.67  642.18  1582.35  1405.61  14.62  21.61  554.43  2388.03  9070.23   \n",
              "3  518.67  642.92  1585.61  1392.27  14.62  21.61  555.21  2388.00  9064.57   \n",
              "4  518.67  641.68  1588.63  1397.65  14.62  21.61  554.74  2388.04  9076.14   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  522.31  2388.01  8145.32  8.4246  0.03   391  2388  100.0  39.11   \n",
              "1  1.3  ...  522.42  2388.03  8152.85  8.4403  0.03   392  2388  100.0  38.99   \n",
              "2  1.3  ...  522.03  2388.00  8150.17  8.3901  0.03   391  2388  100.0  38.85   \n",
              "3  1.3  ...  522.49  2388.08  8146.56  8.3878  0.03   392  2388  100.0  38.96   \n",
              "4  1.3  ...  522.58  2388.03  8147.80  8.3869  0.03   392  2388  100.0  39.14   \n",
              "\n",
              "      s_20  \n",
              "0  23.3537  \n",
              "1  23.4491  \n",
              "2  23.3669  \n",
              "3  23.2951  \n",
              "4  23.4583  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.36</td>\n",
              "      <td>1583.23</td>\n",
              "      <td>1396.84</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.97</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>9062.17</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.31</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>8145.32</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.11</td>\n",
              "      <td>23.3537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.50</td>\n",
              "      <td>1584.69</td>\n",
              "      <td>1396.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.55</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>9061.78</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8152.85</td>\n",
              "      <td>8.4403</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.18</td>\n",
              "      <td>1582.35</td>\n",
              "      <td>1405.61</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.43</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>9070.23</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.03</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8150.17</td>\n",
              "      <td>8.3901</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.85</td>\n",
              "      <td>23.3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1585.61</td>\n",
              "      <td>1392.27</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>555.21</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>9064.57</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.49</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8146.56</td>\n",
              "      <td>8.3878</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.96</td>\n",
              "      <td>23.2951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.68</td>\n",
              "      <td>1588.63</td>\n",
              "      <td>1397.65</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.74</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9076.14</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.58</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8147.80</td>\n",
              "      <td>8.3869</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.14</td>\n",
              "      <td>23.4583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Construction"
      ],
      "metadata": {
        "id": "SL1dv6EX4NUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "PA_LrxmV4NUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "BV6PD9sl4NUw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "83kJj9eJ4NU1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "t18eQ8H3EfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "Ex7mZbQNEfGW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "SPE41-R2EfGX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "a2kynIDbEfGZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[index_cols[1]]+[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import is_finalizing\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class MLPWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "    def clean_cols(self,df):\n",
        "        if(\"unit_number\" in df.columns): del df[\"unit_number\"]\n",
        "        if(\"unit_number\" in df.columns): del df[\"unit_number\"]\n",
        "        if(\"time\" in df.columns): del df[\"time\"]\n",
        "        if((not self.include_settings)): \n",
        "            for col in settings_cols:\n",
        "                if(col in df.columns): del df[col]\n",
        "        return df\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Drop irrelevant column\n",
        "        data = pd.DataFrame(X).copy()\n",
        "        data = self.clean_cols(data)\n",
        "        \n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data)\n",
        "        data = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out())\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "\n",
        "        # Scale the data\n",
        "        data = self.scaler.fit_transform(data)\n",
        "        data = pd.DataFrame(data, \n",
        "                            columns=self.scaler.get_feature_names_out())\n",
        "        X_train = data.copy()\n",
        "        \n",
        "        # Clip and transform labels\n",
        "        data2 = pd.DataFrame(y, columns=[\"RUL\"]).copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = data2\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        INPUT_SHAPE = X_train.shape[1]\n",
        "\n",
        "        # Fit model\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.columns) != len(self.feature_cols)):\n",
        "            X_train = self.transform_features(X)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def transform_features(self, df):\n",
        "        # Drop irrelevant column\n",
        "        data = pd.DataFrame(df).copy()\n",
        "        data = self.clean_cols(data)\n",
        "        \n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.transform(data)\n",
        "        data = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out())\n",
        "        # self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "\n",
        "        # Scale the data\n",
        "        data = self.scaler.transform(data)\n",
        "        data = pd.DataFrame(data, \n",
        "                            columns=self.scaler.get_feature_names_out())\n",
        "        return data\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        X_test = self.transform_features(X)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = pd.DataFrame(y, columns=[\"RUL\"]).copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = data2\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)"
      ],
      "metadata": {
        "id": "-mG7sVkcpALn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = pd.DataFrame(test)\n",
        "    test2 = model.clean_cols(test2)\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2)\n",
        "    test2 = pd.DataFrame(transf, \n",
        "                         columns=model.polyft.get_feature_names_out())\n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2 = model.scaler.transform(test2)\n",
        "    test2 = pd.DataFrame(test2, \n",
        "                         columns=model.polyft.get_feature_names_out())\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 layer4=None, activation4=\"tanh\"    , dropout4=0.1,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model.add(Dense(layer1, input_dim=INPUT_SHAPE, activation=activation1))\n",
        "    model.add(Dropout(dropout1))\n",
        "\n",
        "    # Additional hidden layers\n",
        "    if(layer2 is not None):\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        if (layer3 is not None):\n",
        "            model.add(Dense(layer3, activation=activation3))\n",
        "            model.add(Dropout(dropout3))\n",
        "            if (layer4 is not None):\n",
        "                model.add(Dense(layer4, activation=activation4))\n",
        "                model.add(Dropout(dropout4))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "NbakKD-DlU5-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-1 "
      ],
      "metadata": {
        "id": "DU8TxguXIChd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "zkCJJsiS-J7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6216329789186076  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 140),\n",
        "('basemodel__epochs', 40),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__dropout1', 0.6738055381845307),\n",
        "('basemodel__model__layer1', 274),\n",
        "('basemodel__model__learning_rate', 0.0026697581512638087),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "iWX0RiAL4uGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=140,\n",
        "                           epochs=40,\n",
        "                           model__activation1='selu',\n",
        "                           model__dropout1=0.6738055381845307, \n",
        "                           model__layer1=274, \n",
        "                           model__learning_rate=0.0026697581512638087,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "id": "xfYRKHQKi3Xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a039c0da-caba-4c35-90fb-0e4656098e53"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=140, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=40, model=<function create_model at 0x00000174B0F1F820>, model__activation1='selu', model__dropout1=0.6738055381845307, model__layer1=274, model__learning_rate=0.0026697581512638087, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000174B06D62B0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000174B06D6AC0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SF4CE-ab5IKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd32ec6-e05e-43e8-f2d0-7bc9d70e839d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 274)               6028      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 274)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 275       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,303\n",
            "Trainable params: 6,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=15391.626, rmse=124.063, r2=-0.635; v_loss=13940.530, v_rmse=118.070, v_r2=-0.078; \n",
            "E 2\t: loss=4297.826, rmse=65.558, r2=0.543; v_loss=7979.636, v_rmse=89.329, v_r2=0.383; \n",
            "E 3\t: loss=3759.965, rmse=61.319, r2=0.601; v_loss=7625.051, v_rmse=87.322, v_r2=0.410; \n",
            "E 4\t: loss=3654.921, rmse=60.456, r2=0.612; v_loss=7147.630, v_rmse=84.544, v_r2=0.447; \n",
            "E 5\t: loss=3574.013, rmse=59.783, r2=0.620; v_loss=7012.498, v_rmse=83.741, v_r2=0.458; \n",
            "E 6\t: loss=3522.844, rmse=59.354, r2=0.626; v_loss=7304.687, v_rmse=85.467, v_r2=0.435; \n",
            "E 7\t: loss=3511.281, rmse=59.256, r2=0.627; v_loss=7137.217, v_rmse=84.482, v_r2=0.448; \n",
            "E 8\t: loss=3482.232, rmse=59.010, r2=0.630; v_loss=7044.893, v_rmse=83.934, v_r2=0.455; \n",
            "E 9\t: loss=3454.641, rmse=58.776, r2=0.633; v_loss=7183.586, v_rmse=84.756, v_r2=0.444; \n",
            "E 10\t: loss=3458.954, rmse=58.813, r2=0.633; v_loss=6991.294, v_rmse=83.614, v_r2=0.459; \n",
            "E 11\t: loss=3446.091, rmse=58.703, r2=0.634; v_loss=7321.890, v_rmse=85.568, v_r2=0.434; \n",
            "E 12\t: loss=3440.448, rmse=58.655, r2=0.635; v_loss=6963.527, v_rmse=83.448, v_r2=0.461; \n",
            "E 13\t: loss=3443.034, rmse=58.677, r2=0.634; v_loss=7018.608, v_rmse=83.777, v_r2=0.457; \n",
            "E 14\t: loss=3413.951, rmse=58.429, r2=0.637; v_loss=6976.922, v_rmse=83.528, v_r2=0.460; \n",
            "E 15\t: loss=3451.119, rmse=58.746, r2=0.633; v_loss=6986.935, v_rmse=83.588, v_r2=0.460; \n",
            "E 16\t: loss=3426.032, rmse=58.532, r2=0.636; v_loss=6873.676, v_rmse=82.908, v_r2=0.468; \n",
            "E 17\t: loss=3405.251, rmse=58.355, r2=0.638; v_loss=6899.734, v_rmse=83.065, v_r2=0.466; \n",
            "E 18\t: loss=3426.794, rmse=58.539, r2=0.636; v_loss=7092.770, v_rmse=84.219, v_r2=0.451; \n",
            "E 19\t: loss=3397.832, rmse=58.291, r2=0.639; v_loss=6840.988, v_rmse=82.710, v_r2=0.471; \n",
            "E 20\t: loss=3422.320, rmse=58.501, r2=0.636; v_loss=6959.778, v_rmse=83.425, v_r2=0.462; \n",
            "E 21\t: loss=3410.470, rmse=58.399, r2=0.638; v_loss=6767.211, v_rmse=82.263, v_r2=0.477; \n",
            "E 22\t: loss=3379.077, rmse=58.130, r2=0.641; v_loss=6846.896, v_rmse=82.746, v_r2=0.470; \n",
            "E 23\t: loss=3415.061, rmse=58.439, r2=0.637; v_loss=6949.107, v_rmse=83.361, v_r2=0.462; \n",
            "E 24\t: loss=3427.449, rmse=58.544, r2=0.636; v_loss=6895.478, v_rmse=83.039, v_r2=0.467; \n",
            "E 25\t: loss=3393.671, rmse=58.255, r2=0.640; v_loss=6920.535, v_rmse=83.190, v_r2=0.465; \n",
            "E 26\t: loss=3403.947, rmse=58.343, r2=0.638; v_loss=6906.608, v_rmse=83.106, v_r2=0.466; \n",
            "E 27\t: loss=3414.804, rmse=58.436, r2=0.637; v_loss=6656.699, v_rmse=81.589, v_r2=0.485; \n",
            "Finished: 2022-11-02 09:34:41.939146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "9vLfPZkw5Ixg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c52ebce-6092-40bc-fda6-2c93db8e6379"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.477,RMSE=-50.311\n",
            "Finished: 2022-11-02 09:35:06.085026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "mMYPm8b65n0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8769850696112492  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 47),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.004394643527896066),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 80),\n",
        "('scaler', MinMaxScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "uooUt5Yq5n0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=47,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.004394643527896066,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e33db13-3d72-4c12-a358-d2d5e3bc4062",
        "id": "Lj8fIDg15n0X"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=47, model=<function create_model at 0x00000174B0F1F820>, model__activation1='tanh', model__dropout1=0.1, model__layer1=512, model__learning_rate=0.004394643527896066, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000174B2EFCA30>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000174B2765700>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "y1uxSqWy5n0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70080565-b48b-4746-e409-239833954309"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,777\n",
            "Trainable params: 11,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=399.719, rmse=19.993, r2=0.242; v_loss=120.266, v_rmse=10.967, v_r2=0.788; \n",
            "E 2\t: loss=90.087, rmse=9.491, r2=0.829; v_loss=110.534, v_rmse=10.514, v_r2=0.805; \n",
            "E 3\t: loss=86.128, rmse=9.281, r2=0.837; v_loss=104.702, v_rmse=10.232, v_r2=0.815; \n",
            "E 4\t: loss=83.285, rmse=9.126, r2=0.842; v_loss=99.042, v_rmse=9.952, v_r2=0.825; \n",
            "E 5\t: loss=79.973, rmse=8.943, r2=0.848; v_loss=104.281, v_rmse=10.212, v_r2=0.816; \n",
            "E 6\t: loss=77.831, rmse=8.822, r2=0.852; v_loss=105.798, v_rmse=10.286, v_r2=0.813; \n",
            "E 7\t: loss=75.921, rmse=8.713, r2=0.856; v_loss=115.714, v_rmse=10.757, v_r2=0.796; \n",
            "E 8\t: loss=75.038, rmse=8.662, r2=0.858; v_loss=114.404, v_rmse=10.696, v_r2=0.798; \n",
            "E 9\t: loss=73.844, rmse=8.593, r2=0.860; v_loss=94.146, v_rmse=9.703, v_r2=0.834; \n",
            "E 10\t: loss=72.372, rmse=8.507, r2=0.863; v_loss=101.321, v_rmse=10.066, v_r2=0.821; \n",
            "E 11\t: loss=70.567, rmse=8.400, r2=0.866; v_loss=88.459, v_rmse=9.405, v_r2=0.844; \n",
            "E 12\t: loss=69.364, rmse=8.329, r2=0.868; v_loss=91.867, v_rmse=9.585, v_r2=0.838; \n",
            "E 13\t: loss=67.911, rmse=8.241, r2=0.871; v_loss=110.913, v_rmse=10.532, v_r2=0.804; \n",
            "E 14\t: loss=67.615, rmse=8.223, r2=0.872; v_loss=94.815, v_rmse=9.737, v_r2=0.833; \n",
            "E 15\t: loss=66.795, rmse=8.173, r2=0.873; v_loss=106.351, v_rmse=10.313, v_r2=0.813; \n",
            "E 16\t: loss=66.486, rmse=8.154, r2=0.874; v_loss=95.990, v_rmse=9.797, v_r2=0.831; \n",
            "E 17\t: loss=66.567, rmse=8.159, r2=0.874; v_loss=103.943, v_rmse=10.195, v_r2=0.817; \n",
            "E 18\t: loss=65.580, rmse=8.098, r2=0.876; v_loss=90.400, v_rmse=9.508, v_r2=0.841; \n",
            "E 19\t: loss=65.250, rmse=8.078, r2=0.876; v_loss=93.888, v_rmse=9.690, v_r2=0.834; \n",
            "E 20\t: loss=65.098, rmse=8.068, r2=0.877; v_loss=101.603, v_rmse=10.080, v_r2=0.821; \n",
            "E 21\t: loss=64.601, rmse=8.037, r2=0.878; v_loss=112.966, v_rmse=10.629, v_r2=0.801; \n",
            "E 22\t: loss=64.617, rmse=8.038, r2=0.877; v_loss=105.341, v_rmse=10.264, v_r2=0.814; \n",
            "E 23\t: loss=64.182, rmse=8.011, r2=0.878; v_loss=93.631, v_rmse=9.676, v_r2=0.835; \n",
            "E 24\t: loss=64.446, rmse=8.028, r2=0.878; v_loss=105.053, v_rmse=10.250, v_r2=0.815; \n",
            "E 25\t: loss=63.753, rmse=7.985, r2=0.879; v_loss=104.602, v_rmse=10.227, v_r2=0.816; \n",
            "E 26\t: loss=64.205, rmse=8.013, r2=0.878; v_loss=96.233, v_rmse=9.810, v_r2=0.830; \n",
            "E 27\t: loss=63.498, rmse=7.969, r2=0.880; v_loss=85.638, v_rmse=9.254, v_r2=0.849; \n",
            "E 28\t: loss=63.616, rmse=7.976, r2=0.879; v_loss=93.893, v_rmse=9.690, v_r2=0.834; \n",
            "E 29\t: loss=62.861, rmse=7.928, r2=0.881; v_loss=99.747, v_rmse=9.987, v_r2=0.824; \n",
            "E 30\t: loss=62.945, rmse=7.934, r2=0.881; v_loss=109.902, v_rmse=10.483, v_r2=0.806; \n",
            "E 31\t: loss=62.643, rmse=7.915, r2=0.881; v_loss=91.187, v_rmse=9.549, v_r2=0.839; \n",
            "E 32\t: loss=62.972, rmse=7.936, r2=0.881; v_loss=115.665, v_rmse=10.755, v_r2=0.796; \n",
            "E 33\t: loss=62.603, rmse=7.912, r2=0.881; v_loss=108.441, v_rmse=10.414, v_r2=0.809; \n",
            "E 34\t: loss=62.523, rmse=7.907, r2=0.881; v_loss=102.205, v_rmse=10.110, v_r2=0.820; \n",
            "E 35\t: loss=62.030, rmse=7.876, r2=0.882; v_loss=105.104, v_rmse=10.252, v_r2=0.815; \n",
            "E 36\t: loss=62.118, rmse=7.881, r2=0.882; v_loss=100.599, v_rmse=10.030, v_r2=0.823; \n",
            "E 37\t: loss=61.757, rmse=7.859, r2=0.883; v_loss=88.947, v_rmse=9.431, v_r2=0.843; \n",
            "E 38\t: loss=61.681, rmse=7.854, r2=0.883; v_loss=101.480, v_rmse=10.074, v_r2=0.821; \n",
            "E 39\t: loss=61.338, rmse=7.832, r2=0.884; v_loss=87.777, v_rmse=9.369, v_r2=0.845; \n",
            "E 40\t: loss=61.622, rmse=7.850, r2=0.883; v_loss=100.580, v_rmse=10.029, v_r2=0.823; \n",
            "E 41\t: loss=61.545, rmse=7.845, r2=0.883; v_loss=87.664, v_rmse=9.363, v_r2=0.845; \n",
            "E 42\t: loss=60.786, rmse=7.797, r2=0.885; v_loss=85.222, v_rmse=9.232, v_r2=0.850; \n",
            "E 43\t: loss=61.432, rmse=7.838, r2=0.884; v_loss=94.694, v_rmse=9.731, v_r2=0.833; \n",
            "E 44\t: loss=61.328, rmse=7.831, r2=0.884; v_loss=92.660, v_rmse=9.626, v_r2=0.837; \n",
            "E 45\t: loss=61.351, rmse=7.833, r2=0.884; v_loss=98.644, v_rmse=9.932, v_r2=0.826; \n",
            "E 46\t: loss=61.052, rmse=7.814, r2=0.884; v_loss=98.025, v_rmse=9.901, v_r2=0.827; \n",
            "E 47\t: loss=60.973, rmse=7.809, r2=0.884; v_loss=99.504, v_rmse=9.975, v_r2=0.825; \n",
            "Finished: 2022-11-02 09:37:59.529471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Q1waoIXF5n0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8897a418-cff0-4916-b52e-fad21afe8140"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.845,RMSE=-9.917\n",
            "Finished: 2022-11-02 09:37:59.851027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL "
      ],
      "metadata": {
        "id": "X4OKIiMD6X4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.623044428465008  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 114),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.8089278925268311),\n",
        "('basemodel__model__layer1', 453),\n",
        "('basemodel__model__learning_rate', 0.00336601478011081),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.11337798870650495),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "OUMvs31w6X4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=114,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.8089278925268311, \n",
        "                           model__layer1=453, \n",
        "                           model__learning_rate=0.00336601478011081,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.11337798870650495, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c38870-c668-4066-c611-23b80291ecda",
        "id": "dpKrE34E6X4j"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=114, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=50, model=<function create_model at 0x00000174B0F1F820>, model__activation1='tanh', model__dropout1=0.8089278925268311, model__layer1=453, model__learning_rate=0.00336601478011081, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000174C6BCA760>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000174C6BB5CD0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.11337798870650495, verbose=0),\n",
              "                    poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "HHlBlEju6X4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f973b85-1975-45d1-f21d-93439cfa9716"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 453)               916872    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 453)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 454       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 917,326\n",
            "Trainable params: 917,326\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=13080.769, rmse=114.371, r2=-0.377; v_loss=14543.778, v_rmse=120.598, v_r2=-0.225; \n",
            "E 2\t: loss=8968.767, rmse=94.704, r2=0.056; v_loss=13139.883, v_rmse=114.629, v_r2=-0.107; \n",
            "E 3\t: loss=8105.598, rmse=90.031, r2=0.147; v_loss=11989.110, v_rmse=109.495, v_r2=-0.010; \n",
            "E 4\t: loss=7624.253, rmse=87.317, r2=0.198; v_loss=11161.386, v_rmse=105.647, v_r2=0.060; \n",
            "E 5\t: loss=7104.806, rmse=84.290, r2=0.252; v_loss=10493.174, v_rmse=102.436, v_r2=0.116; \n",
            "E 6\t: loss=6927.544, rmse=83.232, r2=0.271; v_loss=10144.212, v_rmse=100.718, v_r2=0.146; \n",
            "E 7\t: loss=6804.084, rmse=82.487, r2=0.284; v_loss=9991.804, v_rmse=99.959, v_r2=0.158; \n",
            "E 8\t: loss=6739.010, rmse=82.091, r2=0.291; v_loss=9502.823, v_rmse=97.482, v_r2=0.200; \n",
            "E 9\t: loss=6593.305, rmse=81.199, r2=0.306; v_loss=9434.260, v_rmse=97.130, v_r2=0.205; \n",
            "E 10\t: loss=6511.105, rmse=80.691, r2=0.315; v_loss=9164.734, v_rmse=95.733, v_r2=0.228; \n",
            "E 11\t: loss=6358.593, rmse=79.741, r2=0.331; v_loss=8974.083, v_rmse=94.732, v_r2=0.244; \n",
            "E 12\t: loss=6366.244, rmse=79.789, r2=0.330; v_loss=8931.783, v_rmse=94.508, v_r2=0.248; \n",
            "E 13\t: loss=6261.891, rmse=79.132, r2=0.341; v_loss=8681.325, v_rmse=93.174, v_r2=0.269; \n",
            "E 14\t: loss=6209.010, rmse=78.797, r2=0.346; v_loss=8406.404, v_rmse=91.686, v_r2=0.292; \n",
            "E 15\t: loss=6130.092, rmse=78.295, r2=0.355; v_loss=8128.775, v_rmse=90.160, v_r2=0.315; \n",
            "E 16\t: loss=6021.086, rmse=77.596, r2=0.366; v_loss=8118.939, v_rmse=90.105, v_r2=0.316; \n",
            "E 17\t: loss=5877.735, rmse=76.666, r2=0.381; v_loss=8149.234, v_rmse=90.273, v_r2=0.314; \n",
            "E 18\t: loss=5832.937, rmse=76.374, r2=0.386; v_loss=7769.109, v_rmse=88.143, v_r2=0.346; \n",
            "E 19\t: loss=5751.122, rmse=75.836, r2=0.395; v_loss=7694.328, v_rmse=87.717, v_r2=0.352; \n",
            "E 20\t: loss=5670.278, rmse=75.301, r2=0.403; v_loss=7766.313, v_rmse=88.127, v_r2=0.346; \n",
            "E 21\t: loss=5714.618, rmse=75.595, r2=0.399; v_loss=7757.214, v_rmse=88.075, v_r2=0.347; \n",
            "E 22\t: loss=5606.438, rmse=74.876, r2=0.410; v_loss=7520.217, v_rmse=86.719, v_r2=0.367; \n",
            "E 23\t: loss=5508.511, rmse=74.219, r2=0.420; v_loss=7655.162, v_rmse=87.494, v_r2=0.355; \n",
            "E 24\t: loss=5472.032, rmse=73.973, r2=0.424; v_loss=7316.985, v_rmse=85.539, v_r2=0.384; \n",
            "E 25\t: loss=5384.235, rmse=73.377, r2=0.433; v_loss=7381.154, v_rmse=85.914, v_r2=0.378; \n",
            "E 26\t: loss=5400.106, rmse=73.485, r2=0.432; v_loss=7485.410, v_rmse=86.518, v_r2=0.369; \n",
            "E 27\t: loss=5287.206, rmse=72.713, r2=0.443; v_loss=7499.763, v_rmse=86.601, v_r2=0.368; \n",
            "E 28\t: loss=5329.271, rmse=73.002, r2=0.439; v_loss=7313.981, v_rmse=85.522, v_r2=0.384; \n",
            "E 29\t: loss=5245.806, rmse=72.428, r2=0.448; v_loss=7327.080, v_rmse=85.598, v_r2=0.383; \n",
            "E 30\t: loss=5143.151, rmse=71.716, r2=0.459; v_loss=7358.859, v_rmse=85.784, v_r2=0.380; \n",
            "E 31\t: loss=5163.452, rmse=71.857, r2=0.457; v_loss=7430.913, v_rmse=86.203, v_r2=0.374; \n",
            "E 32\t: loss=5091.724, rmse=71.356, r2=0.464; v_loss=7261.932, v_rmse=85.217, v_r2=0.388; \n",
            "E 33\t: loss=5003.114, rmse=70.733, r2=0.473; v_loss=7409.651, v_rmse=86.079, v_r2=0.376; \n",
            "E 34\t: loss=5090.844, rmse=71.350, r2=0.464; v_loss=7215.802, v_rmse=84.946, v_r2=0.392; \n",
            "E 35\t: loss=5070.253, rmse=71.206, r2=0.466; v_loss=7232.937, v_rmse=85.047, v_r2=0.391; \n",
            "E 36\t: loss=5066.106, rmse=71.177, r2=0.467; v_loss=7054.067, v_rmse=83.988, v_r2=0.406; \n",
            "E 37\t: loss=4938.668, rmse=70.276, r2=0.480; v_loss=7246.546, v_rmse=85.127, v_r2=0.390; \n",
            "E 38\t: loss=4956.621, rmse=70.403, r2=0.478; v_loss=7157.285, v_rmse=84.601, v_r2=0.397; \n",
            "E 39\t: loss=4908.781, rmse=70.063, r2=0.483; v_loss=7099.525, v_rmse=84.259, v_r2=0.402; \n",
            "E 40\t: loss=4871.393, rmse=69.795, r2=0.487; v_loss=7244.630, v_rmse=85.115, v_r2=0.390; \n",
            "E 41\t: loss=4841.985, rmse=69.584, r2=0.490; v_loss=7003.344, v_rmse=83.686, v_r2=0.410; \n",
            "E 42\t: loss=4792.143, rmse=69.225, r2=0.496; v_loss=7106.175, v_rmse=84.298, v_r2=0.401; \n",
            "E 43\t: loss=4783.424, rmse=69.162, r2=0.497; v_loss=6889.513, v_rmse=83.003, v_r2=0.420; \n",
            "E 44\t: loss=4790.886, rmse=69.216, r2=0.496; v_loss=7234.405, v_rmse=85.055, v_r2=0.391; \n",
            "E 45\t: loss=4771.514, rmse=69.076, r2=0.498; v_loss=7131.924, v_rmse=84.451, v_r2=0.399; \n",
            "E 46\t: loss=4711.023, rmse=68.637, r2=0.504; v_loss=7070.557, v_rmse=84.087, v_r2=0.404; \n",
            "E 47\t: loss=4725.297, rmse=68.741, r2=0.503; v_loss=7017.301, v_rmse=83.769, v_r2=0.409; \n",
            "E 48\t: loss=4662.987, rmse=68.286, r2=0.509; v_loss=7054.746, v_rmse=83.993, v_r2=0.406; \n",
            "E 49\t: loss=4657.406, rmse=68.245, r2=0.510; v_loss=6941.058, v_rmse=83.313, v_r2=0.415; \n",
            "E 50\t: loss=4656.492, rmse=68.238, r2=0.510; v_loss=6949.235, v_rmse=83.362, v_r2=0.415; \n",
            "Finished: 2022-11-02 09:43:53.284552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "XrGQOj3e6X4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753fbaad-0c75-4a08-af78-a220e55d2bde"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000174B05765E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "R2=-0.375,RMSE=-48.532\n",
            "Finished: 2022-11-02 09:43:53.407527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "xUq7j-FC7J6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8488892610573798  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 97),\n",
        "('basemodel__epochs', 24),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__dropout1', 0.15096258494167586),\n",
        "('basemodel__model__layer1', 264),\n",
        "('basemodel__model__learning_rate', 0.0040754761072153145),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.17873567459530804),\n",
        "('clip_y', 105),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "XfyXyuQl7J65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=105\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=97,\n",
        "                           epochs=250,\n",
        "                           model__activation1='relu',\n",
        "                           model__dropout1=0.15096258494167586, \n",
        "                           model__layer1=264, \n",
        "                           model__learning_rate=0.0040754761072153145,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.17873567459530804, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33f644a-99b6-443d-9c0a-8a9fcc412a43",
        "id": "AxhumNq67J7A"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=97, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=250, model=<function create_model at 0x00000174B0F1F820>, model__activation1='relu', model__dropout1=0.15096258494167586, model__layer1=264, model__learning_rate=0.0040754761072153145, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000174FBCED2E0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000174C54771F0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.17873567459530804, verbose=0),\n",
              "                    clip_y=105, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "3IOHJ_u87J7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f0895f-776d-4d44-ed3c-52c7f81146b7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 264)               534336    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 264)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 265       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,601\n",
            "Trainable params: 534,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=707.313, rmse=26.595, r2=0.338; v_loss=413.919, v_rmse=20.345, v_r2=0.627; \n",
            "E 2\t: loss=369.791, rmse=19.230, r2=0.654; v_loss=375.372, v_rmse=19.375, v_r2=0.662; \n",
            "E 3\t: loss=332.397, rmse=18.232, r2=0.689; v_loss=368.473, v_rmse=19.196, v_r2=0.668; \n",
            "E 4\t: loss=325.942, rmse=18.054, r2=0.695; v_loss=280.132, v_rmse=16.737, v_r2=0.748; \n",
            "E 5\t: loss=321.509, rmse=17.931, r2=0.699; v_loss=298.286, v_rmse=17.271, v_r2=0.731; \n",
            "E 6\t: loss=302.566, rmse=17.394, r2=0.717; v_loss=313.431, v_rmse=17.704, v_r2=0.718; \n",
            "E 7\t: loss=299.826, rmse=17.315, r2=0.719; v_loss=302.596, v_rmse=17.395, v_r2=0.727; \n",
            "E 8\t: loss=289.958, rmse=17.028, r2=0.729; v_loss=286.833, v_rmse=16.936, v_r2=0.742; \n",
            "E 9\t: loss=289.132, rmse=17.004, r2=0.729; v_loss=258.719, v_rmse=16.085, v_r2=0.767; \n",
            "E 10\t: loss=279.027, rmse=16.704, r2=0.739; v_loss=306.990, v_rmse=17.521, v_r2=0.724; \n",
            "E 11\t: loss=291.154, rmse=17.063, r2=0.728; v_loss=281.711, v_rmse=16.784, v_r2=0.746; \n",
            "E 12\t: loss=286.276, rmse=16.920, r2=0.732; v_loss=259.691, v_rmse=16.115, v_r2=0.766; \n",
            "E 13\t: loss=286.314, rmse=16.921, r2=0.732; v_loss=319.189, v_rmse=17.866, v_r2=0.713; \n",
            "E 14\t: loss=267.239, rmse=16.347, r2=0.750; v_loss=325.353, v_rmse=18.038, v_r2=0.707; \n",
            "E 15\t: loss=261.696, rmse=16.177, r2=0.755; v_loss=304.151, v_rmse=17.440, v_r2=0.726; \n",
            "E 16\t: loss=260.472, rmse=16.139, r2=0.756; v_loss=290.580, v_rmse=17.046, v_r2=0.738; \n",
            "E 17\t: loss=261.487, rmse=16.171, r2=0.755; v_loss=254.864, v_rmse=15.964, v_r2=0.770; \n",
            "E 18\t: loss=258.418, rmse=16.075, r2=0.758; v_loss=297.250, v_rmse=17.241, v_r2=0.732; \n",
            "E 19\t: loss=251.722, rmse=15.866, r2=0.764; v_loss=238.010, v_rmse=15.428, v_r2=0.786; \n",
            "E 20\t: loss=256.690, rmse=16.022, r2=0.760; v_loss=266.478, v_rmse=16.324, v_r2=0.760; \n",
            "E 21\t: loss=242.884, rmse=15.585, r2=0.773; v_loss=228.708, v_rmse=15.123, v_r2=0.794; \n",
            "E 22\t: loss=242.696, rmse=15.579, r2=0.773; v_loss=239.547, v_rmse=15.477, v_r2=0.784; \n",
            "E 23\t: loss=244.822, rmse=15.647, r2=0.771; v_loss=230.824, v_rmse=15.193, v_r2=0.792; \n",
            "E 24\t: loss=245.683, rmse=15.674, r2=0.770; v_loss=248.023, v_rmse=15.749, v_r2=0.777; \n",
            "E 25\t: loss=233.668, rmse=15.286, r2=0.781; v_loss=216.650, v_rmse=14.719, v_r2=0.805; \n",
            "E 26\t: loss=239.878, rmse=15.488, r2=0.776; v_loss=220.041, v_rmse=14.834, v_r2=0.802; \n",
            "E 27\t: loss=231.212, rmse=15.206, r2=0.784; v_loss=289.812, v_rmse=17.024, v_r2=0.739; \n",
            "E 28\t: loss=224.716, rmse=14.991, r2=0.790; v_loss=233.037, v_rmse=15.266, v_r2=0.790; \n",
            "E 29\t: loss=237.596, rmse=15.414, r2=0.778; v_loss=325.943, v_rmse=18.054, v_r2=0.706; \n",
            "E 30\t: loss=227.972, rmse=15.099, r2=0.787; v_loss=224.673, v_rmse=14.989, v_r2=0.798; \n",
            "E 31\t: loss=222.957, rmse=14.932, r2=0.791; v_loss=197.743, v_rmse=14.062, v_r2=0.822; \n",
            "E 32\t: loss=217.473, rmse=14.747, r2=0.797; v_loss=221.354, v_rmse=14.878, v_r2=0.801; \n",
            "E 33\t: loss=224.370, rmse=14.979, r2=0.790; v_loss=254.545, v_rmse=15.954, v_r2=0.771; \n",
            "E 34\t: loss=218.554, rmse=14.784, r2=0.795; v_loss=275.064, v_rmse=16.585, v_r2=0.752; \n",
            "E 35\t: loss=207.841, rmse=14.417, r2=0.806; v_loss=238.463, v_rmse=15.442, v_r2=0.785; \n",
            "E 36\t: loss=213.961, rmse=14.627, r2=0.800; v_loss=193.760, v_rmse=13.920, v_r2=0.826; \n",
            "E 37\t: loss=211.268, rmse=14.535, r2=0.802; v_loss=212.022, v_rmse=14.561, v_r2=0.809; \n",
            "E 38\t: loss=206.373, rmse=14.366, r2=0.807; v_loss=225.142, v_rmse=15.005, v_r2=0.797; \n",
            "E 39\t: loss=203.169, rmse=14.254, r2=0.810; v_loss=220.008, v_rmse=14.833, v_r2=0.802; \n",
            "E 40\t: loss=204.275, rmse=14.292, r2=0.809; v_loss=198.855, v_rmse=14.102, v_r2=0.821; \n",
            "E 41\t: loss=211.240, rmse=14.534, r2=0.802; v_loss=241.442, v_rmse=15.538, v_r2=0.783; \n",
            "E 42\t: loss=200.180, rmse=14.149, r2=0.813; v_loss=201.545, v_rmse=14.197, v_r2=0.818; \n",
            "E 43\t: loss=200.770, rmse=14.169, r2=0.812; v_loss=206.878, v_rmse=14.383, v_r2=0.814; \n",
            "E 44\t: loss=206.166, rmse=14.358, r2=0.807; v_loss=230.581, v_rmse=15.185, v_r2=0.792; \n",
            "E 45\t: loss=203.137, rmse=14.253, r2=0.810; v_loss=215.583, v_rmse=14.683, v_r2=0.806; \n",
            "E 46\t: loss=198.967, rmse=14.106, r2=0.814; v_loss=255.462, v_rmse=15.983, v_r2=0.770; \n",
            "E 47\t: loss=195.594, rmse=13.985, r2=0.817; v_loss=256.377, v_rmse=16.012, v_r2=0.769; \n",
            "E 48\t: loss=194.856, rmse=13.959, r2=0.818; v_loss=216.472, v_rmse=14.713, v_r2=0.805; \n",
            "E 49\t: loss=195.145, rmse=13.969, r2=0.817; v_loss=262.149, v_rmse=16.191, v_r2=0.764; \n",
            "E 50\t: loss=195.609, rmse=13.986, r2=0.817; v_loss=233.160, v_rmse=15.270, v_r2=0.790; \n",
            "E 51\t: loss=199.791, rmse=14.135, r2=0.813; v_loss=216.885, v_rmse=14.727, v_r2=0.805; \n",
            "E 52\t: loss=191.943, rmse=13.854, r2=0.820; v_loss=184.637, v_rmse=13.588, v_r2=0.834; \n",
            "E 53\t: loss=194.898, rmse=13.961, r2=0.818; v_loss=184.825, v_rmse=13.595, v_r2=0.834; \n",
            "E 54\t: loss=198.846, rmse=14.101, r2=0.814; v_loss=213.133, v_rmse=14.599, v_r2=0.808; \n",
            "E 55\t: loss=192.374, rmse=13.870, r2=0.820; v_loss=209.853, v_rmse=14.486, v_r2=0.811; \n",
            "E 56\t: loss=187.300, rmse=13.686, r2=0.825; v_loss=196.693, v_rmse=14.025, v_r2=0.823; \n",
            "E 57\t: loss=194.944, rmse=13.962, r2=0.818; v_loss=196.148, v_rmse=14.005, v_r2=0.823; \n",
            "E 58\t: loss=192.406, rmse=13.871, r2=0.820; v_loss=216.752, v_rmse=14.722, v_r2=0.805; \n",
            "E 59\t: loss=187.230, rmse=13.683, r2=0.825; v_loss=206.507, v_rmse=14.370, v_r2=0.814; \n",
            "E 60\t: loss=186.291, rmse=13.649, r2=0.826; v_loss=192.475, v_rmse=13.874, v_r2=0.827; \n",
            "E 61\t: loss=185.357, rmse=13.615, r2=0.827; v_loss=243.708, v_rmse=15.611, v_r2=0.781; \n",
            "E 62\t: loss=182.712, rmse=13.517, r2=0.829; v_loss=208.032, v_rmse=14.423, v_r2=0.813; \n",
            "E 63\t: loss=194.919, rmse=13.961, r2=0.818; v_loss=230.427, v_rmse=15.180, v_r2=0.792; \n",
            "E 64\t: loss=194.418, rmse=13.943, r2=0.818; v_loss=176.880, v_rmse=13.300, v_r2=0.841; \n",
            "E 65\t: loss=182.691, rmse=13.516, r2=0.829; v_loss=233.820, v_rmse=15.291, v_r2=0.789; \n",
            "E 66\t: loss=184.103, rmse=13.568, r2=0.828; v_loss=208.731, v_rmse=14.448, v_r2=0.812; \n",
            "E 67\t: loss=184.443, rmse=13.581, r2=0.827; v_loss=215.918, v_rmse=14.694, v_r2=0.806; \n",
            "E 68\t: loss=190.441, rmse=13.800, r2=0.822; v_loss=189.192, v_rmse=13.755, v_r2=0.830; \n",
            "E 69\t: loss=177.640, rmse=13.328, r2=0.834; v_loss=209.265, v_rmse=14.466, v_r2=0.812; \n",
            "E 70\t: loss=182.667, rmse=13.515, r2=0.829; v_loss=257.099, v_rmse=16.034, v_r2=0.768; \n",
            "E 71\t: loss=183.283, rmse=13.538, r2=0.828; v_loss=171.238, v_rmse=13.086, v_r2=0.846; \n",
            "E 72\t: loss=179.810, rmse=13.409, r2=0.832; v_loss=190.454, v_rmse=13.800, v_r2=0.828; \n",
            "E 73\t: loss=183.272, rmse=13.538, r2=0.829; v_loss=212.951, v_rmse=14.593, v_r2=0.808; \n",
            "E 74\t: loss=178.059, rmse=13.344, r2=0.833; v_loss=227.598, v_rmse=15.086, v_r2=0.795; \n",
            "Finished: 2022-11-02 09:53:36.564649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "bQgkkrV47J7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d966071e-75fb-438c-94f3-4c9bcadb3220"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.814,RMSE=-14.569\n",
            "Finished: 2022-11-02 09:53:36.695682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-2"
      ],
      "metadata": {
        "id": "FDHk5EzS8XuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "w3w40nFu8Xug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.6117982346232361  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 215),\n",
        "('basemodel__epochs', 31),\n",
        "('basemodel__model__activation1', 'sigmoid'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.535540507143301),\n",
        "('basemodel__model__dropout2', 0.2838929138188482),\n",
        "('basemodel__model__layer1', 62),\n",
        "('basemodel__model__layer2', 401),\n",
        "('basemodel__model__learning_rate', 0.002945657435413331),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.3558423584914324),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "Bt8LxsyX8Xun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=215,\n",
        "                           epochs=31,\n",
        "                           model__activation1='sigmoid',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.535540507143301, \n",
        "                           model__dropout2=0.2838929138188482, \n",
        "                           model__layer1=62, \n",
        "                           model__layer2=401, \n",
        "                           model__learning_rate=0.002945657435413331,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.3558423584914324, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1285cad2-5763-4072-a729-f73eda5368b8",
        "id": "AzAbUlFJ8Xuv"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=215, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=31, model=<function create_model at 0x00000174B0F1F820>, model__activation1='sigmoid', model__activation2='elu', model__dropout1=0.535540507143301, model__dropout...del__layer2=401, model__learning_rate=0.002945657435413331, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000175F2634640>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000175F26347F0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.3558423584914324, verbose=0))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "x0gUTFtS8Xu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c037698e-4a2a-4773-c126-0a8f9c714cd8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 62)                1364      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 62)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 401)               25263     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 401)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,029\n",
            "Trainable params: 27,029\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=8377.563, rmse=91.529, r2=0.194; v_loss=3677.683, v_rmse=60.644, v_r2=0.569; \n",
            "E 2\t: loss=4548.064, rmse=67.439, r2=0.562; v_loss=3830.185, v_rmse=61.888, v_r2=0.551; \n",
            "E 3\t: loss=4373.919, rmse=66.136, r2=0.579; v_loss=3585.292, v_rmse=59.877, v_r2=0.580; \n",
            "E 4\t: loss=4208.685, rmse=64.874, r2=0.595; v_loss=3547.162, v_rmse=59.558, v_r2=0.584; \n",
            "E 5\t: loss=4152.713, rmse=64.442, r2=0.600; v_loss=3723.802, v_rmse=61.023, v_r2=0.564; \n",
            "E 6\t: loss=4063.391, rmse=63.745, r2=0.609; v_loss=3585.220, v_rmse=59.877, v_r2=0.580; \n",
            "E 7\t: loss=4027.126, rmse=63.460, r2=0.612; v_loss=3632.217, v_rmse=60.268, v_r2=0.574; \n",
            "E 8\t: loss=4001.663, rmse=63.259, r2=0.615; v_loss=3732.765, v_rmse=61.096, v_r2=0.563; \n",
            "E 9\t: loss=3986.073, rmse=63.135, r2=0.616; v_loss=3645.247, v_rmse=60.376, v_r2=0.573; \n",
            "E 10\t: loss=3924.644, rmse=62.647, r2=0.622; v_loss=3667.426, v_rmse=60.559, v_r2=0.570; \n",
            "E 11\t: loss=3882.510, rmse=62.310, r2=0.626; v_loss=3799.176, v_rmse=61.637, v_r2=0.555; \n",
            "E 12\t: loss=3877.301, rmse=62.268, r2=0.627; v_loss=3882.705, v_rmse=62.311, v_r2=0.545; \n",
            "E 13\t: loss=3860.308, rmse=62.131, r2=0.628; v_loss=3687.350, v_rmse=60.724, v_r2=0.568; \n",
            "E 14\t: loss=3792.403, rmse=61.582, r2=0.635; v_loss=3769.549, v_rmse=61.397, v_r2=0.558; \n",
            "E 15\t: loss=3825.918, rmse=61.854, r2=0.632; v_loss=3742.024, v_rmse=61.172, v_r2=0.561; \n",
            "E 16\t: loss=3802.571, rmse=61.665, r2=0.634; v_loss=3641.056, v_rmse=60.341, v_r2=0.573; \n",
            "E 17\t: loss=3747.242, rmse=61.215, r2=0.639; v_loss=3705.489, v_rmse=60.873, v_r2=0.566; \n",
            "E 18\t: loss=3788.562, rmse=61.551, r2=0.635; v_loss=3765.611, v_rmse=61.365, v_r2=0.559; \n",
            "E 19\t: loss=3696.711, rmse=60.801, r2=0.644; v_loss=3857.025, v_rmse=62.105, v_r2=0.548; \n",
            "E 20\t: loss=3729.047, rmse=61.066, r2=0.641; v_loss=3981.404, v_rmse=63.098, v_r2=0.533; \n",
            "E 21\t: loss=3757.251, rmse=61.296, r2=0.638; v_loss=3697.098, v_rmse=60.804, v_r2=0.567; \n",
            "E 22\t: loss=3727.872, rmse=61.056, r2=0.641; v_loss=3731.807, v_rmse=61.089, v_r2=0.563; \n",
            "E 23\t: loss=3701.989, rmse=60.844, r2=0.644; v_loss=3742.420, v_rmse=61.175, v_r2=0.561; \n",
            "E 24\t: loss=3678.002, rmse=60.647, r2=0.646; v_loss=3778.887, v_rmse=61.473, v_r2=0.557; \n",
            "E 25\t: loss=3710.705, rmse=60.916, r2=0.643; v_loss=3775.635, v_rmse=61.446, v_r2=0.557; \n",
            "E 26\t: loss=3670.837, rmse=60.587, r2=0.647; v_loss=3861.490, v_rmse=62.141, v_r2=0.547; \n",
            "E 27\t: loss=3699.326, rmse=60.822, r2=0.644; v_loss=3717.267, v_rmse=60.969, v_r2=0.564; \n",
            "E 28\t: loss=3665.957, rmse=60.547, r2=0.647; v_loss=3760.814, v_rmse=61.325, v_r2=0.559; \n",
            "E 29\t: loss=3628.328, rmse=60.236, r2=0.651; v_loss=3775.077, v_rmse=61.442, v_r2=0.558; \n",
            "E 30\t: loss=3637.104, rmse=60.308, r2=0.650; v_loss=3700.397, v_rmse=60.831, v_r2=0.566; \n",
            "E 31\t: loss=3627.960, rmse=60.233, r2=0.651; v_loss=3837.869, v_rmse=61.951, v_r2=0.550; \n",
            "Finished: 2022-11-02 09:58:00.757701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "WTB1R-9-8Xu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e9d6cf-b61c-4a1f-8450-1d02f657b9cc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-1.014,RMSE=-58.744\n",
            "Finished: 2022-11-02 09:58:00.855702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "P3IBawiY8XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8675039655819224  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 164),\n",
        "('basemodel__epochs', 29),\n",
        "('basemodel__model__activation1', 'elu'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.8791215719915316),\n",
        "('basemodel__model__dropout2', 0.1),\n",
        "('basemodel__model__layer1', 511),\n",
        "('basemodel__model__layer2', 512),\n",
        "('basemodel__model__learning_rate', 0.009861716088609234),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 80),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "95Sz7A0l8XvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=164,\n",
        "                           epochs=29,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout1=0.8791215719915316, \n",
        "                           model__dropout2=0.1, \n",
        "                           model__layer1=511, \n",
        "                           model__layer2=512, \n",
        "                           model__learning_rate=0.009861716088609234,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37740ddd-0ffa-4413-d818-e93bd4dfc772",
        "id": "8P2llTd78XvH"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=164, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=29, model=<function create_model at 0x00000174B0F1F820>, model__activation1='elu', model__activation2='tanh', model__dropout1=0.8791215719915316, model__dropout2=...yer1=511, model__layer2=512, model__learning_rate=0.009861716088609234, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000017612D7D520>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000017616D885B0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "vh-GouSB8XvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b3be0a-e8df-4709-ba26-2a4bb5c90ca2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 511)               11242     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 511)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               262144    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273,899\n",
            "Trainable params: 273,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=438.358, rmse=20.937, r2=0.169; v_loss=108.707, v_rmse=10.426, v_r2=0.808; \n",
            "E 2\t: loss=80.488, rmse=8.972, r2=0.847; v_loss=97.889, v_rmse=9.894, v_r2=0.827; \n",
            "E 3\t: loss=77.254, rmse=8.789, r2=0.854; v_loss=94.028, v_rmse=9.697, v_r2=0.834; \n",
            "E 4\t: loss=75.945, rmse=8.715, r2=0.856; v_loss=84.828, v_rmse=9.210, v_r2=0.850; \n",
            "E 5\t: loss=75.296, rmse=8.677, r2=0.857; v_loss=91.958, v_rmse=9.589, v_r2=0.838; \n",
            "E 6\t: loss=73.319, rmse=8.563, r2=0.861; v_loss=93.539, v_rmse=9.672, v_r2=0.835; \n",
            "E 7\t: loss=73.533, rmse=8.575, r2=0.861; v_loss=97.806, v_rmse=9.890, v_r2=0.828; \n",
            "E 8\t: loss=72.813, rmse=8.533, r2=0.862; v_loss=94.313, v_rmse=9.711, v_r2=0.834; \n",
            "E 9\t: loss=72.338, rmse=8.505, r2=0.863; v_loss=80.497, v_rmse=8.972, v_r2=0.858; \n",
            "E 10\t: loss=72.703, rmse=8.527, r2=0.862; v_loss=99.437, v_rmse=9.972, v_r2=0.825; \n",
            "E 11\t: loss=73.529, rmse=8.575, r2=0.861; v_loss=94.012, v_rmse=9.696, v_r2=0.834; \n",
            "E 12\t: loss=72.244, rmse=8.500, r2=0.863; v_loss=88.888, v_rmse=9.428, v_r2=0.843; \n",
            "E 13\t: loss=71.633, rmse=8.464, r2=0.864; v_loss=105.775, v_rmse=10.285, v_r2=0.814; \n",
            "E 14\t: loss=71.865, rmse=8.477, r2=0.864; v_loss=114.190, v_rmse=10.686, v_r2=0.799; \n",
            "E 15\t: loss=71.013, rmse=8.427, r2=0.865; v_loss=109.286, v_rmse=10.454, v_r2=0.807; \n",
            "E 16\t: loss=72.151, rmse=8.494, r2=0.863; v_loss=92.064, v_rmse=9.595, v_r2=0.838; \n",
            "E 17\t: loss=71.018, rmse=8.427, r2=0.865; v_loss=119.266, v_rmse=10.921, v_r2=0.790; \n",
            "E 18\t: loss=72.232, rmse=8.499, r2=0.863; v_loss=105.791, v_rmse=10.285, v_r2=0.813; \n",
            "E 19\t: loss=71.378, rmse=8.449, r2=0.865; v_loss=101.390, v_rmse=10.069, v_r2=0.821; \n",
            "E 20\t: loss=71.378, rmse=8.449, r2=0.865; v_loss=99.918, v_rmse=9.996, v_r2=0.824; \n",
            "Finished: 2022-11-02 10:00:40.062732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Sc37islE8XvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023dc3d5-50a1-49cc-8283-f2293bcb20cf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.777,RMSE=-11.887\n",
            "Finished: 2022-11-02 10:00:52.972008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "wZocoM5X8XvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6119811339203444  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 477),\n",
        "('basemodel__epochs', 49),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__dropout1', 0.18510920905532013),\n",
        "('basemodel__model__dropout2', 0.2129692928941368),\n",
        "('basemodel__model__layer1', 420),\n",
        "('basemodel__model__layer2', 241),\n",
        "('basemodel__model__learning_rate', 0.009500210759954515),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.11902117833628473),\n",
        "('poly_degree', 3),\n",
        "('scaler', MinMaxScaler())\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "AlgXpCVb8XvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=477,\n",
        "                           epochs=49,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout1=0.18510920905532013, \n",
        "                           model__dropout2=0.2129692928941368, \n",
        "                           model__layer1=420, \n",
        "                           model__layer2=241, \n",
        "                           model__learning_rate=0.009500210759954515,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.11902117833628473, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acf6389-46a8-4bbc-9bea-29e0161147d7",
        "id": "6TR5_NRP8XvP"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=477, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=49, model=<function create_model at 0x00000174B0F1F820>, model__activation1='relu', model__activation2='selu', model__dropout1=0.18510920905532013, model__dropout..._rate=0.009500210759954515, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761C7876A0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001761C78E9A0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.11902117833628473, verbose=0),\n",
              "                    poly_degree=3, scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "kGivi_vW8XvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81006959-b3cb-43bb-a91d-566a746134ac"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 420)               850080    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 420)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 241)               101461    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 241)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 242       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 951,783\n",
            "Trainable params: 951,783\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=7340.618, rmse=85.677, r2=0.229; v_loss=7641.681, v_rmse=87.417, v_r2=0.341; \n",
            "E 2\t: loss=3682.043, rmse=60.680, r2=0.613; v_loss=7074.411, v_rmse=84.110, v_r2=0.390; \n",
            "E 3\t: loss=3491.783, rmse=59.091, r2=0.633; v_loss=7113.791, v_rmse=84.343, v_r2=0.387; \n",
            "E 4\t: loss=3409.295, rmse=58.389, r2=0.642; v_loss=6922.581, v_rmse=83.202, v_r2=0.403; \n",
            "E 5\t: loss=3422.591, rmse=58.503, r2=0.641; v_loss=6724.949, v_rmse=82.006, v_r2=0.420; \n",
            "E 6\t: loss=3425.868, rmse=58.531, r2=0.640; v_loss=7014.762, v_rmse=83.754, v_r2=0.395; \n",
            "E 7\t: loss=3340.124, rmse=57.794, r2=0.649; v_loss=7409.750, v_rmse=86.080, v_r2=0.361; \n",
            "E 8\t: loss=3281.315, rmse=57.283, r2=0.655; v_loss=6911.015, v_rmse=83.133, v_r2=0.404; \n",
            "E 9\t: loss=3298.449, rmse=57.432, r2=0.654; v_loss=6368.667, v_rmse=79.804, v_r2=0.451; \n",
            "E 10\t: loss=3281.832, rmse=57.287, r2=0.655; v_loss=7056.541, v_rmse=84.003, v_r2=0.392; \n",
            "E 11\t: loss=3435.926, rmse=58.617, r2=0.639; v_loss=6569.441, v_rmse=81.052, v_r2=0.434; \n",
            "E 12\t: loss=3319.085, rmse=57.612, r2=0.651; v_loss=6886.449, v_rmse=82.985, v_r2=0.406; \n",
            "E 13\t: loss=3248.588, rmse=56.996, r2=0.659; v_loss=7536.288, v_rmse=86.812, v_r2=0.350; \n",
            "E 14\t: loss=3257.478, rmse=57.074, r2=0.658; v_loss=6191.229, v_rmse=78.684, v_r2=0.466; \n",
            "E 15\t: loss=3243.303, rmse=56.950, r2=0.659; v_loss=6323.798, v_rmse=79.522, v_r2=0.455; \n",
            "E 16\t: loss=3238.794, rmse=56.910, r2=0.660; v_loss=6498.203, v_rmse=80.611, v_r2=0.440; \n",
            "E 17\t: loss=3260.134, rmse=57.098, r2=0.658; v_loss=7028.911, v_rmse=83.839, v_r2=0.394; \n",
            "E 18\t: loss=3223.579, rmse=56.777, r2=0.661; v_loss=6093.614, v_rmse=78.062, v_r2=0.475; \n",
            "E 19\t: loss=3259.663, rmse=57.093, r2=0.658; v_loss=6013.566, v_rmse=77.547, v_r2=0.482; \n",
            "E 20\t: loss=3266.932, rmse=57.157, r2=0.657; v_loss=6768.238, v_rmse=82.269, v_r2=0.417; \n",
            "E 21\t: loss=3206.364, rmse=56.625, r2=0.663; v_loss=6638.694, v_rmse=81.478, v_r2=0.428; \n",
            "E 22\t: loss=3211.656, rmse=56.671, r2=0.663; v_loss=7194.736, v_rmse=84.822, v_r2=0.380; \n",
            "E 23\t: loss=3191.635, rmse=56.495, r2=0.665; v_loss=6871.595, v_rmse=82.895, v_r2=0.408; \n",
            "E 24\t: loss=3238.910, rmse=56.911, r2=0.660; v_loss=6382.452, v_rmse=79.890, v_r2=0.450; \n",
            "E 25\t: loss=3189.649, rmse=56.477, r2=0.665; v_loss=6492.819, v_rmse=80.578, v_r2=0.440; \n",
            "E 26\t: loss=3273.044, rmse=57.211, r2=0.656; v_loss=5896.646, v_rmse=76.790, v_r2=0.492; \n",
            "E 27\t: loss=3326.273, rmse=57.674, r2=0.651; v_loss=7414.673, v_rmse=86.108, v_r2=0.361; \n",
            "E 28\t: loss=3265.510, rmse=57.145, r2=0.657; v_loss=6968.111, v_rmse=83.475, v_r2=0.399; \n",
            "E 29\t: loss=3281.814, rmse=57.287, r2=0.655; v_loss=6867.008, v_rmse=82.867, v_r2=0.408; \n",
            "E 30\t: loss=3232.640, rmse=56.856, r2=0.661; v_loss=6490.927, v_rmse=80.566, v_r2=0.440; \n",
            "Finished: 2022-11-02 10:01:27.881425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "W4aA1r2q8XvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8b0bda-d064-4b79-c927-3995d7a30c3a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.706,RMSE=-54.072\n",
            "Finished: 2022-11-02 10:01:28.025427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "01ti8j0I8Xva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8797075116940171  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.1),\n",
        "('basemodel__model__dropout2', 0.1),\n",
        "('basemodel__model__layer1', 461),\n",
        "('basemodel__model__layer2', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 80),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "dNgvLPHf8Xvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__dropout2=0.1, \n",
        "                           model__layer1=461, \n",
        "                           model__layer2=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa89cb6-df96-4b1a-8acb-934b66dee57d",
        "id": "dAWLzDAC8Xvg"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=50, model=<function create_model at 0x00000174B0F1F820>, model__activation1='tanh', model__activation2='elu', model__dropout1=0.1, model__dropout2=0.1, model__layer1=461, model__layer2=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761CAFFD90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001761CA680D0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "w4AgmUsB8Xvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8957061c-f8a2-404e-c162-0e2a5a80c5c5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 461)               933064    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 461)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 512)               236544    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,170,121\n",
            "Trainable params: 1,170,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=695.343, rmse=26.369, r2=-0.318; v_loss=204.806, v_rmse=14.311, v_r2=0.639; \n",
            "E 2\t: loss=84.252, rmse=9.179, r2=0.840; v_loss=110.154, v_rmse=10.495, v_r2=0.806; \n",
            "E 3\t: loss=73.303, rmse=8.562, r2=0.861; v_loss=99.774, v_rmse=9.989, v_r2=0.824; \n",
            "E 4\t: loss=70.296, rmse=8.384, r2=0.867; v_loss=111.280, v_rmse=10.549, v_r2=0.804; \n",
            "E 5\t: loss=68.859, rmse=8.298, r2=0.869; v_loss=115.218, v_rmse=10.734, v_r2=0.797; \n",
            "E 6\t: loss=68.243, rmse=8.261, r2=0.871; v_loss=86.649, v_rmse=9.309, v_r2=0.847; \n",
            "E 7\t: loss=67.047, rmse=8.188, r2=0.873; v_loss=98.113, v_rmse=9.905, v_r2=0.827; \n",
            "E 8\t: loss=66.958, rmse=8.183, r2=0.873; v_loss=115.277, v_rmse=10.737, v_r2=0.797; \n",
            "E 9\t: loss=65.962, rmse=8.122, r2=0.875; v_loss=114.822, v_rmse=10.716, v_r2=0.798; \n",
            "E 10\t: loss=65.676, rmse=8.104, r2=0.875; v_loss=97.372, v_rmse=9.868, v_r2=0.828; \n",
            "E 11\t: loss=64.441, rmse=8.027, r2=0.878; v_loss=121.701, v_rmse=11.032, v_r2=0.785; \n",
            "E 12\t: loss=65.128, rmse=8.070, r2=0.877; v_loss=113.322, v_rmse=10.645, v_r2=0.800; \n",
            "E 13\t: loss=63.666, rmse=7.979, r2=0.879; v_loss=103.555, v_rmse=10.176, v_r2=0.817; \n",
            "E 14\t: loss=63.558, rmse=7.972, r2=0.880; v_loss=93.417, v_rmse=9.665, v_r2=0.835; \n",
            "E 15\t: loss=62.963, rmse=7.935, r2=0.881; v_loss=115.769, v_rmse=10.760, v_r2=0.796; \n",
            "E 16\t: loss=63.479, rmse=7.967, r2=0.880; v_loss=99.059, v_rmse=9.953, v_r2=0.825; \n",
            "E 17\t: loss=64.190, rmse=8.012, r2=0.878; v_loss=96.314, v_rmse=9.814, v_r2=0.830; \n",
            "E 18\t: loss=64.050, rmse=8.003, r2=0.879; v_loss=104.242, v_rmse=10.210, v_r2=0.816; \n",
            "E 19\t: loss=62.895, rmse=7.931, r2=0.881; v_loss=91.958, v_rmse=9.589, v_r2=0.838; \n",
            "E 20\t: loss=63.049, rmse=7.940, r2=0.880; v_loss=94.944, v_rmse=9.744, v_r2=0.833; \n",
            "E 21\t: loss=62.272, rmse=7.891, r2=0.882; v_loss=116.705, v_rmse=10.803, v_r2=0.794; \n",
            "E 22\t: loss=62.506, rmse=7.906, r2=0.881; v_loss=111.908, v_rmse=10.579, v_r2=0.803; \n",
            "E 23\t: loss=62.143, rmse=7.883, r2=0.882; v_loss=100.255, v_rmse=10.013, v_r2=0.823; \n",
            "E 24\t: loss=62.329, rmse=7.895, r2=0.882; v_loss=143.937, v_rmse=11.997, v_r2=0.746; \n",
            "E 25\t: loss=61.869, rmse=7.866, r2=0.883; v_loss=124.233, v_rmse=11.146, v_r2=0.781; \n",
            "E 26\t: loss=61.395, rmse=7.835, r2=0.884; v_loss=101.864, v_rmse=10.093, v_r2=0.820; \n",
            "E 27\t: loss=61.393, rmse=7.835, r2=0.884; v_loss=108.209, v_rmse=10.402, v_r2=0.809; \n",
            "E 28\t: loss=60.674, rmse=7.789, r2=0.885; v_loss=101.370, v_rmse=10.068, v_r2=0.821; \n",
            "E 29\t: loss=61.195, rmse=7.823, r2=0.884; v_loss=97.403, v_rmse=9.869, v_r2=0.828; \n",
            "E 30\t: loss=60.741, rmse=7.794, r2=0.885; v_loss=115.008, v_rmse=10.724, v_r2=0.797; \n",
            "E 31\t: loss=60.056, rmse=7.750, r2=0.886; v_loss=113.527, v_rmse=10.655, v_r2=0.800; \n",
            "E 32\t: loss=60.482, rmse=7.777, r2=0.885; v_loss=100.413, v_rmse=10.021, v_r2=0.823; \n",
            "E 33\t: loss=60.214, rmse=7.760, r2=0.886; v_loss=115.164, v_rmse=10.731, v_r2=0.797; \n",
            "E 34\t: loss=60.712, rmse=7.792, r2=0.885; v_loss=108.530, v_rmse=10.418, v_r2=0.809; \n",
            "E 35\t: loss=60.216, rmse=7.760, r2=0.886; v_loss=102.432, v_rmse=10.121, v_r2=0.819; \n",
            "E 36\t: loss=60.502, rmse=7.778, r2=0.885; v_loss=102.203, v_rmse=10.110, v_r2=0.820; \n",
            "Finished: 2022-11-02 10:04:17.901571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "N-Pj7cIL8Xvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890e59ad-10e2-4494-d502-c3586ba16ab3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.830,RMSE=-10.379\n",
            "Finished: 2022-11-02 10:04:18.041178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-3"
      ],
      "metadata": {
        "id": "00TdIEZ6FBx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "kL9N0ocMFBx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6031587839965488    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 273),\n",
        "('basemodel__epochs', 18),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.8779935839787812),\n",
        "('basemodel__model__dropout2', 0.10779365305325281),\n",
        "('basemodel__model__dropout3', 0.4510533904028945),\n",
        "('basemodel__model__layer1', 244),\n",
        "('basemodel__model__layer2', 341),\n",
        "('basemodel__model__layer3', 104),\n",
        "('basemodel__model__learning_rate', 0.006744014727126686),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "zmVugjXMFByB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=273,\n",
        "                           epochs=18,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.8779935839787812, \n",
        "                           model__dropout2=0.10779365305325281, \n",
        "                           model__dropout3=0.4510533904028945, \n",
        "                           model__layer1=244, \n",
        "                           model__layer2=341, \n",
        "                           model__layer3=104, \n",
        "                           model__learning_rate=0.006744014727126686,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2f0c17-8139-4104-cd45-4f1ec98bbe7c",
        "id": "hI5gTmNEFByH"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=273, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=18, model=<function create_model at 0x00000174B0F1F820>, model__activation1='selu', model__activation2='tanh', model__activation3='selu', model__dropout1=0.877993...yer3=104, model__learning_rate=0.006744014727126686, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000176151FA040>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000176151FA370>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efc1688-cec2-41ae-b539-9ae4b498fc30",
        "id": "kcvF0xLyFByO"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 244)               5368      \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 244)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 341)               83545     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 341)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 104)               35568     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 104)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,586\n",
            "Trainable params: 124,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=7860.250, rmse=88.658, r2=0.165; v_loss=8814.328, v_rmse=93.885, v_r2=0.318; \n",
            "E 2\t: loss=5090.159, rmse=71.345, r2=0.459; v_loss=6231.676, v_rmse=78.941, v_r2=0.518; \n",
            "E 3\t: loss=4724.363, rmse=68.734, r2=0.498; v_loss=6936.979, v_rmse=83.289, v_r2=0.463; \n",
            "E 4\t: loss=4452.358, rmse=66.726, r2=0.527; v_loss=6273.350, v_rmse=79.204, v_r2=0.515; \n",
            "E 5\t: loss=4335.622, rmse=65.845, r2=0.539; v_loss=7307.053, v_rmse=85.481, v_r2=0.435; \n",
            "E 6\t: loss=4184.757, rmse=64.690, r2=0.555; v_loss=8639.724, v_rmse=92.950, v_r2=0.332; \n",
            "E 7\t: loss=4146.432, rmse=64.393, r2=0.560; v_loss=5691.596, v_rmse=75.443, v_r2=0.560; \n",
            "E 8\t: loss=4122.298, rmse=64.205, r2=0.562; v_loss=8143.381, v_rmse=90.241, v_r2=0.370; \n",
            "E 9\t: loss=4044.196, rmse=63.594, r2=0.570; v_loss=7903.774, v_rmse=88.903, v_r2=0.389; \n",
            "E 10\t: loss=4071.814, rmse=63.811, r2=0.567; v_loss=7269.366, v_rmse=85.261, v_r2=0.438; \n",
            "E 11\t: loss=3986.474, rmse=63.139, r2=0.577; v_loss=6636.202, v_rmse=81.463, v_r2=0.487; \n",
            "E 12\t: loss=3940.774, rmse=62.776, r2=0.581; v_loss=6057.486, v_rmse=77.830, v_r2=0.531; \n",
            "E 13\t: loss=3872.062, rmse=62.226, r2=0.589; v_loss=7351.758, v_rmse=85.742, v_r2=0.431; \n",
            "E 14\t: loss=3915.569, rmse=62.575, r2=0.584; v_loss=7567.487, v_rmse=86.991, v_r2=0.415; \n",
            "E 15\t: loss=3864.864, rmse=62.168, r2=0.589; v_loss=6659.155, v_rmse=81.604, v_r2=0.485; \n",
            "E 16\t: loss=3847.169, rmse=62.026, r2=0.591; v_loss=6200.543, v_rmse=78.744, v_r2=0.520; \n",
            "E 17\t: loss=3884.053, rmse=62.322, r2=0.587; v_loss=7701.220, v_rmse=87.757, v_r2=0.404; \n",
            "E 18\t: loss=3821.760, rmse=61.820, r2=0.594; v_loss=7121.992, v_rmse=84.392, v_r2=0.449; \n",
            "Finished: 2022-11-02 10:07:33.128117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0430bcb8-f895-45a9-cb63-07f31f04598f",
        "id": "QG0jhrtKFByS"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.641,RMSE=-53.034\n",
            "Finished: 2022-11-02 10:07:33.222117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "1Xs7NWLvFByZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8606739658341226    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 246),\n",
        "('basemodel__epochs', 34),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__activation2', 'sigmoid'),\n",
        "('basemodel__model__activation3', 'relu'),\n",
        "('basemodel__model__dropout1', 0.398822951109552),\n",
        "('basemodel__model__dropout2', 0.3447841740069549),\n",
        "('basemodel__model__dropout3', 0.9),\n",
        "('basemodel__model__layer1', 142),\n",
        "('basemodel__model__layer2', 454),\n",
        "('basemodel__model__layer3', 370),\n",
        "('basemodel__model__learning_rate', 0.00337864526028697),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.433392689037953),\n",
        "('clip_y', 80),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "RbLuNAHAFBye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=246,\n",
        "                           epochs=34,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__activation3='relu',\n",
        "                           model__dropout1=0.398822951109552, \n",
        "                           model__dropout2=0.3447841740069549, \n",
        "                           model__dropout3=0.9, \n",
        "                           model__layer1=142, \n",
        "                           model__layer2=454, \n",
        "                           model__layer3=370,  \n",
        "                           model__learning_rate=0.00337864526028697,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.433392689037953, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d396efe0-abe5-4995-eaa3-b213f8584415",
        "id": "PSnWYxQiFByi"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=246, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=34, model=<function create_model at 0x00000174B0F1F820>, model__activation1='relu', model__activation2='sigmoid', model__activation3='relu', model__dropout1=0.398...l__layer3=370, model__learning_rate=0.00337864526028697, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761CA43FD0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000175F1C931F0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.433392689037953, verbose=0),\n",
              "                    clip_y=80)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff1db0a-92a6-42e0-fcee-6c5c8bfb98fb",
        "id": "wU3RI7KvFByq"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 142)               3124      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 142)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 454)               64922     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 454)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 370)               168350    \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 370)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 371       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 236,767\n",
            "Trainable params: 236,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=740.248, rmse=27.207, r2=-0.439; v_loss=94.865, v_rmse=9.740, v_r2=0.828; \n",
            "E 2\t: loss=334.882, rmse=18.300, r2=0.349; v_loss=85.453, v_rmse=9.244, v_r2=0.845; \n",
            "E 3\t: loss=330.609, rmse=18.183, r2=0.357; v_loss=81.445, v_rmse=9.025, v_r2=0.853; \n",
            "E 4\t: loss=320.697, rmse=17.908, r2=0.376; v_loss=71.464, v_rmse=8.454, v_r2=0.871; \n",
            "E 5\t: loss=323.397, rmse=17.983, r2=0.371; v_loss=81.087, v_rmse=9.005, v_r2=0.853; \n",
            "E 6\t: loss=318.173, rmse=17.837, r2=0.381; v_loss=71.183, v_rmse=8.437, v_r2=0.871; \n",
            "E 7\t: loss=317.451, rmse=17.817, r2=0.383; v_loss=71.466, v_rmse=8.454, v_r2=0.871; \n",
            "E 8\t: loss=319.420, rmse=17.872, r2=0.379; v_loss=96.342, v_rmse=9.815, v_r2=0.826; \n",
            "E 9\t: loss=318.992, rmse=17.860, r2=0.380; v_loss=81.039, v_rmse=9.002, v_r2=0.853; \n",
            "E 10\t: loss=311.106, rmse=17.638, r2=0.395; v_loss=81.727, v_rmse=9.040, v_r2=0.852; \n",
            "E 11\t: loss=307.457, rmse=17.534, r2=0.402; v_loss=71.117, v_rmse=8.433, v_r2=0.871; \n",
            "E 12\t: loss=315.815, rmse=17.771, r2=0.386; v_loss=73.318, v_rmse=8.563, v_r2=0.867; \n",
            "E 13\t: loss=316.217, rmse=17.782, r2=0.385; v_loss=80.924, v_rmse=8.996, v_r2=0.854; \n",
            "E 14\t: loss=315.629, rmse=17.766, r2=0.386; v_loss=73.093, v_rmse=8.549, v_r2=0.868; \n",
            "E 15\t: loss=314.227, rmse=17.726, r2=0.389; v_loss=69.288, v_rmse=8.324, v_r2=0.875; \n",
            "E 16\t: loss=311.327, rmse=17.644, r2=0.395; v_loss=72.988, v_rmse=8.543, v_r2=0.868; \n",
            "Finished: 2022-11-02 10:09:58.057154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4e0f30-f151-4e54-be82-93e7662d7444",
        "id": "9s8vEev3FByt"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.829,RMSE=-10.424\n",
            "Finished: 2022-11-02 10:09:58.140179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "yk8grx_3FByx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6144434017693393    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 392),\n",
        "('basemodel__epochs', 25),\n",
        "('basemodel__model__activation1', 'sigmoid'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.26670195337882074),\n",
        "('basemodel__model__dropout2', 0.14342309787217927),\n",
        "('basemodel__model__dropout3', 0.3763758002816012),\n",
        "('basemodel__model__layer1', 211),\n",
        "('basemodel__model__layer2', 16),\n",
        "('basemodel__model__layer3', 398),\n",
        "('basemodel__model__learning_rate', 0.005523882705085696),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('poly_degree', 2),\n",
        "('scaler', MinMaxScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "2TWz2xbfFBy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=392,\n",
        "                           epochs=25,\n",
        "                           model__activation1='sigmoid',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.26670195337882074, \n",
        "                           model__dropout2=0.14342309787217927, \n",
        "                           model__dropout3=0.3763758002816012, \n",
        "                           model__layer1=211, \n",
        "                           model__layer2=16, \n",
        "                           model__layer3=398, \n",
        "                           model__learning_rate=0.005523882705085696,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc0de4b-7fd6-4bfd-a713-44598a9b55c4",
        "id": "97IkcENqFBy1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=392, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=25, model=<function create_model at 0x00000174B0F1F820>, model__activation1='sigmoid', model__activation2='selu', model__activation3='selu', model__dropout1=0.266..., model__learning_rate=0.005523882705085696, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761D0D5CD0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001761D0D5D30>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    poly_degree=2, scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0fca1f-e0bb-47a0-8115-c5f4c7aebc7d",
        "id": "GGBuOcsxFBy4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 211)               53383     \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 211)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 16)                3392      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 398)               6766      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 398)               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 399       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 63,940\n",
            "Trainable params: 63,940\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=11830.938, rmse=108.770, r2=-0.257; v_loss=12077.417, v_rmse=109.897, v_r2=0.066; \n",
            "E 2\t: loss=5883.140, rmse=76.702, r2=0.375; v_loss=7158.837, v_rmse=84.610, v_r2=0.446; \n",
            "E 3\t: loss=4007.680, rmse=63.306, r2=0.574; v_loss=7567.498, v_rmse=86.991, v_r2=0.415; \n",
            "E 4\t: loss=3824.856, rmse=61.845, r2=0.594; v_loss=7334.047, v_rmse=85.639, v_r2=0.433; \n",
            "E 5\t: loss=3666.681, rmse=60.553, r2=0.611; v_loss=6834.506, v_rmse=82.671, v_r2=0.471; \n",
            "E 6\t: loss=3651.223, rmse=60.425, r2=0.612; v_loss=7238.500, v_rmse=85.079, v_r2=0.440; \n",
            "E 7\t: loss=3574.902, rmse=59.790, r2=0.620; v_loss=6738.633, v_rmse=82.089, v_r2=0.479; \n",
            "E 8\t: loss=3562.667, rmse=59.688, r2=0.622; v_loss=7285.822, v_rmse=85.357, v_r2=0.436; \n",
            "E 9\t: loss=3526.146, rmse=59.381, r2=0.625; v_loss=7426.027, v_rmse=86.174, v_r2=0.426; \n",
            "E 10\t: loss=3440.738, rmse=58.658, r2=0.635; v_loss=7343.272, v_rmse=85.693, v_r2=0.432; \n",
            "E 11\t: loss=3485.202, rmse=59.036, r2=0.630; v_loss=7330.792, v_rmse=85.620, v_r2=0.433; \n",
            "E 12\t: loss=3474.883, rmse=58.948, r2=0.631; v_loss=7140.685, v_rmse=84.503, v_r2=0.448; \n",
            "E 13\t: loss=3423.323, rmse=58.509, r2=0.636; v_loss=6856.485, v_rmse=82.804, v_r2=0.470; \n",
            "E 14\t: loss=3419.772, rmse=58.479, r2=0.637; v_loss=7249.748, v_rmse=85.145, v_r2=0.439; \n",
            "E 15\t: loss=3406.567, rmse=58.366, r2=0.638; v_loss=7125.746, v_rmse=84.414, v_r2=0.449; \n",
            "E 16\t: loss=3412.689, rmse=58.418, r2=0.637; v_loss=6763.033, v_rmse=82.238, v_r2=0.477; \n",
            "E 17\t: loss=3389.701, rmse=58.221, r2=0.640; v_loss=6973.582, v_rmse=83.508, v_r2=0.461; \n",
            "E 18\t: loss=3390.693, rmse=58.230, r2=0.640; v_loss=6920.071, v_rmse=83.187, v_r2=0.465; \n",
            "E 19\t: loss=3405.002, rmse=58.352, r2=0.638; v_loss=7305.907, v_rmse=85.475, v_r2=0.435; \n",
            "E 20\t: loss=3413.878, rmse=58.428, r2=0.637; v_loss=7083.731, v_rmse=84.165, v_r2=0.452; \n",
            "E 21\t: loss=3345.414, rmse=57.840, r2=0.645; v_loss=6950.112, v_rmse=83.367, v_r2=0.462; \n",
            "E 22\t: loss=3358.330, rmse=57.951, r2=0.643; v_loss=7381.896, v_rmse=85.918, v_r2=0.429; \n",
            "E 23\t: loss=3350.680, rmse=57.885, r2=0.644; v_loss=6964.288, v_rmse=83.452, v_r2=0.461; \n",
            "E 24\t: loss=3378.235, rmse=58.123, r2=0.641; v_loss=7153.254, v_rmse=84.577, v_r2=0.447; \n",
            "E 25\t: loss=3341.850, rmse=57.809, r2=0.645; v_loss=7165.493, v_rmse=84.649, v_r2=0.446; \n",
            "Finished: 2022-11-02 10:12:38.416709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffdad1b-009a-4bd7-9ac8-de354e11aee0",
        "id": "pNP_HTLyFBy7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.398,RMSE=-48.943\n",
            "Finished: 2022-11-02 10:12:38.538711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "UYgtv941FBy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8700749435053768   \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 403),\n",
        "('basemodel__epochs', 30),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__activation3', 'elu'),\n",
        "('basemodel__model__dropout1', 0.4446452001317711),\n",
        "('basemodel__model__dropout2', 0.6178728243917544),\n",
        "('basemodel__model__dropout3', 0.48882961847253814),\n",
        "('basemodel__model__layer1', 310),\n",
        "('basemodel__model__layer2', 273),\n",
        "('basemodel__model__layer3', 114),\n",
        "('basemodel__model__learning_rate', 0.007023482013202204),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.2747333733591927),\n",
        "('clip_y', 90),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "WszSSJcHFBy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=90\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=403,\n",
        "                           epochs=30,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='elu',\n",
        "                           model__dropout1=0.4446452001317711, \n",
        "                           model__dropout2=0.6178728243917544, \n",
        "                           model__dropout3=0.48882961847253814, \n",
        "                           model__layer1=310, \n",
        "                           model__layer2=273, \n",
        "                           model__layer3=114, \n",
        "                           model__learning_rate=0.007023482013202204,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.2747333733591927, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c64db43-a683-45fe-b4d2-19144cd56a49",
        "id": "5zdwA-JAFBzA"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=403, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=30, model=<function create_model at 0x00000174B0F1F820>, model__activation1='selu', model__activation2='selu', model__activation3='elu', model__dropout1=0.4446452...del__learning_rate=0.007023482013202204, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761D328970>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001761D328B50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.2747333733591927, verbose=0),\n",
              "                    clip_y=90, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea840c8f-d664-4862-8d06-51573322f4d4",
        "id": "_7BYEM3iFBzC"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 310)               627440    \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 310)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 273)               84903     \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 273)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 114)               31236     \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 114)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 115       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 743,694\n",
            "Trainable params: 743,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1994.289, rmse=44.657, r2=-1.797; v_loss=506.814, v_rmse=22.513, v_r2=0.329; \n",
            "E 2\t: loss=435.597, rmse=20.871, r2=0.389; v_loss=174.316, v_rmse=13.203, v_r2=0.769; \n",
            "E 3\t: loss=344.621, rmse=18.564, r2=0.517; v_loss=151.938, v_rmse=12.326, v_r2=0.799; \n",
            "E 4\t: loss=314.813, rmse=17.743, r2=0.558; v_loss=141.582, v_rmse=11.899, v_r2=0.813; \n",
            "E 5\t: loss=292.041, rmse=17.089, r2=0.590; v_loss=147.421, v_rmse=12.142, v_r2=0.805; \n",
            "E 6\t: loss=275.044, rmse=16.584, r2=0.614; v_loss=172.171, v_rmse=13.121, v_r2=0.772; \n",
            "E 7\t: loss=257.736, rmse=16.054, r2=0.638; v_loss=123.516, v_rmse=11.114, v_r2=0.837; \n",
            "E 8\t: loss=249.288, rmse=15.789, r2=0.650; v_loss=120.916, v_rmse=10.996, v_r2=0.840; \n",
            "E 9\t: loss=234.935, rmse=15.328, r2=0.670; v_loss=115.220, v_rmse=10.734, v_r2=0.848; \n",
            "E 10\t: loss=227.715, rmse=15.090, r2=0.681; v_loss=126.305, v_rmse=11.239, v_r2=0.833; \n",
            "E 11\t: loss=220.714, rmse=14.856, r2=0.690; v_loss=130.359, v_rmse=11.417, v_r2=0.827; \n",
            "E 12\t: loss=218.635, rmse=14.786, r2=0.693; v_loss=110.492, v_rmse=10.512, v_r2=0.854; \n",
            "E 13\t: loss=214.324, rmse=14.640, r2=0.699; v_loss=124.813, v_rmse=11.172, v_r2=0.835; \n",
            "E 14\t: loss=208.780, rmse=14.449, r2=0.707; v_loss=125.778, v_rmse=11.215, v_r2=0.834; \n",
            "E 15\t: loss=210.315, rmse=14.502, r2=0.705; v_loss=126.540, v_rmse=11.249, v_r2=0.833; \n",
            "E 16\t: loss=205.600, rmse=14.339, r2=0.712; v_loss=116.536, v_rmse=10.795, v_r2=0.846; \n",
            "E 17\t: loss=199.769, rmse=14.134, r2=0.720; v_loss=127.270, v_rmse=11.281, v_r2=0.832; \n",
            "E 18\t: loss=202.678, rmse=14.236, r2=0.716; v_loss=117.839, v_rmse=10.855, v_r2=0.844; \n",
            "E 19\t: loss=201.110, rmse=14.181, r2=0.718; v_loss=117.843, v_rmse=10.856, v_r2=0.844; \n",
            "E 20\t: loss=200.170, rmse=14.148, r2=0.719; v_loss=123.528, v_rmse=11.114, v_r2=0.837; \n",
            "E 21\t: loss=251.213, rmse=15.850, r2=0.648; v_loss=156.257, v_rmse=12.500, v_r2=0.793; \n",
            "E 22\t: loss=243.876, rmse=15.617, r2=0.658; v_loss=131.294, v_rmse=11.458, v_r2=0.826; \n",
            "Finished: 2022-11-02 10:13:11.111008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f63661b-819b-46fe-c30f-9c7c66e9a1e2",
        "id": "oLf0y74BFBzE"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.825,RMSE=-12.086\n",
            "Finished: 2022-11-02 10:13:11.271985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-4 (TODO)"
      ],
      "metadata": {
        "id": "MfJUDz0oI5zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pb8CuYNOI5zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.5965333341401537    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 66),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'sigmoid'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__activation4', 'relu'),\n",
        "('basemodel__model__dropout1', 0.8385437522647914),\n",
        "('basemodel__model__dropout2', 0.23198581914083677),\n",
        "('basemodel__model__dropout3', 0.1),\n",
        "('basemodel__model__dropout4', 0.18918890917273032),\n",
        "('basemodel__model__layer1', 291),\n",
        "('basemodel__model__layer2', 117),\n",
        "('basemodel__model__layer3', 147),\n",
        "('basemodel__model__layer4', 248),\n",
        "('basemodel__model__learning_rate', 0.01),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.14404412076041206),\n",
        "('scaler', MinMaxScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "B5befZCBI5zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=66,\n",
        "                           epochs=50,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__activation3='selu',\n",
        "                           model__activation4='relu',\n",
        "                           model__dropout1=0.8385437522647914, \n",
        "                           model__dropout2=0.23198581914083677, \n",
        "                           model__dropout3=0.1, \n",
        "                           model__dropout4=0.18918890917273032, \n",
        "                           model__layer1=291, \n",
        "                           model__layer2=117, \n",
        "                           model__layer3=147, \n",
        "                           model__layer4=248, \n",
        "                           model__learning_rate=0.01,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.14404412076041206, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e5a30b-73e9-4814-da94-cb11f3c42577",
        "id": "HjCB0ofWI5zk"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=66, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=50, model=<function create_model at 0x00000174B0F1F820>, model__activation1='selu', model__activation2='sigmoid', model__activation3='selu', model__activation4='re...yer4=248, model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761D7CBEB0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001761D7CB550>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.14404412076041206, verbose=0),\n",
              "                    scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26945f2-8566-4c61-8aa9-f6be8f281a16",
        "id": "WBnAz5ncI5zp"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_52 (Dense)            (None, 291)               6402      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 291)               0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 117)               34164     \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 117)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 147)               17346     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 147)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 248)               36704     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 248)               0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 249       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94,865\n",
            "Trainable params: 94,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=6734.885, rmse=82.066, r2=0.297; v_loss=5419.646, v_rmse=73.618, v_r2=0.501; \n",
            "E 2\t: loss=4657.179, rmse=68.244, r2=0.514; v_loss=5902.580, v_rmse=76.828, v_r2=0.456; \n",
            "E 3\t: loss=4391.785, rmse=66.271, r2=0.542; v_loss=8130.248, v_rmse=90.168, v_r2=0.251; \n",
            "E 4\t: loss=4247.986, rmse=65.177, r2=0.557; v_loss=7494.347, v_rmse=86.570, v_r2=0.310; \n",
            "E 5\t: loss=4200.720, rmse=64.813, r2=0.562; v_loss=6323.992, v_rmse=79.524, v_r2=0.418; \n",
            "E 6\t: loss=4177.078, rmse=64.630, r2=0.564; v_loss=6979.023, v_rmse=83.541, v_r2=0.357; \n",
            "E 7\t: loss=4094.294, rmse=63.987, r2=0.573; v_loss=5745.404, v_rmse=75.798, v_r2=0.471; \n",
            "E 8\t: loss=4077.255, rmse=63.853, r2=0.575; v_loss=6626.708, v_rmse=81.405, v_r2=0.390; \n",
            "E 9\t: loss=4077.941, rmse=63.859, r2=0.575; v_loss=6299.904, v_rmse=79.372, v_r2=0.420; \n",
            "E 10\t: loss=4092.066, rmse=63.969, r2=0.573; v_loss=5809.290, v_rmse=76.219, v_r2=0.465; \n",
            "E 11\t: loss=4034.979, rmse=63.521, r2=0.579; v_loss=6612.735, v_rmse=81.319, v_r2=0.391; \n",
            "E 12\t: loss=4045.525, rmse=63.604, r2=0.578; v_loss=6059.857, v_rmse=77.845, v_r2=0.442; \n",
            "E 13\t: loss=4061.130, rmse=63.727, r2=0.576; v_loss=5791.282, v_rmse=76.100, v_r2=0.467; \n",
            "E 14\t: loss=3997.843, rmse=63.229, r2=0.583; v_loss=6251.225, v_rmse=79.065, v_r2=0.424; \n",
            "E 15\t: loss=4030.174, rmse=63.484, r2=0.580; v_loss=5576.484, v_rmse=74.676, v_r2=0.486; \n",
            "E 16\t: loss=3987.444, rmse=63.146, r2=0.584; v_loss=6375.736, v_rmse=79.848, v_r2=0.413; \n",
            "E 17\t: loss=3990.270, rmse=63.169, r2=0.584; v_loss=5981.065, v_rmse=77.337, v_r2=0.449; \n",
            "E 18\t: loss=3995.787, rmse=63.212, r2=0.583; v_loss=7327.059, v_rmse=85.598, v_r2=0.325; \n",
            "E 19\t: loss=4051.372, rmse=63.650, r2=0.577; v_loss=5291.503, v_rmse=72.743, v_r2=0.513; \n",
            "E 20\t: loss=4026.662, rmse=63.456, r2=0.580; v_loss=5798.687, v_rmse=76.149, v_r2=0.466; \n",
            "E 21\t: loss=4021.184, rmse=63.413, r2=0.581; v_loss=6281.654, v_rmse=79.257, v_r2=0.422; \n",
            "Finished: 2022-11-02 10:17:02.029243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8453293-6b2e-4022-c061-e5f8db99924b",
        "id": "E1ATWFZoI5zt"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.180,RMSE=-44.970\n",
            "Finished: 2022-11-02 10:17:02.159267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "qpedH9HzI5zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.862360484973761    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 141),\n",
        "('basemodel__epochs', 36),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__activation3', 'sigmoid'),\n",
        "('basemodel__model__activation4', 'selu'),\n",
        "('basemodel__model__dropout1', 0.6030375513292561),\n",
        "('basemodel__model__dropout2', 0.404789057124993),\n",
        "('basemodel__model__dropout3', 0.6692037092668784),\n",
        "('basemodel__model__dropout4', 0.5529044823633812),\n",
        "('basemodel__model__layer1', 342),\n",
        "('basemodel__model__layer2', 86),\n",
        "('basemodel__model__layer3', 353),\n",
        "('basemodel__model__layer4', 80),\n",
        "('basemodel__model__learning_rate', 0.0035609790280109383),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.12093724706982273),\n",
        "('clip_y', 89),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "chBMqsKDI5zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=89\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=141,\n",
        "                           epochs=36,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__activation4='selu',\n",
        "                           model__dropout1=0.6030375513292561, \n",
        "                           model__dropout2=0.404789057124993, \n",
        "                           model__dropout3=0.6692037092668784, \n",
        "                           model__dropout4=0.5529044823633812, \n",
        "                           model__layer1=342, \n",
        "                           model__layer2=86, \n",
        "                           model__layer3=353, \n",
        "                           model__layer4=80, \n",
        "                           model__learning_rate=0.0035609790280109383,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013979c5-4fac-4ec9-b8c2-e713e16f3560",
        "id": "BE54ZRkFI5z3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=141, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=36, model=<function create_model at 0x00000174B0F1F820>, model__activation1='selu', model__activation2='selu', model__activation3='sigmoid', model__activation4='s...yer3=353, model__layer4=80, model__learning_rate=0.0035609790280109383, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001761EB15F70>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000017623D205E0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=89)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b939c2f-c33f-45fb-af19-b0bdcd04480d",
        "id": "1UX0DFssI5z6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 342)               7524      \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 342)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 86)                29498     \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 86)                0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 353)               30711     \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 353)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 80)                28320     \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 80)                0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,134\n",
            "Trainable params: 96,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=496.992, rmse=22.293, r2=0.289; v_loss=180.513, v_rmse=13.436, v_r2=0.759; \n",
            "E 2\t: loss=240.571, rmse=15.510, r2=0.656; v_loss=152.728, v_rmse=12.358, v_r2=0.796; \n",
            "E 3\t: loss=218.381, rmse=14.778, r2=0.688; v_loss=136.719, v_rmse=11.693, v_r2=0.817; \n",
            "E 4\t: loss=211.958, rmse=14.559, r2=0.697; v_loss=123.855, v_rmse=11.129, v_r2=0.835; \n",
            "E 5\t: loss=204.191, rmse=14.290, r2=0.708; v_loss=144.196, v_rmse=12.008, v_r2=0.807; \n",
            "E 6\t: loss=200.157, rmse=14.148, r2=0.714; v_loss=141.652, v_rmse=11.902, v_r2=0.811; \n",
            "E 7\t: loss=197.736, rmse=14.062, r2=0.717; v_loss=151.618, v_rmse=12.313, v_r2=0.797; \n",
            "E 8\t: loss=195.751, rmse=13.991, r2=0.720; v_loss=145.569, v_rmse=12.065, v_r2=0.806; \n",
            "E 9\t: loss=198.784, rmse=14.099, r2=0.716; v_loss=127.355, v_rmse=11.285, v_r2=0.830; \n",
            "E 10\t: loss=198.797, rmse=14.100, r2=0.716; v_loss=142.352, v_rmse=11.931, v_r2=0.810; \n",
            "E 11\t: loss=196.613, rmse=14.022, r2=0.719; v_loss=123.207, v_rmse=11.100, v_r2=0.835; \n",
            "E 12\t: loss=196.974, rmse=14.035, r2=0.718; v_loss=137.193, v_rmse=11.713, v_r2=0.817; \n",
            "E 13\t: loss=194.341, rmse=13.941, r2=0.722; v_loss=137.337, v_rmse=11.719, v_r2=0.817; \n",
            "E 14\t: loss=195.580, rmse=13.985, r2=0.720; v_loss=144.425, v_rmse=12.018, v_r2=0.807; \n",
            "E 15\t: loss=192.956, rmse=13.891, r2=0.724; v_loss=150.342, v_rmse=12.261, v_r2=0.799; \n",
            "E 16\t: loss=192.745, rmse=13.883, r2=0.724; v_loss=135.261, v_rmse=11.630, v_r2=0.819; \n",
            "E 17\t: loss=191.332, rmse=13.832, r2=0.726; v_loss=150.404, v_rmse=12.264, v_r2=0.799; \n",
            "E 18\t: loss=191.094, rmse=13.824, r2=0.727; v_loss=134.171, v_rmse=11.583, v_r2=0.821; \n",
            "E 19\t: loss=189.739, rmse=13.775, r2=0.729; v_loss=146.581, v_rmse=12.107, v_r2=0.804; \n",
            "E 20\t: loss=189.677, rmse=13.772, r2=0.729; v_loss=138.312, v_rmse=11.761, v_r2=0.815; \n",
            "E 21\t: loss=191.655, rmse=13.844, r2=0.726; v_loss=137.743, v_rmse=11.736, v_r2=0.816; \n",
            "E 22\t: loss=190.463, rmse=13.801, r2=0.728; v_loss=138.776, v_rmse=11.780, v_r2=0.815; \n",
            "E 23\t: loss=188.893, rmse=13.744, r2=0.730; v_loss=141.493, v_rmse=11.895, v_r2=0.811; \n",
            "E 24\t: loss=186.903, rmse=13.671, r2=0.733; v_loss=148.768, v_rmse=12.197, v_r2=0.801; \n",
            "E 25\t: loss=185.647, rmse=13.625, r2=0.734; v_loss=130.177, v_rmse=11.410, v_r2=0.826; \n",
            "E 26\t: loss=186.185, rmse=13.645, r2=0.734; v_loss=144.670, v_rmse=12.028, v_r2=0.807; \n",
            "E 27\t: loss=182.509, rmse=13.510, r2=0.739; v_loss=142.882, v_rmse=11.953, v_r2=0.809; \n",
            "E 28\t: loss=180.712, rmse=13.443, r2=0.741; v_loss=149.066, v_rmse=12.209, v_r2=0.801; \n",
            "E 29\t: loss=181.105, rmse=13.458, r2=0.741; v_loss=168.216, v_rmse=12.970, v_r2=0.775; \n",
            "E 30\t: loss=180.195, rmse=13.424, r2=0.742; v_loss=164.476, v_rmse=12.825, v_r2=0.780; \n",
            "E 31\t: loss=180.674, rmse=13.442, r2=0.742; v_loss=145.714, v_rmse=12.071, v_r2=0.805; \n",
            "E 32\t: loss=178.435, rmse=13.358, r2=0.745; v_loss=120.755, v_rmse=10.989, v_r2=0.839; \n",
            "E 33\t: loss=179.706, rmse=13.405, r2=0.743; v_loss=154.239, v_rmse=12.419, v_r2=0.794; \n",
            "E 34\t: loss=180.014, rmse=13.417, r2=0.742; v_loss=152.807, v_rmse=12.362, v_r2=0.796; \n",
            "E 35\t: loss=178.626, rmse=13.365, r2=0.744; v_loss=125.649, v_rmse=11.209, v_r2=0.832; \n",
            "E 36\t: loss=177.994, rmse=13.341, r2=0.745; v_loss=139.990, v_rmse=11.832, v_r2=0.813; \n",
            "Finished: 2022-11-02 10:23:27.337490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0baf92-854f-47d0-f998-d2d96957d3d8",
        "id": "ypPnlb7xI5z_"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.817,RMSE=-12.221\n",
            "Finished: 2022-11-02 10:23:27.433492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "CWlv5EFWI50C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5965860921885896    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 297),\n",
        "('basemodel__epochs', 4),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__activation4', 'relu'),\n",
        "('basemodel__model__dropout1', 0.5444566159296994),\n",
        "('basemodel__model__dropout2', 0.4338236298382706),\n",
        "('basemodel__model__dropout3', 0.7048318485513446),\n",
        "('basemodel__model__dropout4', 0.17180189230876136),\n",
        "('basemodel__model__layer1', 458),\n",
        "('basemodel__model__layer2', 113),\n",
        "('basemodel__model__layer3', 161),\n",
        "('basemodel__model__layer4', 494),\n",
        "('basemodel__model__learning_rate', 0.0006019662806120351),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.572593134337274),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "_hRfD2CAI50D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=297,\n",
        "                           epochs=4,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='elu',\n",
        "                           model__activation3='selu',\n",
        "                           model__activation4='relu',\n",
        "                           model__dropout1=0.5444566159296994, \n",
        "                           model__dropout2=0.4338236298382706, \n",
        "                           model__dropout3=0.7048318485513446, \n",
        "                           model__dropout4=0.17180189230876136, \n",
        "                           model__layer1=458, \n",
        "                           model__layer2=113, \n",
        "                           model__layer3=161, \n",
        "                           model__layer4=494, \n",
        "                           model__learning_rate=0.0006019662806120351,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.572593134337274, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d14096-12ac-44ec-b523-0f7c527b4010",
        "id": "zdhee-1GI50E"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=297, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=4, model=<function create_model at 0x00000174B0F1F820>, model__activation1='relu', model__activation2='elu', model__activation3='selu', model__activation4='relu',...er4=494, model__learning_rate=0.0006019662806120351, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000176273D9130>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001761D887D90>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.572593134337274, verbose=0),\n",
              "                    poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac86a7e9-ceb4-446b-b25d-b18ecae183c6",
        "id": "vhJBABSwI50I"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_87 (Dense)            (None, 458)               926992    \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 458)               0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 113)               51867     \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 113)               0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 161)               18354     \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 161)               0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 494)               80028     \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 494)               0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 1)                 495       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,077,736\n",
            "Trainable params: 1,077,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=14000.771, rmse=118.325, r2=-0.275; v_loss=4505.956, v_rmse=67.126, v_r2=0.478; \n",
            "E 2\t: loss=5693.747, rmse=75.457, r2=0.481; v_loss=4349.160, v_rmse=65.948, v_r2=0.496; \n",
            "E 3\t: loss=5065.517, rmse=71.172, r2=0.539; v_loss=4269.471, v_rmse=65.341, v_r2=0.506; \n",
            "E 4\t: loss=4689.347, rmse=68.479, r2=0.573; v_loss=4356.251, v_rmse=66.002, v_r2=0.496; \n",
            "Finished: 2022-11-02 10:26:26.632203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2103b9e-2394-4b04-9cc3-67762f287ae4",
        "id": "qnwVx-VII50K"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.266,RMSE=-35.461\n",
            "Finished: 2022-11-02 10:26:26.793202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "hz9fq_lWI50L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8644256248735079  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 69),\n",
        "             ('basemodel__epochs', 48),\n",
        "             ('basemodel__model__activation1', 'relu'),\n",
        "             ('basemodel__model__activation2', 'sigmoid'),\n",
        "             ('basemodel__model__activation3', 'relu'),\n",
        "             ('basemodel__model__activation4', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.7861582092207701),\n",
        "             ('basemodel__model__dropout2', 0.1651211488004366),\n",
        "             ('basemodel__model__dropout3', 0.3806276727312806),\n",
        "             ('basemodel__model__dropout4', 0.5407685563014424),\n",
        "             ('basemodel__model__layer1', 335),\n",
        "             ('basemodel__model__layer2', 352),\n",
        "             ('basemodel__model__layer3', 87),\n",
        "             ('basemodel__model__layer4', 110),\n",
        "             ('basemodel__model__learning_rate', 0.0013462596203423387),\n",
        "             ('basemodel__model__optim',\n",
        "              keras.optimizers.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.40880873684195296),\n",
        "             ('clip_y', 84),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "9yBfpDmQI50N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=84\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=69,\n",
        "                           epochs=48,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__activation3='relu',\n",
        "                           model__activation4='selu',\n",
        "                           model__dropout1=0.7861582092207701, \n",
        "                           model__dropout2=0.1651211488004366, \n",
        "                           model__dropout3=0.3806276727312806, \n",
        "                           model__dropout4=0.5407685563014424, \n",
        "                           model__layer1=335, \n",
        "                           model__layer2=352, \n",
        "                           model__layer3=87, \n",
        "                           model__layer4=110, \n",
        "                           model__learning_rate=0.0013462596203423387,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.40880873684195296, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6c8b4b-2df4-4acb-bb12-c8a063846683",
        "id": "D8qxuavgI50P"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=69, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000174B0636520>, <keras.callbacks.LambdaCallback object at 0x00000174B06D61F0>], epochs=48, model=<function create_model at 0x00000174B0F1F820>, model__activation1='relu', model__activation2='sigmoid', model__activation3='relu', model__activation4='se...rning_rate=0.0013462596203423387, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001762782C790>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000017617095160>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.40880873684195296, verbose=0),\n",
              "                    clip_y=84, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6683ff-c77e-4b06-c3f3-f8e5c9045cda",
        "id": "TbCjxqHdI50R"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_97 (Dense)            (None, 335)               678040    \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 335)               0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 352)               118272    \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 352)               0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 87)                30711     \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 87)                0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 110)               9680      \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 110)               0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 1)                 111       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 836,814\n",
            "Trainable params: 836,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=423.684, rmse=20.584, r2=0.274; v_loss=166.875, v_rmse=12.918, v_r2=0.737; \n",
            "E 2\t: loss=258.650, rmse=16.083, r2=0.557; v_loss=246.079, v_rmse=15.687, v_r2=0.612; \n",
            "E 3\t: loss=235.103, rmse=15.333, r2=0.597; v_loss=167.121, v_rmse=12.928, v_r2=0.736; \n",
            "E 4\t: loss=215.869, rmse=14.692, r2=0.630; v_loss=275.640, v_rmse=16.602, v_r2=0.565; \n",
            "E 5\t: loss=206.191, rmse=14.359, r2=0.647; v_loss=167.430, v_rmse=12.939, v_r2=0.736; \n",
            "E 6\t: loss=201.635, rmse=14.200, r2=0.654; v_loss=340.731, v_rmse=18.459, v_r2=0.463; \n",
            "E 7\t: loss=199.174, rmse=14.113, r2=0.659; v_loss=289.292, v_rmse=17.009, v_r2=0.544; \n",
            "E 8\t: loss=198.921, rmse=14.104, r2=0.659; v_loss=279.392, v_rmse=16.715, v_r2=0.559; \n",
            "E 9\t: loss=196.984, rmse=14.035, r2=0.662; v_loss=257.013, v_rmse=16.032, v_r2=0.595; \n",
            "E 10\t: loss=191.929, rmse=13.854, r2=0.671; v_loss=272.728, v_rmse=16.514, v_r2=0.570; \n",
            "E 11\t: loss=189.841, rmse=13.778, r2=0.675; v_loss=368.066, v_rmse=19.185, v_r2=0.419; \n",
            "E 12\t: loss=192.417, rmse=13.871, r2=0.670; v_loss=376.571, v_rmse=19.405, v_r2=0.406; \n",
            "E 13\t: loss=189.222, rmse=13.756, r2=0.676; v_loss=258.955, v_rmse=16.092, v_r2=0.592; \n",
            "E 14\t: loss=190.580, rmse=13.805, r2=0.673; v_loss=223.923, v_rmse=14.964, v_r2=0.647; \n",
            "E 15\t: loss=185.726, rmse=13.628, r2=0.682; v_loss=242.707, v_rmse=15.579, v_r2=0.617; \n",
            "E 16\t: loss=188.965, rmse=13.746, r2=0.676; v_loss=216.082, v_rmse=14.700, v_r2=0.659; \n",
            "E 17\t: loss=188.345, rmse=13.724, r2=0.677; v_loss=239.226, v_rmse=15.467, v_r2=0.623; \n",
            "E 18\t: loss=186.671, rmse=13.663, r2=0.680; v_loss=235.231, v_rmse=15.337, v_r2=0.629; \n",
            "E 19\t: loss=185.831, rmse=13.632, r2=0.682; v_loss=223.592, v_rmse=14.953, v_r2=0.647; \n",
            "E 20\t: loss=180.926, rmse=13.451, r2=0.690; v_loss=217.129, v_rmse=14.735, v_r2=0.658; \n",
            "E 21\t: loss=183.129, rmse=13.533, r2=0.686; v_loss=305.052, v_rmse=17.466, v_r2=0.519; \n",
            "E 22\t: loss=179.931, rmse=13.414, r2=0.692; v_loss=222.200, v_rmse=14.906, v_r2=0.650; \n",
            "E 23\t: loss=180.695, rmse=13.442, r2=0.690; v_loss=227.600, v_rmse=15.086, v_r2=0.641; \n",
            "E 24\t: loss=185.359, rmse=13.615, r2=0.682; v_loss=240.435, v_rmse=15.506, v_r2=0.621; \n",
            "E 25\t: loss=180.557, rmse=13.437, r2=0.691; v_loss=268.009, v_rmse=16.371, v_r2=0.577; \n",
            "E 26\t: loss=182.845, rmse=13.522, r2=0.687; v_loss=251.342, v_rmse=15.854, v_r2=0.604; \n",
            "E 27\t: loss=178.687, rmse=13.367, r2=0.694; v_loss=260.551, v_rmse=16.142, v_r2=0.589; \n",
            "E 28\t: loss=177.962, rmse=13.340, r2=0.695; v_loss=289.942, v_rmse=17.028, v_r2=0.543; \n",
            "E 29\t: loss=175.284, rmse=13.240, r2=0.700; v_loss=321.022, v_rmse=17.917, v_r2=0.494; \n",
            "E 30\t: loss=180.219, rmse=13.425, r2=0.691; v_loss=225.384, v_rmse=15.013, v_r2=0.645; \n",
            "E 31\t: loss=177.375, rmse=13.318, r2=0.696; v_loss=194.973, v_rmse=13.963, v_r2=0.692; \n",
            "E 32\t: loss=176.346, rmse=13.280, r2=0.698; v_loss=243.297, v_rmse=15.598, v_r2=0.616; \n",
            "E 33\t: loss=176.556, rmse=13.287, r2=0.697; v_loss=234.014, v_rmse=15.298, v_r2=0.631; \n",
            "E 34\t: loss=176.107, rmse=13.271, r2=0.698; v_loss=271.681, v_rmse=16.483, v_r2=0.571; \n",
            "Finished: 2022-11-02 10:32:39.800063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacfd527-9a11-4363-e0b5-45ddaadd8b6b",
        "id": "Yz7_bVa-I50T"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.316,RMSE=-22.091\n",
            "Finished: 2022-11-02 10:32:43.843187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "haoiX8X2iOwG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}