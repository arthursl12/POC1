{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "Q4QwyfhXs_hv",
        "n7MBDuPasy-s",
        "e7-_jqRw3cRa",
        "QinQ4hWStzHt",
        "boZqFQNlraCh",
        "IIXnBTkfxpCf",
        "SL1dv6EX4NUk",
        "r6YQTm7aOf2G",
        "klzYEWjrZiXt",
        "MQi8MHh20wou",
        "BlwL5EnXQcuy"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKbJxcmHRVAUoSKEanbLyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "41c02b42-dc40-431e-e53c-eed90fceb186"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f649ab6-ee12-4ed4-a39b-3dfcbb108792"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/CMaps/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgkQUCfsWAGK",
        "outputId": "e36c0cf5-f1ee-40a6-c330-1e272ab6fea2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "[WinError 2] The system cannot find the file specified: 'dataset_2/'\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1,folder=folder)\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "9ac83116-2180-4cb0-d2f9-35bb11f2e2d2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "2dd5aa0b-647b-4680-fcf5-6b375dd60868"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "onw4pCwZy-1s",
        "outputId": "35af8543-08ba-459a-eada-d092bf146e76"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lmFKjQaeip1b",
        "outputId": "c705ad90-f1ba-4e63-f7b4-3827f42b764d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "2641e6d8-237f-4661-df6c-fbb1cb7974f3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "26hK4VWkx1R7",
        "outputId": "77cf03a8-9b36-4b04-8e22-89ffcfcb3904"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Construction"
      ],
      "metadata": {
        "id": "SL1dv6EX4NUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "PA_LrxmV4NUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "BV6PD9sl4NUw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "83kJj9eJ4NU1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "t18eQ8H3EfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "Ex7mZbQNEfGW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "SPE41-R2EfGX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "a2kynIDbEfGZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[index_cols[1]]+[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import is_finalizing\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class MLPWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "    def clean_cols(self,df):\n",
        "        if(\"unit_number\" in df.columns): del df[\"unit_number\"]\n",
        "        if(\"unit_number\" in df.columns): del df[\"unit_number\"]\n",
        "        if(\"time\" in df.columns): del df[\"time\"]\n",
        "        if((not self.include_settings)): \n",
        "            for col in settings_cols:\n",
        "                if(col in df.columns): del df[col]\n",
        "        return df\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Drop irrelevant column\n",
        "        data = pd.DataFrame(X).copy()\n",
        "        data = self.clean_cols(data)\n",
        "        \n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data)\n",
        "        data = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out())\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "\n",
        "        # Scale the data\n",
        "        data = self.scaler.fit_transform(data)\n",
        "        data = pd.DataFrame(data, \n",
        "                            columns=self.scaler.get_feature_names_out())\n",
        "        X_train = data.copy()\n",
        "        \n",
        "        # Clip and transform labels\n",
        "        data2 = pd.DataFrame(y, columns=[\"RUL\"]).copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = data2\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        INPUT_SHAPE = X_train.shape[1]\n",
        "\n",
        "        # Fit model\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.columns) != len(self.feature_cols)):\n",
        "            X_train = self.transform_features(X)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def transform_features(self, df):\n",
        "        # Drop irrelevant column\n",
        "        data = pd.DataFrame(df).copy()\n",
        "        data = self.clean_cols(data)\n",
        "        \n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.transform(data)\n",
        "        data = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out())\n",
        "        # self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "\n",
        "        # Scale the data\n",
        "        data = self.scaler.transform(data)\n",
        "        data = pd.DataFrame(data, \n",
        "                            columns=self.scaler.get_feature_names_out())\n",
        "        return data\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        X_test = self.transform_features(X)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = pd.DataFrame(y, columns=[\"RUL\"]).copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = data2\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)"
      ],
      "metadata": {
        "id": "-mG7sVkcpALn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = pd.DataFrame(test)\n",
        "    test2 = model.clean_cols(test2)\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2)\n",
        "    test2 = pd.DataFrame(transf, \n",
        "                         columns=model.polyft.get_feature_names_out())\n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2 = model.scaler.transform(test2)\n",
        "    test2 = pd.DataFrame(test2, \n",
        "                         columns=model.polyft.get_feature_names_out())\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 layer4=None, activation4=\"tanh\"    , dropout4=0.1,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model.add(Dense(layer1, input_dim=INPUT_SHAPE, activation=activation1))\n",
        "    model.add(Dropout(dropout1))\n",
        "\n",
        "    # Additional hidden layers\n",
        "    if(layer2 is not None):\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        if (layer3 is not None):\n",
        "            model.add(Dense(layer3, activation=activation3))\n",
        "            model.add(Dropout(dropout3))\n",
        "            if (layer4 is not None):\n",
        "                model.add(Dense(layer4, activation=activation4))\n",
        "                model.add(Dropout(dropout4))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "NbakKD-DlU5-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-1"
      ],
      "metadata": {
        "id": "DU8TxguXIChd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "zkCJJsiS-J7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6275937811619965  \n",
        "Test: 0.504\n",
        "```\n",
        "('basemodel__batch_size', 262),\n",
        "('basemodel__epochs', 47),\n",
        "('basemodel__model__activation', 'relu'),\n",
        "('basemodel__model__dropout', 0.42198962995190514),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.00528953958947019),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.17975244796806303),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "iWX0RiAL4uGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=262,\n",
        "                           epochs=47,\n",
        "                           model__activation1='relu',\n",
        "                           model__dropout1=0.42198962995190514, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.00528953958947019,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.17975244796806303, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "id": "xfYRKHQKi3Xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109676dd-d00b-40f9-d7ca-b636659bdcf6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=262, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=47, model=<function create_model at 0x000001C61804DDC0>, model__activation1='relu', model__dropout1=0.42198962995190514, model__layer1=512, model__learning_rate=0.00528953958947019, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C6532841C0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C618000A90>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.17975244796806303, verbose=0))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SF4CE-ab5IKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58cc0178-937d-4d6a-a3b4-473cd8727392"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,777\n",
            "Trainable params: 11,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=7768.790, rmse=88.141, r2=-0.742; v_loss=4409.638, v_rmse=66.405, v_r2=0.258; \n",
            "E 2\t: loss=2299.978, rmse=47.958, r2=0.484; v_loss=2736.304, v_rmse=52.310, v_r2=0.539; \n",
            "E 3\t: loss=1662.483, rmse=40.774, r2=0.627; v_loss=2625.097, v_rmse=51.236, v_r2=0.558; \n",
            "E 4\t: loss=1608.881, rmse=40.111, r2=0.639; v_loss=2628.638, v_rmse=51.270, v_r2=0.558; \n",
            "E 5\t: loss=1596.526, rmse=39.957, r2=0.642; v_loss=2566.683, v_rmse=50.662, v_r2=0.568; \n",
            "E 6\t: loss=1592.156, rmse=39.902, r2=0.643; v_loss=2583.245, v_rmse=50.826, v_r2=0.565; \n",
            "E 7\t: loss=1583.912, rmse=39.798, r2=0.645; v_loss=2556.475, v_rmse=50.562, v_r2=0.570; \n",
            "E 8\t: loss=1582.204, rmse=39.777, r2=0.645; v_loss=2561.202, v_rmse=50.608, v_r2=0.569; \n",
            "E 9\t: loss=1573.533, rmse=39.668, r2=0.647; v_loss=2565.298, v_rmse=50.649, v_r2=0.568; \n",
            "E 10\t: loss=1580.401, rmse=39.754, r2=0.646; v_loss=2642.027, v_rmse=51.401, v_r2=0.555; \n",
            "E 11\t: loss=1575.077, rmse=39.687, r2=0.647; v_loss=2548.785, v_rmse=50.485, v_r2=0.571; \n",
            "E 12\t: loss=1578.563, rmse=39.731, r2=0.646; v_loss=2531.116, v_rmse=50.310, v_r2=0.574; \n",
            "E 13\t: loss=1573.584, rmse=39.668, r2=0.647; v_loss=2518.590, v_rmse=50.186, v_r2=0.576; \n",
            "E 14\t: loss=1570.906, rmse=39.635, r2=0.648; v_loss=2585.951, v_rmse=50.852, v_r2=0.565; \n",
            "E 15\t: loss=1569.336, rmse=39.615, r2=0.648; v_loss=2655.540, v_rmse=51.532, v_r2=0.553; \n",
            "E 16\t: loss=1573.943, rmse=39.673, r2=0.647; v_loss=2592.504, v_rmse=50.917, v_r2=0.564; \n",
            "E 17\t: loss=1564.826, rmse=39.558, r2=0.649; v_loss=2623.961, v_rmse=51.225, v_r2=0.558; \n",
            "E 18\t: loss=1567.255, rmse=39.589, r2=0.649; v_loss=2645.806, v_rmse=51.437, v_r2=0.555; \n",
            "E 19\t: loss=1577.906, rmse=39.723, r2=0.646; v_loss=2618.034, v_rmse=51.167, v_r2=0.559; \n",
            "E 20\t: loss=1575.859, rmse=39.697, r2=0.647; v_loss=2525.624, v_rmse=50.256, v_r2=0.575; \n",
            "E 21\t: loss=1576.784, rmse=39.709, r2=0.646; v_loss=2532.970, v_rmse=50.329, v_r2=0.574; \n",
            "E 22\t: loss=1562.263, rmse=39.525, r2=0.650; v_loss=2568.651, v_rmse=50.682, v_r2=0.568; \n",
            "E 23\t: loss=1574.418, rmse=39.679, r2=0.647; v_loss=2496.751, v_rmse=49.967, v_r2=0.580; \n",
            "E 24\t: loss=1569.501, rmse=39.617, r2=0.648; v_loss=2538.042, v_rmse=50.379, v_r2=0.573; \n",
            "E 25\t: loss=1564.938, rmse=39.559, r2=0.649; v_loss=2540.247, v_rmse=50.401, v_r2=0.572; \n",
            "E 26\t: loss=1555.359, rmse=39.438, r2=0.651; v_loss=2578.983, v_rmse=50.784, v_r2=0.566; \n",
            "E 27\t: loss=1573.444, rmse=39.667, r2=0.647; v_loss=2486.687, v_rmse=49.867, v_r2=0.581; \n",
            "E 28\t: loss=1573.044, rmse=39.662, r2=0.647; v_loss=2592.905, v_rmse=50.921, v_r2=0.564; \n",
            "E 29\t: loss=1568.113, rmse=39.599, r2=0.648; v_loss=2587.351, v_rmse=50.866, v_r2=0.564; \n",
            "E 30\t: loss=1562.259, rmse=39.525, r2=0.650; v_loss=2525.915, v_rmse=50.258, v_r2=0.575; \n",
            "E 31\t: loss=1561.935, rmse=39.521, r2=0.650; v_loss=2573.612, v_rmse=50.731, v_r2=0.567; \n",
            "Finished: 2022-10-16 08:54:09.745824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "9vLfPZkw5Ixg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27595284-a8c1-466f-855c-51e0af92eb08"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C617E6B790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "R2=0.506,RMSE=-29.199\n",
            "Finished: 2022-10-16 08:54:12.730080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "mMYPm8b65n0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8670568151811345  \n",
        "Test: 0.865\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'sigmoid'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 450),\n",
        "('basemodel__model__learning_rate', 0.006977518145392822),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 80),\n",
        "('scaler', MinMaxScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "uooUt5Yq5n0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='sigmoid',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=450, \n",
        "                           model__learning_rate=0.006977518145392822,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a6c57d-ee5b-4a4a-f83f-7f318b2fae99",
        "id": "Lj8fIDg15n0X"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=50, model=<function create_model at 0x000001C61804DDC0>, model__activation1='sigmoid', model__dropout1=0.1, model__layer1=450, model__learning_rate=0.006977518145392822, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C617DF6AF0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C6194942B0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "y1uxSqWy5n0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0141405-10d6-45e2-ef36-870e696017a3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 450)               9900      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 450)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 451       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,351\n",
            "Trainable params: 10,351\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=343.262, rmse=18.527, r2=0.428; v_loss=121.074, v_rmse=11.003, v_r2=0.783; \n",
            "E 2\t: loss=111.671, rmse=10.567, r2=0.814; v_loss=98.067, v_rmse=9.903, v_r2=0.824; \n",
            "E 3\t: loss=95.680, rmse=9.782, r2=0.841; v_loss=94.655, v_rmse=9.729, v_r2=0.831; \n",
            "E 4\t: loss=92.671, rmse=9.627, r2=0.846; v_loss=95.667, v_rmse=9.781, v_r2=0.829; \n",
            "E 5\t: loss=90.965, rmse=9.538, r2=0.848; v_loss=94.582, v_rmse=9.725, v_r2=0.831; \n",
            "E 6\t: loss=88.197, rmse=9.391, r2=0.853; v_loss=98.511, v_rmse=9.925, v_r2=0.824; \n",
            "E 7\t: loss=86.304, rmse=9.290, r2=0.856; v_loss=89.350, v_rmse=9.453, v_r2=0.840; \n",
            "E 8\t: loss=84.089, rmse=9.170, r2=0.860; v_loss=90.165, v_rmse=9.496, v_r2=0.839; \n",
            "E 9\t: loss=84.130, rmse=9.172, r2=0.860; v_loss=89.919, v_rmse=9.483, v_r2=0.839; \n",
            "E 10\t: loss=84.037, rmse=9.167, r2=0.860; v_loss=86.559, v_rmse=9.304, v_r2=0.845; \n",
            "E 11\t: loss=83.251, rmse=9.124, r2=0.861; v_loss=87.943, v_rmse=9.378, v_r2=0.843; \n",
            "E 12\t: loss=82.832, rmse=9.101, r2=0.862; v_loss=85.506, v_rmse=9.247, v_r2=0.847; \n",
            "E 13\t: loss=81.928, rmse=9.051, r2=0.863; v_loss=86.799, v_rmse=9.317, v_r2=0.845; \n",
            "E 14\t: loss=82.552, rmse=9.086, r2=0.862; v_loss=86.353, v_rmse=9.293, v_r2=0.845; \n",
            "E 15\t: loss=82.253, rmse=9.069, r2=0.863; v_loss=86.049, v_rmse=9.276, v_r2=0.846; \n",
            "E 16\t: loss=81.641, rmse=9.036, r2=0.864; v_loss=85.302, v_rmse=9.236, v_r2=0.847; \n",
            "E 17\t: loss=81.504, rmse=9.028, r2=0.864; v_loss=86.317, v_rmse=9.291, v_r2=0.845; \n",
            "E 18\t: loss=80.828, rmse=8.990, r2=0.865; v_loss=85.725, v_rmse=9.259, v_r2=0.847; \n",
            "E 19\t: loss=80.897, rmse=8.994, r2=0.865; v_loss=84.163, v_rmse=9.174, v_r2=0.849; \n",
            "E 20\t: loss=80.300, rmse=8.961, r2=0.866; v_loss=89.562, v_rmse=9.464, v_r2=0.840; \n",
            "E 21\t: loss=80.075, rmse=8.948, r2=0.867; v_loss=85.934, v_rmse=9.270, v_r2=0.846; \n",
            "E 22\t: loss=79.848, rmse=8.936, r2=0.867; v_loss=84.200, v_rmse=9.176, v_r2=0.849; \n",
            "E 23\t: loss=79.723, rmse=8.929, r2=0.867; v_loss=83.812, v_rmse=9.155, v_r2=0.850; \n",
            "E 24\t: loss=79.306, rmse=8.905, r2=0.868; v_loss=85.220, v_rmse=9.231, v_r2=0.847; \n",
            "E 25\t: loss=79.015, rmse=8.889, r2=0.868; v_loss=84.550, v_rmse=9.195, v_r2=0.849; \n",
            "E 26\t: loss=78.739, rmse=8.873, r2=0.869; v_loss=86.261, v_rmse=9.288, v_r2=0.846; \n",
            "E 27\t: loss=78.514, rmse=8.861, r2=0.869; v_loss=86.204, v_rmse=9.285, v_r2=0.846; \n",
            "E 28\t: loss=78.019, rmse=8.833, r2=0.870; v_loss=94.741, v_rmse=9.733, v_r2=0.830; \n",
            "E 29\t: loss=78.179, rmse=8.842, r2=0.870; v_loss=85.189, v_rmse=9.230, v_r2=0.847; \n",
            "E 30\t: loss=79.129, rmse=8.895, r2=0.868; v_loss=83.884, v_rmse=9.159, v_r2=0.850; \n",
            "E 31\t: loss=77.875, rmse=8.825, r2=0.870; v_loss=85.155, v_rmse=9.228, v_r2=0.848; \n",
            "E 32\t: loss=78.485, rmse=8.859, r2=0.869; v_loss=84.673, v_rmse=9.202, v_r2=0.848; \n",
            "E 33\t: loss=78.256, rmse=8.846, r2=0.870; v_loss=89.047, v_rmse=9.436, v_r2=0.841; \n",
            "E 34\t: loss=77.975, rmse=8.830, r2=0.870; v_loss=87.724, v_rmse=9.366, v_r2=0.843; \n",
            "E 35\t: loss=77.487, rmse=8.803, r2=0.871; v_loss=85.494, v_rmse=9.246, v_r2=0.847; \n",
            "E 36\t: loss=77.566, rmse=8.807, r2=0.871; v_loss=85.368, v_rmse=9.239, v_r2=0.847; \n",
            "E 37\t: loss=78.182, rmse=8.842, r2=0.870; v_loss=86.693, v_rmse=9.311, v_r2=0.845; \n",
            "E 38\t: loss=77.989, rmse=8.831, r2=0.870; v_loss=86.936, v_rmse=9.324, v_r2=0.844; \n",
            "E 39\t: loss=77.919, rmse=8.827, r2=0.870; v_loss=85.020, v_rmse=9.221, v_r2=0.848; \n",
            "E 40\t: loss=77.459, rmse=8.801, r2=0.871; v_loss=85.125, v_rmse=9.226, v_r2=0.848; \n",
            "E 41\t: loss=78.066, rmse=8.836, r2=0.870; v_loss=88.051, v_rmse=9.384, v_r2=0.842; \n",
            "E 42\t: loss=77.724, rmse=8.816, r2=0.870; v_loss=85.539, v_rmse=9.249, v_r2=0.847; \n",
            "E 43\t: loss=77.033, rmse=8.777, r2=0.872; v_loss=88.948, v_rmse=9.431, v_r2=0.841; \n",
            "E 44\t: loss=77.516, rmse=8.804, r2=0.871; v_loss=85.108, v_rmse=9.225, v_r2=0.848; \n",
            "E 45\t: loss=77.551, rmse=8.806, r2=0.871; v_loss=90.381, v_rmse=9.507, v_r2=0.838; \n",
            "E 46\t: loss=77.609, rmse=8.810, r2=0.871; v_loss=85.945, v_rmse=9.271, v_r2=0.846; \n",
            "E 47\t: loss=77.413, rmse=8.798, r2=0.871; v_loss=89.114, v_rmse=9.440, v_r2=0.840; \n",
            "E 48\t: loss=77.558, rmse=8.807, r2=0.871; v_loss=86.947, v_rmse=9.325, v_r2=0.844; \n",
            "Finished: 2022-10-16 08:56:36.208243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Q1waoIXF5n0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe575951-25b3-478c-d2f6-85c54801e903"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.855,RMSE=-10.152\n",
            "Finished: 2022-10-16 08:57:04.260956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL "
      ],
      "metadata": {
        "id": "X4OKIiMD6X4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.6307902416968273  \n",
        "Test: 0.289\n",
        "```\n",
        "('basemodel__batch_size', 197),\n",
        "('basemodel__epochs', 41),\n",
        "('basemodel__model__activation', 'relu'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 400),\n",
        "('basemodel__model__learning_rate', 0.01),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('poly_degree', 2),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "OUMvs31w6X4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=197,\n",
        "                           epochs=41,\n",
        "                           model__activation1='relu',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=400, \n",
        "                           model__learning_rate=0.01,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551c79ad-a52a-485f-a02a-1f68ded8be0e",
        "id": "dpKrE34E6X4j"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=197, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=41, model=<function create_model at 0x000001C61804DDC0>, model__activation1='relu', model__dropout1=0.1, model__layer1=400, model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C6186A1AC0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C618643B80>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "HHlBlEju6X4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a72403-87b2-48c6-f541-9f2f33bf228b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 400)               101200    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,601\n",
            "Trainable params: 101,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3590.689, rmse=59.922, r2=0.211; v_loss=2748.295, v_rmse=52.424, v_r2=0.561; \n",
            "E 2\t: loss=1942.870, rmse=44.078, r2=0.573; v_loss=2533.745, v_rmse=50.336, v_r2=0.596; \n",
            "E 3\t: loss=1824.145, rmse=42.710, r2=0.599; v_loss=2450.530, v_rmse=49.503, v_r2=0.609; \n",
            "E 4\t: loss=1733.372, rmse=41.634, r2=0.619; v_loss=2581.042, v_rmse=50.804, v_r2=0.588; \n",
            "E 5\t: loss=1717.820, rmse=41.447, r2=0.622; v_loss=2567.043, v_rmse=50.666, v_r2=0.590; \n",
            "E 6\t: loss=1692.822, rmse=41.144, r2=0.628; v_loss=2762.525, v_rmse=52.560, v_r2=0.559; \n",
            "E 7\t: loss=1710.080, rmse=41.353, r2=0.624; v_loss=2751.144, v_rmse=52.451, v_r2=0.561; \n",
            "E 8\t: loss=1708.064, rmse=41.329, r2=0.625; v_loss=2577.152, v_rmse=50.766, v_r2=0.589; \n",
            "E 9\t: loss=1689.479, rmse=41.103, r2=0.629; v_loss=2740.046, v_rmse=52.345, v_r2=0.563; \n",
            "E 10\t: loss=1719.492, rmse=41.467, r2=0.622; v_loss=2809.525, v_rmse=53.005, v_r2=0.552; \n",
            "E 11\t: loss=1726.253, rmse=41.548, r2=0.621; v_loss=2583.686, v_rmse=50.830, v_r2=0.588; \n",
            "E 12\t: loss=1681.349, rmse=41.004, r2=0.630; v_loss=2568.516, v_rmse=50.681, v_r2=0.590; \n",
            "E 13\t: loss=1675.370, rmse=40.931, r2=0.632; v_loss=2824.650, v_rmse=53.147, v_r2=0.549; \n",
            "E 14\t: loss=1681.126, rmse=41.002, r2=0.630; v_loss=2712.137, v_rmse=52.078, v_r2=0.567; \n",
            "E 15\t: loss=1669.558, rmse=40.860, r2=0.633; v_loss=2382.906, v_rmse=48.815, v_r2=0.620; \n",
            "E 16\t: loss=1686.245, rmse=41.064, r2=0.629; v_loss=2587.359, v_rmse=50.866, v_r2=0.587; \n",
            "E 17\t: loss=1666.735, rmse=40.826, r2=0.634; v_loss=2677.732, v_rmse=51.747, v_r2=0.573; \n",
            "E 18\t: loss=1692.579, rmse=41.141, r2=0.628; v_loss=2772.406, v_rmse=52.654, v_r2=0.558; \n",
            "E 19\t: loss=1680.530, rmse=40.994, r2=0.631; v_loss=2672.459, v_rmse=51.696, v_r2=0.573; \n",
            "E 20\t: loss=1668.867, rmse=40.852, r2=0.633; v_loss=2823.058, v_rmse=53.132, v_r2=0.549; \n",
            "E 21\t: loss=1689.645, rmse=41.105, r2=0.629; v_loss=2660.970, v_rmse=51.585, v_r2=0.575; \n",
            "E 22\t: loss=1665.819, rmse=40.814, r2=0.634; v_loss=2492.334, v_rmse=49.923, v_r2=0.602; \n",
            "E 23\t: loss=1663.098, rmse=40.781, r2=0.634; v_loss=2895.900, v_rmse=53.814, v_r2=0.538; \n",
            "E 24\t: loss=1665.322, rmse=40.808, r2=0.634; v_loss=2444.904, v_rmse=49.446, v_r2=0.610; \n",
            "E 25\t: loss=1672.722, rmse=40.899, r2=0.632; v_loss=2532.550, v_rmse=50.324, v_r2=0.596; \n",
            "E 26\t: loss=1664.078, rmse=40.793, r2=0.634; v_loss=2535.842, v_rmse=50.357, v_r2=0.595; \n",
            "E 27\t: loss=1697.775, rmse=41.204, r2=0.627; v_loss=2492.866, v_rmse=49.929, v_r2=0.602; \n",
            "E 28\t: loss=1663.907, rmse=40.791, r2=0.634; v_loss=2982.251, v_rmse=54.610, v_r2=0.524; \n",
            "Finished: 2022-10-16 08:57:37.733650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "XrGQOj3e6X4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fedb68-4c3c-4e12-cdd3-d21325472c9d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.597,RMSE=-26.379\n",
            "Finished: 2022-10-16 08:57:37.851678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "xUq7j-FC7J6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8693404879366771  \n",
        "Test: 0.874\n",
        "```\n",
        "('basemodel__batch_size', 278),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'relu'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 469),\n",
        "('basemodel__model__learning_rate', 0.002874922426530888),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 80),\n",
        "('poly_degree', 2),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "XfyXyuQl7J65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=278,\n",
        "                           epochs=50,\n",
        "                           model__activation1='relu',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=469, \n",
        "                           model__learning_rate=0.002874922426530888,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f2abb0-a3ba-40ed-e080-50f91442ec94",
        "id": "AxhumNq67J7A"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=278, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=50, model=<function create_model at 0x000001C61804DDC0>, model__activation1='relu', model__dropout1=0.1, model__layer1=469, model__learning_rate=0.002874922426530888, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C618879DC0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C6188938B0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "3IOHJ_u87J7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c13761-bbac-46f2-9652-5685a4ebb114"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 469)               118657    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 469)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 470       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 119,127\n",
            "Trainable params: 119,127\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1629.454, rmse=40.366, r2=-1.716; v_loss=780.958, v_rmse=27.946, v_r2=-0.398; \n",
            "E 2\t: loss=491.348, rmse=22.166, r2=0.181; v_loss=314.425, v_rmse=17.732, v_r2=0.437; \n",
            "E 3\t: loss=282.066, rmse=16.795, r2=0.530; v_loss=232.004, v_rmse=15.232, v_r2=0.585; \n",
            "E 4\t: loss=220.318, rmse=14.843, r2=0.633; v_loss=189.044, v_rmse=13.749, v_r2=0.662; \n",
            "E 5\t: loss=169.954, rmse=13.037, r2=0.717; v_loss=142.829, v_rmse=11.951, v_r2=0.744; \n",
            "E 6\t: loss=134.422, rmse=11.594, r2=0.776; v_loss=116.756, v_rmse=10.805, v_r2=0.791; \n",
            "E 7\t: loss=111.370, rmse=10.553, r2=0.814; v_loss=103.264, v_rmse=10.162, v_r2=0.815; \n",
            "E 8\t: loss=101.625, rmse=10.081, r2=0.831; v_loss=103.167, v_rmse=10.157, v_r2=0.815; \n",
            "E 9\t: loss=95.669, rmse=9.781, r2=0.841; v_loss=95.612, v_rmse=9.778, v_r2=0.829; \n",
            "E 10\t: loss=93.223, rmse=9.655, r2=0.845; v_loss=94.263, v_rmse=9.709, v_r2=0.831; \n",
            "E 11\t: loss=92.265, rmse=9.605, r2=0.846; v_loss=91.665, v_rmse=9.574, v_r2=0.836; \n",
            "E 12\t: loss=88.260, rmse=9.395, r2=0.853; v_loss=93.399, v_rmse=9.664, v_r2=0.833; \n",
            "E 13\t: loss=87.856, rmse=9.373, r2=0.854; v_loss=91.263, v_rmse=9.553, v_r2=0.837; \n",
            "E 14\t: loss=87.311, rmse=9.344, r2=0.854; v_loss=92.425, v_rmse=9.614, v_r2=0.835; \n",
            "E 15\t: loss=86.210, rmse=9.285, r2=0.856; v_loss=91.902, v_rmse=9.587, v_r2=0.835; \n",
            "E 16\t: loss=86.469, rmse=9.299, r2=0.856; v_loss=96.786, v_rmse=9.838, v_r2=0.827; \n",
            "E 17\t: loss=87.660, rmse=9.363, r2=0.854; v_loss=106.104, v_rmse=10.301, v_r2=0.810; \n",
            "E 18\t: loss=88.945, rmse=9.431, r2=0.852; v_loss=96.317, v_rmse=9.814, v_r2=0.828; \n",
            "E 19\t: loss=85.881, rmse=9.267, r2=0.857; v_loss=93.718, v_rmse=9.681, v_r2=0.832; \n",
            "E 20\t: loss=86.873, rmse=9.321, r2=0.855; v_loss=90.064, v_rmse=9.490, v_r2=0.839; \n",
            "E 21\t: loss=85.095, rmse=9.225, r2=0.858; v_loss=88.310, v_rmse=9.397, v_r2=0.842; \n",
            "E 22\t: loss=85.597, rmse=9.252, r2=0.857; v_loss=93.503, v_rmse=9.670, v_r2=0.833; \n",
            "E 23\t: loss=85.307, rmse=9.236, r2=0.858; v_loss=92.023, v_rmse=9.593, v_r2=0.835; \n",
            "E 24\t: loss=85.055, rmse=9.223, r2=0.858; v_loss=91.526, v_rmse=9.567, v_r2=0.836; \n",
            "E 25\t: loss=83.257, rmse=9.125, r2=0.861; v_loss=100.686, v_rmse=10.034, v_r2=0.820; \n",
            "E 26\t: loss=83.571, rmse=9.142, r2=0.861; v_loss=92.323, v_rmse=9.608, v_r2=0.835; \n",
            "E 27\t: loss=84.618, rmse=9.199, r2=0.859; v_loss=90.028, v_rmse=9.488, v_r2=0.839; \n",
            "E 28\t: loss=82.523, rmse=9.084, r2=0.862; v_loss=92.471, v_rmse=9.616, v_r2=0.834; \n",
            "E 29\t: loss=83.164, rmse=9.119, r2=0.861; v_loss=92.534, v_rmse=9.619, v_r2=0.834; \n",
            "E 30\t: loss=82.269, rmse=9.070, r2=0.863; v_loss=91.059, v_rmse=9.542, v_r2=0.837; \n",
            "E 31\t: loss=83.099, rmse=9.116, r2=0.862; v_loss=91.576, v_rmse=9.570, v_r2=0.836; \n",
            "E 32\t: loss=83.130, rmse=9.118, r2=0.861; v_loss=90.071, v_rmse=9.491, v_r2=0.839; \n",
            "E 33\t: loss=80.732, rmse=8.985, r2=0.865; v_loss=89.839, v_rmse=9.478, v_r2=0.839; \n",
            "E 34\t: loss=82.067, rmse=9.059, r2=0.863; v_loss=90.843, v_rmse=9.531, v_r2=0.837; \n",
            "E 35\t: loss=81.416, rmse=9.023, r2=0.864; v_loss=90.421, v_rmse=9.509, v_r2=0.838; \n",
            "E 36\t: loss=81.339, rmse=9.019, r2=0.864; v_loss=92.339, v_rmse=9.609, v_r2=0.835; \n",
            "E 37\t: loss=81.516, rmse=9.029, r2=0.864; v_loss=88.985, v_rmse=9.433, v_r2=0.841; \n",
            "E 38\t: loss=82.573, rmse=9.087, r2=0.862; v_loss=88.794, v_rmse=9.423, v_r2=0.841; \n",
            "Finished: 2022-10-16 08:58:16.965054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "bQgkkrV47J7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7489cc77-3795-4c3c-aa0c-21708cea164f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.875,RMSE=-9.428\n",
            "Finished: 2022-10-16 08:58:17.045025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-2"
      ],
      "metadata": {
        "id": "FDHk5EzS8XuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "w3w40nFu8Xug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6272918246191982  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 180),\n",
        "             ('basemodel__epochs', 10),\n",
        "             ('basemodel__model__activation1', 'selu'),\n",
        "             ('basemodel__model__activation2', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.6877162153707456),\n",
        "             ('basemodel__model__dropout2', 0.23474535539749616),\n",
        "             ('basemodel__model__layer1', 468),\n",
        "             ('basemodel__model__layer2', 435),\n",
        "             ('basemodel__model__learning_rate', 0.009683115627232612),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "Bt8LxsyX8Xun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=180,\n",
        "                           epochs=10,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__dropout1=0.6877162153707456, \n",
        "                           model__dropout2=0.23474535539749616, \n",
        "                           model__layer1=468, \n",
        "                           model__layer2=435, \n",
        "                           model__learning_rate=0.009683115627232612,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fc867c-0263-4c30-b98c-e77a7e4ed727",
        "id": "AzAbUlFJ8Xuv"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=180, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=10, model=<function create_model at 0x000001C61804DDC0>, model__activation1='selu', model__activation2='sigmoid', model__dropout1=0.6877162153707456, model__dropo..., model__layer1=468, model__layer2=435, model__learning_rate=0.009683115627232612, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C6189F2640>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C618895100>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "x0gUTFtS8Xu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b37955-526e-4bd8-ed9f-a30f125d0241"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 468)               10296     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 468)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 435)               204015    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 435)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 436       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 214,747\n",
            "Trainable params: 214,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=4170.941, rmse=64.583, r2=0.083; v_loss=2915.295, v_rmse=53.993, v_r2=0.535; \n",
            "E 2\t: loss=1744.857, rmse=41.771, r2=0.616; v_loss=2682.597, v_rmse=51.794, v_r2=0.572; \n",
            "E 3\t: loss=1698.402, rmse=41.212, r2=0.627; v_loss=2613.920, v_rmse=51.127, v_r2=0.583; \n",
            "E 4\t: loss=1664.486, rmse=40.798, r2=0.634; v_loss=2494.608, v_rmse=49.946, v_r2=0.602; \n",
            "E 5\t: loss=1665.719, rmse=40.813, r2=0.634; v_loss=2526.695, v_rmse=50.266, v_r2=0.597; \n",
            "E 6\t: loss=1659.798, rmse=40.741, r2=0.635; v_loss=2649.898, v_rmse=51.477, v_r2=0.577; \n",
            "E 7\t: loss=1647.517, rmse=40.590, r2=0.638; v_loss=2596.053, v_rmse=50.951, v_r2=0.586; \n",
            "E 8\t: loss=1649.539, rmse=40.615, r2=0.637; v_loss=2665.893, v_rmse=51.632, v_r2=0.575; \n",
            "E 9\t: loss=1647.970, rmse=40.595, r2=0.638; v_loss=2551.532, v_rmse=50.513, v_r2=0.593; \n",
            "E 10\t: loss=1644.021, rmse=40.547, r2=0.639; v_loss=2611.165, v_rmse=51.100, v_r2=0.583; \n",
            "Finished: 2022-10-16 08:58:43.349571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "WTB1R-9-8Xu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de497b95-2e38-4a21-9dee-3cfbcaef78a5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.466,RMSE=-30.355\n",
            "Finished: 2022-10-16 08:58:43.443147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "P3IBawiY8XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8708908017407038  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 272),\n",
        "             ('basemodel__epochs', 39),\n",
        "             ('basemodel__model__activation1', 'elu'),\n",
        "             ('basemodel__model__activation2', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.3474531287065963),\n",
        "             ('basemodel__model__dropout2', 0.36614542849836884),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 139),\n",
        "             ('basemodel__model__learning_rate', 0.0015318728990539984),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.23383223141315412),\n",
        "             ('clip_y', 80),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "95Sz7A0l8XvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=272,\n",
        "                           epochs=39,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__dropout1=0.3474531287065963, \n",
        "                           model__dropout2=0.36614542849836884, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=139, \n",
        "                           model__learning_rate=0.0015318728990539984,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.23383223141315412, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59373baf-efd0-41b3-f23a-d5be1ec36400",
        "id": "8P2llTd78XvH"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=272, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=39, model=<function create_model at 0x000001C61804DDC0>, model__activation1='elu', model__activation2='sigmoid', model__dropout1=0.3474531287065963, model__dropou...139, model__learning_rate=0.0015318728990539984, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C653CF98B0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C653CF9EE0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.23383223141315412, verbose=0),\n",
              "                    clip_y=80)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "vh-GouSB8XvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97cb2433-9c99-4bc9-cf8d-1334bc3c4154"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_29 (Dense)            (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 139)               71307     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 139)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 140       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,711\n",
            "Trainable params: 82,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3658.698, rmse=60.487, r2=-5.073; v_loss=3032.722, v_rmse=55.070, v_r2=-4.278; \n",
            "E 2\t: loss=2521.760, rmse=50.217, r2=-3.186; v_loss=2170.686, v_rmse=46.591, v_r2=-2.778; \n",
            "E 3\t: loss=1737.511, rmse=41.683, r2=-1.884; v_loss=1427.802, v_rmse=37.786, v_r2=-1.485; \n",
            "E 4\t: loss=1095.119, rmse=33.093, r2=-0.818; v_loss=847.193, v_rmse=29.107, v_r2=-0.474; \n",
            "E 5\t: loss=625.279, rmse=25.006, r2=-0.038; v_loss=450.009, v_rmse=21.213, v_r2=0.217; \n",
            "E 6\t: loss=320.108, rmse=17.892, r2=0.469; v_loss=206.779, v_rmse=14.380, v_r2=0.640; \n",
            "E 7\t: loss=160.515, rmse=12.669, r2=0.734; v_loss=105.385, v_rmse=10.266, v_r2=0.817; \n",
            "E 8\t: loss=107.336, rmse=10.360, r2=0.822; v_loss=85.845, v_rmse=9.265, v_r2=0.851; \n",
            "E 9\t: loss=102.305, rmse=10.115, r2=0.830; v_loss=86.631, v_rmse=9.308, v_r2=0.849; \n",
            "E 10\t: loss=100.595, rmse=10.030, r2=0.833; v_loss=90.867, v_rmse=9.532, v_r2=0.842; \n",
            "E 11\t: loss=100.429, rmse=10.021, r2=0.833; v_loss=80.660, v_rmse=8.981, v_r2=0.860; \n",
            "E 12\t: loss=98.750, rmse=9.937, r2=0.836; v_loss=82.201, v_rmse=9.066, v_r2=0.857; \n",
            "E 13\t: loss=98.563, rmse=9.928, r2=0.836; v_loss=78.798, v_rmse=8.877, v_r2=0.863; \n",
            "E 14\t: loss=97.817, rmse=9.890, r2=0.838; v_loss=81.166, v_rmse=9.009, v_r2=0.859; \n",
            "E 15\t: loss=99.646, rmse=9.982, r2=0.835; v_loss=83.554, v_rmse=9.141, v_r2=0.855; \n",
            "E 16\t: loss=98.244, rmse=9.912, r2=0.837; v_loss=98.498, v_rmse=9.925, v_r2=0.829; \n",
            "E 17\t: loss=96.962, rmse=9.847, r2=0.839; v_loss=87.961, v_rmse=9.379, v_r2=0.847; \n",
            "E 18\t: loss=98.289, rmse=9.914, r2=0.837; v_loss=80.435, v_rmse=8.969, v_r2=0.860; \n",
            "E 19\t: loss=96.672, rmse=9.832, r2=0.840; v_loss=79.106, v_rmse=8.894, v_r2=0.862; \n",
            "E 20\t: loss=96.890, rmse=9.843, r2=0.839; v_loss=85.105, v_rmse=9.225, v_r2=0.852; \n",
            "E 21\t: loss=97.423, rmse=9.870, r2=0.838; v_loss=88.820, v_rmse=9.424, v_r2=0.845; \n",
            "E 22\t: loss=96.142, rmse=9.805, r2=0.840; v_loss=79.799, v_rmse=8.933, v_r2=0.861; \n",
            "E 23\t: loss=96.061, rmse=9.801, r2=0.841; v_loss=79.410, v_rmse=8.911, v_r2=0.862; \n",
            "E 24\t: loss=95.270, rmse=9.761, r2=0.842; v_loss=94.492, v_rmse=9.721, v_r2=0.836; \n",
            "E 25\t: loss=95.174, rmse=9.756, r2=0.842; v_loss=81.504, v_rmse=9.028, v_r2=0.858; \n",
            "E 26\t: loss=95.909, rmse=9.793, r2=0.841; v_loss=79.364, v_rmse=8.909, v_r2=0.862; \n",
            "E 27\t: loss=95.931, rmse=9.794, r2=0.841; v_loss=88.373, v_rmse=9.401, v_r2=0.846; \n",
            "E 28\t: loss=94.354, rmse=9.714, r2=0.843; v_loss=88.467, v_rmse=9.406, v_r2=0.846; \n",
            "E 29\t: loss=95.059, rmse=9.750, r2=0.842; v_loss=85.231, v_rmse=9.232, v_r2=0.852; \n",
            "E 30\t: loss=95.618, rmse=9.778, r2=0.841; v_loss=81.737, v_rmse=9.041, v_r2=0.858; \n",
            "E 31\t: loss=95.535, rmse=9.774, r2=0.841; v_loss=79.048, v_rmse=8.891, v_r2=0.862; \n",
            "E 32\t: loss=95.035, rmse=9.749, r2=0.842; v_loss=84.572, v_rmse=9.196, v_r2=0.853; \n",
            "E 33\t: loss=95.281, rmse=9.761, r2=0.842; v_loss=81.424, v_rmse=9.024, v_r2=0.858; \n",
            "Finished: 2022-10-16 08:59:25.982456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Sc37islE8XvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a10d90-ce38-4a90-d14a-47cfbb8f25f9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.873,RMSE=-9.515\n",
            "Finished: 2022-10-16 08:59:26.065457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "wZocoM5X8XvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6262323565109925  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 30),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.9),\n",
        "             ('basemodel__model__dropout2', 0.1),\n",
        "             ('basemodel__model__layer1', 320),\n",
        "             ('basemodel__model__layer2', 512),\n",
        "             ('basemodel__model__learning_rate', 0.0027118397103578972),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "AlgXpCVb8XvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=30,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.9, \n",
        "                           model__dropout2=0.1, \n",
        "                           model__layer1=320, \n",
        "                           model__layer2=512, \n",
        "                           model__learning_rate=0.0027118397103578972,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb3e455-8d7e-4768-c7ad-dd88b48aae5f",
        "id": "6TR5_NRP8XvP"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=30, model=<function create_model at 0x000001C61804DDC0>, model__activation1='tanh', model__activation2='elu', model__dropout1=0.9, model__dropout2=0.1, model__layer1=320, model__layer2=512, model__learning_rate=0.0027118397103578972, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C6542B0670>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C65413C970>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "kGivi_vW8XvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e51cba-4d2e-4861-97af-86530291e5e2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 320)               647680    \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 320)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               164352    \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 812,545\n",
            "Trainable params: 812,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3144.958, rmse=56.080, r2=0.309; v_loss=4510.296, v_rmse=67.159, v_r2=0.280; \n",
            "E 2\t: loss=2522.772, rmse=50.227, r2=0.446; v_loss=5034.386, v_rmse=70.953, v_r2=0.197; \n",
            "E 3\t: loss=2454.726, rmse=49.545, r2=0.460; v_loss=5331.406, v_rmse=73.016, v_r2=0.149; \n",
            "E 4\t: loss=2382.406, rmse=48.810, r2=0.476; v_loss=5133.264, v_rmse=71.647, v_r2=0.181; \n",
            "E 5\t: loss=2325.881, rmse=48.227, r2=0.489; v_loss=5273.468, v_rmse=72.619, v_r2=0.158; \n",
            "E 6\t: loss=2334.083, rmse=48.312, r2=0.487; v_loss=5651.250, v_rmse=75.175, v_r2=0.098; \n",
            "E 7\t: loss=2302.134, rmse=47.981, r2=0.494; v_loss=5545.218, v_rmse=74.466, v_r2=0.115; \n",
            "E 8\t: loss=2316.326, rmse=48.128, r2=0.491; v_loss=5631.623, v_rmse=75.044, v_r2=0.101; \n",
            "E 9\t: loss=2295.099, rmse=47.907, r2=0.496; v_loss=4512.438, v_rmse=67.175, v_r2=0.280; \n",
            "E 10\t: loss=2264.553, rmse=47.587, r2=0.502; v_loss=6046.972, v_rmse=77.762, v_r2=0.035; \n",
            "E 11\t: loss=2248.074, rmse=47.414, r2=0.506; v_loss=5320.084, v_rmse=72.939, v_r2=0.151; \n",
            "E 12\t: loss=2249.391, rmse=47.428, r2=0.506; v_loss=4404.528, v_rmse=66.367, v_r2=0.297; \n",
            "E 13\t: loss=2260.116, rmse=47.541, r2=0.503; v_loss=5189.220, v_rmse=72.036, v_r2=0.172; \n",
            "E 14\t: loss=2256.013, rmse=47.498, r2=0.504; v_loss=5935.416, v_rmse=77.042, v_r2=0.053; \n",
            "E 15\t: loss=2227.609, rmse=47.198, r2=0.510; v_loss=5214.402, v_rmse=72.211, v_r2=0.168; \n",
            "E 16\t: loss=2256.635, rmse=47.504, r2=0.504; v_loss=5292.032, v_rmse=72.746, v_r2=0.155; \n",
            "E 17\t: loss=2238.363, rmse=47.311, r2=0.508; v_loss=5158.305, v_rmse=71.821, v_r2=0.177; \n",
            "E 18\t: loss=2243.136, rmse=47.362, r2=0.507; v_loss=5462.964, v_rmse=73.912, v_r2=0.128; \n",
            "E 19\t: loss=2233.500, rmse=47.260, r2=0.509; v_loss=5070.875, v_rmse=71.210, v_r2=0.191; \n",
            "E 20\t: loss=2203.576, rmse=46.942, r2=0.516; v_loss=4921.343, v_rmse=70.152, v_r2=0.215; \n",
            "E 21\t: loss=2211.242, rmse=47.024, r2=0.514; v_loss=5886.721, v_rmse=76.725, v_r2=0.060; \n",
            "E 22\t: loss=2217.003, rmse=47.085, r2=0.513; v_loss=5024.935, v_rmse=70.887, v_r2=0.198; \n",
            "E 23\t: loss=2248.472, rmse=47.418, r2=0.506; v_loss=4949.354, v_rmse=70.352, v_r2=0.210; \n",
            "E 24\t: loss=2208.261, rmse=46.992, r2=0.515; v_loss=5135.013, v_rmse=71.659, v_r2=0.180; \n",
            "E 25\t: loss=2221.258, rmse=47.130, r2=0.512; v_loss=4434.544, v_rmse=66.592, v_r2=0.292; \n",
            "Finished: 2022-10-16 09:00:57.995335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "W4aA1r2q8XvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9414e273-988e-48f6-97e9-ff9795b8a5be"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.210,RMSE=-36.946\n",
            "Finished: 2022-10-16 09:00:58.155336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "01ti8j0I8Xva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8653619825760903  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 235),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'sigmoid'),\n",
        "             ('basemodel__model__activation2', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__dropout2', 0.22990220831017208),\n",
        "             ('basemodel__model__layer1', 81),\n",
        "             ('basemodel__model__layer2', 211),\n",
        "             ('basemodel__model__learning_rate', 0.01),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('clip_y', 80),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', MinMaxScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "dNgvLPHf8Xvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=235,\n",
        "                           epochs=50,\n",
        "                           model__activation1='sigmoid',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__dropout2=0.22990220831017208, \n",
        "                           model__layer1=81, \n",
        "                           model__layer2=211, \n",
        "                           model__learning_rate=0.01,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3b62b1-5a39-4fca-e6a6-386ed98aa37f",
        "id": "dAWLzDAC8Xvg"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=235, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=50, model=<function create_model at 0x000001C61804DDC0>, model__activation1='sigmoid', model__activation2='elu', model__dropout1=0.1, model__dropout2=0.2299022083..._layer1=81, model__layer2=211, model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C7808D0670>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C7808D0AC0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "w4AgmUsB8Xvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c141589-934f-4779-a538-cee0f4dffc4e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_35 (Dense)            (None, 81)                163944    \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 81)                0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 211)               17302     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 211)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 212       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181,458\n",
            "Trainable params: 181,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=499.261, rmse=22.344, r2=0.168; v_loss=197.844, v_rmse=14.066, v_r2=0.646; \n",
            "E 2\t: loss=181.981, rmse=13.490, r2=0.697; v_loss=144.246, v_rmse=12.010, v_r2=0.742; \n",
            "E 3\t: loss=158.725, rmse=12.599, r2=0.735; v_loss=153.160, v_rmse=12.376, v_r2=0.726; \n",
            "E 4\t: loss=145.683, rmse=12.070, r2=0.757; v_loss=125.699, v_rmse=11.212, v_r2=0.775; \n",
            "E 5\t: loss=139.543, rmse=11.813, r2=0.767; v_loss=120.368, v_rmse=10.971, v_r2=0.785; \n",
            "E 6\t: loss=136.166, rmse=11.669, r2=0.773; v_loss=152.336, v_rmse=12.342, v_r2=0.727; \n",
            "E 7\t: loss=140.412, rmse=11.850, r2=0.766; v_loss=135.460, v_rmse=11.639, v_r2=0.758; \n",
            "E 8\t: loss=138.931, rmse=11.787, r2=0.768; v_loss=131.732, v_rmse=11.477, v_r2=0.764; \n",
            "E 9\t: loss=135.229, rmse=11.629, r2=0.775; v_loss=121.564, v_rmse=11.026, v_r2=0.782; \n",
            "E 10\t: loss=131.280, rmse=11.458, r2=0.781; v_loss=141.597, v_rmse=11.899, v_r2=0.747; \n",
            "E 11\t: loss=132.817, rmse=11.525, r2=0.779; v_loss=132.307, v_rmse=11.502, v_r2=0.763; \n",
            "E 12\t: loss=130.848, rmse=11.439, r2=0.782; v_loss=122.079, v_rmse=11.049, v_r2=0.781; \n",
            "E 13\t: loss=132.259, rmse=11.500, r2=0.780; v_loss=130.294, v_rmse=11.415, v_r2=0.767; \n",
            "E 14\t: loss=135.059, rmse=11.621, r2=0.775; v_loss=156.806, v_rmse=12.522, v_r2=0.719; \n",
            "E 15\t: loss=138.518, rmse=11.769, r2=0.769; v_loss=126.454, v_rmse=11.245, v_r2=0.774; \n",
            "E 16\t: loss=133.907, rmse=11.572, r2=0.777; v_loss=147.732, v_rmse=12.154, v_r2=0.736; \n",
            "E 17\t: loss=128.845, rmse=11.351, r2=0.785; v_loss=122.603, v_rmse=11.073, v_r2=0.781; \n",
            "E 18\t: loss=129.701, rmse=11.389, r2=0.784; v_loss=126.173, v_rmse=11.233, v_r2=0.774; \n",
            "E 19\t: loss=129.530, rmse=11.381, r2=0.784; v_loss=118.509, v_rmse=10.886, v_r2=0.788; \n",
            "E 20\t: loss=128.576, rmse=11.339, r2=0.786; v_loss=132.127, v_rmse=11.495, v_r2=0.763; \n",
            "E 21\t: loss=129.996, rmse=11.402, r2=0.783; v_loss=115.319, v_rmse=10.739, v_r2=0.794; \n",
            "E 22\t: loss=124.890, rmse=11.175, r2=0.792; v_loss=113.201, v_rmse=10.640, v_r2=0.797; \n",
            "E 23\t: loss=127.141, rmse=11.276, r2=0.788; v_loss=112.904, v_rmse=10.626, v_r2=0.798; \n",
            "E 24\t: loss=127.495, rmse=11.291, r2=0.788; v_loss=118.982, v_rmse=10.908, v_r2=0.787; \n",
            "E 25\t: loss=127.615, rmse=11.297, r2=0.787; v_loss=118.545, v_rmse=10.888, v_r2=0.788; \n",
            "E 26\t: loss=126.429, rmse=11.244, r2=0.789; v_loss=126.377, v_rmse=11.242, v_r2=0.774; \n",
            "E 27\t: loss=130.730, rmse=11.434, r2=0.782; v_loss=127.616, v_rmse=11.297, v_r2=0.772; \n",
            "Finished: 2022-10-16 09:01:16.009668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "N-Pj7cIL8Xvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a79ae8-0a65-41bd-9fa7-4d6735bf3a6f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.800,RMSE=-11.927\n",
            "Finished: 2022-10-16 09:01:16.164693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-3"
      ],
      "metadata": {
        "id": "00TdIEZ6FBx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "kL9N0ocMFBx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6120201145167702    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 244),\n",
        "             ('basemodel__epochs', 25),\n",
        "             ('basemodel__model__activation1', 'elu'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__dropout2', 0.6452357951609182),\n",
        "             ('basemodel__model__dropout3', 0.10365428493216054),\n",
        "             ('basemodel__model__layer1', 33),\n",
        "             ('basemodel__model__layer2', 216),\n",
        "             ('basemodel__model__layer3', 480),\n",
        "             ('basemodel__model__learning_rate', 0.0023087723482705077),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.17402892098258826),\n",
        "             ('scaler', MinMaxScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "zmVugjXMFByB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=244,\n",
        "                           epochs=25,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='elu',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__dropout2=0.6452357951609182, \n",
        "                           model__dropout3=0.1, \n",
        "                           model__layer1=33, \n",
        "                           model__layer2=216, \n",
        "                           model__layer3=480, \n",
        "                           model__learning_rate=0.0023087723482705077,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.17402892098258826, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44066f6-a371-4ae8-d82c-08bf54b050d0",
        "id": "hI5gTmNEFByH"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=244, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=25, model=<function create_model at 0x000001C61804DDC0>, model__activation1='elu', model__activation2='tanh', model__activation3='elu', model__dropout1=0.1, model_...del__learning_rate=0.0023087723482705077, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C78DD48BE0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C78DD63F10>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.17402892098258826, verbose=0),\n",
              "                    scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37653907-6e1d-4542-8e77-753c85b08e1e",
        "id": "kcvF0xLyFByO"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_38 (Dense)            (None, 33)                726       \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 33)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 216)               7344      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 216)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 480)               104160    \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 480)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 481       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 112,711\n",
            "Trainable params: 112,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5151.860, rmse=71.776, r2=-0.154; v_loss=2921.153, v_rmse=54.048, v_r2=0.513; \n",
            "E 2\t: loss=2054.655, rmse=45.328, r2=0.540; v_loss=2758.806, v_rmse=52.524, v_r2=0.540; \n",
            "E 3\t: loss=1923.468, rmse=43.857, r2=0.569; v_loss=2697.630, v_rmse=51.939, v_r2=0.550; \n",
            "E 4\t: loss=1862.050, rmse=43.151, r2=0.583; v_loss=2686.898, v_rmse=51.835, v_r2=0.552; \n",
            "E 5\t: loss=1838.200, rmse=42.874, r2=0.588; v_loss=2565.139, v_rmse=50.647, v_r2=0.572; \n",
            "E 6\t: loss=1800.482, rmse=42.432, r2=0.597; v_loss=2570.675, v_rmse=50.702, v_r2=0.572; \n",
            "E 7\t: loss=1785.635, rmse=42.257, r2=0.600; v_loss=2605.089, v_rmse=51.040, v_r2=0.566; \n",
            "E 8\t: loss=1759.308, rmse=41.944, r2=0.606; v_loss=2487.146, v_rmse=49.871, v_r2=0.585; \n",
            "E 9\t: loss=1748.807, rmse=41.819, r2=0.608; v_loss=2551.792, v_rmse=50.515, v_r2=0.575; \n",
            "E 10\t: loss=1733.927, rmse=41.640, r2=0.612; v_loss=2486.340, v_rmse=49.863, v_r2=0.586; \n",
            "E 11\t: loss=1722.660, rmse=41.505, r2=0.614; v_loss=2494.319, v_rmse=49.943, v_r2=0.584; \n",
            "E 12\t: loss=1703.054, rmse=41.268, r2=0.619; v_loss=2647.136, v_rmse=51.450, v_r2=0.559; \n",
            "E 13\t: loss=1700.670, rmse=41.239, r2=0.619; v_loss=2546.782, v_rmse=50.466, v_r2=0.576; \n",
            "E 14\t: loss=1694.764, rmse=41.168, r2=0.621; v_loss=2507.882, v_rmse=50.079, v_r2=0.582; \n",
            "E 15\t: loss=1707.111, rmse=41.317, r2=0.618; v_loss=2594.226, v_rmse=50.934, v_r2=0.568; \n",
            "E 16\t: loss=1690.562, rmse=41.116, r2=0.621; v_loss=2568.831, v_rmse=50.684, v_r2=0.572; \n",
            "E 17\t: loss=1671.293, rmse=40.881, r2=0.626; v_loss=2465.905, v_rmse=49.658, v_r2=0.589; \n",
            "E 18\t: loss=1675.548, rmse=40.933, r2=0.625; v_loss=2511.409, v_rmse=50.114, v_r2=0.581; \n",
            "E 19\t: loss=1661.157, rmse=40.757, r2=0.628; v_loss=2435.731, v_rmse=49.353, v_r2=0.594; \n",
            "E 20\t: loss=1654.786, rmse=40.679, r2=0.629; v_loss=2527.039, v_rmse=50.270, v_r2=0.579; \n",
            "E 21\t: loss=1640.511, rmse=40.503, r2=0.633; v_loss=2614.150, v_rmse=51.129, v_r2=0.564; \n",
            "E 22\t: loss=1649.060, rmse=40.609, r2=0.631; v_loss=2509.643, v_rmse=50.096, v_r2=0.582; \n",
            "E 23\t: loss=1631.697, rmse=40.394, r2=0.635; v_loss=2414.801, v_rmse=49.141, v_r2=0.598; \n",
            "E 24\t: loss=1626.698, rmse=40.332, r2=0.636; v_loss=2412.505, v_rmse=49.117, v_r2=0.598; \n",
            "E 25\t: loss=1621.917, rmse=40.273, r2=0.637; v_loss=2489.529, v_rmse=49.895, v_r2=0.585; \n",
            "Finished: 2022-10-16 09:02:30.001595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e0ceca-4a45-4ae0-e03f-3e75c053e019",
        "id": "QG0jhrtKFByS"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.442,RMSE=-31.051\n",
            "Finished: 2022-10-16 09:02:30.136596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "1Xs7NWLvFByZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.858429482908221    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 387),\n",
        "             ('basemodel__epochs', 37),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.6025012184092352),\n",
        "             ('basemodel__model__dropout2', 0.584225016100644),\n",
        "             ('basemodel__model__dropout3', 0.6585832537238048),\n",
        "             ('basemodel__model__layer1', 462),\n",
        "             ('basemodel__model__layer2', 287),\n",
        "             ('basemodel__model__layer3', 303),\n",
        "             ('basemodel__model__learning_rate', 0.0047806961601746184),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.5866937471711482),\n",
        "             ('clip_y', 80),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "RbLuNAHAFBye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=387,\n",
        "                           epochs=37,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='elu',\n",
        "                           model__dropout1=0.6025012184092352, \n",
        "                           model__dropout2=0.584225016100644, \n",
        "                           model__dropout3=0.6585832537238048, \n",
        "                           model__layer1=462, \n",
        "                           model__layer2=287, \n",
        "                           model__layer3=383,  \n",
        "                           model__learning_rate=0.0047806961601746184,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.5866937471711482, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47606989-fe93-42e6-a57e-cb0b9f76d332",
        "id": "PSnWYxQiFByi"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=387, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=37, model=<function create_model at 0x000001C61804DDC0>, model__activation1='tanh', model__activation2='selu', model__activation3='elu', model__dropout1=0.6025012...layer3=383, model__learning_rate=0.0047806961601746184, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C79D032F10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C79D032430>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.5866937471711482, verbose=0),\n",
              "                    clip_y=80)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0722e70e-b430-4a28-c866-a9fd19fc4042",
        "id": "wU3RI7KvFByq"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 462)               10164     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 462)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 287)               132881    \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 287)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 383)               110304    \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 383)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 1)                 384       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 253,733\n",
            "Trainable params: 253,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1528.859, rmse=39.101, r2=-1.507; v_loss=164.643, v_rmse=12.831, v_r2=0.719; \n",
            "E 2\t: loss=289.611, rmse=17.018, r2=0.525; v_loss=110.849, v_rmse=10.528, v_r2=0.811; \n",
            "E 3\t: loss=203.656, rmse=14.271, r2=0.666; v_loss=96.043, v_rmse=9.800, v_r2=0.836; \n",
            "E 4\t: loss=182.057, rmse=13.493, r2=0.702; v_loss=113.939, v_rmse=10.674, v_r2=0.806; \n",
            "E 5\t: loss=178.307, rmse=13.353, r2=0.708; v_loss=91.562, v_rmse=9.569, v_r2=0.844; \n",
            "E 6\t: loss=163.059, rmse=12.769, r2=0.733; v_loss=119.346, v_rmse=10.925, v_r2=0.796; \n",
            "E 7\t: loss=161.930, rmse=12.725, r2=0.735; v_loss=107.251, v_rmse=10.356, v_r2=0.817; \n",
            "E 8\t: loss=164.221, rmse=12.815, r2=0.731; v_loss=90.307, v_rmse=9.503, v_r2=0.846; \n",
            "E 9\t: loss=152.869, rmse=12.364, r2=0.749; v_loss=101.364, v_rmse=10.068, v_r2=0.827; \n",
            "E 10\t: loss=154.341, rmse=12.423, r2=0.747; v_loss=96.149, v_rmse=9.806, v_r2=0.836; \n",
            "E 11\t: loss=150.070, rmse=12.250, r2=0.754; v_loss=94.644, v_rmse=9.729, v_r2=0.838; \n",
            "E 12\t: loss=145.210, rmse=12.050, r2=0.762; v_loss=102.232, v_rmse=10.111, v_r2=0.826; \n",
            "E 13\t: loss=134.256, rmse=11.587, r2=0.780; v_loss=127.245, v_rmse=11.280, v_r2=0.783; \n",
            "E 14\t: loss=142.314, rmse=11.930, r2=0.767; v_loss=86.219, v_rmse=9.285, v_r2=0.853; \n",
            "E 15\t: loss=129.468, rmse=11.378, r2=0.788; v_loss=106.840, v_rmse=10.336, v_r2=0.818; \n",
            "E 16\t: loss=129.990, rmse=11.401, r2=0.787; v_loss=96.351, v_rmse=9.816, v_r2=0.836; \n",
            "E 17\t: loss=123.430, rmse=11.110, r2=0.798; v_loss=88.596, v_rmse=9.413, v_r2=0.849; \n",
            "E 18\t: loss=126.911, rmse=11.265, r2=0.792; v_loss=83.706, v_rmse=9.149, v_r2=0.857; \n",
            "E 19\t: loss=123.816, rmse=11.127, r2=0.797; v_loss=93.791, v_rmse=9.685, v_r2=0.840; \n",
            "E 20\t: loss=122.617, rmse=11.073, r2=0.799; v_loss=84.033, v_rmse=9.167, v_r2=0.857; \n",
            "E 21\t: loss=126.645, rmse=11.254, r2=0.792; v_loss=102.552, v_rmse=10.127, v_r2=0.825; \n",
            "E 22\t: loss=118.271, rmse=10.875, r2=0.806; v_loss=87.955, v_rmse=9.378, v_r2=0.850; \n",
            "E 23\t: loss=121.634, rmse=11.029, r2=0.801; v_loss=84.107, v_rmse=9.171, v_r2=0.856; \n",
            "E 24\t: loss=116.423, rmse=10.790, r2=0.809; v_loss=104.515, v_rmse=10.223, v_r2=0.822; \n",
            "E 25\t: loss=124.296, rmse=11.149, r2=0.796; v_loss=95.136, v_rmse=9.754, v_r2=0.838; \n",
            "E 26\t: loss=120.947, rmse=10.998, r2=0.802; v_loss=97.784, v_rmse=9.889, v_r2=0.833; \n",
            "E 27\t: loss=124.841, rmse=11.173, r2=0.795; v_loss=85.837, v_rmse=9.265, v_r2=0.854; \n",
            "E 28\t: loss=114.031, rmse=10.679, r2=0.813; v_loss=88.213, v_rmse=9.392, v_r2=0.849; \n",
            "E 29\t: loss=115.715, rmse=10.757, r2=0.810; v_loss=84.351, v_rmse=9.184, v_r2=0.856; \n",
            "E 30\t: loss=116.224, rmse=10.781, r2=0.809; v_loss=92.073, v_rmse=9.595, v_r2=0.843; \n",
            "E 31\t: loss=119.317, rmse=10.923, r2=0.804; v_loss=92.615, v_rmse=9.624, v_r2=0.842; \n",
            "E 32\t: loss=118.205, rmse=10.872, r2=0.806; v_loss=106.933, v_rmse=10.341, v_r2=0.818; \n",
            "E 33\t: loss=131.348, rmse=11.461, r2=0.785; v_loss=108.686, v_rmse=10.425, v_r2=0.815; \n",
            "Finished: 2022-10-16 09:15:41.204042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac14b21-78cc-4975-bd51-46b2bae386a9",
        "id": "9s8vEev3FByt"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.870,RMSE=-9.612\n",
            "Finished: 2022-10-16 09:15:43.674605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "yk8grx_3FByx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6222047496761983    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 315),\n",
        "             ('basemodel__epochs', 27),\n",
        "             ('basemodel__model__activation1', 'elu'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.3672917021354055),\n",
        "             ('basemodel__model__dropout2', 0.2585591117469549),\n",
        "             ('basemodel__model__dropout3', 0.1),\n",
        "             ('basemodel__model__layer1', 456),\n",
        "             ('basemodel__model__layer2', 174),\n",
        "             ('basemodel__model__layer3', 479),\n",
        "             ('basemodel__model__learning_rate', 0.0007321508636106998),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('poly_degree', 2),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "2TWz2xbfFBy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=315,\n",
        "                           epochs=27,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.3672917021354055, \n",
        "                           model__dropout2=0.2585591117469549, \n",
        "                           model__dropout3=0.1, \n",
        "                           model__layer1=456, \n",
        "                           model__layer2=174, \n",
        "                           model__layer3=479, \n",
        "                           model__learning_rate=0.0007321508636106998,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fdc2f4-05cb-4166-8462-449e7fdef99b",
        "id": "97IkcENqFBy1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=315, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=27, model=<function create_model at 0x000001C61804DDC0>, model__activation1='elu', model__activation2='selu', model__activation3='selu', model__dropout1=0.3672917...174, model__layer3=479, model__learning_rate=0.0007321508636106998, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C6187E5DF0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C6187E5EE0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d327390-b3e4-4d31-f494-e1d271af6525",
        "id": "GGBuOcsxFBy4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_46 (Dense)            (None, 456)               115368    \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 456)               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 174)               79518     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 174)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 479)               83825     \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 479)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 1)                 480       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,191\n",
            "Trainable params: 279,191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5595.553, rmse=74.803, r2=-0.230; v_loss=2966.990, v_rmse=54.470, v_r2=0.526; \n",
            "E 2\t: loss=1984.132, rmse=44.544, r2=0.564; v_loss=2529.798, v_rmse=50.297, v_r2=0.596; \n",
            "E 3\t: loss=1719.906, rmse=41.472, r2=0.622; v_loss=2541.904, v_rmse=50.417, v_r2=0.594; \n",
            "E 4\t: loss=1684.097, rmse=41.038, r2=0.630; v_loss=2500.410, v_rmse=50.004, v_r2=0.601; \n",
            "E 5\t: loss=1667.052, rmse=40.830, r2=0.634; v_loss=2521.068, v_rmse=50.210, v_r2=0.598; \n",
            "E 6\t: loss=1657.558, rmse=40.713, r2=0.636; v_loss=2680.907, v_rmse=51.777, v_r2=0.572; \n",
            "E 7\t: loss=1652.274, rmse=40.648, r2=0.637; v_loss=2569.443, v_rmse=50.690, v_r2=0.590; \n",
            "E 8\t: loss=1649.558, rmse=40.615, r2=0.637; v_loss=2736.262, v_rmse=52.309, v_r2=0.563; \n",
            "E 9\t: loss=1642.069, rmse=40.522, r2=0.639; v_loss=2550.647, v_rmse=50.504, v_r2=0.593; \n",
            "E 10\t: loss=1640.884, rmse=40.508, r2=0.639; v_loss=2700.741, v_rmse=51.969, v_r2=0.569; \n",
            "E 11\t: loss=1644.304, rmse=40.550, r2=0.639; v_loss=2586.120, v_rmse=50.854, v_r2=0.587; \n",
            "E 12\t: loss=1635.885, rmse=40.446, r2=0.640; v_loss=2669.296, v_rmse=51.665, v_r2=0.574; \n",
            "E 13\t: loss=1632.232, rmse=40.401, r2=0.641; v_loss=2723.538, v_rmse=52.188, v_r2=0.565; \n",
            "E 14\t: loss=1635.377, rmse=40.440, r2=0.641; v_loss=2717.429, v_rmse=52.129, v_r2=0.566; \n",
            "E 15\t: loss=1620.083, rmse=40.250, r2=0.644; v_loss=2636.778, v_rmse=51.350, v_r2=0.579; \n",
            "E 16\t: loss=1625.744, rmse=40.321, r2=0.643; v_loss=2596.975, v_rmse=50.961, v_r2=0.586; \n",
            "E 17\t: loss=1614.124, rmse=40.176, r2=0.645; v_loss=2675.395, v_rmse=51.724, v_r2=0.573; \n",
            "E 18\t: loss=1620.785, rmse=40.259, r2=0.644; v_loss=2684.807, v_rmse=51.815, v_r2=0.572; \n",
            "E 19\t: loss=1628.864, rmse=40.359, r2=0.642; v_loss=2636.722, v_rmse=51.349, v_r2=0.579; \n",
            "E 20\t: loss=1618.735, rmse=40.234, r2=0.644; v_loss=2682.216, v_rmse=51.790, v_r2=0.572; \n",
            "E 21\t: loss=1618.082, rmse=40.225, r2=0.644; v_loss=2591.410, v_rmse=50.906, v_r2=0.586; \n",
            "E 22\t: loss=1605.766, rmse=40.072, r2=0.647; v_loss=2780.904, v_rmse=52.734, v_r2=0.556; \n",
            "E 23\t: loss=1609.724, rmse=40.121, r2=0.646; v_loss=2582.910, v_rmse=50.822, v_r2=0.588; \n",
            "E 24\t: loss=1615.128, rmse=40.189, r2=0.645; v_loss=2703.847, v_rmse=51.999, v_r2=0.568; \n",
            "E 25\t: loss=1604.121, rmse=40.051, r2=0.647; v_loss=2678.274, v_rmse=51.752, v_r2=0.573; \n",
            "E 26\t: loss=1604.317, rmse=40.054, r2=0.647; v_loss=2686.269, v_rmse=51.829, v_r2=0.571; \n",
            "E 27\t: loss=1605.414, rmse=40.068, r2=0.647; v_loss=2571.881, v_rmse=50.714, v_r2=0.590; \n",
            "Finished: 2022-10-16 09:17:15.725524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8bf7b6-4ef7-4749-a6d2-fc6506a9c2a0",
        "id": "pNP_HTLyFBy7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.416,RMSE=-31.766\n",
            "Finished: 2022-10-16 09:17:15.837217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "UYgtv941FBy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8679661672429307   \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 283),\n",
        "             ('basemodel__epochs', 14),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__dropout2', 0.53425143831743),\n",
        "             ('basemodel__model__dropout3', 0.1),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 512),\n",
        "             ('basemodel__model__layer3', 305),\n",
        "             ('basemodel__model__learning_rate', 0.009573430971057319),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('clip_y', 80),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "WszSSJcHFBy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=283,\n",
        "                           epochs=14,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='elu',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__dropout2=0.53425143831743, \n",
        "                           model__dropout3=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=512, \n",
        "                           model__layer3=305, \n",
        "                           model__learning_rate=0.009573430971057319,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0df2e2-25e0-49e9-9f7d-5ab67846125c",
        "id": "5zdwA-JAFBzA"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=283, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=14, model=<function create_model at 0x000001C61804DDC0>, model__activation1='tanh', model__activation2='relu', model__activation3='elu', model__dropout1=0.1, model...__layer3=305, model__learning_rate=0.009573430971057319, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C653FB9BE0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C653FB9E80>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba648f7-1a35-4f74-a7c6-0cf5c1665fc8",
        "id": "_7BYEM3iFBzC"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_50 (Dense)            (None, 512)               1036288   \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 305)               156465    \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 305)               0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 1)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,455,715\n",
            "Trainable params: 1,455,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1060.059, rmse=32.559, r2=-0.767; v_loss=233.672, v_rmse=15.286, v_r2=0.582; \n",
            "E 2\t: loss=223.953, rmse=14.965, r2=0.627; v_loss=161.829, v_rmse=12.721, v_r2=0.710; \n",
            "E 3\t: loss=181.498, rmse=13.472, r2=0.698; v_loss=188.262, v_rmse=13.721, v_r2=0.663; \n",
            "E 4\t: loss=170.994, rmse=13.076, r2=0.715; v_loss=170.825, v_rmse=13.070, v_r2=0.694; \n",
            "E 5\t: loss=165.488, rmse=12.864, r2=0.724; v_loss=186.666, v_rmse=13.663, v_r2=0.666; \n",
            "E 6\t: loss=161.025, rmse=12.690, r2=0.732; v_loss=176.949, v_rmse=13.302, v_r2=0.683; \n",
            "E 7\t: loss=159.082, rmse=12.613, r2=0.735; v_loss=161.335, v_rmse=12.702, v_r2=0.711; \n",
            "E 8\t: loss=152.144, rmse=12.335, r2=0.746; v_loss=167.985, v_rmse=12.961, v_r2=0.699; \n",
            "E 9\t: loss=155.569, rmse=12.473, r2=0.741; v_loss=142.563, v_rmse=11.940, v_r2=0.745; \n",
            "E 10\t: loss=154.085, rmse=12.413, r2=0.743; v_loss=142.568, v_rmse=11.940, v_r2=0.745; \n",
            "E 11\t: loss=159.217, rmse=12.618, r2=0.735; v_loss=177.473, v_rmse=13.322, v_r2=0.682; \n",
            "E 12\t: loss=154.248, rmse=12.420, r2=0.743; v_loss=190.524, v_rmse=13.803, v_r2=0.659; \n",
            "E 13\t: loss=157.347, rmse=12.544, r2=0.738; v_loss=143.376, v_rmse=11.974, v_r2=0.743; \n",
            "Finished: 2022-10-16 09:19:08.647380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2df2f1-131e-4772-d6dc-e99c2ae4df32",
        "id": "oLf0y74BFBzE"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.758,RMSE=-13.132\n",
            "Finished: 2022-10-16 09:19:08.802380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-4"
      ],
      "metadata": {
        "id": "MfJUDz0oI5zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pb8CuYNOI5zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.8684757521280048    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 127),\n",
        "             ('basemodel__epochs', 17),\n",
        "             ('basemodel__model__activation1', 'relu'),\n",
        "             ('basemodel__model__activation2', 'sigmoid'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__activation4', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.405658593077186),\n",
        "             ('basemodel__model__dropout2', 0.3589949636608206),\n",
        "             ('basemodel__model__dropout3', 0.4633066337493309),\n",
        "             ('basemodel__model__dropout4', 0.32587881379978234),\n",
        "             ('basemodel__model__layer1', 308),\n",
        "             ('basemodel__model__layer2', 442),\n",
        "             ('basemodel__model__layer3', 301),\n",
        "             ('basemodel__model__layer4', 153),\n",
        "             ('basemodel__model__learning_rate', 0.0038661981642895585),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.14630628708453258),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "B5befZCBI5zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=127,\n",
        "                           epochs=17,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__activation3='elu',\n",
        "                           model__activation4='elu',\n",
        "                           model__dropout1=0.405658593077186, \n",
        "                           model__dropout2=0.3589949636608206, \n",
        "                           model__dropout3=0.4633066337493309, \n",
        "                           model__dropout4=0.32587881379978234, \n",
        "                           model__layer1=308, \n",
        "                           model__layer2=442, \n",
        "                           model__layer3=301, \n",
        "                           model__layer4=153, \n",
        "                           model__learning_rate=0.0038661981642895585,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.14630628708453258, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12865da-d82b-4de2-fc1a-94a6f3183c20",
        "id": "HjCB0ofWI5zk"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=127, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=17, model=<function create_model at 0x000001C61804DDC0>, model__activation1='relu', model__activation2='sigmoid', model__activation3='elu', model__activation4='el...l__layer4=153, model__learning_rate=0.0038661981642895585, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C79FF38E80>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C79FF38190>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.14630628708453258, verbose=0))"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c637014a-05e7-4a90-8462-37c28d435114",
        "id": "WBnAz5ncI5zp"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_54 (Dense)            (None, 308)               6776      \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 308)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 442)               136578    \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 442)               0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 301)               133343    \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 301)               0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 153)               46206     \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 153)               0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 1)                 154       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 323,057\n",
            "Trainable params: 323,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2413.610, rmse=49.129, r2=0.463; v_loss=3234.348, v_rmse=56.871, v_r2=0.473; \n",
            "E 2\t: loss=1875.603, rmse=43.308, r2=0.582; v_loss=2584.919, v_rmse=50.842, v_r2=0.579; \n",
            "E 3\t: loss=1781.908, rmse=42.213, r2=0.603; v_loss=2616.983, v_rmse=51.156, v_r2=0.573; \n",
            "E 4\t: loss=1740.640, rmse=41.721, r2=0.612; v_loss=2739.655, v_rmse=52.342, v_r2=0.553; \n",
            "E 5\t: loss=1725.595, rmse=41.540, r2=0.616; v_loss=2758.416, v_rmse=52.521, v_r2=0.550; \n",
            "E 6\t: loss=1700.624, rmse=41.239, r2=0.621; v_loss=2685.445, v_rmse=51.821, v_r2=0.562; \n",
            "E 7\t: loss=1694.370, rmse=41.163, r2=0.623; v_loss=2751.003, v_rmse=52.450, v_r2=0.552; \n",
            "E 8\t: loss=1682.621, rmse=41.020, r2=0.625; v_loss=2647.463, v_rmse=51.454, v_r2=0.568; \n",
            "E 9\t: loss=1673.943, rmse=40.914, r2=0.627; v_loss=2596.349, v_rmse=50.954, v_r2=0.577; \n",
            "E 10\t: loss=1643.316, rmse=40.538, r2=0.634; v_loss=2570.470, v_rmse=50.700, v_r2=0.581; \n",
            "E 11\t: loss=1643.318, rmse=40.538, r2=0.634; v_loss=2755.917, v_rmse=52.497, v_r2=0.551; \n",
            "E 12\t: loss=1675.859, rmse=40.937, r2=0.627; v_loss=2659.210, v_rmse=51.568, v_r2=0.567; \n",
            "E 13\t: loss=1642.790, rmse=40.531, r2=0.634; v_loss=2620.773, v_rmse=51.193, v_r2=0.573; \n",
            "E 14\t: loss=1634.532, rmse=40.429, r2=0.636; v_loss=2759.643, v_rmse=52.532, v_r2=0.550; \n",
            "E 15\t: loss=1638.736, rmse=40.481, r2=0.635; v_loss=3060.858, v_rmse=55.325, v_r2=0.501; \n",
            "E 16\t: loss=1621.960, rmse=40.274, r2=0.639; v_loss=2679.923, v_rmse=51.768, v_r2=0.563; \n",
            "E 17\t: loss=1625.900, rmse=40.322, r2=0.638; v_loss=2919.809, v_rmse=54.035, v_r2=0.524; \n",
            "Finished: 2022-10-16 09:22:00.965727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756a1671-d492-4016-86a7-f91334913885",
        "id": "E1ATWFZoI5zt"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.610,RMSE=-25.966\n",
            "Finished: 2022-10-16 09:22:02.970379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "qpedH9HzI5zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8527803619368491    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 344),\n",
        "             ('basemodel__epochs', 27),\n",
        "             ('basemodel__model__activation1', 'elu'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__activation3', 'sigmoid'),\n",
        "             ('basemodel__model__activation4', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.6749954668968566),\n",
        "             ('basemodel__model__dropout2', 0.2102017209355273),\n",
        "             ('basemodel__model__dropout3', 0.1),\n",
        "             ('basemodel__model__dropout4', 0.47711054364433003),\n",
        "             ('basemodel__model__layer1', 464),\n",
        "             ('basemodel__model__layer2', 371),\n",
        "             ('basemodel__model__layer3', 16),\n",
        "             ('basemodel__model__layer4', 476),\n",
        "             ('basemodel__model__learning_rate', 0.004154798051053557),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('clip_y', 80),\n",
        "             ('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "chBMqsKDI5zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=344,\n",
        "                           epochs=27,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__activation4='sigmoid',\n",
        "                           model__dropout1=0.6749954668968566, \n",
        "                           model__dropout2=0.2102017209355273, \n",
        "                           model__dropout3=0.1, \n",
        "                           model__dropout4=0.47711054364433003, \n",
        "                           model__layer1=464, \n",
        "                           model__layer2=371, \n",
        "                           model__layer3=16, \n",
        "                           model__layer4=476, \n",
        "                           model__learning_rate=0.004154798051053557,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1bd8dc-b6b5-4d6f-b1cc-7151f028ebb4",
        "id": "BE54ZRkFI5z3"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=344, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=27, model=<function create_model at 0x000001C61804DDC0>, model__activation1='elu', model__activation2='selu', model__activation3='sigmoid', model__activation4='si...16, model__layer4=476, model__learning_rate=0.004154798051053557, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C7A06093D0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C7A06200A0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4198b9f1-419f-479a-d6c8-171873908a43",
        "id": "1UX0DFssI5z6"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_59 (Dense)            (None, 464)               10208     \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 464)               0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 371)               172515    \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 371)               0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 16)                5952      \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 476)               8092      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 476)               0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 477       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 197,244\n",
            "Trainable params: 197,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1105.493, rmse=33.249, r2=-0.842; v_loss=195.483, v_rmse=13.982, v_r2=0.650; \n",
            "E 2\t: loss=182.324, rmse=13.503, r2=0.696; v_loss=138.591, v_rmse=11.772, v_r2=0.752; \n",
            "E 3\t: loss=133.104, rmse=11.537, r2=0.778; v_loss=103.336, v_rmse=10.165, v_r2=0.815; \n",
            "E 4\t: loss=116.389, rmse=10.788, r2=0.806; v_loss=110.095, v_rmse=10.493, v_r2=0.803; \n",
            "E 5\t: loss=107.518, rmse=10.369, r2=0.821; v_loss=95.062, v_rmse=9.750, v_r2=0.830; \n",
            "E 6\t: loss=103.959, rmse=10.196, r2=0.827; v_loss=96.358, v_rmse=9.816, v_r2=0.828; \n",
            "E 7\t: loss=102.339, rmse=10.116, r2=0.829; v_loss=99.166, v_rmse=9.958, v_r2=0.822; \n",
            "E 8\t: loss=102.320, rmse=10.115, r2=0.829; v_loss=100.744, v_rmse=10.037, v_r2=0.820; \n",
            "E 9\t: loss=102.201, rmse=10.109, r2=0.830; v_loss=95.244, v_rmse=9.759, v_r2=0.829; \n",
            "E 10\t: loss=99.076, rmse=9.954, r2=0.835; v_loss=102.307, v_rmse=10.115, v_r2=0.817; \n",
            "E 11\t: loss=100.158, rmse=10.008, r2=0.833; v_loss=96.087, v_rmse=9.802, v_r2=0.828; \n",
            "E 12\t: loss=98.047, rmse=9.902, r2=0.837; v_loss=93.118, v_rmse=9.650, v_r2=0.833; \n",
            "E 13\t: loss=98.504, rmse=9.925, r2=0.836; v_loss=88.763, v_rmse=9.421, v_r2=0.841; \n",
            "E 14\t: loss=98.289, rmse=9.914, r2=0.836; v_loss=93.069, v_rmse=9.647, v_r2=0.833; \n",
            "E 15\t: loss=97.532, rmse=9.876, r2=0.837; v_loss=102.096, v_rmse=10.104, v_r2=0.817; \n",
            "E 16\t: loss=95.900, rmse=9.793, r2=0.840; v_loss=94.189, v_rmse=9.705, v_r2=0.831; \n",
            "E 17\t: loss=95.754, rmse=9.785, r2=0.840; v_loss=96.706, v_rmse=9.834, v_r2=0.827; \n",
            "E 18\t: loss=95.413, rmse=9.768, r2=0.841; v_loss=91.244, v_rmse=9.552, v_r2=0.837; \n",
            "E 19\t: loss=96.461, rmse=9.821, r2=0.839; v_loss=99.283, v_rmse=9.964, v_r2=0.822; \n",
            "E 20\t: loss=95.131, rmse=9.754, r2=0.841; v_loss=97.156, v_rmse=9.857, v_r2=0.826; \n",
            "E 21\t: loss=95.712, rmse=9.783, r2=0.840; v_loss=91.097, v_rmse=9.544, v_r2=0.837; \n",
            "E 22\t: loss=94.430, rmse=9.718, r2=0.843; v_loss=93.540, v_rmse=9.672, v_r2=0.833; \n",
            "E 23\t: loss=95.379, rmse=9.766, r2=0.841; v_loss=101.603, v_rmse=10.080, v_r2=0.818; \n",
            "E 24\t: loss=95.260, rmse=9.760, r2=0.841; v_loss=93.573, v_rmse=9.673, v_r2=0.832; \n",
            "E 25\t: loss=95.422, rmse=9.768, r2=0.841; v_loss=101.894, v_rmse=10.094, v_r2=0.818; \n",
            "E 26\t: loss=93.485, rmse=9.669, r2=0.844; v_loss=94.622, v_rmse=9.727, v_r2=0.831; \n",
            "E 27\t: loss=94.353, rmse=9.714, r2=0.843; v_loss=95.660, v_rmse=9.781, v_r2=0.829; \n",
            "Finished: 2022-10-16 09:23:57.129121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c65c8d-f9f8-4e81-b265-52b95609742f",
        "id": "ypPnlb7xI5z_"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.856,RMSE=-10.118\n",
            "Finished: 2022-10-16 09:23:59.379892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "CWlv5EFWI50C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6121049470412723    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 249),\n",
        "             ('basemodel__epochs', 37),\n",
        "             ('basemodel__model__activation1', 'relu'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__activation4', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.62787764969972),\n",
        "             ('basemodel__model__dropout2', 0.9),\n",
        "             ('basemodel__model__dropout3', 0.6788232857905743),\n",
        "             ('basemodel__model__dropout4', 0.1),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 512),\n",
        "             ('basemodel__model__layer3', 92),\n",
        "             ('basemodel__model__layer4', 133),\n",
        "             ('basemodel__model__learning_rate', 0.0022168133279249643),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('poly_degree', 2),\n",
        "             ('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "_hRfD2CAI50D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=249,\n",
        "                           epochs=37,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='elu',\n",
        "                           model__activation4='sigmoid',\n",
        "                           model__dropout1=0.62787764969972, \n",
        "                           model__dropout2=0.9, \n",
        "                           model__dropout3=0.6788232857905743, \n",
        "                           model__dropout4=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=512, \n",
        "                           model__layer3=92, \n",
        "                           model__layer4=133, \n",
        "                           model__learning_rate=0.0022168133279249643,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f58e902-cc3f-4254-c054-39687c838b71",
        "id": "zdhee-1GI50E"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=249, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=37, model=<function create_model at 0x000001C61804DDC0>, model__activation1='relu', model__activation2='relu', model__activation3='elu', model__activation4='sigmo...del__layer4=133, model__learning_rate=0.0022168133279249643, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C7A096E3A0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C7A096E640>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39ea3c6-bc35-4127-d1ea-88e2daedac07",
        "id": "vhJBABSwI50I"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_64 (Dense)            (None, 512)               129536    \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 92)                47196     \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 92)                0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 133)               12369     \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 133)               0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 1)                 134       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,891\n",
            "Trainable params: 451,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=12713.646, rmse=112.755, r2=-1.794; v_loss=15936.277, v_rmse=126.239, v_r2=-1.543; \n",
            "E 2\t: loss=10260.875, rmse=101.296, r2=-1.255; v_loss=13347.975, v_rmse=115.533, v_r2=-1.130; \n",
            "E 3\t: loss=8317.966, rmse=91.203, r2=-0.828; v_loss=11165.225, v_rmse=105.666, v_r2=-0.782; \n",
            "E 4\t: loss=6791.344, rmse=82.410, r2=-0.493; v_loss=9359.394, v_rmse=96.744, v_r2=-0.494; \n",
            "E 5\t: loss=5610.335, rmse=74.902, r2=-0.233; v_loss=7887.298, v_rmse=88.810, v_r2=-0.259; \n",
            "E 6\t: loss=4373.469, rmse=66.132, r2=0.039; v_loss=6012.741, v_rmse=77.542, v_r2=0.040; \n",
            "E 7\t: loss=3140.839, rmse=56.043, r2=0.310; v_loss=4719.336, v_rmse=68.697, v_r2=0.247; \n",
            "E 8\t: loss=2545.966, rmse=50.458, r2=0.440; v_loss=3857.066, v_rmse=62.105, v_r2=0.384; \n",
            "E 9\t: loss=2180.474, rmse=46.696, r2=0.521; v_loss=3235.774, v_rmse=56.884, v_r2=0.484; \n",
            "E 10\t: loss=2039.354, rmse=45.159, r2=0.552; v_loss=2960.232, v_rmse=54.408, v_r2=0.528; \n",
            "E 11\t: loss=1968.912, rmse=44.372, r2=0.567; v_loss=2817.389, v_rmse=53.079, v_r2=0.550; \n",
            "E 12\t: loss=1939.158, rmse=44.036, r2=0.574; v_loss=2731.291, v_rmse=52.262, v_r2=0.564; \n",
            "E 13\t: loss=1937.243, rmse=44.014, r2=0.574; v_loss=2727.013, v_rmse=52.221, v_r2=0.565; \n",
            "E 14\t: loss=1947.921, rmse=44.135, r2=0.572; v_loss=2719.507, v_rmse=52.149, v_r2=0.566; \n",
            "E 15\t: loss=1924.205, rmse=43.866, r2=0.577; v_loss=2621.354, v_rmse=51.199, v_r2=0.582; \n",
            "E 16\t: loss=1912.644, rmse=43.734, r2=0.580; v_loss=2633.667, v_rmse=51.319, v_r2=0.580; \n",
            "E 17\t: loss=1913.030, rmse=43.738, r2=0.580; v_loss=2648.575, v_rmse=51.464, v_r2=0.577; \n",
            "E 18\t: loss=1918.354, rmse=43.799, r2=0.578; v_loss=2688.850, v_rmse=51.854, v_r2=0.571; \n",
            "E 19\t: loss=1928.461, rmse=43.914, r2=0.576; v_loss=2722.106, v_rmse=52.174, v_r2=0.566; \n",
            "E 20\t: loss=1924.792, rmse=43.872, r2=0.577; v_loss=2656.452, v_rmse=51.541, v_r2=0.576; \n",
            "E 21\t: loss=1918.118, rmse=43.796, r2=0.578; v_loss=2629.427, v_rmse=51.278, v_r2=0.580; \n",
            "Finished: 2022-10-16 09:25:44.861698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c007ec00-2946-4abf-cda6-0a804bb4a1ea",
        "id": "qnwVx-VII50K"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.177,RMSE=-37.689\n",
            "Finished: 2022-10-16 09:25:47.158321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "hz9fq_lWI50L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8425016957390049  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'elu'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'tanh'),\n",
        "             ('basemodel__model__activation4', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.9),\n",
        "             ('basemodel__model__dropout2', 0.1),\n",
        "             ('basemodel__model__dropout3', 0.9),\n",
        "             ('basemodel__model__dropout4', 0.1),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 512),\n",
        "             ('basemodel__model__layer3', 512),\n",
        "             ('basemodel__model__layer4', 512),\n",
        "             ('basemodel__model__learning_rate', 0.0001),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('clip_y', 80),\n",
        "             ('poly_degree', 2),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "9yBfpDmQI50N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='tanh',\n",
        "                           model__activation4='tanh',\n",
        "                           model__dropout1=0.9, \n",
        "                           model__dropout2=0.1, \n",
        "                           model__dropout3=0.9, \n",
        "                           model__dropout4=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=512, \n",
        "                           model__layer3=512, \n",
        "                           model__layer4=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e957f219-1f5b-41ce-d0f4-3ab5c10df620",
        "id": "D8qxuavgI50P"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001C617C32790>, <keras.callbacks.LambdaCallback object at 0x000001C618017520>], epochs=50, model=<function create_model at 0x000001C61804DDC0>, model__activation1='elu', model__activation2='tanh', model__activation3='tanh', model__activation4='tanh',...yer3=512, model__layer4=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001C7A090CE80>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001C7A31C0760>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36543565-0f7a-444b-bced-b54b30eaa235",
        "id": "TbCjxqHdI50R"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_69 (Dense)            (None, 512)               129536    \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 918,017\n",
            "Trainable params: 918,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3220.644, rmse=56.751, r2=-4.367; v_loss=754.177, v_rmse=27.462, v_r2=-0.350; \n",
            "E 2\t: loss=757.890, rmse=27.530, r2=-0.263; v_loss=560.649, v_rmse=23.678, v_r2=-0.004; \n",
            "E 3\t: loss=400.338, rmse=20.008, r2=0.333; v_loss=437.328, v_rmse=20.912, v_r2=0.217; \n",
            "E 4\t: loss=288.258, rmse=16.978, r2=0.520; v_loss=252.121, v_rmse=15.878, v_r2=0.549; \n",
            "E 5\t: loss=239.290, rmse=15.469, r2=0.601; v_loss=181.080, v_rmse=13.457, v_r2=0.676; \n",
            "E 6\t: loss=212.136, rmse=14.565, r2=0.646; v_loss=159.669, v_rmse=12.636, v_r2=0.714; \n",
            "E 7\t: loss=194.388, rmse=13.942, r2=0.676; v_loss=146.958, v_rmse=12.123, v_r2=0.737; \n",
            "E 8\t: loss=176.522, rmse=13.286, r2=0.706; v_loss=147.585, v_rmse=12.148, v_r2=0.736; \n",
            "E 9\t: loss=162.100, rmse=12.732, r2=0.730; v_loss=146.131, v_rmse=12.088, v_r2=0.738; \n",
            "E 10\t: loss=151.014, rmse=12.289, r2=0.748; v_loss=150.035, v_rmse=12.249, v_r2=0.731; \n",
            "E 11\t: loss=143.976, rmse=11.999, r2=0.760; v_loss=149.212, v_rmse=12.215, v_r2=0.733; \n",
            "E 12\t: loss=138.950, rmse=11.788, r2=0.768; v_loss=148.205, v_rmse=12.174, v_r2=0.735; \n",
            "E 13\t: loss=136.331, rmse=11.676, r2=0.773; v_loss=150.211, v_rmse=12.256, v_r2=0.731; \n",
            "E 14\t: loss=129.696, rmse=11.388, r2=0.784; v_loss=149.191, v_rmse=12.214, v_r2=0.733; \n",
            "E 15\t: loss=126.831, rmse=11.262, r2=0.789; v_loss=146.167, v_rmse=12.090, v_r2=0.738; \n",
            "E 16\t: loss=125.102, rmse=11.185, r2=0.792; v_loss=142.581, v_rmse=11.941, v_r2=0.745; \n",
            "E 17\t: loss=123.504, rmse=11.113, r2=0.794; v_loss=139.329, v_rmse=11.804, v_r2=0.751; \n",
            "E 18\t: loss=120.862, rmse=10.994, r2=0.799; v_loss=128.228, v_rmse=11.324, v_r2=0.770; \n",
            "E 19\t: loss=117.900, rmse=10.858, r2=0.804; v_loss=127.563, v_rmse=11.294, v_r2=0.772; \n",
            "E 20\t: loss=116.175, rmse=10.778, r2=0.806; v_loss=124.842, v_rmse=11.173, v_r2=0.777; \n",
            "E 21\t: loss=115.752, rmse=10.759, r2=0.807; v_loss=121.888, v_rmse=11.040, v_r2=0.782; \n",
            "E 22\t: loss=113.527, rmse=10.655, r2=0.811; v_loss=120.189, v_rmse=10.963, v_r2=0.785; \n",
            "E 23\t: loss=113.592, rmse=10.658, r2=0.811; v_loss=120.694, v_rmse=10.986, v_r2=0.784; \n",
            "E 24\t: loss=108.976, rmse=10.439, r2=0.818; v_loss=115.798, v_rmse=10.761, v_r2=0.793; \n",
            "E 25\t: loss=108.888, rmse=10.435, r2=0.819; v_loss=111.911, v_rmse=10.579, v_r2=0.800; \n",
            "E 26\t: loss=107.717, rmse=10.379, r2=0.820; v_loss=113.328, v_rmse=10.646, v_r2=0.797; \n",
            "E 27\t: loss=106.634, rmse=10.326, r2=0.822; v_loss=115.905, v_rmse=10.766, v_r2=0.793; \n",
            "E 28\t: loss=106.557, rmse=10.323, r2=0.822; v_loss=114.886, v_rmse=10.718, v_r2=0.794; \n",
            "E 29\t: loss=105.012, rmse=10.248, r2=0.825; v_loss=115.583, v_rmse=10.751, v_r2=0.793; \n",
            "E 30\t: loss=103.809, rmse=10.189, r2=0.827; v_loss=112.527, v_rmse=10.608, v_r2=0.799; \n",
            "E 31\t: loss=104.121, rmse=10.204, r2=0.826; v_loss=108.266, v_rmse=10.405, v_r2=0.806; \n",
            "E 32\t: loss=103.208, rmse=10.159, r2=0.828; v_loss=107.590, v_rmse=10.373, v_r2=0.807; \n",
            "E 33\t: loss=102.509, rmse=10.125, r2=0.829; v_loss=110.499, v_rmse=10.512, v_r2=0.802; \n",
            "E 34\t: loss=101.156, rmse=10.058, r2=0.831; v_loss=108.105, v_rmse=10.397, v_r2=0.806; \n",
            "E 35\t: loss=101.535, rmse=10.076, r2=0.831; v_loss=107.574, v_rmse=10.372, v_r2=0.807; \n",
            "E 36\t: loss=102.439, rmse=10.121, r2=0.829; v_loss=103.447, v_rmse=10.171, v_r2=0.815; \n",
            "E 37\t: loss=100.064, rmse=10.003, r2=0.833; v_loss=106.389, v_rmse=10.314, v_r2=0.810; \n",
            "E 38\t: loss=98.917, rmse=9.946, r2=0.835; v_loss=107.203, v_rmse=10.354, v_r2=0.808; \n",
            "E 39\t: loss=98.889, rmse=9.944, r2=0.835; v_loss=101.107, v_rmse=10.055, v_r2=0.819; \n",
            "E 40\t: loss=100.671, rmse=10.033, r2=0.832; v_loss=103.118, v_rmse=10.155, v_r2=0.815; \n",
            "E 41\t: loss=100.744, rmse=10.037, r2=0.832; v_loss=105.677, v_rmse=10.280, v_r2=0.811; \n",
            "E 42\t: loss=97.769, rmse=9.888, r2=0.837; v_loss=100.889, v_rmse=10.044, v_r2=0.819; \n",
            "E 43\t: loss=97.879, rmse=9.893, r2=0.837; v_loss=100.570, v_rmse=10.028, v_r2=0.820; \n",
            "E 44\t: loss=97.224, rmse=9.860, r2=0.838; v_loss=104.906, v_rmse=10.242, v_r2=0.812; \n",
            "E 45\t: loss=97.584, rmse=9.878, r2=0.837; v_loss=100.822, v_rmse=10.041, v_r2=0.820; \n",
            "E 46\t: loss=98.244, rmse=9.912, r2=0.836; v_loss=97.871, v_rmse=9.893, v_r2=0.825; \n",
            "E 47\t: loss=97.262, rmse=9.862, r2=0.838; v_loss=99.763, v_rmse=9.988, v_r2=0.821; \n",
            "E 48\t: loss=96.870, rmse=9.842, r2=0.839; v_loss=97.757, v_rmse=9.887, v_r2=0.825; \n",
            "E 49\t: loss=95.964, rmse=9.796, r2=0.840; v_loss=99.399, v_rmse=9.970, v_r2=0.822; \n",
            "E 50\t: loss=96.828, rmse=9.840, r2=0.839; v_loss=98.652, v_rmse=9.932, v_r2=0.823; \n",
            "Finished: 2022-10-16 09:30:51.917210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180e2266-cf28-44d8-f872-1cda3b10f318",
        "id": "Yz7_bVa-I50T"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.843,RMSE=-10.585\n",
            "Finished: 2022-10-16 09:30:52.014184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF"
      ],
      "metadata": {
        "id": "9PvXh5s96MXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.5,\n",
        "''mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'mlp__model__learning_rate': 0.01, \n",
        "'mlp__model__layer_nodes': [128],\n",
        "'mlp__model__dropout': 0.2,\n",
        "'mlp__model__activation': 'relu',\n",
        "'mlp__epochs': 20, \n",
        "'mlp__batch_size': 64}\n",
        "```"
      ],
      "metadata": {
        "id": "mD827CJN7a6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                model__print_summary=True,\n",
        "                                validation_split=0.5, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[128],\n",
        "                                model__dropout=0.2,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=20, \n",
        "                                batch_size=64))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf014eee-965c-440c-8577-4d9c10f84400",
        "id": "JlLpzMHg7a6Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f406e3db050>, <keras.callbacks.LambdaCallback object at 0x7f406008ff10>], epochs=20, model=<function create_model at 0x7f3fd95efc20>, model__activation='relu', model__dropout=0.2, model__layer_nodes=[128], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f3fd9df3950>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f3fbcfbe450>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.5, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asu3aizd8INi",
        "outputId": "07a25b92-09d4-432a-d254-bb75f45ccbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=2735.080, rmse=52.298, r2=0.294; v_loss=2654.072, v_rmse=51.518, v_r2=0.522; \n",
            "E 1\t: loss=1063.129, rmse=32.606, r2=0.725; v_loss=2618.092, v_rmse=51.167, v_r2=0.528; \n",
            "E 2\t: loss=1061.893, rmse=32.587, r2=0.726; v_loss=2480.985, v_rmse=49.809, v_r2=0.553; \n",
            "E 3\t: loss=1049.969, rmse=32.403, r2=0.729; v_loss=2760.811, v_rmse=52.543, v_r2=0.502; \n",
            "E 4\t: loss=1051.995, rmse=32.434, r2=0.728; v_loss=2802.044, v_rmse=52.934, v_r2=0.495; \n",
            "E 5\t: loss=1048.582, rmse=32.382, r2=0.729; v_loss=2526.332, v_rmse=50.263, v_r2=0.545; \n",
            "E 6\t: loss=1045.081, rmse=32.328, r2=0.730; v_loss=2638.387, v_rmse=51.365, v_r2=0.524; \n",
            "E 7\t: loss=1035.534, rmse=32.180, r2=0.733; v_loss=2611.114, v_rmse=51.099, v_r2=0.529; \n",
            "E 8\t: loss=1032.359, rmse=32.130, r2=0.733; v_loss=2670.928, v_rmse=51.681, v_r2=0.519; \n",
            "E 9\t: loss=1038.198, rmse=32.221, r2=0.732; v_loss=2574.217, v_rmse=50.737, v_r2=0.536; \n",
            "E 10\t: loss=1037.728, rmse=32.214, r2=0.732; v_loss=2707.143, v_rmse=52.030, v_r2=0.512; \n",
            "E 11\t: loss=1036.660, rmse=32.197, r2=0.732; v_loss=2574.864, v_rmse=50.743, v_r2=0.536; \n",
            "E 12\t: loss=1037.219, rmse=32.206, r2=0.732; v_loss=2659.009, v_rmse=51.566, v_r2=0.521; \n",
            "E 13\t: loss=1040.173, rmse=32.252, r2=0.731; v_loss=2679.575, v_rmse=51.765, v_r2=0.517; \n",
            "R2=0.607,RMSE=-43.161\n",
            "Finished: 2022-09-15 12:35:03.885280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hL2ywwC89Cw",
        "outputId": "3ffc62b3-3699-4bed-bf58-0afccc1ef2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.488,RMSE=-29.721\n",
            "Finished: 2022-09-15 12:35:08.268111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-linear RUL"
      ],
      "metadata": {
        "id": "g7ZQn1fSXSDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model,verbose=0, callbacks=[es], \n",
        "                                model__degree=1,\n",
        "                                validation_split=0.2, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oArc4RZsX9oJ",
        "outputId": "3395d465-1371-49c8-b24f-8dcf22930619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f3fd4507690>], model=<function create_model at 0x7f3fc11ce170>, model__degree=1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f3fbc3bafd0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f3fbc023410>], validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f40e9f9bc20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 1),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0611cc-3997-4fbe-a255-ece81d9dcd26",
        "id": "HMRMpZKvXSDk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 128}, 'trf_reg__regressor__validation_split': 0.2, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.01, 'trf_reg__regressor__model__layer_nodes': [512], 'trf_reg__regressor__model__dropout': 0.5, 'trf_reg__regressor__model__activation': 'tanh', 'trf_reg__regressor__epochs': 30, 'trf_reg__regressor__batch_size': 64, 'scaler': MinMaxScaler()}\n",
            "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f3fbebde3d0>], epochs=30, model=<function create_model at 0x7f3fd95efc20>, model__activation='tanh', model__degree=1, model__dropout=0.5, model__layer_nodes=[512], model...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f3fbe2acd50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f3fbeae0f50>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.2, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f40e9f9bc20>,\n",
            "                                                                            kw_args={'a_max': 128,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-15 12:54:32.864065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 128}, \n",
        "'trf_reg__regressor__validation_split': 0.2, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [512],\n",
        "'trf_reg__regressor__model__dropout': 0.5,\n",
        "'trf_reg__regressor__model__activation': 'tanh',\n",
        "'trf_reg__regressor__epochs': 30,\n",
        "'trf_reg__regressor__batch_size': 64,\n",
        "'scaler': MinMaxScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "hWSumSoaY5bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,  \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[512],\n",
        "                                model__dropout=0.5,\n",
        "                                model__activation=\"tanh\",\n",
        "                                epochs=30, \n",
        "                                batch_size=64),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':128})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGgXDP9kXneS",
        "outputId": "613516b8-f10e-43b2-dd15-a8078af4448c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f3fd4507690>, <keras.callbacks.LambdaCallback object at 0x7f3fbc023810>], epochs=30, model=<function create_model at 0x7f3fc11ce170>, model__activation='tanh', model__dro...cs=[<keras.metrics.RootMeanSquaredError object at 0x7f3fbeb848d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f3fbc2c8e10>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f40e9f9bc20>,\n",
              "                                                                            kw_args={'a_max': 128,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29e3c40-6c05-4cab-866e-e80638931931",
        "id": "SvRwAhkeXSDm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_767\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1534 (Dense)          (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout_767 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1535 (Dense)          (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,777\n",
            "Trainable params: 11,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=838.904, rmse=28.964, r2=0.541; v_loss=468.957, v_rmse=21.655, v_r2=0.742; \n",
            "E 1\t: loss=493.887, rmse=22.224, r2=0.730; v_loss=440.370, v_rmse=20.985, v_r2=0.758; \n",
            "E 2\t: loss=458.042, rmse=21.402, r2=0.749; v_loss=465.912, v_rmse=21.585, v_r2=0.744; \n",
            "E 3\t: loss=437.639, rmse=20.920, r2=0.760; v_loss=457.287, v_rmse=21.384, v_r2=0.749; \n",
            "E 4\t: loss=427.951, rmse=20.687, r2=0.766; v_loss=401.129, v_rmse=20.028, v_r2=0.780; \n",
            "E 5\t: loss=419.612, rmse=20.484, r2=0.770; v_loss=408.865, v_rmse=20.220, v_r2=0.775; \n",
            "E 6\t: loss=420.278, rmse=20.501, r2=0.770; v_loss=439.703, v_rmse=20.969, v_r2=0.759; \n",
            "E 7\t: loss=410.436, rmse=20.259, r2=0.775; v_loss=395.441, v_rmse=19.886, v_r2=0.783; \n",
            "E 8\t: loss=410.444, rmse=20.259, r2=0.775; v_loss=395.515, v_rmse=19.888, v_r2=0.783; \n",
            "E 9\t: loss=406.890, rmse=20.172, r2=0.777; v_loss=403.579, v_rmse=20.089, v_r2=0.778; \n",
            "E 10\t: loss=405.002, rmse=20.125, r2=0.778; v_loss=408.452, v_rmse=20.210, v_r2=0.776; \n",
            "E 11\t: loss=402.101, rmse=20.052, r2=0.780; v_loss=402.297, v_rmse=20.057, v_r2=0.779; \n",
            "E 12\t: loss=400.506, rmse=20.013, r2=0.781; v_loss=390.625, v_rmse=19.764, v_r2=0.786; \n",
            "E 13\t: loss=400.672, rmse=20.017, r2=0.781; v_loss=435.520, v_rmse=20.869, v_r2=0.761; \n",
            "E 14\t: loss=400.133, rmse=20.003, r2=0.781; v_loss=406.249, v_rmse=20.156, v_r2=0.777; \n",
            "E 15\t: loss=394.553, rmse=19.863, r2=0.784; v_loss=397.044, v_rmse=19.926, v_r2=0.782; \n",
            "E 16\t: loss=397.832, rmse=19.946, r2=0.782; v_loss=394.259, v_rmse=19.856, v_r2=0.784; \n",
            "E 17\t: loss=395.173, rmse=19.879, r2=0.784; v_loss=402.182, v_rmse=20.054, v_r2=0.779; \n",
            "E 18\t: loss=391.848, rmse=19.795, r2=0.785; v_loss=387.547, v_rmse=19.686, v_r2=0.787; \n",
            "E 19\t: loss=390.880, rmse=19.771, r2=0.786; v_loss=387.856, v_rmse=19.694, v_r2=0.787; \n",
            "E 20\t: loss=390.304, rmse=19.756, r2=0.786; v_loss=386.106, v_rmse=19.650, v_r2=0.788; \n",
            "E 21\t: loss=387.796, rmse=19.693, r2=0.788; v_loss=451.778, v_rmse=21.255, v_r2=0.752; \n",
            "E 22\t: loss=386.844, rmse=19.668, r2=0.788; v_loss=388.903, v_rmse=19.721, v_r2=0.786; \n",
            "E 23\t: loss=386.234, rmse=19.653, r2=0.789; v_loss=385.443, v_rmse=19.633, v_r2=0.788; \n",
            "E 24\t: loss=388.855, rmse=19.719, r2=0.787; v_loss=398.101, v_rmse=19.952, v_r2=0.781; \n",
            "E 25\t: loss=385.341, rmse=19.630, r2=0.789; v_loss=400.994, v_rmse=20.025, v_r2=0.780; \n",
            "E 26\t: loss=385.543, rmse=19.635, r2=0.789; v_loss=411.373, v_rmse=20.282, v_r2=0.774; \n",
            "E 27\t: loss=385.066, rmse=19.623, r2=0.789; v_loss=386.582, v_rmse=19.662, v_r2=0.788; \n",
            "E 28\t: loss=386.048, rmse=19.648, r2=0.789; v_loss=385.699, v_rmse=19.639, v_r2=0.788; \n",
            "E 29\t: loss=383.444, rmse=19.582, r2=0.790; v_loss=416.516, v_rmse=20.409, v_r2=0.771; \n",
            "R2=0.796,RMSE=-19.302\n",
            "Finished: 2022-09-15 13:31:13.610326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC21OkkFXW_5",
        "outputId": "04f50656-5a1c-493e-8f94-0b88fee57eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.808,RMSE=-17.733\n",
            "Finished: 2022-09-15 13:31:13.681717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best result we had so far in training and in testing"
      ],
      "metadata": {
        "id": "RRfdas0GXSDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Linear RUL"
      ],
      "metadata": {
        "id": "XnNMgO2019c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=2,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab654aa-62e6-4ddd-98a0-4fe164f5142c",
        "id": "4ppFFZKW10kf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>], model=<function create_model at 0x7f1959d24050>, model__degree=2, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18c7fc1610>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18c7f49810>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~12min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__degree\": [2],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 1),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]    \n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b5ff53-9af0-495b-a80e-6aee802dd5c8",
        "id": "mJC53HIG10kj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18c8120d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18c7fb3830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f18b173e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x7f18b19e30e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f18b1767290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7f18c7fa9cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'mlp__model__learning_rate': 0.01, 'mlp__model__layer_nodes': [512], 'mlp__model__dropout': 0.4, 'mlp__model__degree': 2, 'mlp__model__activation': 'sigmoid', 'mlp__epochs': 50, 'mlp__batch_size': 512}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f18a9c18990>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='sigmoid', model__degree=2, model__dropout=0.4, model__layer_nodes=[512], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18c41cb210>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18c41cb590>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-16 11:23:08.730504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'mlp__model__learning_rate': 0.01, \n",
        "'mlp__model__layer_nodes': [512], \n",
        "'mlp__model__dropout': 0.4, \n",
        "'mlp__model__degree': 2, \n",
        "'mlp__model__activation': 'sigmoid', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 512}\n",
        "```"
      ],
      "metadata": {
        "id": "XYiWhyX110km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[512],\n",
        "                                model__dropout=0.4,\n",
        "                                model__degree=2,\n",
        "                                model__activation=\"sigmoid\",\n",
        "                                epochs=50, \n",
        "                                batch_size=512))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c59bf6d-b792-4849-cd9f-cea80783ade7",
        "id": "Zd2zCRlE10kn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='sigmoid', model__degree=2, model__dropout=0.4, model__layer_nodes=[512], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18c42d1a50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18c42d1c50>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca58f2f-f53f-4d62-fd6e-26acac38f90d",
        "id": "B-Px76hy10kq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_253\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_506 (Dense)           (None, 512)               129536    \n",
            "                                                                 \n",
            " dropout_253 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_507 (Dense)           (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,049\n",
            "Trainable params: 130,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=5057.620, rmse=71.117, r2=-0.163; v_loss=3196.043, v_rmse=56.534, v_r2=0.484; \n",
            "E 1\t: loss=1720.632, rmse=41.481, r2=0.604; v_loss=2960.801, v_rmse=54.413, v_r2=0.522; \n",
            "E 2\t: loss=1653.111, rmse=40.658, r2=0.620; v_loss=2736.813, v_rmse=52.315, v_r2=0.558; \n",
            "E 3\t: loss=1638.268, rmse=40.476, r2=0.623; v_loss=2730.283, v_rmse=52.252, v_r2=0.559; \n",
            "E 4\t: loss=1625.012, rmse=40.311, r2=0.626; v_loss=2740.308, v_rmse=52.348, v_r2=0.557; \n",
            "E 5\t: loss=1606.013, rmse=40.075, r2=0.631; v_loss=2820.159, v_rmse=53.105, v_r2=0.544; \n",
            "E 6\t: loss=1606.964, rmse=40.087, r2=0.630; v_loss=2604.456, v_rmse=51.034, v_r2=0.579; \n",
            "E 7\t: loss=1606.202, rmse=40.077, r2=0.631; v_loss=2668.386, v_rmse=51.656, v_r2=0.569; \n",
            "E 8\t: loss=1587.813, rmse=39.847, r2=0.635; v_loss=2648.820, v_rmse=51.467, v_r2=0.572; \n",
            "E 9\t: loss=1586.110, rmse=39.826, r2=0.635; v_loss=3018.028, v_rmse=54.937, v_r2=0.512; \n",
            "E 10\t: loss=1578.313, rmse=39.728, r2=0.637; v_loss=2802.641, v_rmse=52.940, v_r2=0.547; \n",
            "E 11\t: loss=1574.841, rmse=39.684, r2=0.638; v_loss=2593.199, v_rmse=50.923, v_r2=0.581; \n",
            "E 12\t: loss=1566.632, rmse=39.581, r2=0.640; v_loss=2852.686, v_rmse=53.411, v_r2=0.539; \n",
            "E 13\t: loss=1549.920, rmse=39.369, r2=0.643; v_loss=2627.878, v_rmse=51.263, v_r2=0.575; \n",
            "E 14\t: loss=1559.062, rmse=39.485, r2=0.641; v_loss=2675.007, v_rmse=51.720, v_r2=0.568; \n",
            "E 15\t: loss=1553.413, rmse=39.413, r2=0.643; v_loss=2776.835, v_rmse=52.696, v_r2=0.551; \n",
            "E 16\t: loss=1542.100, rmse=39.270, r2=0.645; v_loss=2613.190, v_rmse=51.119, v_r2=0.578; \n",
            "E 17\t: loss=1542.858, rmse=39.279, r2=0.645; v_loss=2953.031, v_rmse=54.342, v_r2=0.523; \n",
            "E 18\t: loss=1541.715, rmse=39.265, r2=0.645; v_loss=2659.498, v_rmse=51.570, v_r2=0.570; \n",
            "E 19\t: loss=1530.737, rmse=39.125, r2=0.648; v_loss=2859.923, v_rmse=53.478, v_r2=0.538; \n",
            "E 20\t: loss=1525.696, rmse=39.060, r2=0.649; v_loss=2648.275, v_rmse=51.461, v_r2=0.572; \n",
            "E 21\t: loss=1529.431, rmse=39.108, r2=0.648; v_loss=3072.285, v_rmse=55.428, v_r2=0.504; \n",
            "E 22\t: loss=1522.380, rmse=39.018, r2=0.650; v_loss=2924.243, v_rmse=54.076, v_r2=0.527; \n",
            "E 23\t: loss=1514.099, rmse=38.911, r2=0.652; v_loss=2811.606, v_rmse=53.025, v_r2=0.546; \n",
            "E 24\t: loss=1516.103, rmse=38.937, r2=0.651; v_loss=2814.883, v_rmse=53.055, v_r2=0.545; \n",
            "E 25\t: loss=1508.285, rmse=38.837, r2=0.653; v_loss=2923.265, v_rmse=54.067, v_r2=0.528; \n",
            "E 26\t: loss=1518.947, rmse=38.974, r2=0.651; v_loss=2856.383, v_rmse=53.445, v_r2=0.538; \n",
            "E 27\t: loss=1508.050, rmse=38.834, r2=0.653; v_loss=2782.242, v_rmse=52.747, v_r2=0.550; \n",
            "E 28\t: loss=1503.399, rmse=38.774, r2=0.654; v_loss=2649.618, v_rmse=51.474, v_r2=0.572; \n",
            "E 29\t: loss=1509.930, rmse=38.858, r2=0.653; v_loss=2646.393, v_rmse=51.443, v_r2=0.572; \n",
            "E 30\t: loss=1494.367, rmse=38.657, r2=0.656; v_loss=2633.829, v_rmse=51.321, v_r2=0.574; \n",
            "E 31\t: loss=1506.083, rmse=38.808, r2=0.654; v_loss=2576.338, v_rmse=50.758, v_r2=0.584; \n",
            "E 32\t: loss=1497.476, rmse=38.697, r2=0.656; v_loss=2708.250, v_rmse=52.041, v_r2=0.562; \n",
            "E 33\t: loss=1500.541, rmse=38.737, r2=0.655; v_loss=2989.322, v_rmse=54.675, v_r2=0.517; \n",
            "E 34\t: loss=1493.587, rmse=38.647, r2=0.656; v_loss=2664.660, v_rmse=51.620, v_r2=0.569; \n",
            "E 35\t: loss=1491.050, rmse=38.614, r2=0.657; v_loss=2573.920, v_rmse=50.734, v_r2=0.584; \n",
            "E 36\t: loss=1496.294, rmse=38.682, r2=0.656; v_loss=2672.859, v_rmse=51.700, v_r2=0.568; \n",
            "E 37\t: loss=1491.398, rmse=38.619, r2=0.657; v_loss=3099.339, v_rmse=55.672, v_r2=0.499; \n",
            "E 38\t: loss=1490.654, rmse=38.609, r2=0.657; v_loss=2690.143, v_rmse=51.867, v_r2=0.565; \n",
            "E 39\t: loss=1485.504, rmse=38.542, r2=0.658; v_loss=2574.053, v_rmse=50.735, v_r2=0.584; \n",
            "E 40\t: loss=1480.895, rmse=38.482, r2=0.659; v_loss=2661.047, v_rmse=51.585, v_r2=0.570; \n",
            "E 41\t: loss=1476.297, rmse=38.423, r2=0.660; v_loss=2533.465, v_rmse=50.334, v_r2=0.591; \n",
            "E 42\t: loss=1482.794, rmse=38.507, r2=0.659; v_loss=2662.808, v_rmse=51.602, v_r2=0.570; \n",
            "E 43\t: loss=1477.591, rmse=38.439, r2=0.660; v_loss=2831.034, v_rmse=53.207, v_r2=0.542; \n",
            "E 44\t: loss=1476.469, rmse=38.425, r2=0.660; v_loss=2936.182, v_rmse=54.187, v_r2=0.526; \n",
            "E 45\t: loss=1482.055, rmse=38.497, r2=0.659; v_loss=2645.109, v_rmse=51.431, v_r2=0.573; \n",
            "E 46\t: loss=1483.282, rmse=38.513, r2=0.659; v_loss=2816.157, v_rmse=53.067, v_r2=0.545; \n",
            "R2=0.643,RMSE=-41.179\n",
            "Finished: 2022-09-16 11:24:14.947796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e873cb19-0ed7-4666-93b0-c281d640b013",
        "id": "wsJR7Aa910kr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.333,RMSE=-33.941\n",
            "Finished: 2022-09-16 11:24:17.967695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bad generalization using 2 degree polynomial"
      ],
      "metadata": {
        "id": "cJeQqS7e7wZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "7tVaOoTL2q0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=2,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5c6be2-b863-4e33-acfa-c4a6fef9f8fa",
        "id": "I4_yKNjd2q0X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>], model=<function create_model at 0x7f1959d24050>, model__degree=2, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b1e9b7d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b1e9b590>], verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~10min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__model__degree\": [2],\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 1),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47cbad8c-5b7d-464d-83e3-69196c10f627",
        "id": "UqMZFZ8m2q0Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, 'trf_reg__regressor__validation_split': 0.5, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'trf_reg__regressor__model__learning_rate': 0.01, 'trf_reg__regressor__model__layer_nodes': [16], 'trf_reg__regressor__model__dropout': 0.2, 'trf_reg__regressor__model__degree': 2, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 50, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f18c458e7d0>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='relu', model__degre...1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18c4274cd0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18c5814dd0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.5, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
            "                                                                            kw_args={'a_max': 135,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-16 11:46:03.248889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, \n",
        "'trf_reg__regressor__validation_split': 0.5, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [16], \n",
        "'trf_reg__regressor__model__dropout': 0.2, \n",
        "'trf_reg__regressor__model__degree': 2, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "7lP1ErIS2q0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2,include_bias=False)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback], \n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[16],\n",
        "                                model__dropout=0.2,\n",
        "                                model__degree=2,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':135})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9d5089-d61c-4a4f-e1ee-0904a4067c0f",
        "id": "TDmOy64U2q0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=50, model=<function create_model..._metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b1fc0c10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18a9c57d10>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.5, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 135,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d5ce6c-2fd6-489c-addc-1cdf7916bcec",
        "id": "RaSuF0-Y2q0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_507\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1014 (Dense)          (None, 16)                4048      \n",
            "                                                                 \n",
            " dropout_507 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1015 (Dense)          (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,065\n",
            "Trainable params: 4,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=2450.159, rmse=49.499, r2=-0.206; v_loss=1878.002, v_rmse=43.336, v_r2=0.081; \n",
            "E 1\t: loss=1160.745, rmse=34.070, r2=0.428; v_loss=835.719, v_rmse=28.909, v_r2=0.591; \n",
            "E 2\t: loss=836.896, rmse=28.929, r2=0.588; v_loss=676.510, v_rmse=26.010, v_r2=0.669; \n",
            "E 3\t: loss=722.874, rmse=26.886, r2=0.644; v_loss=631.964, v_rmse=25.139, v_r2=0.691; \n",
            "E 4\t: loss=678.140, rmse=26.041, r2=0.666; v_loss=676.306, v_rmse=26.006, v_r2=0.669; \n",
            "E 5\t: loss=663.531, rmse=25.759, r2=0.673; v_loss=595.711, v_rmse=24.407, v_r2=0.709; \n",
            "E 6\t: loss=639.839, rmse=25.295, r2=0.685; v_loss=608.247, v_rmse=24.663, v_r2=0.702; \n",
            "E 7\t: loss=644.362, rmse=25.384, r2=0.683; v_loss=612.636, v_rmse=24.751, v_r2=0.700; \n",
            "E 8\t: loss=628.113, rmse=25.062, r2=0.691; v_loss=566.844, v_rmse=23.808, v_r2=0.723; \n",
            "E 9\t: loss=624.348, rmse=24.987, r2=0.693; v_loss=582.583, v_rmse=24.137, v_r2=0.715; \n",
            "E 10\t: loss=616.196, rmse=24.823, r2=0.697; v_loss=595.269, v_rmse=24.398, v_r2=0.709; \n",
            "E 11\t: loss=598.409, rmse=24.462, r2=0.705; v_loss=574.393, v_rmse=23.966, v_r2=0.719; \n",
            "E 12\t: loss=602.097, rmse=24.538, r2=0.704; v_loss=578.941, v_rmse=24.061, v_r2=0.717; \n",
            "E 13\t: loss=592.744, rmse=24.346, r2=0.708; v_loss=596.309, v_rmse=24.419, v_r2=0.708; \n",
            "E 14\t: loss=586.969, rmse=24.227, r2=0.711; v_loss=597.977, v_rmse=24.454, v_r2=0.707; \n",
            "E 15\t: loss=580.443, rmse=24.092, r2=0.714; v_loss=584.260, v_rmse=24.171, v_r2=0.714; \n",
            "E 16\t: loss=580.033, rmse=24.084, r2=0.714; v_loss=582.379, v_rmse=24.133, v_r2=0.715; \n",
            "E 17\t: loss=573.118, rmse=23.940, r2=0.718; v_loss=568.306, v_rmse=23.839, v_r2=0.722; \n",
            "E 18\t: loss=549.544, rmse=23.442, r2=0.729; v_loss=578.666, v_rmse=24.055, v_r2=0.717; \n",
            "E 19\t: loss=571.483, rmse=23.906, r2=0.719; v_loss=570.734, v_rmse=23.890, v_r2=0.721; \n",
            "E 20\t: loss=552.137, rmse=23.498, r2=0.728; v_loss=564.766, v_rmse=23.765, v_r2=0.724; \n",
            "E 21\t: loss=558.989, rmse=23.643, r2=0.725; v_loss=604.470, v_rmse=24.586, v_r2=0.704; \n",
            "E 22\t: loss=538.503, rmse=23.206, r2=0.735; v_loss=577.758, v_rmse=24.037, v_r2=0.717; \n",
            "E 23\t: loss=538.306, rmse=23.201, r2=0.735; v_loss=595.892, v_rmse=24.411, v_r2=0.708; \n",
            "E 24\t: loss=535.941, rmse=23.150, r2=0.736; v_loss=569.795, v_rmse=23.870, v_r2=0.721; \n",
            "E 25\t: loss=528.560, rmse=22.990, r2=0.740; v_loss=564.633, v_rmse=23.762, v_r2=0.724; \n",
            "E 26\t: loss=526.613, rmse=22.948, r2=0.741; v_loss=568.015, v_rmse=23.833, v_r2=0.722; \n",
            "E 27\t: loss=529.333, rmse=23.007, r2=0.739; v_loss=578.369, v_rmse=24.049, v_r2=0.717; \n",
            "E 28\t: loss=522.915, rmse=22.867, r2=0.743; v_loss=600.066, v_rmse=24.496, v_r2=0.706; \n",
            "E 29\t: loss=514.703, rmse=22.687, r2=0.747; v_loss=555.826, v_rmse=23.576, v_r2=0.728; \n",
            "E 30\t: loss=513.621, rmse=22.663, r2=0.747; v_loss=576.181, v_rmse=24.004, v_r2=0.718; \n",
            "E 31\t: loss=503.243, rmse=22.433, r2=0.752; v_loss=580.839, v_rmse=24.101, v_r2=0.716; \n",
            "E 32\t: loss=505.049, rmse=22.473, r2=0.751; v_loss=554.757, v_rmse=23.553, v_r2=0.729; \n",
            "E 33\t: loss=500.203, rmse=22.365, r2=0.754; v_loss=576.621, v_rmse=24.013, v_r2=0.718; \n",
            "E 34\t: loss=496.617, rmse=22.285, r2=0.755; v_loss=555.739, v_rmse=23.574, v_r2=0.728; \n",
            "E 35\t: loss=507.188, rmse=22.521, r2=0.750; v_loss=549.575, v_rmse=23.443, v_r2=0.731; \n",
            "E 36\t: loss=493.342, rmse=22.211, r2=0.757; v_loss=553.996, v_rmse=23.537, v_r2=0.729; \n",
            "E 37\t: loss=495.971, rmse=22.270, r2=0.756; v_loss=539.737, v_rmse=23.232, v_r2=0.736; \n",
            "E 38\t: loss=492.537, rmse=22.193, r2=0.757; v_loss=556.856, v_rmse=23.598, v_r2=0.728; \n",
            "E 39\t: loss=489.190, rmse=22.118, r2=0.759; v_loss=552.937, v_rmse=23.515, v_r2=0.729; \n",
            "E 40\t: loss=494.777, rmse=22.244, r2=0.756; v_loss=568.734, v_rmse=23.848, v_r2=0.722; \n",
            "E 41\t: loss=482.349, rmse=21.962, r2=0.762; v_loss=548.344, v_rmse=23.417, v_r2=0.732; \n",
            "E 42\t: loss=477.719, rmse=21.857, r2=0.765; v_loss=545.441, v_rmse=23.355, v_r2=0.733; \n",
            "E 43\t: loss=484.990, rmse=22.022, r2=0.761; v_loss=547.379, v_rmse=23.396, v_r2=0.732; \n",
            "E 44\t: loss=476.649, rmse=21.832, r2=0.765; v_loss=561.027, v_rmse=23.686, v_r2=0.725; \n",
            "E 45\t: loss=476.699, rmse=21.833, r2=0.765; v_loss=571.994, v_rmse=23.916, v_r2=0.720; \n",
            "E 46\t: loss=469.657, rmse=21.672, r2=0.769; v_loss=557.251, v_rmse=23.606, v_r2=0.727; \n",
            "E 47\t: loss=465.526, rmse=21.576, r2=0.771; v_loss=551.758, v_rmse=23.490, v_r2=0.730; \n",
            "E 48\t: loss=471.995, rmse=21.725, r2=0.768; v_loss=560.391, v_rmse=23.673, v_r2=0.726; \n",
            "E 49\t: loss=471.013, rmse=21.703, r2=0.768; v_loss=544.369, v_rmse=23.332, v_r2=0.734; \n",
            "R2=0.776,RMSE=-21.369\n",
            "Finished: 2022-09-16 11:49:10.039298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c26556-5088-463e-e54e-3059e6ed31ac",
        "id": "u-p17w2q2q0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.775,RMSE=-19.536\n",
            "Finished: 2022-09-16 11:50:29.954140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good generalization, but worse than regular features"
      ],
      "metadata": {
        "id": "BEmi7z3WGQLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Linear RUL"
      ],
      "metadata": {
        "id": "meN5SDTg_CzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=3,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51632beb-3946-4027-b5ec-9769df40a4c2",
        "id": "DvY1EKKO_CzZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>], model=<function create_model at 0x7f1959d24050>, model__degree=3, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b190e390>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18c89e9910>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__degree\": [3],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 1),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]    \n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471335a3-140a-4333-9f43-5a6df7d1ef7c",
        "id": "tzbPLuVT_Cza"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'mlp__model__learning_rate': 0.01, 'mlp__model__layer_nodes': [512], 'mlp__model__dropout': 0.4, 'mlp__model__degree': 3, 'mlp__model__activation': 'sigmoid', 'mlp__epochs': 50, 'mlp__batch_size': 512}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f18b18f4290>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='sigmoid', model__degree=3, model__dropout=0.4, model__layer_nodes=[512], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18ae55b7d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b1d54dd0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-16 12:06:39.775037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'mlp__model__learning_rate': 0.01, \n",
        "'mlp__model__layer_nodes': [512], \n",
        "'mlp__model__dropout': 0.4, \n",
        "'mlp__model__degree': 3, \n",
        "'mlp__model__activation': 'sigmoid', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 512}\n",
        "```"
      ],
      "metadata": {
        "id": "-Ut3PpL5_Czc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[512],\n",
        "                                model__dropout=0.4,\n",
        "                                model__degree=3,\n",
        "                                model__activation=\"sigmoid\",\n",
        "                                epochs=50, \n",
        "                                batch_size=512))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ca43fa-91bc-4c35-f0ea-d66e65e2ff89",
        "id": "lODOMlmR_Czd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='sigmoid', model...3, model__dropout=0.4, model__layer_nodes=[512], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18c57d9e90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b02418d0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff788bd-9a1f-4fe3-b577-d0b9362b2ab8",
        "id": "mwR4EzwN_Czd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_761\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1522 (Dense)          (None, 512)               1036288   \n",
            "                                                                 \n",
            " dropout_761 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1523 (Dense)          (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,036,801\n",
            "Trainable params: 1,036,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=5458.847, rmse=73.884, r2=-0.256; v_loss=3615.433, v_rmse=60.128, v_r2=0.416; \n",
            "E 1\t: loss=1796.632, rmse=42.387, r2=0.587; v_loss=2949.010, v_rmse=54.305, v_r2=0.523; \n",
            "E 2\t: loss=1698.000, rmse=41.207, r2=0.609; v_loss=2761.931, v_rmse=52.554, v_r2=0.554; \n",
            "E 3\t: loss=1675.702, rmse=40.935, r2=0.615; v_loss=2764.185, v_rmse=52.576, v_r2=0.553; \n",
            "E 4\t: loss=1669.086, rmse=40.854, r2=0.616; v_loss=2741.880, v_rmse=52.363, v_r2=0.557; \n",
            "E 5\t: loss=1658.792, rmse=40.728, r2=0.618; v_loss=2821.042, v_rmse=53.113, v_r2=0.544; \n",
            "E 6\t: loss=1667.306, rmse=40.833, r2=0.616; v_loss=2631.792, v_rmse=51.301, v_r2=0.575; \n",
            "E 7\t: loss=1661.105, rmse=40.757, r2=0.618; v_loss=2774.665, v_rmse=52.675, v_r2=0.552; \n",
            "E 8\t: loss=1649.179, rmse=40.610, r2=0.621; v_loss=2768.550, v_rmse=52.617, v_r2=0.553; \n",
            "E 9\t: loss=1653.338, rmse=40.661, r2=0.620; v_loss=2934.544, v_rmse=54.171, v_r2=0.526; \n",
            "E 10\t: loss=1637.914, rmse=40.471, r2=0.623; v_loss=2824.758, v_rmse=53.148, v_r2=0.544; \n",
            "E 11\t: loss=1655.116, rmse=40.683, r2=0.619; v_loss=2714.577, v_rmse=52.102, v_r2=0.561; \n",
            "E 12\t: loss=1644.620, rmse=40.554, r2=0.622; v_loss=2825.742, v_rmse=53.158, v_r2=0.543; \n",
            "E 13\t: loss=1639.911, rmse=40.496, r2=0.623; v_loss=2713.071, v_rmse=52.087, v_r2=0.562; \n",
            "E 14\t: loss=1641.671, rmse=40.518, r2=0.622; v_loss=2763.502, v_rmse=52.569, v_r2=0.553; \n",
            "E 15\t: loss=1647.284, rmse=40.587, r2=0.621; v_loss=2828.758, v_rmse=53.186, v_r2=0.543; \n",
            "R2=0.613,RMSE=-42.823\n",
            "Finished: 2022-09-16 12:08:01.614302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47b2d35-2e45-4965-df94-0bb32ae74575",
        "id": "ygI3aJw0_Cze"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.509,RMSE=-29.129\n",
            "Finished: 2022-09-16 12:08:01.694012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar architecture to the NL 1-degree polynomial, but worse results. Slight improvement over 1-degree Linear, better than 2-degree."
      ],
      "metadata": {
        "id": "QZuSahvj_Czf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "0UbrVccP_Czf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=3,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc777fd-9657-4902-a475-a4b5253b3089",
        "id": "yq8yTrfu_Czg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>], model=<function create_model at 0x7f1959d24050>, model__degree=3, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b0121350>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b0121410>], verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~20min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__model__degree\": [3],\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 1),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b964268-4509-4230-bc09-d3e1fbb525a1",
        "id": "i1w6vrL1_Czh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, 'trf_reg__regressor__validation_split': 0.5, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'trf_reg__regressor__model__learning_rate': 0.01, 'trf_reg__regressor__model__layer_nodes': [16], 'trf_reg__regressor__model__dropout': 0.2, 'trf_reg__regressor__model__degree': 3, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 50, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f18b19bc5d0>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='relu', mod...1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18c440d590>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18c564f150>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.5, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
            "                                                                            kw_args={'a_max': 135,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-16 12:33:02.858625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, \n",
        "'trf_reg__regressor__validation_split': 0.5, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [16], \n",
        "'trf_reg__regressor__model__dropout': 0.2, \n",
        "'trf_reg__regressor__model__degree': 3, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "1tQVQNAD_Czh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3,include_bias=False)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback], \n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[16],\n",
        "                                model__dropout=0.2,\n",
        "                                model__degree=3,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':135})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5a5964-7ddb-4240-8cd0-ec798f99a5e1",
        "id": "b1eOudVE_Czh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=50, model=<function cre..._metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b1862b50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b0092c50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.5, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 135,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52a2bb1-6bda-4856-bdc5-460cd203cce3",
        "id": "R5wl6TKp_Czi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1015\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2030 (Dense)          (None, 16)                32384     \n",
            "                                                                 \n",
            " dropout_1015 (Dropout)      (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2031 (Dense)          (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,401\n",
            "Trainable params: 32,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1975.571, rmse=44.447, r2=0.027; v_loss=1402.159, v_rmse=37.445, v_r2=0.314; \n",
            "E 1\t: loss=1257.777, rmse=35.465, r2=0.381; v_loss=1110.082, v_rmse=33.318, v_r2=0.457; \n",
            "E 2\t: loss=1061.762, rmse=32.585, r2=0.477; v_loss=951.694, v_rmse=30.850, v_r2=0.534; \n",
            "E 3\t: loss=926.742, rmse=30.442, r2=0.544; v_loss=830.629, v_rmse=28.821, v_r2=0.594; \n",
            "E 4\t: loss=856.466, rmse=29.265, r2=0.578; v_loss=802.247, v_rmse=28.324, v_r2=0.607; \n",
            "E 5\t: loss=821.784, rmse=28.667, r2=0.595; v_loss=771.883, v_rmse=27.783, v_r2=0.622; \n",
            "E 6\t: loss=787.382, rmse=28.060, r2=0.612; v_loss=782.979, v_rmse=27.982, v_r2=0.617; \n",
            "E 7\t: loss=761.541, rmse=27.596, r2=0.625; v_loss=799.018, v_rmse=28.267, v_r2=0.609; \n",
            "E 8\t: loss=751.391, rmse=27.412, r2=0.630; v_loss=725.970, v_rmse=26.944, v_r2=0.645; \n",
            "E 9\t: loss=731.602, rmse=27.048, r2=0.640; v_loss=735.524, v_rmse=27.121, v_r2=0.640; \n",
            "E 10\t: loss=704.165, rmse=26.536, r2=0.653; v_loss=756.943, v_rmse=27.513, v_r2=0.630; \n",
            "E 11\t: loss=678.724, rmse=26.052, r2=0.666; v_loss=725.716, v_rmse=26.939, v_r2=0.645; \n",
            "E 12\t: loss=680.853, rmse=26.093, r2=0.665; v_loss=682.099, v_rmse=26.117, v_r2=0.666; \n",
            "E 13\t: loss=673.211, rmse=25.946, r2=0.669; v_loss=791.441, v_rmse=28.133, v_r2=0.613; \n",
            "E 14\t: loss=645.406, rmse=25.405, r2=0.682; v_loss=689.940, v_rmse=26.267, v_r2=0.662; \n",
            "E 15\t: loss=646.512, rmse=25.427, r2=0.682; v_loss=660.232, v_rmse=25.695, v_r2=0.677; \n",
            "E 16\t: loss=624.102, rmse=24.982, r2=0.693; v_loss=744.758, v_rmse=27.290, v_r2=0.636; \n",
            "E 17\t: loss=628.425, rmse=25.068, r2=0.691; v_loss=698.857, v_rmse=26.436, v_r2=0.658; \n",
            "E 18\t: loss=608.295, rmse=24.664, r2=0.700; v_loss=716.634, v_rmse=26.770, v_r2=0.649; \n",
            "E 19\t: loss=607.638, rmse=24.650, r2=0.701; v_loss=651.482, v_rmse=25.524, v_r2=0.681; \n",
            "E 20\t: loss=603.992, rmse=24.576, r2=0.703; v_loss=679.537, v_rmse=26.068, v_r2=0.668; \n",
            "E 21\t: loss=589.005, rmse=24.269, r2=0.710; v_loss=659.001, v_rmse=25.671, v_r2=0.678; \n",
            "E 22\t: loss=580.245, rmse=24.088, r2=0.714; v_loss=665.377, v_rmse=25.795, v_r2=0.674; \n",
            "E 23\t: loss=576.014, rmse=24.000, r2=0.716; v_loss=622.764, v_rmse=24.955, v_r2=0.695; \n",
            "E 24\t: loss=560.198, rmse=23.668, r2=0.724; v_loss=634.439, v_rmse=25.188, v_r2=0.690; \n",
            "E 25\t: loss=549.117, rmse=23.433, r2=0.730; v_loss=596.674, v_rmse=24.427, v_r2=0.708; \n",
            "E 26\t: loss=546.115, rmse=23.369, r2=0.731; v_loss=637.478, v_rmse=25.248, v_r2=0.688; \n",
            "E 27\t: loss=560.391, rmse=23.673, r2=0.724; v_loss=659.010, v_rmse=25.671, v_r2=0.678; \n",
            "E 28\t: loss=551.967, rmse=23.494, r2=0.728; v_loss=630.836, v_rmse=25.116, v_r2=0.691; \n",
            "E 29\t: loss=539.852, rmse=23.235, r2=0.734; v_loss=615.070, v_rmse=24.801, v_r2=0.699; \n",
            "E 30\t: loss=535.336, rmse=23.137, r2=0.736; v_loss=619.936, v_rmse=24.899, v_r2=0.697; \n",
            "E 31\t: loss=528.813, rmse=22.996, r2=0.740; v_loss=627.534, v_rmse=25.051, v_r2=0.693; \n",
            "E 32\t: loss=526.747, rmse=22.951, r2=0.741; v_loss=619.439, v_rmse=24.889, v_r2=0.697; \n",
            "E 33\t: loss=521.573, rmse=22.838, r2=0.743; v_loss=571.351, v_rmse=23.903, v_r2=0.720; \n",
            "E 34\t: loss=517.462, rmse=22.748, r2=0.745; v_loss=619.473, v_rmse=24.889, v_r2=0.697; \n",
            "E 35\t: loss=530.934, rmse=23.042, r2=0.739; v_loss=590.470, v_rmse=24.300, v_r2=0.711; \n",
            "E 36\t: loss=518.389, rmse=22.768, r2=0.745; v_loss=607.767, v_rmse=24.653, v_r2=0.703; \n",
            "E 37\t: loss=522.038, rmse=22.848, r2=0.743; v_loss=586.189, v_rmse=24.211, v_r2=0.713; \n",
            "E 38\t: loss=514.122, rmse=22.674, r2=0.747; v_loss=618.027, v_rmse=24.860, v_r2=0.698; \n",
            "E 39\t: loss=509.559, rmse=22.573, r2=0.749; v_loss=643.582, v_rmse=25.369, v_r2=0.685; \n",
            "E 40\t: loss=502.982, rmse=22.427, r2=0.752; v_loss=583.107, v_rmse=24.148, v_r2=0.715; \n",
            "E 41\t: loss=503.087, rmse=22.430, r2=0.752; v_loss=589.620, v_rmse=24.282, v_r2=0.712; \n",
            "E 42\t: loss=508.796, rmse=22.557, r2=0.749; v_loss=613.814, v_rmse=24.775, v_r2=0.700; \n",
            "E 43\t: loss=517.705, rmse=22.753, r2=0.745; v_loss=651.032, v_rmse=25.515, v_r2=0.681; \n",
            "E 44\t: loss=500.282, rmse=22.367, r2=0.754; v_loss=588.084, v_rmse=24.250, v_r2=0.712; \n",
            "E 45\t: loss=497.407, rmse=22.303, r2=0.755; v_loss=633.980, v_rmse=25.179, v_r2=0.690; \n",
            "E 46\t: loss=500.176, rmse=22.365, r2=0.754; v_loss=601.802, v_rmse=24.532, v_r2=0.706; \n",
            "E 47\t: loss=497.776, rmse=22.311, r2=0.755; v_loss=586.657, v_rmse=24.221, v_r2=0.713; \n",
            "E 48\t: loss=501.675, rmse=22.398, r2=0.753; v_loss=602.801, v_rmse=24.552, v_r2=0.705; \n",
            "E 49\t: loss=490.049, rmse=22.137, r2=0.759; v_loss=598.652, v_rmse=24.467, v_r2=0.707; \n",
            "R2=0.756,RMSE=-22.299\n",
            "Finished: 2022-09-16 12:36:47.505725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0daeca02-ab52-4b70-8e21-4db20ad072ef",
        "id": "wnpOvvMW_Czj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.782,RMSE=-19.248\n",
            "Finished: 2022-09-16 12:36:55.847390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Didn't improve by using more features, actually worsened a bit"
      ],
      "metadata": {
        "id": "ce6SCO2n_Czj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-2"
      ],
      "metadata": {
        "id": "ASKtHvQOTfAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "X6_zQ3jWTfAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=1,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df84cf47-2994-4c9d-b250-0704b1e1f072",
        "id": "5f63UagqTfAN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>], model=<function create_model at 0x7f1959d24050>, model__degree=1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b66c0e90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b0476990>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 2),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fcf4dc4-90c9-4e42-8faa-fb43ca2abf3d",
        "id": "LCqeE9pJTfAO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.5, 'mlp__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'mlp__model__learning_rate': 0.01, 'mlp__model__layer_nodes': [512, 32], 'mlp__model__dropout': 0.1, 'mlp__model__activation': 'relu', 'mlp__epochs': 50, 'mlp__batch_size': 64}\n",
            "Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f18ae1c6750>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='relu', model__degree=1, model__dropout=0.1, model__layer_nodes=[512, 32], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18ae08c8d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b164b450>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.5, verbose=0))])\n",
            "Finished: 2022-09-16 12:53:07.103359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.5, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'mlp__model__learning_rate': 0.01, \n",
        "'mlp__model__layer_nodes': [512, 32], \n",
        "'mlp__model__dropout': 0.1, \n",
        "'mlp__model__activation': 'relu', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 64}\n",
        "```"
      ],
      "metadata": {
        "id": "3T-oN8JLTfAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,  \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[512,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=64))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b714860-31e5-4df0-8dc3-7d6191be497e",
        "id": "Pb0zLIA-TfAP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=50, model=<function create_model at 0x7f1959d24050>, model__activation='relu', model__dropout=0.1, model__layer_nodes=[512, 32], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b3319410>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18a727aa90>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.5, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acd88b2-2e0c-4dc0-cbf8-1c20d6cc00e0",
        "id": "6EsuSIyQTfAQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1270\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2794 (Dense)          (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout_1524 (Dropout)      (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2795 (Dense)          (None, 32)                16416     \n",
            "                                                                 \n",
            " dropout_1525 (Dropout)      (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2796 (Dense)          (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,713\n",
            "Trainable params: 27,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=2102.799, rmse=45.856, r2=0.457; v_loss=2749.837, v_rmse=52.439, v_r2=0.504; \n",
            "E 1\t: loss=1151.336, rmse=33.931, r2=0.703; v_loss=2782.477, v_rmse=52.749, v_r2=0.498; \n",
            "E 2\t: loss=1141.589, rmse=33.787, r2=0.705; v_loss=2627.731, v_rmse=51.261, v_r2=0.526; \n",
            "E 3\t: loss=1142.928, rmse=33.807, r2=0.705; v_loss=2701.002, v_rmse=51.971, v_r2=0.513; \n",
            "E 4\t: loss=1127.194, rmse=33.574, r2=0.709; v_loss=2720.698, v_rmse=52.160, v_r2=0.510; \n",
            "E 5\t: loss=1119.392, rmse=33.457, r2=0.711; v_loss=2616.871, v_rmse=51.155, v_r2=0.528; \n",
            "E 6\t: loss=1145.217, rmse=33.841, r2=0.704; v_loss=3645.848, v_rmse=60.381, v_r2=0.343; \n",
            "E 7\t: loss=1135.252, rmse=33.694, r2=0.707; v_loss=2923.479, v_rmse=54.069, v_r2=0.473; \n",
            "E 8\t: loss=1108.568, rmse=33.295, r2=0.714; v_loss=2612.334, v_rmse=51.111, v_r2=0.529; \n",
            "E 9\t: loss=1132.959, rmse=33.659, r2=0.707; v_loss=2520.291, v_rmse=50.202, v_r2=0.546; \n",
            "E 10\t: loss=1100.715, rmse=33.177, r2=0.716; v_loss=2919.625, v_rmse=54.034, v_r2=0.474; \n",
            "E 11\t: loss=1102.283, rmse=33.201, r2=0.715; v_loss=3061.831, v_rmse=55.334, v_r2=0.448; \n",
            "E 12\t: loss=1119.940, rmse=33.465, r2=0.711; v_loss=2585.767, v_rmse=50.850, v_r2=0.534; \n",
            "E 13\t: loss=1116.052, rmse=33.407, r2=0.712; v_loss=2766.168, v_rmse=52.594, v_r2=0.501; \n",
            "E 14\t: loss=1102.024, rmse=33.197, r2=0.715; v_loss=2665.190, v_rmse=51.625, v_r2=0.520; \n",
            "E 15\t: loss=1087.725, rmse=32.981, r2=0.719; v_loss=2655.059, v_rmse=51.527, v_r2=0.521; \n",
            "E 16\t: loss=1108.179, rmse=33.289, r2=0.714; v_loss=3022.894, v_rmse=54.981, v_r2=0.455; \n",
            "E 17\t: loss=1099.959, rmse=33.166, r2=0.716; v_loss=2495.375, v_rmse=49.954, v_r2=0.550; \n",
            "E 18\t: loss=1101.449, rmse=33.188, r2=0.715; v_loss=3007.138, v_rmse=54.837, v_r2=0.458; \n",
            "E 19\t: loss=1105.786, rmse=33.253, r2=0.714; v_loss=3065.247, v_rmse=55.365, v_r2=0.447; \n",
            "E 20\t: loss=1114.297, rmse=33.381, r2=0.712; v_loss=2564.273, v_rmse=50.639, v_r2=0.538; \n",
            "R2=0.623,RMSE=-42.308\n",
            "Finished: 2022-09-16 12:55:10.458874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c0d8f5-e9df-4c3f-9732-516c1657cd55",
        "id": "fWq5Y8EpTfAR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.528,RMSE=-28.550\n",
            "Finished: 2022-09-16 12:55:16.728608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better than one layer, but still bad"
      ],
      "metadata": {
        "id": "hoq9MO1iXksI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-linear RUL"
      ],
      "metadata": {
        "id": "rfYbxWOjTfAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model,verbose=0, callbacks=[es], \n",
        "                                model__degree=1,\n",
        "                                validation_split=0.2, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5c8b33-73f5-4469-f3e0-b2c719dc612f",
        "id": "ngQ3UTu2TfAS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>], model=<function create_model at 0x7f1959d24050>, model__degree=1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18a727a490>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18a727a390>], validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 2),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4bd6d4-5429-4277-d703-05207e94145f",
        "id": "oJwL-efhTfAS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 137}, 'trf_reg__regressor__validation_split': 0.4, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.01, 'trf_reg__regressor__model__layer_nodes': [512, 256], 'trf_reg__regressor__model__dropout': 0.4, 'trf_reg__regressor__model__activation': 'tanh', 'trf_reg__regressor__epochs': 20, 'trf_reg__regressor__batch_size': 256, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=256, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f18a8dc3d50>], epochs=20, model=<function create_model at 0x7f1959d24050>, model__activation='tanh', model__degree=1, model__dropout=0.4, model__layer_nodes=[512, 256...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18a8bc31d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18a8da0d50>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.4, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
            "                                                                            kw_args={'a_max': 137,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-16 13:18:20.724336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 137}, \n",
        "'trf_reg__regressor__validation_split': 0.4, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [512, 256], \n",
        "'trf_reg__regressor__model__dropout': 0.4, \n",
        "'trf_reg__regressor__model__activation': 'tanh', \n",
        "'trf_reg__regressor__epochs': 20, \n",
        "'trf_reg__regressor__batch_size': 256, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "IkAPvAbnTfAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,  \n",
        "                                validation_split=0.4, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[512,256],\n",
        "                                model__dropout=0.4,\n",
        "                                model__activation=\"tanh\",\n",
        "                                epochs=20, \n",
        "                                batch_size=64),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':137})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d18327-decc-461c-8658-c356af589692",
        "id": "9VBV0LqDTfAT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=20, model=<function create_model at 0x7f1959d24050>, model__activation='tanh', model__d...cs=[<keras.metrics.RootMeanSquaredError object at 0x7f18b1baf850>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b1bafbd0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.4, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 137,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fff865c-1ea9-45db-9203-61129b0be80e",
        "id": "y_28cO-aTfAU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1524\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3556 (Dense)          (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout_2032 (Dropout)      (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3557 (Dense)          (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_2033 (Dropout)      (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3558 (Dense)          (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142,849\n",
            "Trainable params: 142,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=942.921, rmse=30.707, r2=0.550; v_loss=574.277, v_rmse=23.964, v_r2=0.727; \n",
            "E 1\t: loss=471.066, rmse=21.704, r2=0.775; v_loss=486.593, v_rmse=22.059, v_r2=0.768; \n",
            "E 2\t: loss=460.946, rmse=21.470, r2=0.780; v_loss=501.828, v_rmse=22.402, v_r2=0.761; \n",
            "E 3\t: loss=456.211, rmse=21.359, r2=0.782; v_loss=512.118, v_rmse=22.630, v_r2=0.756; \n",
            "E 4\t: loss=453.106, rmse=21.286, r2=0.784; v_loss=556.554, v_rmse=23.591, v_r2=0.735; \n",
            "E 5\t: loss=452.393, rmse=21.270, r2=0.784; v_loss=498.456, v_rmse=22.326, v_r2=0.763; \n",
            "E 6\t: loss=442.265, rmse=21.030, r2=0.789; v_loss=501.146, v_rmse=22.386, v_r2=0.761; \n",
            "E 7\t: loss=448.073, rmse=21.168, r2=0.786; v_loss=498.781, v_rmse=22.333, v_r2=0.762; \n",
            "E 8\t: loss=447.514, rmse=21.155, r2=0.786; v_loss=496.347, v_rmse=22.279, v_r2=0.764; \n",
            "E 9\t: loss=445.704, rmse=21.112, r2=0.787; v_loss=520.746, v_rmse=22.820, v_r2=0.752; \n",
            "E 10\t: loss=443.072, rmse=21.049, r2=0.789; v_loss=485.564, v_rmse=22.036, v_r2=0.769; \n",
            "E 11\t: loss=439.639, rmse=20.968, r2=0.790; v_loss=522.185, v_rmse=22.851, v_r2=0.751; \n",
            "E 12\t: loss=442.396, rmse=21.033, r2=0.789; v_loss=503.338, v_rmse=22.435, v_r2=0.760; \n",
            "E 13\t: loss=445.293, rmse=21.102, r2=0.787; v_loss=495.378, v_rmse=22.257, v_r2=0.764; \n",
            "E 14\t: loss=440.265, rmse=20.982, r2=0.790; v_loss=527.823, v_rmse=22.974, v_r2=0.749; \n",
            "E 15\t: loss=435.961, rmse=20.880, r2=0.792; v_loss=502.108, v_rmse=22.408, v_r2=0.761; \n",
            "E 16\t: loss=440.456, rmse=20.987, r2=0.790; v_loss=515.096, v_rmse=22.696, v_r2=0.755; \n",
            "E 17\t: loss=438.666, rmse=20.944, r2=0.791; v_loss=543.501, v_rmse=23.313, v_r2=0.741; \n",
            "E 18\t: loss=427.653, rmse=20.680, r2=0.796; v_loss=545.323, v_rmse=23.352, v_r2=0.740; \n",
            "E 19\t: loss=437.797, rmse=20.924, r2=0.791; v_loss=529.610, v_rmse=23.013, v_r2=0.748; \n",
            "R2=0.790,RMSE=-20.986\n",
            "Finished: 2022-09-16 13:19:46.703923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60dafb7-a695-4cd3-9b76-71895ee41cde",
        "id": "aB-1jdTyTfAU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.793,RMSE=-18.829\n",
            "Finished: 2022-09-16 13:19:49.918665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to 1-layer, but slightly worse"
      ],
      "metadata": {
        "id": "eyTFAWTyTfAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Linear RUL"
      ],
      "metadata": {
        "id": "sFNijKRYTfAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=2,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed8083d-13fc-4e36-b4ff-6663976c371d",
        "id": "bBY8CCvFTfAV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=2, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa530f7a890>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa530f64e90>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~20min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__degree\": [2],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 2),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]    \n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f411442e-92c5-4bfe-aa71-5e13272f9b87",
        "id": "i9Ku1z9UTfAX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa486534680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 40 calls to <function Model.make_train_function.<locals>.train_function at 0x7fa530f28ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa48c3ffa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa48c3ff8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fa48624b830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4865bd710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': MinMaxScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'mlp__model__learning_rate': 0.0001, 'mlp__model__layer_nodes': [256, 64], 'mlp__model__dropout': 0.1, 'mlp__model__degree': 2, 'mlp__model__activation': 'relu', 'mlp__epochs': 50, 'mlp__batch_size': 32}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
            "                ('scaler', MinMaxScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa49d2e77d0>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__degree=2, model__dropout=0.1, model__layer_nodes=[256, 64], model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa49c237f90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa49c237c10>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-16 16:28:00.703761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': MinMaxScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'mlp__model__learning_rate': 0.0001, \n",
        "'mlp__model__layer_nodes': [256, 64], \n",
        "'mlp__model__dropout': 0.1, \n",
        "'mlp__model__degree': 2, \n",
        "'mlp__model__activation': 'relu', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 32}\n",
        "```"
      ],
      "metadata": {
        "id": "1XQwmEnqTfAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'  , MinMaxScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.0001, \n",
        "                                model__layer_nodes=[256,64],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=2,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009e15dc-3d70-427f-bfe9-ad1003d51fd9",
        "id": "-4EDVhZmTfAX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__degree=2, model__dropout=0.1, model__layer_nodes=[256, 64], model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c3ec4d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48655c4d0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4cd38d-ad07-44b6-e078-cfaaa479d6b1",
        "id": "gaqYXKSDTfAY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_253\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_759 (Dense)           (None, 256)               64768     \n",
            "                                                                 \n",
            " dropout_506 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_760 (Dense)           (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_507 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_761 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,281\n",
            "Trainable params: 81,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=8284.538, rmse=91.019, r2=-0.906; v_loss=6221.021, v_rmse=78.873, v_r2=-0.005; \n",
            "E 1\t: loss=2922.514, rmse=54.060, r2=0.328; v_loss=3443.834, v_rmse=58.684, v_r2=0.443; \n",
            "E 2\t: loss=1995.804, rmse=44.674, r2=0.541; v_loss=3080.219, v_rmse=55.500, v_r2=0.502; \n",
            "E 3\t: loss=1899.980, rmse=43.589, r2=0.563; v_loss=3010.358, v_rmse=54.867, v_r2=0.514; \n",
            "E 4\t: loss=1869.363, rmse=43.236, r2=0.570; v_loss=2978.029, v_rmse=54.571, v_r2=0.519; \n",
            "E 5\t: loss=1838.023, rmse=42.872, r2=0.577; v_loss=2941.780, v_rmse=54.238, v_r2=0.525; \n",
            "E 6\t: loss=1812.580, rmse=42.574, r2=0.583; v_loss=2826.316, v_rmse=53.163, v_r2=0.543; \n",
            "E 7\t: loss=1797.847, rmse=42.401, r2=0.586; v_loss=2871.809, v_rmse=53.589, v_r2=0.536; \n",
            "E 8\t: loss=1776.821, rmse=42.152, r2=0.591; v_loss=2859.972, v_rmse=53.479, v_r2=0.538; \n",
            "E 9\t: loss=1765.124, rmse=42.013, r2=0.594; v_loss=2888.550, v_rmse=53.745, v_r2=0.533; \n",
            "E 10\t: loss=1761.266, rmse=41.967, r2=0.595; v_loss=2903.701, v_rmse=53.886, v_r2=0.531; \n",
            "E 11\t: loss=1760.211, rmse=41.955, r2=0.595; v_loss=2784.740, v_rmse=52.771, v_r2=0.550; \n",
            "E 12\t: loss=1744.301, rmse=41.765, r2=0.599; v_loss=2799.768, v_rmse=52.913, v_r2=0.548; \n",
            "E 13\t: loss=1740.650, rmse=41.721, r2=0.600; v_loss=2759.294, v_rmse=52.529, v_r2=0.554; \n",
            "E 14\t: loss=1747.603, rmse=41.804, r2=0.598; v_loss=2787.063, v_rmse=52.793, v_r2=0.550; \n",
            "E 15\t: loss=1743.012, rmse=41.749, r2=0.599; v_loss=2794.093, v_rmse=52.859, v_r2=0.548; \n",
            "E 16\t: loss=1734.686, rmse=41.650, r2=0.601; v_loss=2793.779, v_rmse=52.856, v_r2=0.549; \n",
            "E 17\t: loss=1747.989, rmse=41.809, r2=0.598; v_loss=2770.266, v_rmse=52.633, v_r2=0.552; \n",
            "E 18\t: loss=1730.536, rmse=41.600, r2=0.602; v_loss=2764.785, v_rmse=52.581, v_r2=0.553; \n",
            "E 19\t: loss=1730.020, rmse=41.594, r2=0.602; v_loss=2776.090, v_rmse=52.689, v_r2=0.551; \n",
            "E 20\t: loss=1717.943, rmse=41.448, r2=0.605; v_loss=2740.688, v_rmse=52.352, v_r2=0.557; \n",
            "E 21\t: loss=1705.311, rmse=41.295, r2=0.608; v_loss=2889.294, v_rmse=53.752, v_r2=0.533; \n",
            "E 22\t: loss=1713.635, rmse=41.396, r2=0.606; v_loss=2815.146, v_rmse=53.058, v_r2=0.545; \n",
            "E 23\t: loss=1710.933, rmse=41.363, r2=0.606; v_loss=2819.774, v_rmse=53.102, v_r2=0.544; \n",
            "E 24\t: loss=1706.219, rmse=41.306, r2=0.608; v_loss=2901.539, v_rmse=53.866, v_r2=0.531; \n",
            "E 25\t: loss=1705.452, rmse=41.297, r2=0.608; v_loss=2774.104, v_rmse=52.670, v_r2=0.552; \n",
            "E 26\t: loss=1695.518, rmse=41.177, r2=0.610; v_loss=2736.074, v_rmse=52.307, v_r2=0.558; \n",
            "E 27\t: loss=1690.222, rmse=41.112, r2=0.611; v_loss=2732.450, v_rmse=52.273, v_r2=0.558; \n",
            "E 28\t: loss=1693.997, rmse=41.158, r2=0.610; v_loss=2769.346, v_rmse=52.625, v_r2=0.552; \n",
            "E 29\t: loss=1682.006, rmse=41.012, r2=0.613; v_loss=2700.385, v_rmse=51.965, v_r2=0.564; \n",
            "E 30\t: loss=1698.964, rmse=41.218, r2=0.609; v_loss=2688.895, v_rmse=51.855, v_r2=0.565; \n",
            "E 31\t: loss=1677.632, rmse=40.959, r2=0.614; v_loss=2694.416, v_rmse=51.908, v_r2=0.565; \n",
            "E 32\t: loss=1687.435, rmse=41.078, r2=0.612; v_loss=2712.890, v_rmse=52.085, v_r2=0.562; \n",
            "E 33\t: loss=1678.358, rmse=40.968, r2=0.614; v_loss=2826.073, v_rmse=53.161, v_r2=0.543; \n",
            "E 34\t: loss=1670.402, rmse=40.871, r2=0.616; v_loss=2781.956, v_rmse=52.744, v_r2=0.550; \n",
            "E 35\t: loss=1677.739, rmse=40.960, r2=0.614; v_loss=2750.590, v_rmse=52.446, v_r2=0.555; \n",
            "E 36\t: loss=1675.361, rmse=40.931, r2=0.615; v_loss=2733.765, v_rmse=52.285, v_r2=0.558; \n",
            "E 37\t: loss=1655.303, rmse=40.685, r2=0.619; v_loss=2834.786, v_rmse=53.243, v_r2=0.542; \n",
            "E 38\t: loss=1664.735, rmse=40.801, r2=0.617; v_loss=2664.461, v_rmse=51.618, v_r2=0.569; \n",
            "E 39\t: loss=1660.944, rmse=40.755, r2=0.618; v_loss=2621.471, v_rmse=51.200, v_r2=0.576; \n",
            "E 40\t: loss=1669.776, rmse=40.863, r2=0.616; v_loss=2751.449, v_rmse=52.454, v_r2=0.555; \n",
            "E 41\t: loss=1641.793, rmse=40.519, r2=0.622; v_loss=2644.064, v_rmse=51.420, v_r2=0.573; \n",
            "E 42\t: loss=1659.131, rmse=40.732, r2=0.618; v_loss=2611.548, v_rmse=51.103, v_r2=0.578; \n",
            "E 43\t: loss=1654.826, rmse=40.680, r2=0.619; v_loss=2706.818, v_rmse=52.027, v_r2=0.563; \n",
            "E 44\t: loss=1643.248, rmse=40.537, r2=0.622; v_loss=2781.475, v_rmse=52.740, v_r2=0.551; \n",
            "E 45\t: loss=1650.818, rmse=40.630, r2=0.620; v_loss=2699.939, v_rmse=51.961, v_r2=0.564; \n",
            "E 46\t: loss=1649.748, rmse=40.617, r2=0.620; v_loss=2668.080, v_rmse=51.653, v_r2=0.569; \n",
            "R2=0.624,RMSE=-42.237\n",
            "Finished: 2022-09-16 16:31:59.393568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaac89cb-e3ee-4676-e60f-904b4561a217",
        "id": "2AQcrJwwTfAY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.419,RMSE=-31.683\n",
            "Finished: 2022-09-16 16:31:59.488230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bad generalization using 2 degree polynomial and more layers. The overall result is slightly better than one layer only"
      ],
      "metadata": {
        "id": "Pc1iy2FZTfAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "iEVKcC76TfAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=2,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a01e024-a30f-47cd-a686-b8417c7819be",
        "id": "5hAl0IZdTfAZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=2, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48b030150>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa4865ebbd0>], verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~25min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__model__degree\": [2],\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 2),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0ae6f0-7c28-4ab4-dd56-5976d1077ee2",
        "id": "44dpLAoaTfAZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119}, 'trf_reg__regressor__validation_split': 0.1, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [128, 32], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__degree': 2, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 50, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa48edc43d0>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__degre...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa4866c0390>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48c4cd050>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.1, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
            "                                                                            kw_args={'a_max': 119,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-16 16:57:02.898310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119}, \n",
        "'trf_reg__regressor__validation_split': 0.1, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.001, \n",
        "'trf_reg__regressor__model__layer_nodes': [128, 32], \n",
        "'trf_reg__regressor__model__dropout': 0.1, \n",
        "'trf_reg__regressor__model__degree': 2, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "j2iUNjKaTfAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2,include_bias=False)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback], \n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[128,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=2,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':119})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144671ca-f738-4e5b-cb69-e198fdf08b93",
        "id": "fd29f_a_TfAZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=50, model=<function create_model...cs=[<keras.metrics.RootMeanSquaredError object at 0x7fa48cd1e690>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48cd1edd0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.1, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 119,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffacb682-4f10-4dce-bfd4-2fb2faecd2d8",
        "id": "2uGJ5HRKTfAa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_507\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1521 (Dense)          (None, 128)               32384     \n",
            "                                                                 \n",
            " dropout_1014 (Dropout)      (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1522 (Dense)          (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_1015 (Dropout)      (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1523 (Dense)          (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,545\n",
            "Trainable params: 36,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1413.037, rmse=37.590, r2=0.096; v_loss=488.686, v_rmse=22.106, v_r2=0.677; \n",
            "E 1\t: loss=483.385, rmse=21.986, r2=0.691; v_loss=398.733, v_rmse=19.968, v_r2=0.736; \n",
            "E 2\t: loss=422.136, rmse=20.546, r2=0.730; v_loss=362.305, v_rmse=19.034, v_r2=0.760; \n",
            "E 3\t: loss=398.772, rmse=19.969, r2=0.745; v_loss=316.355, v_rmse=17.786, v_r2=0.791; \n",
            "E 4\t: loss=394.120, rmse=19.852, r2=0.748; v_loss=353.858, v_rmse=18.811, v_r2=0.766; \n",
            "E 5\t: loss=390.026, rmse=19.749, r2=0.751; v_loss=458.276, v_rmse=21.407, v_r2=0.697; \n",
            "E 6\t: loss=381.493, rmse=19.532, r2=0.756; v_loss=304.791, v_rmse=17.458, v_r2=0.798; \n",
            "E 7\t: loss=381.658, rmse=19.536, r2=0.756; v_loss=356.421, v_rmse=18.879, v_r2=0.764; \n",
            "E 8\t: loss=380.057, rmse=19.495, r2=0.757; v_loss=317.875, v_rmse=17.829, v_r2=0.790; \n",
            "E 9\t: loss=377.267, rmse=19.423, r2=0.759; v_loss=335.368, v_rmse=18.313, v_r2=0.778; \n",
            "E 10\t: loss=372.255, rmse=19.294, r2=0.762; v_loss=342.379, v_rmse=18.503, v_r2=0.773; \n",
            "E 11\t: loss=367.879, rmse=19.180, r2=0.765; v_loss=361.548, v_rmse=19.014, v_r2=0.761; \n",
            "E 12\t: loss=370.256, rmse=19.242, r2=0.763; v_loss=525.009, v_rmse=22.913, v_r2=0.653; \n",
            "E 13\t: loss=366.512, rmse=19.145, r2=0.766; v_loss=387.907, v_rmse=19.695, v_r2=0.743; \n",
            "E 14\t: loss=371.211, rmse=19.267, r2=0.763; v_loss=306.926, v_rmse=17.519, v_r2=0.797; \n",
            "E 15\t: loss=363.333, rmse=19.061, r2=0.768; v_loss=433.929, v_rmse=20.831, v_r2=0.713; \n",
            "E 16\t: loss=358.710, rmse=18.940, r2=0.771; v_loss=343.936, v_rmse=18.546, v_r2=0.772; \n",
            "E 17\t: loss=360.813, rmse=18.995, r2=0.769; v_loss=329.736, v_rmse=18.159, v_r2=0.782; \n",
            "E 18\t: loss=359.650, rmse=18.964, r2=0.770; v_loss=375.120, v_rmse=19.368, v_r2=0.752; \n",
            "E 19\t: loss=359.865, rmse=18.970, r2=0.770; v_loss=315.998, v_rmse=17.776, v_r2=0.791; \n",
            "E 20\t: loss=357.537, rmse=18.909, r2=0.771; v_loss=341.496, v_rmse=18.480, v_r2=0.774; \n",
            "E 21\t: loss=354.616, rmse=18.831, r2=0.773; v_loss=313.833, v_rmse=17.715, v_r2=0.792; \n",
            "E 22\t: loss=357.798, rmse=18.916, r2=0.771; v_loss=343.085, v_rmse=18.523, v_r2=0.773; \n",
            "E 23\t: loss=356.684, rmse=18.886, r2=0.772; v_loss=340.391, v_rmse=18.450, v_r2=0.775; \n",
            "E 24\t: loss=354.550, rmse=18.830, r2=0.773; v_loss=324.842, v_rmse=18.023, v_r2=0.785; \n",
            "E 25\t: loss=354.716, rmse=18.834, r2=0.773; v_loss=359.324, v_rmse=18.956, v_r2=0.762; \n",
            "E 26\t: loss=354.873, rmse=18.838, r2=0.773; v_loss=356.942, v_rmse=18.893, v_r2=0.764; \n",
            "E 27\t: loss=351.766, rmse=18.755, r2=0.775; v_loss=390.598, v_rmse=19.764, v_r2=0.741; \n",
            "E 28\t: loss=353.011, rmse=18.789, r2=0.774; v_loss=322.692, v_rmse=17.964, v_r2=0.786; \n",
            "E 29\t: loss=351.880, rmse=18.758, r2=0.775; v_loss=348.680, v_rmse=18.673, v_r2=0.769; \n",
            "E 30\t: loss=353.421, rmse=18.800, r2=0.774; v_loss=319.007, v_rmse=17.861, v_r2=0.789; \n",
            "E 31\t: loss=350.007, rmse=18.708, r2=0.776; v_loss=431.445, v_rmse=20.771, v_r2=0.714; \n",
            "E 32\t: loss=349.257, rmse=18.688, r2=0.777; v_loss=316.692, v_rmse=17.796, v_r2=0.790; \n",
            "E 33\t: loss=346.735, rmse=18.621, r2=0.778; v_loss=320.979, v_rmse=17.916, v_r2=0.788; \n",
            "E 34\t: loss=348.312, rmse=18.663, r2=0.777; v_loss=319.520, v_rmse=17.875, v_r2=0.789; \n",
            "E 35\t: loss=345.355, rmse=18.584, r2=0.779; v_loss=321.771, v_rmse=17.938, v_r2=0.787; \n",
            "E 36\t: loss=347.302, rmse=18.636, r2=0.778; v_loss=306.096, v_rmse=17.496, v_r2=0.797; \n",
            "E 37\t: loss=349.908, rmse=18.706, r2=0.776; v_loss=318.165, v_rmse=17.837, v_r2=0.789; \n",
            "E 38\t: loss=348.202, rmse=18.660, r2=0.777; v_loss=341.507, v_rmse=18.480, v_r2=0.774; \n",
            "E 39\t: loss=348.679, rmse=18.673, r2=0.777; v_loss=310.809, v_rmse=17.630, v_r2=0.794; \n",
            "E 40\t: loss=345.573, rmse=18.590, r2=0.779; v_loss=300.181, v_rmse=17.326, v_r2=0.801; \n",
            "R2=0.813,RMSE=-17.093\n",
            "Finished: 2022-09-16 16:59:41.281030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb40a46-a956-4e92-8556-df0115a6fa21",
        "id": "OhusKvrITfAa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.840,RMSE=-15.687\n",
            "Finished: 2022-09-16 17:00:08.047966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best result so far"
      ],
      "metadata": {
        "id": "JsaIzYXZTfAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Linear RUL"
      ],
      "metadata": {
        "id": "Wq35b3zETfAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=3,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bb6fbd-8857-4518-e390-91597be7f875",
        "id": "EqXo-fQFTfAb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=3, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c38d290>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48c38de50>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~25min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__degree\": [3],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 2),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]    \n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740dc8ad-fbd4-4d48-e9f6-ef2909fdc88e",
        "id": "FG4-jHxyTfAb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': MinMaxScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'mlp__model__learning_rate': 0.0001, 'mlp__model__layer_nodes': [256, 64], 'mlp__model__dropout': 0.1, 'mlp__model__degree': 3, 'mlp__model__activation': 'relu', 'mlp__epochs': 50, 'mlp__batch_size': 32}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
            "                ('scaler', MinMaxScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa48df59450>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__degree=3, model__dropout=0.1, model__layer_nodes=[256, 64], model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48ca910d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa486465610>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-16 17:22:47.138300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': MinMaxScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'mlp__model__learning_rate': 0.0001, \n",
        "'mlp__model__layer_nodes': [256, 64], \n",
        "'mlp__model__dropout': 0.1, \n",
        "'mlp__model__degree': 3, \n",
        "'mlp__model__activation': 'relu', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 32}\n",
        "```"
      ],
      "metadata": {
        "id": "Em0ufItUTfAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.0001, \n",
        "                                model__layer_nodes=[256,64],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=3,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50260f4-71ae-4c64-bb1e-febcac9b04d0",
        "id": "WMslJCNsTfAc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__de...el__dropout=0.1, model__layer_nodes=[256, 64], model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa49d378810>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48e3923d0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9551c3d8-ee72-4651-d283-acdb084ad036",
        "id": "dVqfqSU6TfAc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_761\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2283 (Dense)          (None, 256)               518144    \n",
            "                                                                 \n",
            " dropout_1522 (Dropout)      (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2284 (Dense)          (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_1523 (Dropout)      (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2285 (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,657\n",
            "Trainable params: 534,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=4928.556, rmse=70.204, r2=-0.134; v_loss=4148.228, v_rmse=64.407, v_r2=0.330; \n",
            "E 1\t: loss=2718.525, rmse=52.139, r2=0.375; v_loss=3459.529, v_rmse=58.818, v_r2=0.441; \n",
            "E 2\t: loss=2237.423, rmse=47.301, r2=0.485; v_loss=3121.430, v_rmse=55.870, v_r2=0.496; \n",
            "E 3\t: loss=2078.780, rmse=45.594, r2=0.522; v_loss=3128.920, v_rmse=55.937, v_r2=0.494; \n",
            "E 4\t: loss=1990.499, rmse=44.615, r2=0.542; v_loss=2975.279, v_rmse=54.546, v_r2=0.519; \n",
            "E 5\t: loss=1937.999, rmse=44.023, r2=0.554; v_loss=3056.378, v_rmse=55.285, v_r2=0.506; \n",
            "E 6\t: loss=1877.659, rmse=43.332, r2=0.568; v_loss=2911.718, v_rmse=53.960, v_r2=0.529; \n",
            "E 7\t: loss=1829.676, rmse=42.775, r2=0.579; v_loss=2932.719, v_rmse=54.155, v_r2=0.526; \n",
            "E 8\t: loss=1807.201, rmse=42.511, r2=0.584; v_loss=2834.582, v_rmse=53.241, v_r2=0.542; \n",
            "E 9\t: loss=1761.010, rmse=41.964, r2=0.595; v_loss=2938.211, v_rmse=54.205, v_r2=0.525; \n",
            "E 10\t: loss=1731.749, rmse=41.614, r2=0.602; v_loss=2869.977, v_rmse=53.572, v_r2=0.536; \n",
            "E 11\t: loss=1706.645, rmse=41.312, r2=0.607; v_loss=2676.836, v_rmse=51.738, v_r2=0.567; \n",
            "E 12\t: loss=1684.088, rmse=41.038, r2=0.613; v_loss=2720.652, v_rmse=52.160, v_r2=0.560; \n",
            "E 13\t: loss=1654.192, rmse=40.672, r2=0.619; v_loss=2659.324, v_rmse=51.569, v_r2=0.570; \n",
            "E 14\t: loss=1644.000, rmse=40.546, r2=0.622; v_loss=2715.875, v_rmse=52.114, v_r2=0.561; \n",
            "E 15\t: loss=1622.258, rmse=40.277, r2=0.627; v_loss=2757.119, v_rmse=52.508, v_r2=0.554; \n",
            "E 16\t: loss=1615.605, rmse=40.195, r2=0.628; v_loss=2731.413, v_rmse=52.263, v_r2=0.559; \n",
            "E 17\t: loss=1609.389, rmse=40.117, r2=0.630; v_loss=2766.564, v_rmse=52.598, v_r2=0.553; \n",
            "E 18\t: loss=1591.286, rmse=39.891, r2=0.634; v_loss=2674.965, v_rmse=51.720, v_r2=0.568; \n",
            "E 19\t: loss=1578.673, rmse=39.733, r2=0.637; v_loss=2695.037, v_rmse=51.914, v_r2=0.564; \n",
            "E 20\t: loss=1569.241, rmse=39.614, r2=0.639; v_loss=2735.781, v_rmse=52.305, v_r2=0.558; \n",
            "E 21\t: loss=1570.865, rmse=39.634, r2=0.639; v_loss=3046.629, v_rmse=55.196, v_r2=0.508; \n",
            "E 22\t: loss=1558.399, rmse=39.477, r2=0.642; v_loss=2844.517, v_rmse=53.334, v_r2=0.540; \n",
            "E 23\t: loss=1559.893, rmse=39.495, r2=0.641; v_loss=2881.123, v_rmse=53.676, v_r2=0.534; \n",
            "E 24\t: loss=1557.008, rmse=39.459, r2=0.642; v_loss=2813.964, v_rmse=53.047, v_r2=0.545; \n",
            "E 25\t: loss=1550.936, rmse=39.382, r2=0.643; v_loss=2833.620, v_rmse=53.232, v_r2=0.542; \n",
            "E 26\t: loss=1547.909, rmse=39.343, r2=0.644; v_loss=2647.356, v_rmse=51.452, v_r2=0.572; \n",
            "E 27\t: loss=1542.464, rmse=39.274, r2=0.645; v_loss=2596.769, v_rmse=50.958, v_r2=0.580; \n",
            "E 28\t: loss=1555.529, rmse=39.440, r2=0.642; v_loss=2578.409, v_rmse=50.778, v_r2=0.583; \n",
            "E 29\t: loss=1539.378, rmse=39.235, r2=0.646; v_loss=2666.530, v_rmse=51.638, v_r2=0.569; \n",
            "E 30\t: loss=1547.117, rmse=39.333, r2=0.644; v_loss=2616.678, v_rmse=51.153, v_r2=0.577; \n",
            "E 31\t: loss=1542.292, rmse=39.272, r2=0.645; v_loss=2768.759, v_rmse=52.619, v_r2=0.553; \n",
            "E 32\t: loss=1542.380, rmse=39.273, r2=0.645; v_loss=2677.756, v_rmse=51.747, v_r2=0.567; \n",
            "E 33\t: loss=1541.157, rmse=39.258, r2=0.645; v_loss=2890.392, v_rmse=53.762, v_r2=0.533; \n",
            "E 34\t: loss=1524.625, rmse=39.046, r2=0.649; v_loss=2752.729, v_rmse=52.466, v_r2=0.555; \n",
            "E 35\t: loss=1535.914, rmse=39.191, r2=0.647; v_loss=2726.136, v_rmse=52.212, v_r2=0.559; \n",
            "E 36\t: loss=1541.916, rmse=39.267, r2=0.645; v_loss=2816.538, v_rmse=53.071, v_r2=0.545; \n",
            "E 37\t: loss=1531.086, rmse=39.129, r2=0.648; v_loss=2987.383, v_rmse=54.657, v_r2=0.517; \n",
            "E 38\t: loss=1521.049, rmse=39.001, r2=0.650; v_loss=2660.125, v_rmse=51.576, v_r2=0.570; \n",
            "E 39\t: loss=1524.318, rmse=39.043, r2=0.649; v_loss=2657.026, v_rmse=51.546, v_r2=0.571; \n",
            "E 40\t: loss=1536.856, rmse=39.203, r2=0.646; v_loss=2605.555, v_rmse=51.045, v_r2=0.579; \n",
            "E 41\t: loss=1516.965, rmse=38.948, r2=0.651; v_loss=2566.632, v_rmse=50.662, v_r2=0.585; \n",
            "E 42\t: loss=1526.243, rmse=39.067, r2=0.649; v_loss=2747.607, v_rmse=52.418, v_r2=0.556; \n",
            "E 43\t: loss=1524.641, rmse=39.047, r2=0.649; v_loss=2757.548, v_rmse=52.512, v_r2=0.554; \n",
            "E 44\t: loss=1522.812, rmse=39.023, r2=0.650; v_loss=2832.498, v_rmse=53.221, v_r2=0.542; \n",
            "E 45\t: loss=1517.299, rmse=38.953, r2=0.651; v_loss=2670.944, v_rmse=51.681, v_r2=0.568; \n",
            "E 46\t: loss=1515.401, rmse=38.928, r2=0.651; v_loss=2573.658, v_rmse=50.731, v_r2=0.584; \n",
            "E 47\t: loss=1519.002, rmse=38.974, r2=0.651; v_loss=2908.661, v_rmse=53.932, v_r2=0.530; \n",
            "E 48\t: loss=1515.776, rmse=38.933, r2=0.651; v_loss=2793.946, v_rmse=52.858, v_r2=0.548; \n",
            "E 49\t: loss=1537.837, rmse=39.215, r2=0.646; v_loss=2797.096, v_rmse=52.888, v_r2=0.548; \n",
            "R2=0.643,RMSE=-41.157\n",
            "Finished: 2022-09-16 17:30:53.017436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c0737a-abf8-4143-deda-3e989a2be024",
        "id": "wZMSv8bDTfAd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.551,RMSE=-27.830\n",
            "Finished: 2022-09-16 17:31:09.294675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar architecture to the Linear 1-layer and Linear 1-poly 1-layer. Better than 2-degree (like in MLP-1) "
      ],
      "metadata": {
        "id": "ah7YjnBDTfAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "L545rFPDTfAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=3,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3652507-8a4d-41ce-c394-a24976d33098",
        "id": "IyyuMtZGTfAe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=3, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c9bd6d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa49c272090>], verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~30min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__model__degree\": [3],\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 2),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b475cf77-340f-4cca-838a-a1a82c14e4ee",
        "id": "7ShexFbWTfAf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119}, 'trf_reg__regressor__validation_split': 0.1, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [128, 32], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__degree': 3, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 50, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa486644f90>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', mod...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa486145790>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48f5ed110>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.1, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
            "                                                                            kw_args={'a_max': 119,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-16 18:00:36.578513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119}, \n",
        "'trf_reg__regressor__validation_split': 0.1, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.001, \n",
        "'trf_reg__regressor__model__layer_nodes': [128, 32], \n",
        "'trf_reg__regressor__model__dropout': 0.1, \n",
        "'trf_reg__regressor__model__degree': 3, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "rAdL1xqVTfAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3,include_bias=False)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback], \n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[128,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=3,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':119})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857470b7-0ebf-4f45-823e-f784dd20c1e4",
        "id": "gSdqA3pSTfAg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=50, model=<function cre...cs=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c754950>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48b232c10>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.1, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 119,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5dcbe7e-2903-44f1-b86d-737752aaf426",
        "id": "77Qqfz_iTfAh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1015\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3045 (Dense)          (None, 128)               259072    \n",
            "                                                                 \n",
            " dropout_2030 (Dropout)      (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3046 (Dense)          (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_2031 (Dropout)      (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3047 (Dense)          (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 263,233\n",
            "Trainable params: 263,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1069.400, rmse=32.702, r2=0.316; v_loss=596.888, v_rmse=24.431, v_r2=0.605; \n",
            "E 1\t: loss=610.972, rmse=24.718, r2=0.609; v_loss=816.812, v_rmse=28.580, v_r2=0.459; \n",
            "E 2\t: loss=512.447, rmse=22.637, r2=0.672; v_loss=516.061, v_rmse=22.717, v_r2=0.658; \n",
            "E 3\t: loss=471.222, rmse=21.708, r2=0.699; v_loss=363.970, v_rmse=19.078, v_r2=0.759; \n",
            "E 4\t: loss=448.736, rmse=21.183, r2=0.713; v_loss=348.443, v_rmse=18.667, v_r2=0.769; \n",
            "E 5\t: loss=439.847, rmse=20.973, r2=0.719; v_loss=382.838, v_rmse=19.566, v_r2=0.747; \n",
            "E 6\t: loss=432.167, rmse=20.789, r2=0.724; v_loss=332.072, v_rmse=18.223, v_r2=0.780; \n",
            "E 7\t: loss=421.281, rmse=20.525, r2=0.731; v_loss=436.790, v_rmse=20.900, v_r2=0.711; \n",
            "E 8\t: loss=418.292, rmse=20.452, r2=0.732; v_loss=360.468, v_rmse=18.986, v_r2=0.761; \n",
            "E 9\t: loss=407.903, rmse=20.197, r2=0.739; v_loss=318.212, v_rmse=17.839, v_r2=0.789; \n",
            "E 10\t: loss=407.358, rmse=20.183, r2=0.739; v_loss=332.178, v_rmse=18.226, v_r2=0.780; \n",
            "E 11\t: loss=394.423, rmse=19.860, r2=0.748; v_loss=345.400, v_rmse=18.585, v_r2=0.771; \n",
            "E 12\t: loss=393.433, rmse=19.835, r2=0.748; v_loss=778.737, v_rmse=27.906, v_r2=0.485; \n",
            "E 13\t: loss=392.650, rmse=19.815, r2=0.749; v_loss=674.409, v_rmse=25.969, v_r2=0.554; \n",
            "E 14\t: loss=391.702, rmse=19.791, r2=0.749; v_loss=332.028, v_rmse=18.222, v_r2=0.780; \n",
            "E 15\t: loss=385.186, rmse=19.626, r2=0.754; v_loss=343.909, v_rmse=18.545, v_r2=0.772; \n",
            "E 16\t: loss=383.013, rmse=19.571, r2=0.755; v_loss=374.458, v_rmse=19.351, v_r2=0.752; \n",
            "E 17\t: loss=383.752, rmse=19.590, r2=0.755; v_loss=326.726, v_rmse=18.076, v_r2=0.784; \n",
            "E 18\t: loss=380.171, rmse=19.498, r2=0.757; v_loss=357.239, v_rmse=18.901, v_r2=0.764; \n",
            "E 19\t: loss=376.329, rmse=19.399, r2=0.759; v_loss=409.267, v_rmse=20.230, v_r2=0.729; \n",
            "E 20\t: loss=374.123, rmse=19.342, r2=0.761; v_loss=375.363, v_rmse=19.374, v_r2=0.752; \n",
            "E 21\t: loss=372.599, rmse=19.303, r2=0.762; v_loss=338.178, v_rmse=18.390, v_r2=0.776; \n",
            "E 22\t: loss=378.248, rmse=19.449, r2=0.758; v_loss=461.261, v_rmse=21.477, v_r2=0.695; \n",
            "E 23\t: loss=374.869, rmse=19.362, r2=0.760; v_loss=421.292, v_rmse=20.525, v_r2=0.721; \n",
            "E 24\t: loss=368.372, rmse=19.193, r2=0.764; v_loss=312.732, v_rmse=17.684, v_r2=0.793; \n",
            "E 25\t: loss=369.603, rmse=19.225, r2=0.764; v_loss=336.011, v_rmse=18.331, v_r2=0.778; \n",
            "E 26\t: loss=368.656, rmse=19.200, r2=0.764; v_loss=385.962, v_rmse=19.646, v_r2=0.745; \n",
            "E 27\t: loss=368.500, rmse=19.196, r2=0.764; v_loss=493.997, v_rmse=22.226, v_r2=0.673; \n",
            "E 28\t: loss=368.977, rmse=19.209, r2=0.764; v_loss=316.281, v_rmse=17.784, v_r2=0.791; \n",
            "E 29\t: loss=363.013, rmse=19.053, r2=0.768; v_loss=366.682, v_rmse=19.149, v_r2=0.757; \n",
            "E 30\t: loss=366.170, rmse=19.136, r2=0.766; v_loss=314.000, v_rmse=17.720, v_r2=0.792; \n",
            "E 31\t: loss=358.608, rmse=18.937, r2=0.771; v_loss=554.407, v_rmse=23.546, v_r2=0.633; \n",
            "E 32\t: loss=361.089, rmse=19.002, r2=0.769; v_loss=372.492, v_rmse=19.300, v_r2=0.753; \n",
            "E 33\t: loss=355.737, rmse=18.861, r2=0.772; v_loss=338.443, v_rmse=18.397, v_r2=0.776; \n",
            "E 34\t: loss=360.616, rmse=18.990, r2=0.769; v_loss=317.130, v_rmse=17.808, v_r2=0.790; \n",
            "E 35\t: loss=359.083, rmse=18.949, r2=0.770; v_loss=336.655, v_rmse=18.348, v_r2=0.777; \n",
            "E 36\t: loss=358.984, rmse=18.947, r2=0.770; v_loss=321.567, v_rmse=17.932, v_r2=0.787; \n",
            "E 37\t: loss=358.075, rmse=18.923, r2=0.771; v_loss=337.024, v_rmse=18.358, v_r2=0.777; \n",
            "E 38\t: loss=356.395, rmse=18.878, r2=0.772; v_loss=369.177, v_rmse=19.214, v_r2=0.756; \n",
            "R2=0.807,RMSE=-17.334\n",
            "Finished: 2022-09-16 18:05:05.469834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777ddb97-a702-4e45-e910-b3f91dd491eb",
        "id": "0sdfpqfqTfAh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.840,RMSE=-15.697\n",
            "Finished: 2022-09-16 18:05:09.679005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best result from 1 and 2 layers"
      ],
      "metadata": {
        "id": "9JaRLPi0TfAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-3"
      ],
      "metadata": {
        "id": "8zklqLZcYu_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "B5-iHqvoYu_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=1,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa277ee4-bea3-4929-e5bb-b1d33fdabf64",
        "id": "M7b9omyhYu_V"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48a8d4410>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48a8d46d0>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 3),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b46c05-fe0f-4379-f4c3-7e235d6c94e1",
        "id": "v3-MHcdlYu_W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'mlp__model__learning_rate': 0.01, 'mlp__model__layer_nodes': [64, 128, 256], 'mlp__model__dropout': 0.4, 'mlp__model__activation': 'tanh', 'mlp__epochs': 10, 'mlp__batch_size': 32}\n",
            "Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa488d90a50>], epochs=10, model=<function create_model at 0x7fa530f75e60>, model__activation='tanh', model__degree=1, model__dropout=0.4, model__layer_nodes=[64, 128, 256], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48ceb4190>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa4889c3150>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-16 18:23:17.325693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'mlp__model__learning_rate': 0.01, \n",
        "'mlp__model__layer_nodes': [64, 128, 256], \n",
        "'mlp__model__dropout': 0.4, \n",
        "'mlp__model__activation': 'tanh', \n",
        "'mlp__epochs': 10,\n",
        "'mlp__batch_size': 32}\n",
        "```"
      ],
      "metadata": {
        "id": "KgvZfj8sYu_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,  \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[64,128,256],\n",
        "                                model__dropout=0.4,\n",
        "                                model__activation=\"tanh\",\n",
        "                                epochs=10, \n",
        "                                batch_size=32))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4add8f2-d3f7-459f-e8ac-b2fe1864efe1",
        "id": "euUxsGazYu_X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=10, model=<function create_model at 0x7fa530f75e60>, model__activation='tanh', model__dropout=0.4, model__layer_nodes=[64, 128, 256], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa49d2d4d10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48aca6210>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe3fb45-734a-4ef0-b58e-8d6fc8568f59",
        "id": "3aFA_cdCYu_Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1775\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6084 (Dense)          (None, 64)                1408      \n",
            "                                                                 \n",
            " dropout_4309 (Dropout)      (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6085 (Dense)          (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_4310 (Dropout)      (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6086 (Dense)          (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_4311 (Dropout)      (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6087 (Dense)          (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,009\n",
            "Trainable params: 43,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=2317.994, rmse=48.146, r2=0.467; v_loss=2718.120, v_rmse=52.136, v_r2=0.561; \n",
            "E 1\t: loss=1710.940, rmse=41.364, r2=0.606; v_loss=2695.191, v_rmse=51.915, v_r2=0.564; \n",
            "E 2\t: loss=1690.843, rmse=41.120, r2=0.611; v_loss=2614.068, v_rmse=51.128, v_r2=0.578; \n",
            "E 3\t: loss=1668.707, rmse=40.850, r2=0.616; v_loss=2696.457, v_rmse=51.927, v_r2=0.564; \n",
            "E 4\t: loss=1678.878, rmse=40.974, r2=0.614; v_loss=2703.528, v_rmse=51.995, v_r2=0.563; \n",
            "E 5\t: loss=1670.719, rmse=40.874, r2=0.616; v_loss=2636.413, v_rmse=51.346, v_r2=0.574; \n",
            "E 6\t: loss=1676.676, rmse=40.947, r2=0.614; v_loss=2579.591, v_rmse=50.790, v_r2=0.583; \n",
            "E 7\t: loss=1667.500, rmse=40.835, r2=0.616; v_loss=2767.240, v_rmse=52.605, v_r2=0.553; \n",
            "E 8\t: loss=1662.858, rmse=40.778, r2=0.617; v_loss=2723.575, v_rmse=52.188, v_r2=0.560; \n",
            "E 9\t: loss=1674.563, rmse=40.921, r2=0.615; v_loss=2678.597, v_rmse=51.755, v_r2=0.567; \n",
            "R2=0.631,RMSE=-41.866\n",
            "Finished: 2022-09-16 19:26:20.335015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b5a7ff-749b-4779-a4d1-e94bc8d47bcc",
        "id": "a05dcl3UYu_Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.467,RMSE=-30.332\n",
            "Finished: 2022-09-16 19:26:20.413887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As bad as one layer."
      ],
      "metadata": {
        "id": "89GmbuoKYu_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-linear RUL"
      ],
      "metadata": {
        "id": "tFo3anUVYu_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model,verbose=0, callbacks=[es], \n",
        "                                model__degree=1,\n",
        "                                validation_split=0.2, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f87b54-24ca-4d6c-b968-d1b963298300",
        "id": "MFXAFzg5Yu_b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48a8c5390>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48a8c5250>], validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 3),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b7673e-1f43-4476-c921-426f93ae00fe",
        "id": "kpQDj71oYu_b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 143}, 'trf_reg__regressor__validation_split': 0.5, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.01, 'trf_reg__regressor__model__layer_nodes': [64, 128, 32], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__activation': 'tanh', 'trf_reg__regressor__epochs': 30, 'trf_reg__regressor__batch_size': 64, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa488bc6e50>], epochs=30, model=<function create_model at 0x7fa530f75e60>, model__activation='tanh', model__degree=1, model__dropout=0.1, model__layer_nodes=[64, 128, 3...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa481e43d10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa4860bc2d0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.5, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
            "                                                                            kw_args={'a_max': 143,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-16 18:41:15.587800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 143},\n",
        "'trf_reg__regressor__validation_split': 0.5, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [64, 128, 32], \n",
        "'trf_reg__regressor__model__dropout': 0.1, \n",
        "'trf_reg__regressor__model__activation': 'tanh', \n",
        "'trf_reg__regressor__epochs': 30, \n",
        "'trf_reg__regressor__batch_size': 64, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "a6SRCCymYu_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,  \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[64,128,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__activation=\"tanh\",\n",
        "                                epochs=30, \n",
        "                                batch_size=64),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':143})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8f40f7-80e6-4982-eea4-413e89c91109",
        "id": "b0Z9l462Yu_c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=30, model=<function create_model at 0x7fa530f75e60>, model__activation='tanh', model__d...cs=[<keras.metrics.RootMeanSquaredError object at 0x7fa4862c6b50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa488d28d50>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.5, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 143,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17aa3e3-5433-4594-d9e2-1fa55295ee01",
        "id": "v8uKaeY9Yu_d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1776\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6088 (Dense)          (None, 64)                1408      \n",
            "                                                                 \n",
            " dropout_4312 (Dropout)      (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6089 (Dense)          (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_4313 (Dropout)      (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6090 (Dense)          (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_4314 (Dropout)      (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6091 (Dense)          (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,889\n",
            "Trainable params: 13,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=5548.609, rmse=74.489, r2=-1.450; v_loss=3158.894, v_rmse=56.204, v_r2=-0.374; \n",
            "E 1\t: loss=1495.012, rmse=38.665, r2=0.340; v_loss=831.255, v_rmse=28.832, v_r2=0.638; \n",
            "E 2\t: loss=549.427, rmse=23.440, r2=0.757; v_loss=608.781, v_rmse=24.673, v_r2=0.735; \n",
            "E 3\t: loss=507.855, rmse=22.536, r2=0.776; v_loss=654.985, v_rmse=25.593, v_r2=0.715; \n",
            "E 4\t: loss=499.140, rmse=22.341, r2=0.780; v_loss=645.418, v_rmse=25.405, v_r2=0.719; \n",
            "E 5\t: loss=502.628, rmse=22.419, r2=0.778; v_loss=647.521, v_rmse=25.446, v_r2=0.718; \n",
            "E 6\t: loss=490.044, rmse=22.137, r2=0.784; v_loss=616.576, v_rmse=24.831, v_r2=0.732; \n",
            "E 7\t: loss=495.953, rmse=22.270, r2=0.781; v_loss=671.136, v_rmse=25.906, v_r2=0.708; \n",
            "E 8\t: loss=493.801, rmse=22.222, r2=0.782; v_loss=609.049, v_rmse=24.679, v_r2=0.735; \n",
            "E 9\t: loss=486.563, rmse=22.058, r2=0.785; v_loss=627.052, v_rmse=25.041, v_r2=0.727; \n",
            "E 10\t: loss=485.360, rmse=22.031, r2=0.786; v_loss=640.923, v_rmse=25.316, v_r2=0.721; \n",
            "E 11\t: loss=486.685, rmse=22.061, r2=0.785; v_loss=676.702, v_rmse=26.014, v_r2=0.706; \n",
            "E 12\t: loss=488.209, rmse=22.095, r2=0.784; v_loss=614.336, v_rmse=24.786, v_r2=0.733; \n",
            "E 13\t: loss=471.784, rmse=21.721, r2=0.792; v_loss=615.421, v_rmse=24.808, v_r2=0.732; \n",
            "E 14\t: loss=488.948, rmse=22.112, r2=0.784; v_loss=626.931, v_rmse=25.039, v_r2=0.727; \n",
            "E 15\t: loss=475.967, rmse=21.817, r2=0.790; v_loss=642.556, v_rmse=25.349, v_r2=0.720; \n",
            "E 16\t: loss=477.182, rmse=21.844, r2=0.789; v_loss=628.482, v_rmse=25.070, v_r2=0.727; \n",
            "E 17\t: loss=472.492, rmse=21.737, r2=0.791; v_loss=628.360, v_rmse=25.067, v_r2=0.727; \n",
            "E 18\t: loss=472.758, rmse=21.743, r2=0.791; v_loss=616.101, v_rmse=24.821, v_r2=0.732; \n",
            "R2=0.775,RMSE=-22.649\n",
            "Finished: 2022-09-16 19:28:19.673744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0334fa-803c-4f36-d286-a52748842eff",
        "id": "w281y3uWYu_d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.762,RMSE=-20.274\n",
            "Finished: 2022-09-16 19:28:22.263094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to 1-layer, but slightly worse"
      ],
      "metadata": {
        "id": "eF3rQVspYu_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Linear RUL"
      ],
      "metadata": {
        "id": "35HJqUg3Yu_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=2,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90346930-afee-4a2d-e3aa-b1c46f0a79d7",
        "id": "d9334HlKYu_e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=2, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa488c3a650>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa488c3a150>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~15min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__degree\": [2],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 3),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]    \n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d83b6fe-e3c0-4690-89e2-1bcb9315da0e",
        "id": "HxXWQsKDYu_f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.1, 'mlp__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'mlp__model__learning_rate': 0.01, 'mlp__model__layer_nodes': [256, 16, 32], 'mlp__model__dropout': 0.1, 'mlp__model__degree': 2, 'mlp__model__activation': 'tanh', 'mlp__epochs': 50, 'mlp__batch_size': 64}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa48a748c10>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='tanh', model__degree=2, model__dropout=0.1, model__layer_nodes=[256, 16, 32], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c825450>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48abcbe10>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.1, verbose=0))])\n",
            "Finished: 2022-09-16 18:56:40.482439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.1, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'mlp__model__learning_rate': 0.01,\n",
        "'mlp__model__layer_nodes': [256, 16, 32], \n",
        "'mlp__model__dropout': 0.1, \n",
        "'mlp__model__degree': 2, \n",
        "'mlp__model__activation': 'tanh', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 64}\n",
        "```"
      ],
      "metadata": {
        "id": "OWhK7nE8Yu_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'  , MinMaxScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[256,16,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=2,\n",
        "                                model__activation=\"tanh\",\n",
        "                                epochs=50, \n",
        "                                batch_size=64))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db91c9b4-2be6-4cd6-cdb9-f2de3ec32815",
        "id": "1Pg9YfYqYu_f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa4863d6610>, <keras.callbacks.LambdaCallback object at 0x7fa488bc7690>], epochs=50, model=<function create_model at 0x7fa4888839e0>, model__activation='tanh', model__degree=2, model__dropout=0.1, model__layer_nodes=[256, 16, 32], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48f66d710>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48ae161d0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.1, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825907f8-9694-4641-c3ef-f5da73dfc72f",
        "id": "ZEiUaMhsYu_g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1778\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6096 (Dense)          (None, 256)               64768     \n",
            "                                                                 \n",
            " dropout_4318 (Dropout)      (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6097 (Dense)          (None, 16)                4112      \n",
            "                                                                 \n",
            " dropout_4319 (Dropout)      (None, 16)                0         \n",
            "                                                                 \n",
            " dense_6098 (Dense)          (None, 32)                544       \n",
            "                                                                 \n",
            " dropout_4320 (Dropout)      (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6099 (Dense)          (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,457\n",
            "Trainable params: 69,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=8513.498, rmse=91.196, r2=-0.753; v_loss=8082.742, v_rmse=89.904, v_r2=-0.290; \n",
            "E 1\t: loss=4772.402, rmse=69.083, r2=-0.049; v_loss=6640.583, v_rmse=81.490, v_r2=-0.060; \n",
            "E 2\t: loss=4585.873, rmse=67.719, r2=-0.008; v_loss=6529.456, v_rmse=80.805, v_r2=-0.042; \n",
            "E 3\t: loss=4594.659, rmse=67.784, r2=-0.010; v_loss=6556.648, v_rmse=80.973, v_r2=-0.046; \n",
            "E 4\t: loss=4592.214, rmse=67.766, r2=-0.009; v_loss=6513.875, v_rmse=80.709, v_r2=-0.040; \n",
            "E 5\t: loss=4589.818, rmse=67.748, r2=-0.009; v_loss=6558.097, v_rmse=80.982, v_r2=-0.047; \n",
            "E 6\t: loss=4585.787, rmse=67.718, r2=-0.008; v_loss=6504.149, v_rmse=80.648, v_r2=-0.038; \n",
            "E 7\t: loss=4593.643, rmse=67.776, r2=-0.010; v_loss=6526.847, v_rmse=80.789, v_r2=-0.042; \n",
            "E 8\t: loss=4585.076, rmse=67.713, r2=-0.008; v_loss=6525.250, v_rmse=80.779, v_r2=-0.041; \n",
            "E 9\t: loss=4588.741, rmse=67.740, r2=-0.009; v_loss=6537.313, v_rmse=80.854, v_r2=-0.043; \n",
            "E 10\t: loss=4594.625, rmse=67.784, r2=-0.010; v_loss=6546.755, v_rmse=80.912, v_r2=-0.045; \n",
            "E 11\t: loss=4588.688, rmse=67.740, r2=-0.009; v_loss=6554.601, v_rmse=80.960, v_r2=-0.046; \n",
            "E 12\t: loss=4589.617, rmse=67.747, r2=-0.009; v_loss=6548.196, v_rmse=80.921, v_r2=-0.045; \n",
            "E 13\t: loss=4582.531, rmse=67.694, r2=-0.007; v_loss=6533.210, v_rmse=80.828, v_r2=-0.043; \n",
            "E 14\t: loss=4589.733, rmse=67.748, r2=-0.009; v_loss=6487.983, v_rmse=80.548, v_r2=-0.035; \n",
            "E 15\t: loss=4577.292, rmse=67.656, r2=-0.006; v_loss=6522.973, v_rmse=80.765, v_r2=-0.041; \n",
            "E 16\t: loss=4579.417, rmse=67.671, r2=-0.007; v_loss=6561.818, v_rmse=81.005, v_r2=-0.047; \n",
            "E 17\t: loss=4593.000, rmse=67.772, r2=-0.010; v_loss=6538.897, v_rmse=80.863, v_r2=-0.044; \n",
            "E 18\t: loss=4589.651, rmse=67.747, r2=-0.009; v_loss=6549.740, v_rmse=80.930, v_r2=-0.045; \n",
            "E 19\t: loss=4583.721, rmse=67.703, r2=-0.007; v_loss=6552.146, v_rmse=80.945, v_r2=-0.046; \n",
            "E 20\t: loss=4600.300, rmse=67.826, r2=-0.011; v_loss=6547.165, v_rmse=80.915, v_r2=-0.045; \n",
            "R2=-0.001,RMSE=-68.899\n",
            "Finished: 2022-09-16 19:56:49.184173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757066a3-16bb-4fb3-c31b-c631c8c60ba3",
        "id": "mglkpa6IYu_g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.543,RMSE=-51.625\n",
            "Finished: 2022-09-16 19:56:54.732906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Could not learn, nor generalize"
      ],
      "metadata": {
        "id": "lS-uFpu4Yu_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "XC483NwNYu_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=2,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99770a15-2e9e-4a69-bc81-76fc42bd1c9a",
        "id": "2GyGvk6kYu_h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa4863d6610>], model=<function create_model at 0x7fa4888839e0>, model__degree=2, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48ae51550>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48659e310>], verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONTINUE HERE"
      ],
      "metadata": {
        "id": "g80x0mS94ooe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ~20min\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__model__degree\": [2],\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 3),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d80d886-d743-4ade-c2cf-73c5b3921d17",
        "id": "gJ4NPv1sYu_i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119},\n",
        "'trf_reg__regressor__validation_split': 0.1, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.001, \n",
        "'trf_reg__regressor__model__layer_nodes': [128, 32], \n",
        "'trf_reg__regressor__model__dropout': 0.1, \n",
        "'trf_reg__regressor__model__degree': 2, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "vI5tSEHEYu_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=2,include_bias=False)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback], \n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[128,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=2,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':119})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144671ca-f738-4e5b-cb69-e198fdf08b93",
        "id": "wWl5NX4gYu_i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=50, model=<function create_model...cs=[<keras.metrics.RootMeanSquaredError object at 0x7fa48cd1e690>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48cd1edd0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.1, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 119,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffacb682-4f10-4dce-bfd4-2fb2faecd2d8",
        "id": "eSmb_LICYu_i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_507\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1521 (Dense)          (None, 128)               32384     \n",
            "                                                                 \n",
            " dropout_1014 (Dropout)      (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1522 (Dense)          (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_1015 (Dropout)      (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1523 (Dense)          (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,545\n",
            "Trainable params: 36,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1413.037, rmse=37.590, r2=0.096; v_loss=488.686, v_rmse=22.106, v_r2=0.677; \n",
            "E 1\t: loss=483.385, rmse=21.986, r2=0.691; v_loss=398.733, v_rmse=19.968, v_r2=0.736; \n",
            "E 2\t: loss=422.136, rmse=20.546, r2=0.730; v_loss=362.305, v_rmse=19.034, v_r2=0.760; \n",
            "E 3\t: loss=398.772, rmse=19.969, r2=0.745; v_loss=316.355, v_rmse=17.786, v_r2=0.791; \n",
            "E 4\t: loss=394.120, rmse=19.852, r2=0.748; v_loss=353.858, v_rmse=18.811, v_r2=0.766; \n",
            "E 5\t: loss=390.026, rmse=19.749, r2=0.751; v_loss=458.276, v_rmse=21.407, v_r2=0.697; \n",
            "E 6\t: loss=381.493, rmse=19.532, r2=0.756; v_loss=304.791, v_rmse=17.458, v_r2=0.798; \n",
            "E 7\t: loss=381.658, rmse=19.536, r2=0.756; v_loss=356.421, v_rmse=18.879, v_r2=0.764; \n",
            "E 8\t: loss=380.057, rmse=19.495, r2=0.757; v_loss=317.875, v_rmse=17.829, v_r2=0.790; \n",
            "E 9\t: loss=377.267, rmse=19.423, r2=0.759; v_loss=335.368, v_rmse=18.313, v_r2=0.778; \n",
            "E 10\t: loss=372.255, rmse=19.294, r2=0.762; v_loss=342.379, v_rmse=18.503, v_r2=0.773; \n",
            "E 11\t: loss=367.879, rmse=19.180, r2=0.765; v_loss=361.548, v_rmse=19.014, v_r2=0.761; \n",
            "E 12\t: loss=370.256, rmse=19.242, r2=0.763; v_loss=525.009, v_rmse=22.913, v_r2=0.653; \n",
            "E 13\t: loss=366.512, rmse=19.145, r2=0.766; v_loss=387.907, v_rmse=19.695, v_r2=0.743; \n",
            "E 14\t: loss=371.211, rmse=19.267, r2=0.763; v_loss=306.926, v_rmse=17.519, v_r2=0.797; \n",
            "E 15\t: loss=363.333, rmse=19.061, r2=0.768; v_loss=433.929, v_rmse=20.831, v_r2=0.713; \n",
            "E 16\t: loss=358.710, rmse=18.940, r2=0.771; v_loss=343.936, v_rmse=18.546, v_r2=0.772; \n",
            "E 17\t: loss=360.813, rmse=18.995, r2=0.769; v_loss=329.736, v_rmse=18.159, v_r2=0.782; \n",
            "E 18\t: loss=359.650, rmse=18.964, r2=0.770; v_loss=375.120, v_rmse=19.368, v_r2=0.752; \n",
            "E 19\t: loss=359.865, rmse=18.970, r2=0.770; v_loss=315.998, v_rmse=17.776, v_r2=0.791; \n",
            "E 20\t: loss=357.537, rmse=18.909, r2=0.771; v_loss=341.496, v_rmse=18.480, v_r2=0.774; \n",
            "E 21\t: loss=354.616, rmse=18.831, r2=0.773; v_loss=313.833, v_rmse=17.715, v_r2=0.792; \n",
            "E 22\t: loss=357.798, rmse=18.916, r2=0.771; v_loss=343.085, v_rmse=18.523, v_r2=0.773; \n",
            "E 23\t: loss=356.684, rmse=18.886, r2=0.772; v_loss=340.391, v_rmse=18.450, v_r2=0.775; \n",
            "E 24\t: loss=354.550, rmse=18.830, r2=0.773; v_loss=324.842, v_rmse=18.023, v_r2=0.785; \n",
            "E 25\t: loss=354.716, rmse=18.834, r2=0.773; v_loss=359.324, v_rmse=18.956, v_r2=0.762; \n",
            "E 26\t: loss=354.873, rmse=18.838, r2=0.773; v_loss=356.942, v_rmse=18.893, v_r2=0.764; \n",
            "E 27\t: loss=351.766, rmse=18.755, r2=0.775; v_loss=390.598, v_rmse=19.764, v_r2=0.741; \n",
            "E 28\t: loss=353.011, rmse=18.789, r2=0.774; v_loss=322.692, v_rmse=17.964, v_r2=0.786; \n",
            "E 29\t: loss=351.880, rmse=18.758, r2=0.775; v_loss=348.680, v_rmse=18.673, v_r2=0.769; \n",
            "E 30\t: loss=353.421, rmse=18.800, r2=0.774; v_loss=319.007, v_rmse=17.861, v_r2=0.789; \n",
            "E 31\t: loss=350.007, rmse=18.708, r2=0.776; v_loss=431.445, v_rmse=20.771, v_r2=0.714; \n",
            "E 32\t: loss=349.257, rmse=18.688, r2=0.777; v_loss=316.692, v_rmse=17.796, v_r2=0.790; \n",
            "E 33\t: loss=346.735, rmse=18.621, r2=0.778; v_loss=320.979, v_rmse=17.916, v_r2=0.788; \n",
            "E 34\t: loss=348.312, rmse=18.663, r2=0.777; v_loss=319.520, v_rmse=17.875, v_r2=0.789; \n",
            "E 35\t: loss=345.355, rmse=18.584, r2=0.779; v_loss=321.771, v_rmse=17.938, v_r2=0.787; \n",
            "E 36\t: loss=347.302, rmse=18.636, r2=0.778; v_loss=306.096, v_rmse=17.496, v_r2=0.797; \n",
            "E 37\t: loss=349.908, rmse=18.706, r2=0.776; v_loss=318.165, v_rmse=17.837, v_r2=0.789; \n",
            "E 38\t: loss=348.202, rmse=18.660, r2=0.777; v_loss=341.507, v_rmse=18.480, v_r2=0.774; \n",
            "E 39\t: loss=348.679, rmse=18.673, r2=0.777; v_loss=310.809, v_rmse=17.630, v_r2=0.794; \n",
            "E 40\t: loss=345.573, rmse=18.590, r2=0.779; v_loss=300.181, v_rmse=17.326, v_r2=0.801; \n",
            "R2=0.813,RMSE=-17.093\n",
            "Finished: 2022-09-16 16:59:41.281030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb40a46-a956-4e92-8556-df0115a6fa21",
        "id": "CRtIwApDYu_i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.840,RMSE=-15.687\n",
            "Finished: 2022-09-16 17:00:08.047966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best result so far"
      ],
      "metadata": {
        "id": "hR9cqkAbYu_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Linear RUL"
      ],
      "metadata": {
        "id": "SXuVmxk4Yu_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=3,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bb6fbd-8857-4518-e390-91597be7f875",
        "id": "-6acHU5sYu_k"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=3, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c38d290>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48c38de50>], verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~25min\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__degree\": [3],\n",
        "        \"mlp__model__optim\":[Adam,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": all_permutations(layer_sizes, 3),\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]    \n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740dc8ad-fbd4-4d48-e9f6-ef2909fdc88e",
        "id": "iCDxk9k4Yu_l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'scaler': MinMaxScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'mlp__model__learning_rate': 0.0001, 'mlp__model__layer_nodes': [256, 64], 'mlp__model__dropout': 0.1, 'mlp__model__degree': 3, 'mlp__model__activation': 'relu', 'mlp__epochs': 50, 'mlp__batch_size': 32}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
            "                ('scaler', MinMaxScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa48df59450>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__degree=3, model__dropout=0.1, model__layer_nodes=[256, 64], model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48ca910d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa486465610>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-16 17:22:47.138300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': MinMaxScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'mlp__model__learning_rate': 0.0001, \n",
        "'mlp__model__layer_nodes': [256, 64], \n",
        "'mlp__model__dropout': 0.1, \n",
        "'mlp__model__degree': 3, \n",
        "'mlp__model__activation': 'relu', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 32}\n",
        "```"
      ],
      "metadata": {
        "id": "zykggq7zYu_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],\n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.0001, \n",
        "                                model__layer_nodes=[256,64],\n",
        "                                model__dropout=0.1,\n",
        "                                model__degree=3,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50260f4-71ae-4c64-bb1e-febcac9b04d0",
        "id": "NzjiHzdyYu_l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>, <keras.callbacks.LambdaCallback object at 0x7fa520152cd0>], epochs=50, model=<function create_model at 0x7fa530f75e60>, model__activation='relu', model__de...el__dropout=0.1, model__layer_nodes=[256, 64], model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa49d378810>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa48e3923d0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9551c3d8-ee72-4651-d283-acdb084ad036",
        "id": "m4cIB2TAYu_m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_761\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2283 (Dense)          (None, 256)               518144    \n",
            "                                                                 \n",
            " dropout_1522 (Dropout)      (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2284 (Dense)          (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_1523 (Dropout)      (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2285 (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,657\n",
            "Trainable params: 534,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=4928.556, rmse=70.204, r2=-0.134; v_loss=4148.228, v_rmse=64.407, v_r2=0.330; \n",
            "E 1\t: loss=2718.525, rmse=52.139, r2=0.375; v_loss=3459.529, v_rmse=58.818, v_r2=0.441; \n",
            "E 2\t: loss=2237.423, rmse=47.301, r2=0.485; v_loss=3121.430, v_rmse=55.870, v_r2=0.496; \n",
            "E 3\t: loss=2078.780, rmse=45.594, r2=0.522; v_loss=3128.920, v_rmse=55.937, v_r2=0.494; \n",
            "E 4\t: loss=1990.499, rmse=44.615, r2=0.542; v_loss=2975.279, v_rmse=54.546, v_r2=0.519; \n",
            "E 5\t: loss=1937.999, rmse=44.023, r2=0.554; v_loss=3056.378, v_rmse=55.285, v_r2=0.506; \n",
            "E 6\t: loss=1877.659, rmse=43.332, r2=0.568; v_loss=2911.718, v_rmse=53.960, v_r2=0.529; \n",
            "E 7\t: loss=1829.676, rmse=42.775, r2=0.579; v_loss=2932.719, v_rmse=54.155, v_r2=0.526; \n",
            "E 8\t: loss=1807.201, rmse=42.511, r2=0.584; v_loss=2834.582, v_rmse=53.241, v_r2=0.542; \n",
            "E 9\t: loss=1761.010, rmse=41.964, r2=0.595; v_loss=2938.211, v_rmse=54.205, v_r2=0.525; \n",
            "E 10\t: loss=1731.749, rmse=41.614, r2=0.602; v_loss=2869.977, v_rmse=53.572, v_r2=0.536; \n",
            "E 11\t: loss=1706.645, rmse=41.312, r2=0.607; v_loss=2676.836, v_rmse=51.738, v_r2=0.567; \n",
            "E 12\t: loss=1684.088, rmse=41.038, r2=0.613; v_loss=2720.652, v_rmse=52.160, v_r2=0.560; \n",
            "E 13\t: loss=1654.192, rmse=40.672, r2=0.619; v_loss=2659.324, v_rmse=51.569, v_r2=0.570; \n",
            "E 14\t: loss=1644.000, rmse=40.546, r2=0.622; v_loss=2715.875, v_rmse=52.114, v_r2=0.561; \n",
            "E 15\t: loss=1622.258, rmse=40.277, r2=0.627; v_loss=2757.119, v_rmse=52.508, v_r2=0.554; \n",
            "E 16\t: loss=1615.605, rmse=40.195, r2=0.628; v_loss=2731.413, v_rmse=52.263, v_r2=0.559; \n",
            "E 17\t: loss=1609.389, rmse=40.117, r2=0.630; v_loss=2766.564, v_rmse=52.598, v_r2=0.553; \n",
            "E 18\t: loss=1591.286, rmse=39.891, r2=0.634; v_loss=2674.965, v_rmse=51.720, v_r2=0.568; \n",
            "E 19\t: loss=1578.673, rmse=39.733, r2=0.637; v_loss=2695.037, v_rmse=51.914, v_r2=0.564; \n",
            "E 20\t: loss=1569.241, rmse=39.614, r2=0.639; v_loss=2735.781, v_rmse=52.305, v_r2=0.558; \n",
            "E 21\t: loss=1570.865, rmse=39.634, r2=0.639; v_loss=3046.629, v_rmse=55.196, v_r2=0.508; \n",
            "E 22\t: loss=1558.399, rmse=39.477, r2=0.642; v_loss=2844.517, v_rmse=53.334, v_r2=0.540; \n",
            "E 23\t: loss=1559.893, rmse=39.495, r2=0.641; v_loss=2881.123, v_rmse=53.676, v_r2=0.534; \n",
            "E 24\t: loss=1557.008, rmse=39.459, r2=0.642; v_loss=2813.964, v_rmse=53.047, v_r2=0.545; \n",
            "E 25\t: loss=1550.936, rmse=39.382, r2=0.643; v_loss=2833.620, v_rmse=53.232, v_r2=0.542; \n",
            "E 26\t: loss=1547.909, rmse=39.343, r2=0.644; v_loss=2647.356, v_rmse=51.452, v_r2=0.572; \n",
            "E 27\t: loss=1542.464, rmse=39.274, r2=0.645; v_loss=2596.769, v_rmse=50.958, v_r2=0.580; \n",
            "E 28\t: loss=1555.529, rmse=39.440, r2=0.642; v_loss=2578.409, v_rmse=50.778, v_r2=0.583; \n",
            "E 29\t: loss=1539.378, rmse=39.235, r2=0.646; v_loss=2666.530, v_rmse=51.638, v_r2=0.569; \n",
            "E 30\t: loss=1547.117, rmse=39.333, r2=0.644; v_loss=2616.678, v_rmse=51.153, v_r2=0.577; \n",
            "E 31\t: loss=1542.292, rmse=39.272, r2=0.645; v_loss=2768.759, v_rmse=52.619, v_r2=0.553; \n",
            "E 32\t: loss=1542.380, rmse=39.273, r2=0.645; v_loss=2677.756, v_rmse=51.747, v_r2=0.567; \n",
            "E 33\t: loss=1541.157, rmse=39.258, r2=0.645; v_loss=2890.392, v_rmse=53.762, v_r2=0.533; \n",
            "E 34\t: loss=1524.625, rmse=39.046, r2=0.649; v_loss=2752.729, v_rmse=52.466, v_r2=0.555; \n",
            "E 35\t: loss=1535.914, rmse=39.191, r2=0.647; v_loss=2726.136, v_rmse=52.212, v_r2=0.559; \n",
            "E 36\t: loss=1541.916, rmse=39.267, r2=0.645; v_loss=2816.538, v_rmse=53.071, v_r2=0.545; \n",
            "E 37\t: loss=1531.086, rmse=39.129, r2=0.648; v_loss=2987.383, v_rmse=54.657, v_r2=0.517; \n",
            "E 38\t: loss=1521.049, rmse=39.001, r2=0.650; v_loss=2660.125, v_rmse=51.576, v_r2=0.570; \n",
            "E 39\t: loss=1524.318, rmse=39.043, r2=0.649; v_loss=2657.026, v_rmse=51.546, v_r2=0.571; \n",
            "E 40\t: loss=1536.856, rmse=39.203, r2=0.646; v_loss=2605.555, v_rmse=51.045, v_r2=0.579; \n",
            "E 41\t: loss=1516.965, rmse=38.948, r2=0.651; v_loss=2566.632, v_rmse=50.662, v_r2=0.585; \n",
            "E 42\t: loss=1526.243, rmse=39.067, r2=0.649; v_loss=2747.607, v_rmse=52.418, v_r2=0.556; \n",
            "E 43\t: loss=1524.641, rmse=39.047, r2=0.649; v_loss=2757.548, v_rmse=52.512, v_r2=0.554; \n",
            "E 44\t: loss=1522.812, rmse=39.023, r2=0.650; v_loss=2832.498, v_rmse=53.221, v_r2=0.542; \n",
            "E 45\t: loss=1517.299, rmse=38.953, r2=0.651; v_loss=2670.944, v_rmse=51.681, v_r2=0.568; \n",
            "E 46\t: loss=1515.401, rmse=38.928, r2=0.651; v_loss=2573.658, v_rmse=50.731, v_r2=0.584; \n",
            "E 47\t: loss=1519.002, rmse=38.974, r2=0.651; v_loss=2908.661, v_rmse=53.932, v_r2=0.530; \n",
            "E 48\t: loss=1515.776, rmse=38.933, r2=0.651; v_loss=2793.946, v_rmse=52.858, v_r2=0.548; \n",
            "E 49\t: loss=1537.837, rmse=39.215, r2=0.646; v_loss=2797.096, v_rmse=52.888, v_r2=0.548; \n",
            "R2=0.643,RMSE=-41.157\n",
            "Finished: 2022-09-16 17:30:53.017436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c0737a-abf8-4143-deda-3e989a2be024",
        "id": "Xm7o3tevYu_m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.551,RMSE=-27.830\n",
            "Finished: 2022-09-16 17:31:09.294675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar architecture to the Linear 1-layer and Linear 1-poly 1-layer. Better than 2-degree (like in MLP-1) "
      ],
      "metadata": {
        "id": "moI9LLZsYu_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "qFdH2S1xYu_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3, include_bias=False)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                model__degree=3,\n",
        "                                verbose=0, callbacks=[es],  \n",
        "                                ),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3652507-8a4d-41ce-c394-a24976d33098",
        "id": "SV7yUfTKYu_n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fa530f0c610>], model=<function create_model at 0x7fa530f75e60>, model__degree=3, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fa48c9bd6d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fa49c272090>], verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fa5acad2c20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~10min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__model__degree\": [3],\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations(layer_sizes, 3),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b475cf77-340f-4cca-838a-a1a82c14e4ee",
        "id": "p_Sruc4zYu_n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, \n",
        "'trf_reg__regressor__validation_split': 0.5, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [16], \n",
        "'trf_reg__regressor__model__dropout': 0.2, \n",
        "'trf_reg__regressor__model__degree': 3, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "9UXiyA9WYu_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3,include_bias=False)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback], \n",
        "                                model__print_summary=True,   \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[16],\n",
        "                                model__dropout=0.2,\n",
        "                                model__degree=3,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':135})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5a5964-7ddb-4240-8cd0-ec798f99a5e1",
        "id": "LaHHM9B_Yu_p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3, include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f1959d5b8d0>, <keras.callbacks.LambdaCallback object at 0x7f195016cf10>], epochs=50, model=<function cre..._metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f18b1862b50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f18b0092c50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.5, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f19d590bc20>,\n",
              "                                                                            kw_args={'a_max': 135,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52a2bb1-6bda-4856-bdc5-460cd203cce3",
        "id": "AjrjZ_3rYu_p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1015\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2030 (Dense)          (None, 16)                32384     \n",
            "                                                                 \n",
            " dropout_1015 (Dropout)      (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2031 (Dense)          (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,401\n",
            "Trainable params: 32,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1975.571, rmse=44.447, r2=0.027; v_loss=1402.159, v_rmse=37.445, v_r2=0.314; \n",
            "E 1\t: loss=1257.777, rmse=35.465, r2=0.381; v_loss=1110.082, v_rmse=33.318, v_r2=0.457; \n",
            "E 2\t: loss=1061.762, rmse=32.585, r2=0.477; v_loss=951.694, v_rmse=30.850, v_r2=0.534; \n",
            "E 3\t: loss=926.742, rmse=30.442, r2=0.544; v_loss=830.629, v_rmse=28.821, v_r2=0.594; \n",
            "E 4\t: loss=856.466, rmse=29.265, r2=0.578; v_loss=802.247, v_rmse=28.324, v_r2=0.607; \n",
            "E 5\t: loss=821.784, rmse=28.667, r2=0.595; v_loss=771.883, v_rmse=27.783, v_r2=0.622; \n",
            "E 6\t: loss=787.382, rmse=28.060, r2=0.612; v_loss=782.979, v_rmse=27.982, v_r2=0.617; \n",
            "E 7\t: loss=761.541, rmse=27.596, r2=0.625; v_loss=799.018, v_rmse=28.267, v_r2=0.609; \n",
            "E 8\t: loss=751.391, rmse=27.412, r2=0.630; v_loss=725.970, v_rmse=26.944, v_r2=0.645; \n",
            "E 9\t: loss=731.602, rmse=27.048, r2=0.640; v_loss=735.524, v_rmse=27.121, v_r2=0.640; \n",
            "E 10\t: loss=704.165, rmse=26.536, r2=0.653; v_loss=756.943, v_rmse=27.513, v_r2=0.630; \n",
            "E 11\t: loss=678.724, rmse=26.052, r2=0.666; v_loss=725.716, v_rmse=26.939, v_r2=0.645; \n",
            "E 12\t: loss=680.853, rmse=26.093, r2=0.665; v_loss=682.099, v_rmse=26.117, v_r2=0.666; \n",
            "E 13\t: loss=673.211, rmse=25.946, r2=0.669; v_loss=791.441, v_rmse=28.133, v_r2=0.613; \n",
            "E 14\t: loss=645.406, rmse=25.405, r2=0.682; v_loss=689.940, v_rmse=26.267, v_r2=0.662; \n",
            "E 15\t: loss=646.512, rmse=25.427, r2=0.682; v_loss=660.232, v_rmse=25.695, v_r2=0.677; \n",
            "E 16\t: loss=624.102, rmse=24.982, r2=0.693; v_loss=744.758, v_rmse=27.290, v_r2=0.636; \n",
            "E 17\t: loss=628.425, rmse=25.068, r2=0.691; v_loss=698.857, v_rmse=26.436, v_r2=0.658; \n",
            "E 18\t: loss=608.295, rmse=24.664, r2=0.700; v_loss=716.634, v_rmse=26.770, v_r2=0.649; \n",
            "E 19\t: loss=607.638, rmse=24.650, r2=0.701; v_loss=651.482, v_rmse=25.524, v_r2=0.681; \n",
            "E 20\t: loss=603.992, rmse=24.576, r2=0.703; v_loss=679.537, v_rmse=26.068, v_r2=0.668; \n",
            "E 21\t: loss=589.005, rmse=24.269, r2=0.710; v_loss=659.001, v_rmse=25.671, v_r2=0.678; \n",
            "E 22\t: loss=580.245, rmse=24.088, r2=0.714; v_loss=665.377, v_rmse=25.795, v_r2=0.674; \n",
            "E 23\t: loss=576.014, rmse=24.000, r2=0.716; v_loss=622.764, v_rmse=24.955, v_r2=0.695; \n",
            "E 24\t: loss=560.198, rmse=23.668, r2=0.724; v_loss=634.439, v_rmse=25.188, v_r2=0.690; \n",
            "E 25\t: loss=549.117, rmse=23.433, r2=0.730; v_loss=596.674, v_rmse=24.427, v_r2=0.708; \n",
            "E 26\t: loss=546.115, rmse=23.369, r2=0.731; v_loss=637.478, v_rmse=25.248, v_r2=0.688; \n",
            "E 27\t: loss=560.391, rmse=23.673, r2=0.724; v_loss=659.010, v_rmse=25.671, v_r2=0.678; \n",
            "E 28\t: loss=551.967, rmse=23.494, r2=0.728; v_loss=630.836, v_rmse=25.116, v_r2=0.691; \n",
            "E 29\t: loss=539.852, rmse=23.235, r2=0.734; v_loss=615.070, v_rmse=24.801, v_r2=0.699; \n",
            "E 30\t: loss=535.336, rmse=23.137, r2=0.736; v_loss=619.936, v_rmse=24.899, v_r2=0.697; \n",
            "E 31\t: loss=528.813, rmse=22.996, r2=0.740; v_loss=627.534, v_rmse=25.051, v_r2=0.693; \n",
            "E 32\t: loss=526.747, rmse=22.951, r2=0.741; v_loss=619.439, v_rmse=24.889, v_r2=0.697; \n",
            "E 33\t: loss=521.573, rmse=22.838, r2=0.743; v_loss=571.351, v_rmse=23.903, v_r2=0.720; \n",
            "E 34\t: loss=517.462, rmse=22.748, r2=0.745; v_loss=619.473, v_rmse=24.889, v_r2=0.697; \n",
            "E 35\t: loss=530.934, rmse=23.042, r2=0.739; v_loss=590.470, v_rmse=24.300, v_r2=0.711; \n",
            "E 36\t: loss=518.389, rmse=22.768, r2=0.745; v_loss=607.767, v_rmse=24.653, v_r2=0.703; \n",
            "E 37\t: loss=522.038, rmse=22.848, r2=0.743; v_loss=586.189, v_rmse=24.211, v_r2=0.713; \n",
            "E 38\t: loss=514.122, rmse=22.674, r2=0.747; v_loss=618.027, v_rmse=24.860, v_r2=0.698; \n",
            "E 39\t: loss=509.559, rmse=22.573, r2=0.749; v_loss=643.582, v_rmse=25.369, v_r2=0.685; \n",
            "E 40\t: loss=502.982, rmse=22.427, r2=0.752; v_loss=583.107, v_rmse=24.148, v_r2=0.715; \n",
            "E 41\t: loss=503.087, rmse=22.430, r2=0.752; v_loss=589.620, v_rmse=24.282, v_r2=0.712; \n",
            "E 42\t: loss=508.796, rmse=22.557, r2=0.749; v_loss=613.814, v_rmse=24.775, v_r2=0.700; \n",
            "E 43\t: loss=517.705, rmse=22.753, r2=0.745; v_loss=651.032, v_rmse=25.515, v_r2=0.681; \n",
            "E 44\t: loss=500.282, rmse=22.367, r2=0.754; v_loss=588.084, v_rmse=24.250, v_r2=0.712; \n",
            "E 45\t: loss=497.407, rmse=22.303, r2=0.755; v_loss=633.980, v_rmse=25.179, v_r2=0.690; \n",
            "E 46\t: loss=500.176, rmse=22.365, r2=0.754; v_loss=601.802, v_rmse=24.532, v_r2=0.706; \n",
            "E 47\t: loss=497.776, rmse=22.311, r2=0.755; v_loss=586.657, v_rmse=24.221, v_r2=0.713; \n",
            "E 48\t: loss=501.675, rmse=22.398, r2=0.753; v_loss=602.801, v_rmse=24.552, v_r2=0.705; \n",
            "E 49\t: loss=490.049, rmse=22.137, r2=0.759; v_loss=598.652, v_rmse=24.467, v_r2=0.707; \n",
            "R2=0.756,RMSE=-22.299\n",
            "Finished: 2022-09-16 12:36:47.505725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0daeca02-ab52-4b70-8e21-4db20ad072ef",
        "id": "SUuL-qYtYu_q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.782,RMSE=-19.248\n",
            "Finished: 2022-09-16 12:36:55.847390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Didn't improve by using more features, actually worsened a bit"
      ],
      "metadata": {
        "id": "tqQDbFdHYu_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smoothing"
      ],
      "metadata": {
        "id": "71pMNTXGThUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_smoothing(df, sensors, n_samples, alpha=0.4, unit_col='unit_number'):\n",
        "    df = df.copy()\n",
        "    # first, calculate the exponential weighted mean of desired sensors\n",
        "    df[sensors] = df.groupby(unit_col)[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
        "    \n",
        "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
        "    def create_mask(data, samples):\n",
        "        result = np.ones_like(data)\n",
        "        result[0:samples] = 0\n",
        "        return result\n",
        "    \n",
        "    mask = df.groupby(unit_col)[unit_col].transform(create_mask, samples=n_samples).astype(bool)\n",
        "    df = df[mask]\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "6_o6DTiy4K9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "6wI15po34UWL",
        "outputId": "a997b915-68ec-4cc3-fc29-732c458a1700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0      1400.60  14.62  ...  2388.02  8138.62  8.4195  0.03   392  2388  100.0   \n",
              "1      1403.14  14.62  ...  2388.07  8131.49  8.4318  0.03   392  2388  100.0   \n",
              "2      1404.20  14.62  ...  2388.03  8133.23  8.4178  0.03   390  2388  100.0   \n",
              "3      1401.87  14.62  ...  2388.08  8133.83  8.3682  0.03   392  2388  100.0   \n",
              "4      1406.22  14.62  ...  2388.04  8133.80  8.4294  0.03   393  2388  100.0   \n",
              "...        ...    ...  ...      ...      ...     ...   ...   ...   ...    ...   \n",
              "20626  1428.63  14.62  ...  2388.26  8137.60  8.4956  0.03   397  2388  100.0   \n",
              "20627  1433.58  14.62  ...  2388.22  8136.50  8.5139  0.03   395  2388  100.0   \n",
              "20628  1428.18  14.62  ...  2388.24  8141.05  8.5646  0.03   398  2388  100.0   \n",
              "20629  1426.53  14.62  ...  2388.23  8139.29  8.5389  0.03   395  2388  100.0   \n",
              "20630  1432.14  14.62  ...  2388.26  8137.33  8.5036  0.03   396  2388  100.0   \n",
              "\n",
              "        s_19     s_20  RUL  \n",
              "0      39.06  23.4190  191  \n",
              "1      39.00  23.4236  190  \n",
              "2      38.95  23.3442  189  \n",
              "3      38.88  23.3739  188  \n",
              "4      38.90  23.4044  187  \n",
              "...      ...      ...  ...  \n",
              "20626  38.49  22.9735    4  \n",
              "20627  38.30  23.1594    3  \n",
              "20628  38.44  22.9333    2  \n",
              "20629  38.29  23.0640    1  \n",
              "20630  38.37  23.0522    0  \n",
              "\n",
              "[20631 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58604028-f847-4406-9c51-08ebb286604f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58604028-f847-4406-9c51-08ebb286604f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58604028-f847-4406-9c51-08ebb286604f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58604028-f847-4406-9c51-08ebb286604f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss_train = StandardScaler().fit_transform(train)\n",
        "ss_train = pd.DataFrame(ss_train, columns=train.columns)\n",
        "ss_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "bq_0sSnP5Nf3",
        "outputId": "ffc7eee4-1e23-420b-9782-2e6a95f743ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number      time      op_1      op_2  op_3  s_0       s_1  \\\n",
              "0        -1.728084 -1.565170 -0.315980 -1.372953   0.0  0.0 -1.721725   \n",
              "1        -1.728084 -1.550652  0.872722 -1.031720   0.0  0.0 -1.061780   \n",
              "2        -1.728084 -1.536134 -1.961874  1.015677   0.0  0.0 -0.661813   \n",
              "3        -1.728084 -1.521616  0.324090 -0.008022   0.0  0.0 -0.661813   \n",
              "4        -1.728084 -1.507098 -0.864611 -0.690488   0.0  0.0 -0.621816   \n",
              "...            ...       ...       ...       ...   ...  ...       ...   \n",
              "20626     1.659204  1.265868 -0.178822 -1.031720   0.0  0.0  1.618000   \n",
              "20627     1.659204  1.280386 -0.727453 -1.714186   0.0  0.0  1.717992   \n",
              "20628     1.659204  1.294904  0.186933 -0.008022   0.0  0.0  1.478011   \n",
              "20629     1.659204  1.309423 -0.498857  1.015677   0.0  0.0  1.098043   \n",
              "20630     1.659204  1.323941 -1.458962 -1.714186   0.0  0.0  2.337940   \n",
              "\n",
              "            s_2       s_3           s_4  ...      s_12      s_13      s_14  \\\n",
              "0     -0.134255 -0.925936 -1.776357e-15  ... -1.058890 -0.269071 -0.603816   \n",
              "1      0.211528 -0.643726 -1.776357e-15  ... -0.363646 -0.642845 -0.275852   \n",
              "2     -0.413166 -0.525953 -1.776357e-15  ... -0.919841 -0.551629 -0.649144   \n",
              "3     -1.261314 -0.784831 -1.776357e-15  ... -0.224597 -0.520176 -1.971665   \n",
              "4     -1.251528 -0.301518 -1.776357e-15  ... -0.780793 -0.521748 -0.339845   \n",
              "...         ...       ...           ...  ...       ...       ...       ...   \n",
              "20626  1.216258  2.188375 -1.776357e-15  ...  2.278282 -0.322542  1.425294   \n",
              "20627  2.279706  2.738351 -1.776357e-15  ...  1.722087 -0.380207  1.913240   \n",
              "20628  1.946971  2.138377 -1.776357e-15  ...  2.000184 -0.141684  3.265092   \n",
              "20629  2.403666  1.955051 -1.776357e-15  ...  1.861136 -0.233948  2.579834   \n",
              "20630  1.607712  2.578358 -1.776357e-15  ...  2.278282 -0.336696  1.638604   \n",
              "\n",
              "               s_15      s_16  s_17  s_18      s_19      s_20       RUL  \n",
              "0     -1.387779e-17 -0.781710   0.0   0.0  1.348493  1.194427  1.207796  \n",
              "1     -1.387779e-17 -0.781710   0.0   0.0  1.016528  1.236922  1.193277  \n",
              "2     -1.387779e-17 -2.073094   0.0   0.0  0.739891  0.503423  1.178759  \n",
              "3     -1.387779e-17 -0.781710   0.0   0.0  0.352598  0.777792  1.164241  \n",
              "4     -1.387779e-17 -0.136018   0.0   0.0  0.463253  1.059552  1.149723  \n",
              "...             ...       ...   ...   ...       ...       ...       ...  \n",
              "20626 -1.387779e-17  2.446751   0.0   0.0 -1.805173 -2.921113 -1.507098  \n",
              "20627 -1.387779e-17  1.155367   0.0   0.0 -2.856395 -1.203764 -1.521616  \n",
              "20628 -1.387779e-17  3.092444   0.0   0.0 -2.081810 -3.292481 -1.536134  \n",
              "20629 -1.387779e-17  1.155367   0.0   0.0 -2.911722 -2.085072 -1.550652  \n",
              "20630 -1.387779e-17  1.801059   0.0   0.0 -2.469103 -2.194080 -1.565170  \n",
              "\n",
              "[20631 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66b038b0-fb1d-48f9-b21a-7fa9ebd8d20c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.565170</td>\n",
              "      <td>-0.315980</td>\n",
              "      <td>-1.372953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.721725</td>\n",
              "      <td>-0.134255</td>\n",
              "      <td>-0.925936</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.058890</td>\n",
              "      <td>-0.269071</td>\n",
              "      <td>-0.603816</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.781710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.348493</td>\n",
              "      <td>1.194427</td>\n",
              "      <td>1.207796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.550652</td>\n",
              "      <td>0.872722</td>\n",
              "      <td>-1.031720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.061780</td>\n",
              "      <td>0.211528</td>\n",
              "      <td>-0.643726</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.363646</td>\n",
              "      <td>-0.642845</td>\n",
              "      <td>-0.275852</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.781710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.016528</td>\n",
              "      <td>1.236922</td>\n",
              "      <td>1.193277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.536134</td>\n",
              "      <td>-1.961874</td>\n",
              "      <td>1.015677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.661813</td>\n",
              "      <td>-0.413166</td>\n",
              "      <td>-0.525953</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.919841</td>\n",
              "      <td>-0.551629</td>\n",
              "      <td>-0.649144</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-2.073094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739891</td>\n",
              "      <td>0.503423</td>\n",
              "      <td>1.178759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.521616</td>\n",
              "      <td>0.324090</td>\n",
              "      <td>-0.008022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.661813</td>\n",
              "      <td>-1.261314</td>\n",
              "      <td>-0.784831</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.224597</td>\n",
              "      <td>-0.520176</td>\n",
              "      <td>-1.971665</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.781710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352598</td>\n",
              "      <td>0.777792</td>\n",
              "      <td>1.164241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.507098</td>\n",
              "      <td>-0.864611</td>\n",
              "      <td>-0.690488</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.621816</td>\n",
              "      <td>-1.251528</td>\n",
              "      <td>-0.301518</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.780793</td>\n",
              "      <td>-0.521748</td>\n",
              "      <td>-0.339845</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.136018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.463253</td>\n",
              "      <td>1.059552</td>\n",
              "      <td>1.149723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.265868</td>\n",
              "      <td>-0.178822</td>\n",
              "      <td>-1.031720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>1.216258</td>\n",
              "      <td>2.188375</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.278282</td>\n",
              "      <td>-0.322542</td>\n",
              "      <td>1.425294</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>2.446751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.805173</td>\n",
              "      <td>-2.921113</td>\n",
              "      <td>-1.507098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.280386</td>\n",
              "      <td>-0.727453</td>\n",
              "      <td>-1.714186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.717992</td>\n",
              "      <td>2.279706</td>\n",
              "      <td>2.738351</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.722087</td>\n",
              "      <td>-0.380207</td>\n",
              "      <td>1.913240</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>1.155367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.856395</td>\n",
              "      <td>-1.203764</td>\n",
              "      <td>-1.521616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.294904</td>\n",
              "      <td>0.186933</td>\n",
              "      <td>-0.008022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.478011</td>\n",
              "      <td>1.946971</td>\n",
              "      <td>2.138377</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000184</td>\n",
              "      <td>-0.141684</td>\n",
              "      <td>3.265092</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>3.092444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.081810</td>\n",
              "      <td>-3.292481</td>\n",
              "      <td>-1.536134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.309423</td>\n",
              "      <td>-0.498857</td>\n",
              "      <td>1.015677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.098043</td>\n",
              "      <td>2.403666</td>\n",
              "      <td>1.955051</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.861136</td>\n",
              "      <td>-0.233948</td>\n",
              "      <td>2.579834</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>1.155367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.911722</td>\n",
              "      <td>-2.085072</td>\n",
              "      <td>-1.550652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.323941</td>\n",
              "      <td>-1.458962</td>\n",
              "      <td>-1.714186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.337940</td>\n",
              "      <td>1.607712</td>\n",
              "      <td>2.578358</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.278282</td>\n",
              "      <td>-0.336696</td>\n",
              "      <td>1.638604</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>1.801059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.469103</td>\n",
              "      <td>-2.194080</td>\n",
              "      <td>-1.565170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66b038b0-fb1d-48f9-b21a-7fa9ebd8d20c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66b038b0-fb1d-48f9-b21a-7fa9ebd8d20c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66b038b0-fb1d-48f9-b21a-7fa9ebd8d20c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ss_train['s_2']-e_ss_train['s_2']).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FCUf5-Y5tHk",
        "outputId": "6effde6e-5b72-444b-c0c7-72b6e77a0b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09587839238736667"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e_ss_train = exponential_smoothing(ss_train, [\"s_0\",\"s_2\"], 0, 0.1)\n",
        "e_ss_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "lZuHDfnv4kZ3",
        "outputId": "c3b9ceae-9043-4c98-9c64-2f458e4f6722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number      time      op_1      op_2  op_3  s_0       s_1  \\\n",
              "0        -1.728084 -1.565170 -0.315980 -1.372953   0.0  0.0 -1.721725   \n",
              "1        -1.728084 -1.550652  0.872722 -1.031720   0.0  0.0 -1.061780   \n",
              "2        -1.728084 -1.536134 -1.961874  1.015677   0.0  0.0 -0.661813   \n",
              "3        -1.728084 -1.521616  0.324090 -0.008022   0.0  0.0 -0.661813   \n",
              "4        -1.728084 -1.507098 -0.864611 -0.690488   0.0  0.0 -0.621816   \n",
              "...            ...       ...       ...       ...   ...  ...       ...   \n",
              "20626     1.659204  1.265868 -0.178822 -1.031720   0.0  0.0  1.618000   \n",
              "20627     1.659204  1.280386 -0.727453 -1.714186   0.0  0.0  1.717992   \n",
              "20628     1.659204  1.294904  0.186933 -0.008022   0.0  0.0  1.478011   \n",
              "20629     1.659204  1.309423 -0.498857  1.015677   0.0  0.0  1.098043   \n",
              "20630     1.659204  1.323941 -1.458962 -1.714186   0.0  0.0  2.337940   \n",
              "\n",
              "            s_2       s_3           s_4  ...      s_12      s_13      s_14  \\\n",
              "0     -0.134255 -0.925936 -1.776357e-15  ... -1.058890 -0.269071 -0.603816   \n",
              "1      0.047736 -0.643726 -1.776357e-15  ... -0.363646 -0.642845 -0.275852   \n",
              "2     -0.122338 -0.525953 -1.776357e-15  ... -0.919841 -0.551629 -0.649144   \n",
              "3     -0.453532 -0.784831 -1.776357e-15  ... -0.224597 -0.520176 -1.971665   \n",
              "4     -0.648398 -0.301518 -1.776357e-15  ... -0.780793 -0.521748 -0.339845   \n",
              "...         ...       ...           ...  ...       ...       ...       ...   \n",
              "20626  1.361246  2.188375 -1.776357e-15  ...  2.278282 -0.322542  1.425294   \n",
              "20627  1.453092  2.738351 -1.776357e-15  ...  1.722087 -0.380207  1.913240   \n",
              "20628  1.502480  2.138377 -1.776357e-15  ...  2.000184 -0.141684  3.265092   \n",
              "20629  1.592599  1.955051 -1.776357e-15  ...  1.861136 -0.233948  2.579834   \n",
              "20630  1.594110  2.578358 -1.776357e-15  ...  2.278282 -0.336696  1.638604   \n",
              "\n",
              "               s_15      s_16  s_17  s_18      s_19      s_20       RUL  \n",
              "0     -1.387779e-17 -0.781710   0.0   0.0  1.348493  1.194427  1.207796  \n",
              "1     -1.387779e-17 -0.781710   0.0   0.0  1.016528  1.236922  1.193277  \n",
              "2     -1.387779e-17 -2.073094   0.0   0.0  0.739891  0.503423  1.178759  \n",
              "3     -1.387779e-17 -0.781710   0.0   0.0  0.352598  0.777792  1.164241  \n",
              "4     -1.387779e-17 -0.136018   0.0   0.0  0.463253  1.059552  1.149723  \n",
              "...             ...       ...   ...   ...       ...       ...       ...  \n",
              "20626 -1.387779e-17  2.446751   0.0   0.0 -1.805173 -2.921113 -1.507098  \n",
              "20627 -1.387779e-17  1.155367   0.0   0.0 -2.856395 -1.203764 -1.521616  \n",
              "20628 -1.387779e-17  3.092444   0.0   0.0 -2.081810 -3.292481 -1.536134  \n",
              "20629 -1.387779e-17  1.155367   0.0   0.0 -2.911722 -2.085072 -1.550652  \n",
              "20630 -1.387779e-17  1.801059   0.0   0.0 -2.469103 -2.194080 -1.565170  \n",
              "\n",
              "[20631 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17767703-47ae-418a-b209-64c72544e5f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.565170</td>\n",
              "      <td>-0.315980</td>\n",
              "      <td>-1.372953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.721725</td>\n",
              "      <td>-0.134255</td>\n",
              "      <td>-0.925936</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.058890</td>\n",
              "      <td>-0.269071</td>\n",
              "      <td>-0.603816</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.781710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.348493</td>\n",
              "      <td>1.194427</td>\n",
              "      <td>1.207796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.550652</td>\n",
              "      <td>0.872722</td>\n",
              "      <td>-1.031720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.061780</td>\n",
              "      <td>0.047736</td>\n",
              "      <td>-0.643726</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.363646</td>\n",
              "      <td>-0.642845</td>\n",
              "      <td>-0.275852</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.781710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.016528</td>\n",
              "      <td>1.236922</td>\n",
              "      <td>1.193277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.536134</td>\n",
              "      <td>-1.961874</td>\n",
              "      <td>1.015677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.661813</td>\n",
              "      <td>-0.122338</td>\n",
              "      <td>-0.525953</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.919841</td>\n",
              "      <td>-0.551629</td>\n",
              "      <td>-0.649144</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-2.073094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739891</td>\n",
              "      <td>0.503423</td>\n",
              "      <td>1.178759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.521616</td>\n",
              "      <td>0.324090</td>\n",
              "      <td>-0.008022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.661813</td>\n",
              "      <td>-0.453532</td>\n",
              "      <td>-0.784831</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.224597</td>\n",
              "      <td>-0.520176</td>\n",
              "      <td>-1.971665</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.781710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352598</td>\n",
              "      <td>0.777792</td>\n",
              "      <td>1.164241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.728084</td>\n",
              "      <td>-1.507098</td>\n",
              "      <td>-0.864611</td>\n",
              "      <td>-0.690488</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.621816</td>\n",
              "      <td>-0.648398</td>\n",
              "      <td>-0.301518</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.780793</td>\n",
              "      <td>-0.521748</td>\n",
              "      <td>-0.339845</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>-0.136018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.463253</td>\n",
              "      <td>1.059552</td>\n",
              "      <td>1.149723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.265868</td>\n",
              "      <td>-0.178822</td>\n",
              "      <td>-1.031720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>1.361246</td>\n",
              "      <td>2.188375</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.278282</td>\n",
              "      <td>-0.322542</td>\n",
              "      <td>1.425294</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>2.446751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.805173</td>\n",
              "      <td>-2.921113</td>\n",
              "      <td>-1.507098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.280386</td>\n",
              "      <td>-0.727453</td>\n",
              "      <td>-1.714186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.717992</td>\n",
              "      <td>1.453092</td>\n",
              "      <td>2.738351</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.722087</td>\n",
              "      <td>-0.380207</td>\n",
              "      <td>1.913240</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>1.155367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.856395</td>\n",
              "      <td>-1.203764</td>\n",
              "      <td>-1.521616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.294904</td>\n",
              "      <td>0.186933</td>\n",
              "      <td>-0.008022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.478011</td>\n",
              "      <td>1.502480</td>\n",
              "      <td>2.138377</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000184</td>\n",
              "      <td>-0.141684</td>\n",
              "      <td>3.265092</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>3.092444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.081810</td>\n",
              "      <td>-3.292481</td>\n",
              "      <td>-1.536134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.309423</td>\n",
              "      <td>-0.498857</td>\n",
              "      <td>1.015677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.098043</td>\n",
              "      <td>1.592599</td>\n",
              "      <td>1.955051</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.861136</td>\n",
              "      <td>-0.233948</td>\n",
              "      <td>2.579834</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>1.155367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.911722</td>\n",
              "      <td>-2.085072</td>\n",
              "      <td>-1.550652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>1.659204</td>\n",
              "      <td>1.323941</td>\n",
              "      <td>-1.458962</td>\n",
              "      <td>-1.714186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.337940</td>\n",
              "      <td>1.594110</td>\n",
              "      <td>2.578358</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.278282</td>\n",
              "      <td>-0.336696</td>\n",
              "      <td>1.638604</td>\n",
              "      <td>-1.387779e-17</td>\n",
              "      <td>1.801059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.469103</td>\n",
              "      <td>-2.194080</td>\n",
              "      <td>-1.565170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17767703-47ae-418a-b209-64c72544e5f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17767703-47ae-418a-b209-64c72544e5f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17767703-47ae-418a-b209-64c72544e5f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwm9UqIr4Yyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF 3"
      ],
      "metadata": {
        "id": "JDcMN66I8WZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M2igVtXS4MV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Linear RUL"
      ],
      "metadata": {
        "id": "ZQ2hpA7tKcAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures()),\n",
        "    ('scaler'  ,   MinMaxScaler()),\n",
        "    ('mlp'  ,   KerasRegressor(model=create_model_pol,verbose=0, callbacks=[es], \n",
        "                               validation_split=0.2, \n",
        "                               model__metrics=[RMSE(), R2()],\n",
        "                               model__loss='mse'))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7581c5-b437-4e41-8e69-ae8e448c4c9a",
        "id": "dGdg2ByKKhmc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures()), ('scaler', MinMaxScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>], model=<function create_model at 0x7f36b04c3320>, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f362c2ea850>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f36b0528250>], validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~6min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__optim\":[Adam,SGD,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": [[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]],\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012570dd-35cc-496a-f9c5-be1600f86c48",
        "id": "qkp8l9AgKhmd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 2 folds for each of 41 candidates, totalling 82 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f36422dfe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f364204a7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x7f3628569b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3628487950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7f3642041e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.gradient_descent.SGD'>, 'mlp__model__learning_rate': 0.001, 'mlp__model__layer_nodes': [128, 256, 512], 'mlp__model__dropout': 0.4, 'mlp__model__activation': 'sigmoid', 'mlp__epochs': 50, 'mlp__batch_size': 512}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures()), ('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36281d8550>], epochs=50, model=<function create_model at 0x7f36b04c3320>, model__activation='sigmoid', model__dropout=0.4, model__layer_nodes=[128, 256, 512], model__learning_rate=0.001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f36281d8d10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f36284c0550>], model__optim=<class 'keras.optimizer_v2.gradient_descent.SGD'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-12 10:48:50.150156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.gradient_descent.SGD'>, 'mlp__model__learning_rate': 0.001, \n",
        "'mlp__model__layer_nodes': [128, 256, 512], \n",
        "'mlp__model__dropout': 0.4, \n",
        "'mlp__model__activation': 'sigmoid', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 512}\n",
        "```"
      ],
      "metadata": {
        "id": "bgJ0ugeZKhmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures()),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model_pol, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=SGD,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[128,256,512],\n",
        "                                model__dropout=0.4,\n",
        "                                model__activation='sigmoid',\n",
        "                                epochs=50, \n",
        "                                batch_size=512))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de61af16-00ca-4b12-c701-04672efdaee5",
        "id": "joPgZ3UeKhme"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures()), ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>, <keras.callbacks.LambdaCallback object at 0x7f36c01c4850>], epochs=50, model=<function create_model at 0x7f36b04c3320>, model__activation='sigmoid', model__dropout=0.4, model__layer_nodes=[128, 256, 512], model__learning_rate=0.001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f361648bd50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f361648b850>], model__optim=<class 'keras.optimizer_v2.gradient_descent.SGD'>, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27554139-1f6c-4b32-93e4-ae3a86ff7434",
        "id": "EWMM8n3gKhme"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=4271.573, rmse=65.357, r2=0.017; v_loss=3707.898, v_rmse=60.893, v_r2=0.401; \n",
            "E 1\t: loss=1938.243, rmse=44.025, r2=0.554; v_loss=2839.112, v_rmse=53.283, v_r2=0.541; \n",
            "E 2\t: loss=1759.316, rmse=41.944, r2=0.595; v_loss=2711.072, v_rmse=52.068, v_r2=0.562; \n",
            "E 3\t: loss=1734.720, rmse=41.650, r2=0.601; v_loss=2709.544, v_rmse=52.053, v_r2=0.562; \n",
            "E 4\t: loss=1716.355, rmse=41.429, r2=0.605; v_loss=2621.782, v_rmse=51.203, v_r2=0.576; \n",
            "E 5\t: loss=1714.445, rmse=41.406, r2=0.606; v_loss=2598.654, v_rmse=50.977, v_r2=0.580; \n",
            "E 6\t: loss=1699.979, rmse=41.231, r2=0.609; v_loss=2570.351, v_rmse=50.699, v_r2=0.585; \n",
            "E 7\t: loss=1699.774, rmse=41.228, r2=0.609; v_loss=2664.598, v_rmse=51.620, v_r2=0.569; \n",
            "E 8\t: loss=1669.670, rmse=40.862, r2=0.616; v_loss=2607.967, v_rmse=51.068, v_r2=0.579; \n",
            "E 9\t: loss=1662.341, rmse=40.772, r2=0.618; v_loss=2865.036, v_rmse=53.526, v_r2=0.537; \n",
            "E 10\t: loss=1645.317, rmse=40.563, r2=0.622; v_loss=2657.781, v_rmse=51.554, v_r2=0.570; \n",
            "E 11\t: loss=1641.543, rmse=40.516, r2=0.622; v_loss=2583.149, v_rmse=50.825, v_r2=0.583; \n",
            "E 12\t: loss=1638.355, rmse=40.477, r2=0.623; v_loss=2766.257, v_rmse=52.595, v_r2=0.553; \n",
            "E 13\t: loss=1621.628, rmse=40.269, r2=0.627; v_loss=2592.054, v_rmse=50.912, v_r2=0.581; \n",
            "E 14\t: loss=1616.919, rmse=40.211, r2=0.628; v_loss=2603.854, v_rmse=51.028, v_r2=0.579; \n",
            "E 15\t: loss=1615.949, rmse=40.199, r2=0.628; v_loss=2669.961, v_rmse=51.672, v_r2=0.569; \n",
            "E 16\t: loss=1616.084, rmse=40.201, r2=0.628; v_loss=2521.032, v_rmse=50.210, v_r2=0.593; \n",
            "E 17\t: loss=1611.284, rmse=40.141, r2=0.629; v_loss=2770.538, v_rmse=52.636, v_r2=0.552; \n",
            "E 18\t: loss=1600.718, rmse=40.009, r2=0.632; v_loss=2615.737, v_rmse=51.144, v_r2=0.577; \n",
            "E 19\t: loss=1600.670, rmse=40.008, r2=0.632; v_loss=2750.708, v_rmse=52.447, v_r2=0.555; \n",
            "E 20\t: loss=1590.578, rmse=39.882, r2=0.634; v_loss=2546.329, v_rmse=50.461, v_r2=0.589; \n",
            "E 21\t: loss=1606.289, rmse=40.079, r2=0.630; v_loss=3072.527, v_rmse=55.430, v_r2=0.503; \n",
            "E 22\t: loss=1596.107, rmse=39.951, r2=0.633; v_loss=2773.296, v_rmse=52.662, v_r2=0.552; \n",
            "E 23\t: loss=1592.532, rmse=39.907, r2=0.634; v_loss=2754.838, v_rmse=52.487, v_r2=0.555; \n",
            "E 24\t: loss=1584.756, rmse=39.809, r2=0.635; v_loss=2780.689, v_rmse=52.732, v_r2=0.551; \n",
            "E 25\t: loss=1584.811, rmse=39.810, r2=0.635; v_loss=2858.316, v_rmse=53.463, v_r2=0.538; \n",
            "E 26\t: loss=1591.958, rmse=39.899, r2=0.634; v_loss=2878.594, v_rmse=53.653, v_r2=0.535; \n",
            "E 27\t: loss=1590.332, rmse=39.879, r2=0.634; v_loss=2732.787, v_rmse=52.276, v_r2=0.558; \n",
            "E 28\t: loss=1583.080, rmse=39.788, r2=0.636; v_loss=2630.674, v_rmse=51.290, v_r2=0.575; \n",
            "E 29\t: loss=1581.740, rmse=39.771, r2=0.636; v_loss=2546.362, v_rmse=50.461, v_r2=0.588; \n",
            "E 30\t: loss=1577.062, rmse=39.712, r2=0.637; v_loss=2634.325, v_rmse=51.326, v_r2=0.574; \n",
            "E 31\t: loss=1578.937, rmse=39.736, r2=0.637; v_loss=2521.557, v_rmse=50.215, v_r2=0.593; \n",
            "E 32\t: loss=1579.228, rmse=39.740, r2=0.637; v_loss=2629.236, v_rmse=51.276, v_r2=0.575; \n",
            "E 33\t: loss=1579.705, rmse=39.745, r2=0.637; v_loss=2952.550, v_rmse=54.337, v_r2=0.523; \n",
            "E 34\t: loss=1585.003, rmse=39.812, r2=0.635; v_loss=2683.485, v_rmse=51.802, v_r2=0.566; \n",
            "E 35\t: loss=1578.085, rmse=39.725, r2=0.637; v_loss=2590.632, v_rmse=50.898, v_r2=0.581; \n",
            "R2=0.634,RMSE=-41.667\n",
            "Finished: 2022-09-12 10:50:02.870685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf84126d-f36d-4a4e-87c0-d0957ab972dd",
        "id": "VPNuSj3lKhme"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.469,RMSE=-30.277\n",
            "Finished: 2022-09-12 10:50:06.977277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9d41Lbllb5Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Linear RUL"
      ],
      "metadata": {
        "id": "qnIpTnKzb5uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'  ,   MinMaxScaler()),\n",
        "    ('mlp'  ,   KerasRegressor(model=create_model_pol3,verbose=0, callbacks=[es], \n",
        "                               validation_split=0.2, \n",
        "                               model__metrics=[RMSE(), R2()],\n",
        "                               model__loss='mse'))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb184eab-99ca-43cd-d142-b17e38fecd86",
        "id": "ujyScHoYb5uF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>], model=<function create_model_pol3 at 0x7f361b2a1dd0>, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f361b402f10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f361b402090>], validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~6min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"mlp__epochs\": [1,5,10,20,30,50],\n",
        "        \"mlp__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"mlp__batch_size\": [32,64,128,256,512],\n",
        "        \"mlp__model__optim\":[Adam,SGD,RMSprop],\n",
        "        \"mlp__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"mlp__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"mlp__model__layer_nodes\": [[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]],\n",
        "        \"mlp__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac36cf7a-da05-4517-cccb-4c0957c1ec19",
        "id": "8bz0KOLBb5uI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 2 folds for each of 41 candidates, totalling 82 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "Best params:  {'scaler': StandardScaler(), 'mlp__validation_split': 0.2, 'mlp__model__optim': <class 'keras.optimizer_v2.gradient_descent.SGD'>, 'mlp__model__learning_rate': 0.001, 'mlp__model__layer_nodes': [128, 256, 512], 'mlp__model__dropout': 0.4, 'mlp__model__activation': 'sigmoid', 'mlp__epochs': 50, 'mlp__batch_size': 512}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('mlp',\n",
            "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f361b542610>], epochs=50, model=<function create_model_pol3 at 0x7f361b2a1dd0>, model__activation='sigmoid', model__dropout=0.4, model__layer_nodes=[128, 256, 512], model__learning_rate=0.001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f361b3e2c50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f361afdcc10>], model__optim=<class 'keras.optimizer_v2.gradient_descent.SGD'>, validation_split=0.2, verbose=0))])\n",
            "Finished: 2022-09-12 11:32:34.664989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'scaler': StandardScaler(), \n",
        "'mlp__validation_split': 0.2, \n",
        "'mlp__model__optim': <class 'keras.optimizer_v2.gradient_descent.SGD'>,\n",
        "'mlp__model__learning_rate': 0.001, \n",
        "'mlp__model__layer_nodes': [128, 256, 512], \n",
        "'mlp__model__dropout': 0.4, \n",
        "'mlp__model__activation': 'sigmoid', \n",
        "'mlp__epochs': 50, \n",
        "'mlp__batch_size': 512}\n",
        "```"
      ],
      "metadata": {
        "id": "f2UG9WWxb5uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'  , StandardScaler()),\n",
        "    ('mlp'     , KerasRegressor(model=create_model_pol3, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.2, \n",
        "                                model__optim=SGD,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[128,256,512],\n",
        "                                model__dropout=0.4,\n",
        "                                model__activation='sigmoid',\n",
        "                                epochs=50, \n",
        "                                batch_size=512))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8434fc71-c0d6-44de-8da6-eff4d2595b7c",
        "id": "IGDY9Vasb5uK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=512, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>, <keras.callbacks.LambdaCallback object at 0x7f36c01c4850>], epochs=50, model=<function create_model_pol3 at 0x7f361b2a1dd0>, model__activation='sigmoid', model__dropout=0.4, model__layer_nodes=[128, 256, 512], model__learning_rate=0.001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f3628307ad0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f3628307a50>], model__optim=<class 'keras.optimizer_v2.gradient_descent.SGD'>, validation_split=0.2, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4e3b1c-898d-48ab-cfe3-e008ba6ca767",
        "id": "ZrhXAliIb5uL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=3859.454, rmse=62.125, r2=0.112; v_loss=3244.542, v_rmse=56.961, v_r2=0.476; \n",
            "E 1\t: loss=1869.120, rmse=43.233, r2=0.570; v_loss=3304.891, v_rmse=57.488, v_r2=0.466; \n",
            "E 2\t: loss=1816.944, rmse=42.626, r2=0.582; v_loss=2708.521, v_rmse=52.043, v_r2=0.562; \n",
            "E 3\t: loss=1755.046, rmse=41.893, r2=0.596; v_loss=2778.461, v_rmse=52.711, v_r2=0.551; \n",
            "E 4\t: loss=1729.353, rmse=41.585, r2=0.602; v_loss=2693.361, v_rmse=51.898, v_r2=0.565; \n",
            "E 5\t: loss=1723.992, rmse=41.521, r2=0.603; v_loss=2670.318, v_rmse=51.675, v_r2=0.568; \n",
            "E 6\t: loss=1698.269, rmse=41.210, r2=0.609; v_loss=2668.869, v_rmse=51.661, v_r2=0.569; \n",
            "E 7\t: loss=1697.971, rmse=41.206, r2=0.609; v_loss=2667.741, v_rmse=51.650, v_r2=0.569; \n",
            "E 8\t: loss=1675.807, rmse=40.937, r2=0.615; v_loss=2689.505, v_rmse=51.860, v_r2=0.565; \n",
            "E 9\t: loss=1668.688, rmse=40.850, r2=0.616; v_loss=3041.413, v_rmse=55.149, v_r2=0.508; \n",
            "E 10\t: loss=1650.078, rmse=40.621, r2=0.620; v_loss=2714.094, v_rmse=52.097, v_r2=0.561; \n",
            "E 11\t: loss=1645.906, rmse=40.570, r2=0.621; v_loss=2593.109, v_rmse=50.923, v_r2=0.581; \n",
            "E 12\t: loss=1644.726, rmse=40.555, r2=0.622; v_loss=2785.568, v_rmse=52.778, v_r2=0.550; \n",
            "E 13\t: loss=1637.778, rmse=40.469, r2=0.623; v_loss=2657.344, v_rmse=51.549, v_r2=0.571; \n",
            "E 14\t: loss=1623.451, rmse=40.292, r2=0.627; v_loss=2643.109, v_rmse=51.411, v_r2=0.573; \n",
            "E 15\t: loss=1620.327, rmse=40.253, r2=0.627; v_loss=2736.085, v_rmse=52.308, v_r2=0.558; \n",
            "E 16\t: loss=1627.034, rmse=40.337, r2=0.626; v_loss=2564.023, v_rmse=50.636, v_r2=0.586; \n",
            "E 17\t: loss=1619.200, rmse=40.239, r2=0.628; v_loss=2841.541, v_rmse=53.306, v_r2=0.541; \n",
            "E 18\t: loss=1609.504, rmse=40.119, r2=0.630; v_loss=2755.156, v_rmse=52.490, v_r2=0.555; \n",
            "E 19\t: loss=1616.572, rmse=40.207, r2=0.628; v_loss=2789.636, v_rmse=52.817, v_r2=0.549; \n",
            "E 20\t: loss=1593.005, rmse=39.912, r2=0.634; v_loss=2606.225, v_rmse=51.051, v_r2=0.579; \n",
            "E 21\t: loss=1608.490, rmse=40.106, r2=0.630; v_loss=3037.995, v_rmse=55.118, v_r2=0.509; \n",
            "E 22\t: loss=1602.250, rmse=40.028, r2=0.631; v_loss=2795.559, v_rmse=52.873, v_r2=0.548; \n",
            "E 23\t: loss=1599.308, rmse=39.991, r2=0.632; v_loss=2777.107, v_rmse=52.698, v_r2=0.551; \n",
            "E 24\t: loss=1593.720, rmse=39.921, r2=0.633; v_loss=2834.953, v_rmse=53.244, v_r2=0.542; \n",
            "E 25\t: loss=1596.159, rmse=39.952, r2=0.633; v_loss=2800.625, v_rmse=52.921, v_r2=0.547; \n",
            "R2=0.633,RMSE=-41.706\n",
            "Finished: 2022-09-12 11:33:42.501943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436366a7-8428-42cc-d9e8-06dac2e656ec",
        "id": "i2m4PTdnb5uM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.401,RMSE=-32.164\n",
            "Finished: 2022-09-12 11:33:45.020869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mesmo modelo do Poly2"
      ],
      "metadata": {
        "id": "WlYXOKrjeZTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(2) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "YaO6E-pbUiWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures()),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol,verbose=0, callbacks=[es], \n",
        "                                validation_split=0.2, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0c596c-bee2-4b2c-fd72-8c5360275b70",
        "id": "ojfhw8TQUwUw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures()), ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>], model=<function create_model_pol at 0x7f36162f0cb0>, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f36286c33d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f36286c3b50>], validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f373c87e4d0>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~10min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": [[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]],\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8637a0d2-f199-474b-dc79-6b5f7afce7bb",
        "id": "eVyBrw_5UwUx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 2 folds for each of 41 candidates, totalling 82 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, 'trf_reg__regressor__validation_split': 0.5, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'trf_reg__regressor__model__learning_rate': 0.01, 'trf_reg__regressor__model__layer_nodes': [64, 128, 256], 'trf_reg__regressor__model__dropout': 0.5, 'trf_reg__regressor__model__activation': 'tanh', 'trf_reg__regressor__epochs': 30, 'trf_reg__regressor__batch_size': 256, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures()), ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=256, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f361d5693d0>], epochs=30, model=<function create_model_pol at 0x7f36162f0cb0>, model__activation='tanh', model__dropout=0.5, model_...1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f3619dedbd0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f36285df2d0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.5, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f373c87e4d0>,\n",
            "                                                                            kw_args={'a_max': 135,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-12 11:02:22.779693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, \n",
        "'trf_reg__regressor__validation_split': 0.5, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [64, 128, 256], \n",
        "'trf_reg__regressor__model__dropout': 0.5, \n",
        "'trf_reg__regressor__model__activation': 'tanh', \n",
        "'trf_reg__regressor__epochs': 30, \n",
        "'trf_reg__regressor__batch_size': 256, \n",
        "'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "J8KO_NQEUwUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures()),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[64, 128, 256],\n",
        "                                model__dropout=0.5,\n",
        "                                model__activation=\"tanh\",\n",
        "                                epochs=30, \n",
        "                                batch_size=256),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':135})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632903da-4612-463c-a5b8-fef265bf1e56",
        "id": "2UgoPCJPUwUz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures()), ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=256, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>, <keras.callbacks.LambdaCallback object at 0x7f36c01c4850>], epochs=30, model=<function create_model_pol at 0x7f36162f0...1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f36165ef7d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f36165ef690>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.5, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f373c87e4d0>,\n",
              "                                                                            kw_args={'a_max': 135,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(X_train, y_train)\n",
        "# reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "# eval.show_result(reclipped_y, model.predict(X_train))\n",
        "# eval.show_result_cv(reclipped_y, X_train, model)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())\n",
        "# eval.show_result_cv(y_train, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6d87e1-656b-4e9a-e087-6f893c249b46",
        "id": "m-BLDmN-UwU0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=5314.098, rmse=72.898, r2=-1.617; v_loss=1288.184, v_rmse=35.891, v_r2=0.370; \n",
            "E 1\t: loss=812.940, rmse=28.512, r2=0.600; v_loss=665.227, v_rmse=25.792, v_r2=0.675; \n",
            "E 2\t: loss=576.975, rmse=24.020, r2=0.716; v_loss=567.214, v_rmse=23.816, v_r2=0.722; \n",
            "E 3\t: loss=526.989, rmse=22.956, r2=0.741; v_loss=540.345, v_rmse=23.245, v_r2=0.736; \n",
            "E 4\t: loss=509.114, rmse=22.564, r2=0.749; v_loss=530.718, v_rmse=23.037, v_r2=0.740; \n",
            "E 5\t: loss=509.515, rmse=22.572, r2=0.749; v_loss=527.402, v_rmse=22.965, v_r2=0.742; \n",
            "E 6\t: loss=506.129, rmse=22.497, r2=0.751; v_loss=529.495, v_rmse=23.011, v_r2=0.741; \n",
            "E 7\t: loss=498.015, rmse=22.316, r2=0.755; v_loss=560.912, v_rmse=23.684, v_r2=0.726; \n",
            "E 8\t: loss=495.849, rmse=22.268, r2=0.756; v_loss=550.318, v_rmse=23.459, v_r2=0.731; \n",
            "E 9\t: loss=479.884, rmse=21.906, r2=0.764; v_loss=544.229, v_rmse=23.329, v_r2=0.734; \n",
            "E 10\t: loss=492.787, rmse=22.199, r2=0.757; v_loss=545.064, v_rmse=23.347, v_r2=0.733; \n",
            "E 11\t: loss=492.276, rmse=22.187, r2=0.758; v_loss=530.727, v_rmse=23.038, v_r2=0.740; \n",
            "E 12\t: loss=480.826, rmse=21.928, r2=0.763; v_loss=538.606, v_rmse=23.208, v_r2=0.736; \n",
            "E 13\t: loss=482.418, rmse=21.964, r2=0.762; v_loss=529.720, v_rmse=23.016, v_r2=0.741; \n",
            "E 14\t: loss=480.109, rmse=21.911, r2=0.764; v_loss=555.547, v_rmse=23.570, v_r2=0.728; \n",
            "R2=0.776,RMSE=-21.353\n",
            "Finished: 2022-09-12 11:06:15.790672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "# eval.show_result(reclipped_y, model.predict(X_test))"
      ],
      "metadata": {
        "id": "HdeyhGEMUwU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3e34bd-6026-44cc-d263-09587f47e71f",
        "id": "ExoiDur7UwU2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.753,RMSE=-20.475\n",
            "Finished: 2022-09-12 11:06:20.553177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3ThmdU4XYZbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures(3) + Non-Linear RUL"
      ],
      "metadata": {
        "id": "bH0hyH8aYZ_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol3,verbose=0, callbacks=[es], \n",
        "                                validation_split=0.2, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a502f3e6-cb79-4f97-c8a2-b6c393ef705c",
        "id": "RuGywAhDYZ_O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>], model=<function create_model_pol3 at 0x7f361d4e1ef0>, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f361d5f16d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f36167e2750>], validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f373c87e4d0>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~10min\n",
        "GRID_SEARCH = False\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": [[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]],\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                             factor=2, scorer='r2', ignore_warnings=True, cv=3)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7662b845-348e-456b-b0e1-f7e2c8030c4d",
        "id": "SHp_CfLjYZ_P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 2 folds for each of 41 candidates, totalling 82 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 133}, 'trf_reg__regressor__validation_split': 0.1, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [64, 128, 256], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 30, 'trf_reg__regressor__batch_size': 64, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f361b41a550>], epochs=30, model=<function create_model_pol3 at 0x7f361d4e1ef0>, model__activation='relu', model__dropout=0....1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f36286b3110>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f361d018d50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.1, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f373c87e4d0>,\n",
            "                                                                            kw_args={'a_max': 133,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-12 11:19:28.580776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 133}, \n",
        "'trf_reg__regressor__validation_split': 0.1, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.001, \n",
        "'trf_reg__regressor__model__layer_nodes': [64, 128, 256], \n",
        "'trf_reg__regressor__model__dropout': 0.1, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 30,\n",
        " 'trf_reg__regressor__batch_size': 64, \n",
        " 'scaler': StandardScaler()}\n",
        "```"
      ],
      "metadata": {
        "id": "WjDSEYQ3YZ_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol3, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[64, 128, 256],\n",
        "                                model__dropout=0.1,\n",
        "                                model__activation=\"relu\",\n",
        "                                epochs=30, \n",
        "                                batch_size=64),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':133})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9140bc28-6ed6-4c0f-9eec-5e20b739d524",
        "id": "jv2L95lJYZ_Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=64, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f36c0d21d10>, <keras.callbacks.LambdaCallback object at 0x7f36c01c4850>], epochs=30, model=<function create_model_pol3 at 0x7...1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f3628705c90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f3642112b50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.1, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f373c87e4d0>,\n",
              "                                                                            kw_args={'a_max': 133,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(X_train, y_train)\n",
        "# reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "# eval.show_result(reclipped_y, model.predict(X_train))\n",
        "# eval.show_result_cv(reclipped_y, X_train, model)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())\n",
        "# eval.show_result_cv(y_train, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aef2b9f-2817-4cbf-bc99-741c899dec18",
        "id": "_ISHLBLeYZ_Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=1465.280, rmse=38.279, r2=0.260; v_loss=877.040, v_rmse=29.615, v_r2=0.550; \n",
            "E 1\t: loss=758.275, rmse=27.537, r2=0.617; v_loss=639.657, v_rmse=25.291, v_r2=0.672; \n",
            "E 2\t: loss=628.628, rmse=25.072, r2=0.682; v_loss=544.522, v_rmse=23.335, v_r2=0.721; \n",
            "E 3\t: loss=556.142, rmse=23.583, r2=0.719; v_loss=592.383, v_rmse=24.339, v_r2=0.696; \n",
            "E 4\t: loss=532.007, rmse=23.065, r2=0.731; v_loss=452.094, v_rmse=21.263, v_r2=0.768; \n",
            "E 5\t: loss=501.482, rmse=22.394, r2=0.747; v_loss=453.017, v_rmse=21.284, v_r2=0.767; \n",
            "E 6\t: loss=502.090, rmse=22.407, r2=0.746; v_loss=424.875, v_rmse=20.612, v_r2=0.782; \n",
            "E 7\t: loss=489.451, rmse=22.124, r2=0.753; v_loss=482.244, v_rmse=21.960, v_r2=0.752; \n",
            "E 8\t: loss=482.443, rmse=21.965, r2=0.756; v_loss=482.506, v_rmse=21.966, v_r2=0.752; \n",
            "E 9\t: loss=481.390, rmse=21.941, r2=0.757; v_loss=438.913, v_rmse=20.950, v_r2=0.775; \n",
            "E 10\t: loss=481.096, rmse=21.934, r2=0.757; v_loss=506.945, v_rmse=22.515, v_r2=0.740; \n",
            "E 11\t: loss=480.237, rmse=21.914, r2=0.757; v_loss=457.125, v_rmse=21.380, v_r2=0.765; \n",
            "E 12\t: loss=463.463, rmse=21.528, r2=0.766; v_loss=495.520, v_rmse=22.260, v_r2=0.746; \n",
            "E 13\t: loss=464.523, rmse=21.553, r2=0.765; v_loss=572.930, v_rmse=23.936, v_r2=0.706; \n",
            "E 14\t: loss=460.683, rmse=21.464, r2=0.767; v_loss=472.343, v_rmse=21.733, v_r2=0.758; \n",
            "E 15\t: loss=457.092, rmse=21.380, r2=0.769; v_loss=585.139, v_rmse=24.190, v_r2=0.700; \n",
            "E 16\t: loss=458.290, rmse=21.408, r2=0.768; v_loss=467.257, v_rmse=21.616, v_r2=0.760; \n",
            "E 17\t: loss=461.148, rmse=21.474, r2=0.767; v_loss=468.861, v_rmse=21.653, v_r2=0.759; \n",
            "E 18\t: loss=449.848, rmse=21.210, r2=0.773; v_loss=472.195, v_rmse=21.730, v_r2=0.758; \n",
            "E 19\t: loss=455.341, rmse=21.339, r2=0.770; v_loss=419.608, v_rmse=20.484, v_r2=0.785; \n",
            "E 20\t: loss=453.908, rmse=21.305, r2=0.771; v_loss=822.671, v_rmse=28.682, v_r2=0.578; \n",
            "E 21\t: loss=453.337, rmse=21.292, r2=0.771; v_loss=480.504, v_rmse=21.920, v_r2=0.753; \n",
            "E 22\t: loss=449.037, rmse=21.190, r2=0.773; v_loss=441.747, v_rmse=21.018, v_r2=0.773; \n",
            "E 23\t: loss=449.053, rmse=21.191, r2=0.773; v_loss=560.180, v_rmse=23.668, v_r2=0.712; \n",
            "E 24\t: loss=438.867, rmse=20.949, r2=0.778; v_loss=441.176, v_rmse=21.004, v_r2=0.774; \n",
            "E 25\t: loss=445.686, rmse=21.111, r2=0.775; v_loss=584.306, v_rmse=24.172, v_r2=0.700; \n",
            "E 26\t: loss=435.156, rmse=20.860, r2=0.780; v_loss=587.900, v_rmse=24.247, v_r2=0.698; \n",
            "E 27\t: loss=443.821, rmse=21.067, r2=0.776; v_loss=546.048, v_rmse=23.368, v_r2=0.720; \n",
            "E 28\t: loss=437.459, rmse=20.916, r2=0.779; v_loss=478.659, v_rmse=21.878, v_r2=0.754; \n",
            "E 29\t: loss=441.529, rmse=21.013, r2=0.777; v_loss=557.793, v_rmse=23.618, v_r2=0.714; \n",
            "R2=0.755,RMSE=-21.995\n",
            "Finished: 2022-09-12 11:21:25.450814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "# eval.show_result(reclipped_y, model.predict(X_test))"
      ],
      "metadata": {
        "id": "S4F2y4BSYZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9131234-4cac-4140-b243-e8d180d44624",
        "id": "Y19REws0YZ_R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.811,RMSE=-17.814\n",
            "Finished: 2022-09-12 11:21:51.443498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF"
      ],
      "metadata": {
        "id": "Ny58sYrJcE_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'   ,   MinMaxScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol3_iter,verbose=0, callbacks=[es], \n",
        "                                validation_split=0.2, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvJW3i6X3EDd",
        "outputId": "5e040b93-689d-4730-822e-37ad18680b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', MinMaxScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f8ad2298910>], model=<function create_model_pol3_iter at 0x7f8ad2405e60>, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f8ad2328d90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f8b32153150>], validation_split=0.2, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f8b4de4ec20>,\n",
              "                                                                            kw_args={'a_max': 50,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain, combinations\n",
        "\n",
        "def powerset(iterable):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
      ],
      "metadata": {
        "id": "s8S-brZf2uyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(powerset([16,32,64,128,256,512]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucJyGU442vdx",
        "outputId": "64a1523f-af46-4d00-e328-b912ff5f03da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(),\n",
              " (16,),\n",
              " (32,),\n",
              " (64,),\n",
              " (128,),\n",
              " (256,),\n",
              " (512,),\n",
              " (16, 32),\n",
              " (16, 64),\n",
              " (16, 128),\n",
              " (16, 256),\n",
              " (16, 512),\n",
              " (32, 64),\n",
              " (32, 128),\n",
              " (32, 256),\n",
              " (32, 512),\n",
              " (64, 128),\n",
              " (64, 256),\n",
              " (64, 512),\n",
              " (128, 256),\n",
              " (128, 512),\n",
              " (256, 512),\n",
              " (16, 32, 64),\n",
              " (16, 32, 128),\n",
              " (16, 32, 256),\n",
              " (16, 32, 512),\n",
              " (16, 64, 128),\n",
              " (16, 64, 256),\n",
              " (16, 64, 512),\n",
              " (16, 128, 256),\n",
              " (16, 128, 512),\n",
              " (16, 256, 512),\n",
              " (32, 64, 128),\n",
              " (32, 64, 256),\n",
              " (32, 64, 512),\n",
              " (32, 128, 256),\n",
              " (32, 128, 512),\n",
              " (32, 256, 512),\n",
              " (64, 128, 256),\n",
              " (64, 128, 512),\n",
              " (64, 256, 512),\n",
              " (128, 256, 512),\n",
              " (16, 32, 64, 128),\n",
              " (16, 32, 64, 256),\n",
              " (16, 32, 64, 512),\n",
              " (16, 32, 128, 256),\n",
              " (16, 32, 128, 512),\n",
              " (16, 32, 256, 512),\n",
              " (16, 64, 128, 256),\n",
              " (16, 64, 128, 512),\n",
              " (16, 64, 256, 512),\n",
              " (16, 128, 256, 512),\n",
              " (32, 64, 128, 256),\n",
              " (32, 64, 128, 512),\n",
              " (32, 64, 256, 512),\n",
              " (32, 128, 256, 512),\n",
              " (64, 128, 256, 512),\n",
              " (16, 32, 64, 128, 256),\n",
              " (16, 32, 64, 128, 512),\n",
              " (16, 32, 64, 256, 512),\n",
              " (16, 32, 128, 256, 512),\n",
              " (16, 64, 128, 256, 512),\n",
              " (32, 64, 128, 256, 512),\n",
              " (16, 32, 64, 128, 256, 512)]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "K0mc062L1If0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_RS(base_model, X_train, y_train, param_distributions, \n",
        "                  print_best=True, ignore_warnings=False, \n",
        "                  scorer=reclipper_scorer, cv=5):\n",
        "        search = RandomizedSearchCV(base_model, param_distributions, \n",
        "                                    scoring=scorer, random_state=42, \n",
        "                                    verbose=1, cv=cv)\n",
        "        search.fit(X_train, y_train);\n",
        "\n",
        "        if(print_best): print(\"Best params: \", search.best_params_)\n",
        "        return search.best_estimator_, search"
      ],
      "metadata": {
        "id": "VrsWq67o_26M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": [\n",
        "            [16],[32],[64],[128],[256],[512],\n",
        "            [16,32],[32,64],[64,128],[128,256],[256,512],\n",
        "            [16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]\n",
        "        ],\n",
        "        # \"trf_reg__regressor__model__layer_nodes\": [\n",
        "        #     #[16],[32],[64],[128],[256],[512],\n",
        "        #     [16,32],[32,64],[64,128],[128,256],[256,512]\n",
        "        #     #[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]\n",
        "        # ],\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model,ss = run_RS(model, X_train, y_train, param_distributions, \n",
        "                          scorer='r2', ignore_warnings=True, cv=2)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HasJdgOb1TMO",
        "outputId": "29152e96-ef09-46dc-a183-01619df857d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 147}, 'trf_reg__regressor__validation_split': 0.1, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [256, 512], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__activation': 'tanh', 'trf_reg__regressor__epochs': 5, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f8a32566590>], epochs=5, model=<function create_model_pol3_iter at 0x7f8ad2405e60>, model__activation='tanh', model__dropou...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f8a32541b90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f8a3220b310>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, validation_split=0.1, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7f8b4de4ec20>,\n",
            "                                                                            kw_args={'a_max': 147,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-15 11:12:52.935035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss.cv_results_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW70NaPl2jI3",
        "outputId": "56bdd7e6-4dcf-475f-86a1-45f0de70aa82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 8.09345293,  3.75099039,  6.387573  , 19.48472381,  8.97599912,\n",
              "        34.48569763,  1.81102073, 10.1499145 ,  9.87086678,  6.23128748]),\n",
              " 'std_fit_time': array([1.07878256e+00, 6.74605370e-03, 9.24661160e-02, 2.19633102e+00,\n",
              "        2.48655677e+00, 7.67754614e+00, 3.31569314e-01, 1.19185877e+00,\n",
              "        1.73339558e+00, 8.26859474e-03]),\n",
              " 'mean_score_time': array([2.26794171, 0.59059727, 0.60934365, 0.67661905, 0.99048424,\n",
              "        0.88606107, 0.43230832, 1.66806364, 0.67616022, 0.60011804]),\n",
              " 'std_score_time': array([1.81133842e+00, 7.66042471e-02, 1.76775455e-03, 1.94716454e-03,\n",
              "        2.31766701e-03, 1.14415288e-01, 4.81307507e-03, 9.92515802e-01,\n",
              "        1.38294697e-03, 7.71039724e-02]),\n",
              " 'param_trf_reg__transformer__kw_args': masked_array(data=[{'a_min': 0, 'a_max': 136}, {'a_min': 0, 'a_max': 116},\n",
              "                    {'a_min': 0, 'a_max': 128}, {'a_min': 0, 'a_max': 97},\n",
              "                    {'a_min': 0, 'a_max': 147}, {'a_min': 0, 'a_max': 115},\n",
              "                    {'a_min': 0, 'a_max': 129}, {'a_min': 0, 'a_max': 83},\n",
              "                    {'a_min': 0, 'a_max': 101}, {'a_min': 0, 'a_max': 102}],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__validation_split': masked_array(data=[0.4, 0.1, 0.5, 0.5, 0.1, 0.2, 0.2, 0.4, 0.4, 0.2],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__model__optim': masked_array(data=[<class 'keras.optimizer_v2.adam.Adam'>,\n",
              "                    <class 'keras.optimizer_v2.adam.Adam'>,\n",
              "                    <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
              "                    <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
              "                    <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
              "                    <class 'keras.optimizer_v2.adam.Adam'>,\n",
              "                    <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
              "                    <class 'keras.optimizer_v2.adam.Adam'>,\n",
              "                    <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
              "                    <class 'keras.optimizer_v2.adam.Adam'>],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__model__learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.0001, 0.001, 0.0001, 0.001, 0.001,\n",
              "                    0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__model__layer_nodes': masked_array(data=[list([256, 512]), list([128, 256, 512]),\n",
              "                    list([16, 32]), list([128, 256]), list([256, 512]),\n",
              "                    list([32, 64, 128]), list([256, 512]),\n",
              "                    list([64, 128, 256]), list([64, 128, 256]),\n",
              "                    list([64, 128, 256])],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__model__dropout': masked_array(data=[0.2, 0.1, 0.5, 0.4, 0.1, 0.5, 0.2, 0.4, 0.2, 0.1],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__model__activation': masked_array(data=['tanh', 'tanh', 'relu', 'tanh', 'tanh', 'relu', 'relu',\n",
              "                    'relu', 'tanh', 'sigmoid'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__epochs': masked_array(data=[30, 5, 5, 50, 5, 30, 1, 30, 20, 10],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_trf_reg__regressor__batch_size': masked_array(data=[256, 128, 64, 128, 32, 32, 512, 128, 128, 128],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_scaler': masked_array(data=[StandardScaler(), StandardScaler(), MinMaxScaler(),\n",
              "                    StandardScaler(), StandardScaler(), StandardScaler(),\n",
              "                    MinMaxScaler(), MinMaxScaler(), StandardScaler(),\n",
              "                    MinMaxScaler()],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 136},\n",
              "   'trf_reg__regressor__validation_split': 0.4,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "   'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.2,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 30,\n",
              "   'trf_reg__regressor__batch_size': 256,\n",
              "   'scaler': StandardScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 116},\n",
              "   'trf_reg__regressor__validation_split': 0.1,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "   'trf_reg__regressor__model__layer_nodes': [128, 256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.1,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 5,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': StandardScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 128},\n",
              "   'trf_reg__regressor__validation_split': 0.5,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "   'trf_reg__regressor__model__layer_nodes': [16, 32],\n",
              "   'trf_reg__regressor__model__dropout': 0.5,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 5,\n",
              "   'trf_reg__regressor__batch_size': 64,\n",
              "   'scaler': MinMaxScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 97},\n",
              "   'trf_reg__regressor__validation_split': 0.5,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.0001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.4,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 50,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': StandardScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 147},\n",
              "   'trf_reg__regressor__validation_split': 0.1,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.1,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 5,\n",
              "   'trf_reg__regressor__batch_size': 32,\n",
              "   'scaler': StandardScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 115},\n",
              "   'trf_reg__regressor__validation_split': 0.2,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.0001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [32, 64, 128],\n",
              "   'trf_reg__regressor__model__dropout': 0.5,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 30,\n",
              "   'trf_reg__regressor__batch_size': 32,\n",
              "   'scaler': StandardScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 129},\n",
              "   'trf_reg__regressor__validation_split': 0.2,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.2,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 1,\n",
              "   'trf_reg__regressor__batch_size': 512,\n",
              "   'scaler': MinMaxScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 83},\n",
              "   'trf_reg__regressor__validation_split': 0.4,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.4,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 30,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': MinMaxScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 101},\n",
              "   'trf_reg__regressor__validation_split': 0.4,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.2,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 20,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': StandardScaler()},\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 102},\n",
              "   'trf_reg__regressor__validation_split': 0.2,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.1,\n",
              "   'trf_reg__regressor__model__activation': 'sigmoid',\n",
              "   'trf_reg__regressor__epochs': 10,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': MinMaxScaler()}],\n",
              " 'split0_test_score': array([ 0.58788619,  0.46192711, -0.80789735, -0.12065853,  0.63896514,\n",
              "        -0.00728955,  0.32642349, -0.87882068,  0.35475808, -0.18921452]),\n",
              " 'split1_test_score': array([ 0.4213354 ,  0.24338211, -0.54292841, -0.25081638,  0.43558509,\n",
              "        -0.3276014 ,  0.34520951, -0.99078477,  0.14612622, -0.31086737]),\n",
              " 'mean_test_score': array([ 0.5046108 ,  0.35265461, -0.67541288, -0.18573746,  0.53727511,\n",
              "        -0.16744548,  0.3358165 , -0.93480272,  0.25044215, -0.25004094]),\n",
              " 'std_test_score': array([0.08327539, 0.1092725 , 0.13248447, 0.06507892, 0.10169002,\n",
              "        0.16015593, 0.00939301, 0.05598204, 0.10431593, 0.06082643]),\n",
              " 'rank_test_score': array([ 2,  3,  9,  7,  1,  6,  4, 10,  5,  8], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(list(zip(ss.cv_results_[\"mean_test_score\"],ss.cv_results_[\"params\"])), reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q4bMKyN3GVU",
        "outputId": "2ef18773-6060-45c4-a792-acca3c7509e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.5372751116225745,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 147},\n",
              "   'trf_reg__regressor__validation_split': 0.1,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.1,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 5,\n",
              "   'trf_reg__regressor__batch_size': 32,\n",
              "   'scaler': StandardScaler()}),\n",
              " (0.5046107971957956,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 136},\n",
              "   'trf_reg__regressor__validation_split': 0.4,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "   'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.2,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 30,\n",
              "   'trf_reg__regressor__batch_size': 256,\n",
              "   'scaler': StandardScaler()}),\n",
              " (0.3526546121848719,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 116},\n",
              "   'trf_reg__regressor__validation_split': 0.1,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "   'trf_reg__regressor__model__layer_nodes': [128, 256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.1,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 5,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': StandardScaler()}),\n",
              " (0.3358164983376524,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 129},\n",
              "   'trf_reg__regressor__validation_split': 0.2,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "   'trf_reg__regressor__model__dropout': 0.2,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 1,\n",
              "   'trf_reg__regressor__batch_size': 512,\n",
              "   'scaler': MinMaxScaler()}),\n",
              " (0.25044214966042627,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 101},\n",
              "   'trf_reg__regressor__validation_split': 0.4,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.2,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 20,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': StandardScaler()}),\n",
              " (-0.16744547570535995,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 115},\n",
              "   'trf_reg__regressor__validation_split': 0.2,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.0001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [32, 64, 128],\n",
              "   'trf_reg__regressor__model__dropout': 0.5,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 30,\n",
              "   'trf_reg__regressor__batch_size': 32,\n",
              "   'scaler': StandardScaler()}),\n",
              " (-0.1857374551746026,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 97},\n",
              "   'trf_reg__regressor__validation_split': 0.5,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.0001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.4,\n",
              "   'trf_reg__regressor__model__activation': 'tanh',\n",
              "   'trf_reg__regressor__epochs': 50,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': StandardScaler()}),\n",
              " (-0.25004094445027514,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 102},\n",
              "   'trf_reg__regressor__validation_split': 0.2,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.1,\n",
              "   'trf_reg__regressor__model__activation': 'sigmoid',\n",
              "   'trf_reg__regressor__epochs': 10,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': MinMaxScaler()}),\n",
              " (-0.6754128769970398,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 128},\n",
              "   'trf_reg__regressor__validation_split': 0.5,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "   'trf_reg__regressor__model__layer_nodes': [16, 32],\n",
              "   'trf_reg__regressor__model__dropout': 0.5,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 5,\n",
              "   'trf_reg__regressor__batch_size': 64,\n",
              "   'scaler': MinMaxScaler()}),\n",
              " (-0.9348027242421618,\n",
              "  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 83},\n",
              "   'trf_reg__regressor__validation_split': 0.4,\n",
              "   'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "   'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "   'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "   'trf_reg__regressor__model__dropout': 0.4,\n",
              "   'trf_reg__regressor__model__activation': 'relu',\n",
              "   'trf_reg__regressor__epochs': 30,\n",
              "   'trf_reg__regressor__batch_size': 128,\n",
              "   'scaler': MinMaxScaler()})]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXCjZlkB3I8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss.cv_results_[\"params\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODHyI8xa29Mt",
        "outputId": "6877d7d1-2ae1-4875-b633-bfb0c675c7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 136},\n",
              "  'trf_reg__regressor__validation_split': 0.4,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "  'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "  'trf_reg__regressor__model__dropout': 0.2,\n",
              "  'trf_reg__regressor__model__activation': 'tanh',\n",
              "  'trf_reg__regressor__epochs': 30,\n",
              "  'trf_reg__regressor__batch_size': 256,\n",
              "  'scaler': StandardScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 116},\n",
              "  'trf_reg__regressor__validation_split': 0.1,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "  'trf_reg__regressor__model__layer_nodes': [128, 256, 512],\n",
              "  'trf_reg__regressor__model__dropout': 0.1,\n",
              "  'trf_reg__regressor__model__activation': 'tanh',\n",
              "  'trf_reg__regressor__epochs': 5,\n",
              "  'trf_reg__regressor__batch_size': 128,\n",
              "  'scaler': StandardScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 128},\n",
              "  'trf_reg__regressor__validation_split': 0.5,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.01,\n",
              "  'trf_reg__regressor__model__layer_nodes': [16, 32],\n",
              "  'trf_reg__regressor__model__dropout': 0.5,\n",
              "  'trf_reg__regressor__model__activation': 'relu',\n",
              "  'trf_reg__regressor__epochs': 5,\n",
              "  'trf_reg__regressor__batch_size': 64,\n",
              "  'scaler': MinMaxScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 97},\n",
              "  'trf_reg__regressor__validation_split': 0.5,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.0001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [128, 256],\n",
              "  'trf_reg__regressor__model__dropout': 0.4,\n",
              "  'trf_reg__regressor__model__activation': 'tanh',\n",
              "  'trf_reg__regressor__epochs': 50,\n",
              "  'trf_reg__regressor__batch_size': 128,\n",
              "  'scaler': StandardScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 147},\n",
              "  'trf_reg__regressor__validation_split': 0.1,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "  'trf_reg__regressor__model__dropout': 0.1,\n",
              "  'trf_reg__regressor__model__activation': 'tanh',\n",
              "  'trf_reg__regressor__epochs': 5,\n",
              "  'trf_reg__regressor__batch_size': 32,\n",
              "  'scaler': StandardScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 115},\n",
              "  'trf_reg__regressor__validation_split': 0.2,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.0001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [32, 64, 128],\n",
              "  'trf_reg__regressor__model__dropout': 0.5,\n",
              "  'trf_reg__regressor__model__activation': 'relu',\n",
              "  'trf_reg__regressor__epochs': 30,\n",
              "  'trf_reg__regressor__batch_size': 32,\n",
              "  'scaler': StandardScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 129},\n",
              "  'trf_reg__regressor__validation_split': 0.2,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [256, 512],\n",
              "  'trf_reg__regressor__model__dropout': 0.2,\n",
              "  'trf_reg__regressor__model__activation': 'relu',\n",
              "  'trf_reg__regressor__epochs': 1,\n",
              "  'trf_reg__regressor__batch_size': 512,\n",
              "  'scaler': MinMaxScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 83},\n",
              "  'trf_reg__regressor__validation_split': 0.4,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "  'trf_reg__regressor__model__dropout': 0.4,\n",
              "  'trf_reg__regressor__model__activation': 'relu',\n",
              "  'trf_reg__regressor__epochs': 30,\n",
              "  'trf_reg__regressor__batch_size': 128,\n",
              "  'scaler': MinMaxScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 101},\n",
              "  'trf_reg__regressor__validation_split': 0.4,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.rmsprop.RMSprop,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "  'trf_reg__regressor__model__dropout': 0.2,\n",
              "  'trf_reg__regressor__model__activation': 'tanh',\n",
              "  'trf_reg__regressor__epochs': 20,\n",
              "  'trf_reg__regressor__batch_size': 128,\n",
              "  'scaler': StandardScaler()},\n",
              " {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 102},\n",
              "  'trf_reg__regressor__validation_split': 0.2,\n",
              "  'trf_reg__regressor__model__optim': keras.optimizer_v2.adam.Adam,\n",
              "  'trf_reg__regressor__model__learning_rate': 0.001,\n",
              "  'trf_reg__regressor__model__layer_nodes': [64, 128, 256],\n",
              "  'trf_reg__regressor__model__dropout': 0.1,\n",
              "  'trf_reg__regressor__model__activation': 'sigmoid',\n",
              "  'trf_reg__regressor__epochs': 10,\n",
              "  'trf_reg__regressor__batch_size': 128,\n",
              "  'scaler': MinMaxScaler()}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~5min\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        # \"trf_reg__regressor__model__layer_nodes\": [\n",
        "        #     #[16],[32],[64],[128],[256],[512],\n",
        "        #     [16,32],[32,64],[64,128],[128,256],[256,512]\n",
        "        #     #[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]\n",
        "        # ],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": [\n",
        "            #[16],[32],[64],[128],[256],[512],\n",
        "            [16,32],[32,64],[64,128],[128,256],[256,512]\n",
        "            #[16, 32, 64], [32, 64, 128], [64, 128, 256], [128, 256, 512]\n",
        "        ],\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }\n",
        "\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                            scorer='r2', ignore_warnings=True, cv=2)\n",
        "    print(model)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7uG8Q8Y2UET",
        "outputId": "719c0fd1-56a6-4bea-d82f-ac3c425507c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 2 folds for each of 41 candidates, totalling 82 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 133}, 'trf_reg__regressor__validation_split': 0.1, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, 'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [64, 128], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 10, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
            "                ('scaler', StandardScaler()),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fdee07c9550>], epochs=10, model=<function create_model_pol3_iter at 0x7fdf2d7c53b0>, model__activation='relu', model__dropo...1, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fdee07c95d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fdee07c9c90>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.1, verbose=0),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7fe0443c3c20>,\n",
            "                                                                            kw_args={'a_max': 133,\n",
            "                                                                                     'a_min': 0})))])\n",
            "Finished: 2022-09-14 12:47:47.254812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 135}, \n",
        "'trf_reg__regressor__validation_split': 0.5, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.01, \n",
        "'trf_reg__regressor__model__layer_nodes': [16], \n",
        "'trf_reg__regressor__model__dropout': 0.2, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 50, \n",
        "'trf_reg__regressor__batch_size': 32,\n",
        " 'scaler': StandardScaler()}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "RukiR9jF4kvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol3_iter, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.5, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.01, \n",
        "                                model__layer_nodes=[16],\n",
        "                                model__dropout=0.2,\n",
        "                                model__activation=\"relu\",\n",
        "                                model__print_summary=True,\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':135})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A5hFcCBzBt6",
        "outputId": "9a03d16d-90c0-4a19-995c-dab0761f8ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fdf147adc90>, <keras.callbacks.LambdaCallback object at 0x7fdf147a5d50>], epochs=10, model=<function create_model_pol3_iter..._metrics=[<keras.metrics.RootMeanSquaredError object at 0x7fdf14399450>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fde97049590>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__print_summary=True, validation_split=0.1, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fe0443c3c20>,\n",
              "                                                                            kw_args={'a_max': 133,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 133}, \n",
        "'trf_reg__regressor__validation_split': 0.1, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.adam.Adam'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.001, \n",
        "'trf_reg__regressor__model__layer_nodes': [64, 128], \n",
        "'trf_reg__regressor__model__dropout': 0.1, \n",
        "'trf_reg__regressor__model__activation': 'relu',\n",
        " 'trf_reg__regressor__epochs': 10, \n",
        " 'trf_reg__regressor__batch_size': 32,\n",
        "  'scaler': StandardScaler()}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vjP6dEqeCu01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol3_iter, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=Adam,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[64,128],\n",
        "                                model__dropout=0.2,\n",
        "                                model__activation=\"relu\",\n",
        "                                model__print_summary=True,\n",
        "                                epochs=10, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':133})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "id": "gjJudvrIDQJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8opv-kbyh-Z",
        "outputId": "36ea85d1-6a6b-4541-a029-a07e96410947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_427\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1178 (Dense)          (None, 64)                129600    \n",
            "                                                                 \n",
            " dropout_752 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1179 (Dense)          (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_753 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1180 (Dense)          (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,049\n",
            "Trainable params: 138,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1524.700, rmse=39.047, r2=0.230; v_loss=775.172, v_rmse=27.842, v_r2=0.602; \n",
            "E 1\t: loss=850.998, rmse=29.172, r2=0.570; v_loss=579.347, v_rmse=24.070, v_r2=0.703; \n",
            "E 2\t: loss=692.856, rmse=26.322, r2=0.650; v_loss=569.391, v_rmse=23.862, v_r2=0.708; \n",
            "E 3\t: loss=636.874, rmse=25.236, r2=0.678; v_loss=572.953, v_rmse=23.936, v_r2=0.706; \n",
            "E 4\t: loss=617.942, rmse=24.858, r2=0.688; v_loss=492.087, v_rmse=22.183, v_r2=0.747; \n",
            "E 5\t: loss=595.339, rmse=24.400, r2=0.699; v_loss=474.707, v_rmse=21.788, v_r2=0.756; \n",
            "E 6\t: loss=581.318, rmse=24.111, r2=0.706; v_loss=514.013, v_rmse=22.672, v_r2=0.736; \n",
            "E 7\t: loss=571.581, rmse=23.908, r2=0.711; v_loss=475.672, v_rmse=21.810, v_r2=0.756; \n",
            "E 8\t: loss=565.478, rmse=23.780, r2=0.714; v_loss=471.381, v_rmse=21.711, v_r2=0.758; \n",
            "E 9\t: loss=567.836, rmse=23.829, r2=0.713; v_loss=469.989, v_rmse=21.679, v_r2=0.759; \n",
            "R2=0.772,RMSE=-21.261\n",
            "Finished: 2022-09-14 12:51:00.935846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF 2"
      ],
      "metadata": {
        "id": "beTeF_UDzYI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "list(itertools.combinations([16,32,64], 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JPy_WLjDmQY",
        "outputId": "39f609c4-99a4-4789-dcf5-55823ff34d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16, 32), (16, 64), (32, 64)]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions = {\n",
        "        \"scaler\": [MinMaxScaler(),StandardScaler()],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__epochs\": [1,5,10,20,30,50],\n",
        "        \"trf_reg__regressor__validation_split\":[0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__batch_size\": [32,64,128,256,512],\n",
        "        \"trf_reg__regressor__model__optim\":[Adam,RMSprop],\n",
        "        \"trf_reg__regressor__model__learning_rate\": [1e-2,1e-3,1e-4],\n",
        "        \"trf_reg__regressor__model__dropout\": [0.1,0.2,0.4,0.5],\n",
        "        \"trf_reg__regressor__model__layer_nodes\": all_permutations([16,32,64,128,256,512], 2),\n",
        "        \"trf_reg__regressor__model__activation\": [\"relu\",\"tanh\", \"sigmoid\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "L_BDSV90wygO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV, HalvingGridSearchCV\n",
        "\n",
        "\n",
        "s = HalvingRandomSearchCV(model, param_distributions, factor=2,\n",
        "                               min_resources=500, scoring='r2', \n",
        "                               random_state=42, verbose=1, cv=3)\n",
        "\n",
        "\n",
        "s.fit(X_train, y_train);\n",
        "print(\"Best params: \", s.best_params_)"
      ],
      "metadata": {
        "id": "1Rpq82MJpnVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce9d21d-92cf-440c-89e7-a0c9992602ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 6\n",
            "n_required_iterations: 6\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 3 folds for each of 41 candidates, totalling 123 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8a382e9b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8a32042680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8a32519440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_train_function.<locals>.train_function at 0x7f8a38362c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8a381823b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 454 calls to <function Model.make_train_function.<locals>.train_function at 0x7f8a0a1ff050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 21\n",
            "n_resources: 1000\n",
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 11\n",
            "n_resources: 2000\n",
            "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 6\n",
            "n_resources: 4000\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "----------\n",
            "iter: 4\n",
            "n_candidates: 3\n",
            "n_resources: 8000\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 5\n",
            "n_candidates: 2\n",
            "n_resources: 16000\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119}, 'trf_reg__regressor__validation_split': 0.1, 'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [128, 32], 'trf_reg__regressor__model__dropout': 0.1, 'trf_reg__regressor__model__activation': 'relu', 'trf_reg__regressor__epochs': 50, 'trf_reg__regressor__batch_size': 32, 'scaler': StandardScaler()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 122}, \n",
        "'trf_reg__regressor__validation_split': 0.4, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, \n",
        "'trf_reg__regressor__model__learning_rate': 0.001, 'trf_reg__regressor__model__layer_nodes': [16, 256], \n",
        "'trf_reg__regressor__model__dropout': 0.2, \n",
        "'trf_reg__regressor__model__activation': 'relu', \n",
        "'trf_reg__regressor__epochs': 20, \n",
        "'trf_reg__regressor__batch_size': 64, \n",
        "'scaler': StandardScaler()}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "O8h3t0G80zXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 119}, \n",
        "'trf_reg__regressor__validation_split': 0.1, \n",
        "'trf_reg__regressor__model__optim': <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        " 'trf_reg__regressor__model__learning_rate': 0.001, \n",
        " 'trf_reg__regressor__model__layer_nodes': [128, 32], \n",
        " 'trf_reg__regressor__model__dropout': 0.1, \n",
        " 'trf_reg__regressor__model__activation': 'relu', \n",
        " 'trf_reg__regressor__epochs': 50,\n",
        "  'trf_reg__regressor__batch_size': 32,\n",
        "   'scaler': StandardScaler()}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gEvZW1tO0zMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('scaler'   ,   StandardScaler()),\n",
        "    ('trf_reg'  ,   TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = KerasRegressor(\n",
        "                                model=create_model_pol3_iter, \n",
        "                                model__metrics=[RMSE(), R2()],\n",
        "                                model__loss='mse',\n",
        "                                verbose=0, callbacks=[es,printerCallback],  \n",
        "                                validation_split=0.1, \n",
        "                                model__optim=RMSprop,\n",
        "                                model__learning_rate=0.001, \n",
        "                                model__layer_nodes=[128,32],\n",
        "                                model__dropout=0.1,\n",
        "                                model__activation=\"relu\",\n",
        "                                model__print_summary=True,\n",
        "                                epochs=50, \n",
        "                                batch_size=32),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':119})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftR7f0HMN0eM",
        "outputId": "be378271-662d-4094-a2dd-6e205e37a588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f8ad2298910>, <keras.callbacks.LambdaCallback object at 0x7f8ad22a8f10>], epochs=50, model=<function create_model_pol3_iter...cs=[<keras.metrics.RootMeanSquaredError object at 0x7f8a24130950>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f8a32411810>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__print_summary=True, validation_split=0.1, verbose=0),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7f8b4de4ec20>,\n",
              "                                                                            kw_args={'a_max': 119,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9dc7068-abcc-4c73-ac1d-c4579a690c87",
        "id": "FTEuSqEr1NiD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_280\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_850 (Dense)           (None, 128)               259200    \n",
            "                                                                 \n",
            " dropout_570 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_851 (Dense)           (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_571 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_852 (Dense)           (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 263,361\n",
            "Trainable params: 263,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 0\t: loss=1021.892, rmse=31.967, r2=0.346; v_loss=649.613, v_rmse=25.488, v_r2=0.570; \n",
            "E 1\t: loss=594.124, rmse=24.375, r2=0.620; v_loss=650.956, v_rmse=25.514, v_r2=0.569; \n",
            "E 2\t: loss=508.236, rmse=22.544, r2=0.675; v_loss=438.164, v_rmse=20.932, v_r2=0.710; \n",
            "E 3\t: loss=465.323, rmse=21.571, r2=0.702; v_loss=457.153, v_rmse=21.381, v_r2=0.697; \n",
            "E 4\t: loss=443.010, rmse=21.048, r2=0.717; v_loss=462.887, v_rmse=21.515, v_r2=0.694; \n",
            "E 5\t: loss=434.055, rmse=20.834, r2=0.722; v_loss=459.578, v_rmse=21.438, v_r2=0.696; \n",
            "E 6\t: loss=418.458, rmse=20.456, r2=0.732; v_loss=342.186, v_rmse=18.498, v_r2=0.774; \n",
            "E 7\t: loss=411.598, rmse=20.288, r2=0.737; v_loss=345.709, v_rmse=18.593, v_r2=0.771; \n",
            "E 8\t: loss=402.190, rmse=20.055, r2=0.743; v_loss=480.644, v_rmse=21.924, v_r2=0.682; \n",
            "E 9\t: loss=398.085, rmse=19.952, r2=0.745; v_loss=320.973, v_rmse=17.916, v_r2=0.788; \n",
            "E 10\t: loss=395.100, rmse=19.877, r2=0.747; v_loss=347.136, v_rmse=18.632, v_r2=0.770; \n",
            "E 11\t: loss=383.288, rmse=19.578, r2=0.755; v_loss=370.581, v_rmse=19.250, v_r2=0.755; \n",
            "E 12\t: loss=386.817, rmse=19.668, r2=0.753; v_loss=680.649, v_rmse=26.089, v_r2=0.550; \n",
            "E 13\t: loss=385.274, rmse=19.628, r2=0.754; v_loss=660.803, v_rmse=25.706, v_r2=0.563; \n",
            "E 14\t: loss=377.518, rmse=19.430, r2=0.759; v_loss=343.432, v_rmse=18.532, v_r2=0.773; \n",
            "E 15\t: loss=375.605, rmse=19.381, r2=0.760; v_loss=452.049, v_rmse=21.261, v_r2=0.701; \n",
            "E 16\t: loss=373.217, rmse=19.319, r2=0.761; v_loss=354.190, v_rmse=18.820, v_r2=0.766; \n",
            "E 17\t: loss=371.758, rmse=19.281, r2=0.762; v_loss=316.642, v_rmse=17.794, v_r2=0.790; \n",
            "E 18\t: loss=370.005, rmse=19.236, r2=0.763; v_loss=368.338, v_rmse=19.192, v_r2=0.756; \n",
            "E 19\t: loss=366.518, rmse=19.145, r2=0.766; v_loss=330.057, v_rmse=18.167, v_r2=0.782; \n",
            "E 20\t: loss=363.716, rmse=19.071, r2=0.767; v_loss=462.601, v_rmse=21.508, v_r2=0.694; \n",
            "E 21\t: loss=363.730, rmse=19.072, r2=0.767; v_loss=323.034, v_rmse=17.973, v_r2=0.786; \n",
            "E 22\t: loss=361.478, rmse=19.013, r2=0.769; v_loss=389.459, v_rmse=19.735, v_r2=0.742; \n",
            "E 23\t: loss=364.095, rmse=19.081, r2=0.767; v_loss=431.852, v_rmse=20.781, v_r2=0.714; \n",
            "E 24\t: loss=358.437, rmse=18.932, r2=0.771; v_loss=325.702, v_rmse=18.047, v_r2=0.784; \n",
            "E 25\t: loss=357.162, rmse=18.899, r2=0.772; v_loss=355.768, v_rmse=18.862, v_r2=0.765; \n",
            "E 26\t: loss=357.109, rmse=18.897, r2=0.772; v_loss=352.083, v_rmse=18.764, v_r2=0.767; \n",
            "E 27\t: loss=357.320, rmse=18.903, r2=0.771; v_loss=372.086, v_rmse=19.290, v_r2=0.754; \n",
            "E 28\t: loss=355.524, rmse=18.855, r2=0.773; v_loss=327.776, v_rmse=18.105, v_r2=0.783; \n",
            "E 29\t: loss=351.629, rmse=18.752, r2=0.775; v_loss=480.164, v_rmse=21.913, v_r2=0.682; \n",
            "E 30\t: loss=354.156, rmse=18.819, r2=0.773; v_loss=315.904, v_rmse=17.774, v_r2=0.791; \n",
            "E 31\t: loss=351.878, rmse=18.758, r2=0.775; v_loss=656.191, v_rmse=25.616, v_r2=0.566; \n",
            "E 32\t: loss=349.779, rmse=18.702, r2=0.776; v_loss=321.974, v_rmse=17.944, v_r2=0.787; \n",
            "E 33\t: loss=349.292, rmse=18.689, r2=0.777; v_loss=330.540, v_rmse=18.181, v_r2=0.781; \n",
            "E 34\t: loss=349.142, rmse=18.685, r2=0.777; v_loss=378.742, v_rmse=19.461, v_r2=0.749; \n",
            "E 35\t: loss=347.969, rmse=18.654, r2=0.777; v_loss=356.909, v_rmse=18.892, v_r2=0.764; \n",
            "E 36\t: loss=348.179, rmse=18.660, r2=0.777; v_loss=311.871, v_rmse=17.660, v_r2=0.794; \n",
            "E 37\t: loss=349.973, rmse=18.708, r2=0.776; v_loss=328.919, v_rmse=18.136, v_r2=0.782; \n",
            "E 38\t: loss=346.920, rmse=18.626, r2=0.778; v_loss=393.217, v_rmse=19.830, v_r2=0.740; \n",
            "E 39\t: loss=346.353, rmse=18.611, r2=0.778; v_loss=307.477, v_rmse=17.535, v_r2=0.797; \n",
            "E 40\t: loss=344.972, rmse=18.573, r2=0.779; v_loss=383.138, v_rmse=19.574, v_r2=0.746; \n",
            "E 41\t: loss=347.039, rmse=18.629, r2=0.778; v_loss=506.417, v_rmse=22.504, v_r2=0.665; \n",
            "E 42\t: loss=341.358, rmse=18.476, r2=0.782; v_loss=314.362, v_rmse=17.730, v_r2=0.792; \n",
            "E 43\t: loss=345.449, rmse=18.586, r2=0.779; v_loss=306.207, v_rmse=17.499, v_r2=0.797; \n",
            "E 44\t: loss=341.947, rmse=18.492, r2=0.781; v_loss=376.357, v_rmse=19.400, v_r2=0.751; \n",
            "E 45\t: loss=344.674, rmse=18.565, r2=0.780; v_loss=525.699, v_rmse=22.928, v_r2=0.652; \n",
            "E 46\t: loss=342.813, rmse=18.515, r2=0.781; v_loss=320.140, v_rmse=17.892, v_r2=0.788; \n",
            "E 47\t: loss=343.314, rmse=18.529, r2=0.780; v_loss=355.605, v_rmse=18.857, v_r2=0.765; \n",
            "R2=0.818,RMSE=-16.839\n",
            "Finished: 2022-09-15 11:48:55.049088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WPhqCgqOq0r",
        "outputId": "75d56174-537d-4e10-9566-cb7b50e12928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=5207.414, rmse=72.162, r2=-0.345; v_loss=3045.556, v_rmse=55.187, v_r2=0.451; \n",
            "E 1\t: loss=1527.117, rmse=39.078, r2=0.606; v_loss=2813.525, v_rmse=53.043, v_r2=0.493; \n",
            "E 2\t: loss=1359.615, rmse=36.873, r2=0.649; v_loss=2666.109, v_rmse=51.634, v_r2=0.519; \n",
            "E 3\t: loss=1315.130, rmse=36.265, r2=0.660; v_loss=2877.303, v_rmse=53.640, v_r2=0.481; \n",
            "E 4\t: loss=1290.427, rmse=35.923, r2=0.667; v_loss=2632.022, v_rmse=51.303, v_r2=0.526; \n",
            "E 5\t: loss=1294.368, rmse=35.977, r2=0.666; v_loss=2702.958, v_rmse=51.990, v_r2=0.513; \n",
            "E 6\t: loss=1239.708, rmse=35.209, r2=0.680; v_loss=3236.657, v_rmse=56.892, v_r2=0.417; \n",
            "E 7\t: loss=1272.573, rmse=35.673, r2=0.671; v_loss=3314.008, v_rmse=57.567, v_r2=0.403; \n",
            "E 8\t: loss=1270.919, rmse=35.650, r2=0.672; v_loss=2804.315, v_rmse=52.956, v_r2=0.494; \n",
            "E 9\t: loss=1257.236, rmse=35.458, r2=0.675; v_loss=2682.475, v_rmse=51.793, v_r2=0.516; \n",
            "E 10\t: loss=1252.234, rmse=35.387, r2=0.677; v_loss=2580.146, v_rmse=50.795, v_r2=0.535; \n",
            "E 11\t: loss=1235.938, rmse=35.156, r2=0.681; v_loss=2875.703, v_rmse=53.626, v_r2=0.482; \n",
            "E 12\t: loss=1240.101, rmse=35.215, r2=0.680; v_loss=2998.597, v_rmse=54.759, v_r2=0.459; \n",
            "E 13\t: loss=1221.820, rmse=34.955, r2=0.684; v_loss=2843.069, v_rmse=53.320, v_r2=0.487; \n",
            "E 14\t: loss=1227.091, rmse=35.030, r2=0.683; v_loss=2900.337, v_rmse=53.855, v_r2=0.477; \n",
            "E 15\t: loss=1202.511, rmse=34.677, r2=0.689; v_loss=2727.129, v_rmse=52.222, v_r2=0.508; \n",
            "E 16\t: loss=1195.381, rmse=34.574, r2=0.691; v_loss=2904.663, v_rmse=53.895, v_r2=0.476; \n",
            "E 17\t: loss=1228.552, rmse=35.051, r2=0.683; v_loss=2963.373, v_rmse=54.437, v_r2=0.466; \n",
            "E 18\t: loss=1216.440, rmse=34.877, r2=0.686; v_loss=3066.665, v_rmse=55.377, v_r2=0.447; \n",
            "E 19\t: loss=1210.912, rmse=34.798, r2=0.687; v_loss=2854.012, v_rmse=53.423, v_r2=0.485; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
              "                ('mlp',\n",
              "                 KerasRegressor(batch_size=128, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f64ae3187d0>, <keras.callbacks.LambdaCallback object at 0x7f64aebf8b10>], epochs=20, model=<function create_model at 0x7f6542c000e0>, model__activation='relu', model__dropout=0.1, model__layer_nodes=[16, 32, 64], model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x7f64ae30f6d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f64ae317350>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, validation_split=0.5, verbose=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "# eval.show_result_cv(y_train, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko0Uz9l_OosC",
        "outputId": "037fc530-5397-407f-9e11-7d7f87429dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E 0\t: loss=4787.087, rmse=61.810, r2=0.195; v_loss=3012.669, v_rmse=54.888, v_r2=0.457; \n",
            "E 1\t: loss=1573.484, rmse=39.667, r2=0.594; v_loss=2781.886, v_rmse=52.744, v_r2=0.499; \n",
            "E 2\t: loss=1422.959, rmse=37.722, r2=0.632; v_loss=2648.300, v_rmse=51.462, v_r2=0.523; \n",
            "E 3\t: loss=1322.943, rmse=36.372, r2=0.658; v_loss=2887.253, v_rmse=53.733, v_r2=0.480; \n",
            "E 4\t: loss=1293.984, rmse=35.972, r2=0.666; v_loss=2671.713, v_rmse=51.689, v_r2=0.518; \n",
            "E 5\t: loss=1264.718, rmse=35.563, r2=0.673; v_loss=2667.296, v_rmse=51.646, v_r2=0.519; \n",
            "E 6\t: loss=1209.704, rmse=34.781, r2=0.688; v_loss=3272.676, v_rmse=57.207, v_r2=0.410; \n",
            "E 7\t: loss=1235.243, rmse=35.146, r2=0.681; v_loss=2919.450, v_rmse=54.032, v_r2=0.474; \n",
            "E 8\t: loss=1193.297, rmse=34.544, r2=0.692; v_loss=2588.395, v_rmse=50.876, v_r2=0.533; \n",
            "E 9\t: loss=1183.923, rmse=34.408, r2=0.694; v_loss=2595.500, v_rmse=50.946, v_r2=0.532; \n",
            "E 10\t: loss=1186.067, rmse=34.439, r2=0.694; v_loss=2638.092, v_rmse=51.362, v_r2=0.524; \n",
            "E 11\t: loss=1173.344, rmse=34.254, r2=0.697; v_loss=2639.616, v_rmse=51.377, v_r2=0.524; \n",
            "E 12\t: loss=1171.831, rmse=34.232, r2=0.697; v_loss=2618.583, v_rmse=51.172, v_r2=0.528; \n",
            "E 13\t: loss=1157.851, rmse=34.027, r2=0.701; v_loss=2592.635, v_rmse=50.918, v_r2=0.533; \n",
            "E 14\t: loss=1162.587, rmse=34.097, r2=0.700; v_loss=2737.344, v_rmse=52.320, v_r2=0.507; \n",
            "E 15\t: loss=1155.371, rmse=33.991, r2=0.702; v_loss=2512.420, v_rmse=50.124, v_r2=0.547; \n",
            "E 16\t: loss=1151.620, rmse=33.936, r2=0.703; v_loss=2696.023, v_rmse=51.923, v_r2=0.514; \n",
            "E 17\t: loss=1180.901, rmse=34.364, r2=0.695; v_loss=2919.380, v_rmse=54.031, v_r2=0.474; \n",
            "E 18\t: loss=1146.900, rmse=33.866, r2=0.704; v_loss=2765.089, v_rmse=52.584, v_r2=0.502; \n",
            "E 19\t: loss=1158.254, rmse=34.033, r2=0.701; v_loss=2695.551, v_rmse=51.919, v_r2=0.514; \n",
            "R2=0.610,RMSE=-43.032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHZRacpvZ4Ht",
        "outputId": "81bb0b7c-3386-4a3b-e307-9317d720cb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.643,RMSE=-24.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVkdXy9TLfvK",
        "outputId": "c5035aab-88ab-4084-ccde-d97441f69bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_check_feature_names',\n",
              " '_check_input_parameters',\n",
              " '_check_n_features',\n",
              " '_check_refit_for_multimetric',\n",
              " '_checked_cv_orig',\n",
              " '_estimator_type',\n",
              " '_format_results',\n",
              " '_generate_candidate_params',\n",
              " '_get_param_names',\n",
              " '_get_tags',\n",
              " '_more_tags',\n",
              " '_n_samples_orig',\n",
              " '_pairwise',\n",
              " '_repr_html_',\n",
              " '_repr_html_inner',\n",
              " '_repr_mimebundle_',\n",
              " '_required_parameters',\n",
              " '_run_search',\n",
              " '_select_best_index',\n",
              " '_validate_data',\n",
              " 'aggressive_elimination',\n",
              " 'best_estimator_',\n",
              " 'best_index_',\n",
              " 'best_params_',\n",
              " 'best_score_',\n",
              " 'classes_',\n",
              " 'cv',\n",
              " 'cv_results_',\n",
              " 'decision_function',\n",
              " 'error_score',\n",
              " 'estimator',\n",
              " 'factor',\n",
              " 'feature_names_in_',\n",
              " 'fit',\n",
              " 'get_params',\n",
              " 'inverse_transform',\n",
              " 'max_resources',\n",
              " 'max_resources_',\n",
              " 'min_resources',\n",
              " 'min_resources_',\n",
              " 'multimetric_',\n",
              " 'n_candidates',\n",
              " 'n_candidates_',\n",
              " 'n_features_in_',\n",
              " 'n_iterations_',\n",
              " 'n_jobs',\n",
              " 'n_possible_iterations_',\n",
              " 'n_remaining_candidates_',\n",
              " 'n_required_iterations_',\n",
              " 'n_resources_',\n",
              " 'n_splits_',\n",
              " 'param_distributions',\n",
              " 'pre_dispatch',\n",
              " 'predict',\n",
              " 'predict_log_proba',\n",
              " 'predict_proba',\n",
              " 'random_state',\n",
              " 'refit',\n",
              " 'refit_time_',\n",
              " 'resource',\n",
              " 'return_train_score',\n",
              " 'score',\n",
              " 'score_samples',\n",
              " 'scorer_',\n",
              " 'scoring',\n",
              " 'set_params',\n",
              " 'transform',\n",
              " 'verbose']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search.score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kavu1LPOMwLV",
        "outputId": "c90228cf-454f-4597-d419-7706c337d9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseSearchCV.score of HalvingRandomSearchCV(cv=3,\n",
              "                      estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
              "                                                ('mlp',\n",
              "                                                 KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x7fdf39694cd0>], model=<function create_model at 0x7fdf49de63b0>, validation_split=0.2, verbose=0))]),\n",
              "                      min_resources=500,\n",
              "                      param_distributions={'mlp__epochs': [1, 5, 10, 20, 30,\n",
              "                                                           50],\n",
              "                                           'mlp__model__activation': ['relu'...\n",
              "                                                                         <keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7fdf439f5910>],\n",
              "                                           'mlp__model__optim': [<class 'keras.optimizer_v2.adam.Adam'>,\n",
              "                                                                 <class 'keras.optimizer_v2.gradient_descent.SGD'>,\n",
              "                                                                 <class 'keras.optimizer_v2.rmsprop.RMSprop'>],\n",
              "                                           'mlp__validation_split': [0.1, 0.2,\n",
              "                                                                     0.4, 0.5],\n",
              "                                           'scaler': [MinMaxScaler(),\n",
              "                                                      StandardScaler()]},\n",
              "                      random_state=42, scoring='r2', verbose=1)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "r6YQTm7aOf2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('tree_reg'  ,   DecisionTreeRegressor(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "4PbFjj3G3QUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"tree_reg__criterion\": [\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
        "        \"tree_reg__splitter\": [\"best\", \"random\"],\n",
        "        \"tree_reg__max_depth\": [None,100,200,300],\n",
        "        \"tree_reg__min_samples_split\": [2,5,10,15,20],\n",
        "        \"tree_reg__min_samples_leaf\": [1,2,5,10,15,20,50,100],\n",
        "        \"tree_reg__max_features\": [\"sqrt\", \"log2\"],\n",
        "        \"tree_reg__min_impurity_decrease\": list(np.arange(0,150)/10),\n",
        "        \"tree_reg__ccp_alpha\": list(np.round(np.linspace(0, 2, 81), decimals=3)),\n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions, \n",
        "                            scorer='r2', ignore_warnings=True)\n",
        "    print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfElIPxBI8w3",
        "outputId": "ff2ab789-ac53-4ba1-8f3e-c4a173db1c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "Best params:  {'tree_reg__splitter': 'best', 'tree_reg__min_samples_split': 2, 'tree_reg__min_samples_leaf': 20, 'tree_reg__min_impurity_decrease': 3.5, 'tree_reg__max_features': 'log2', 'tree_reg__max_depth': 200, 'tree_reg__criterion': 'friedman_mse', 'tree_reg__ccp_alpha': 0.675}\n",
            "Pipeline(steps=[('tree_reg',\n",
            "                 DecisionTreeRegressor(ccp_alpha=0.675,\n",
            "                                       criterion='friedman_mse', max_depth=200,\n",
            "                                       max_features='log2',\n",
            "                                       min_impurity_decrease=3.5,\n",
            "                                       min_samples_leaf=20, random_state=42))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "('tree_reg',\n",
        "DecisionTreeRegressor(ccp_alpha=0.675,\n",
        "                    criterion='friedman_mse', max_depth=200,\n",
        "                    max_features='log2',\n",
        "                    min_impurity_decrease=3.5,\n",
        "                    min_samples_leaf=20, random_state=42))\n",
        "```"
      ],
      "metadata": {
        "id": "bKZoX4i15VzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('tree_reg'  ,   DecisionTreeRegressor(ccp_alpha=0.675,\n",
        "                                    criterion='friedman_mse', max_depth=200,\n",
        "                                    max_features='log2',\n",
        "                                    min_impurity_decrease=3.5,\n",
        "                                    min_samples_leaf=20, random_state=42))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZECiy0kVMXxg",
        "outputId": "d4d05ad5-18e4-45c3-b1f8-6111ca081533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tree_reg',\n",
              "                 DecisionTreeRegressor(ccp_alpha=0.675,\n",
              "                                       criterion='friedman_mse', max_depth=200,\n",
              "                                       max_features='log2',\n",
              "                                       min_impurity_decrease=3.5,\n",
              "                                       min_samples_leaf=20, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "eval.show_result_cv(y_train, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vefcPjT2Xb6y",
        "outputId": "80ecfd48-1b04-4f8a-f431-f82e79cf73fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.645,RMSE=-41.037\n",
            "(CV) R2=0.537,RMSE=-46.205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "367rdLmjRETX",
        "outputId": "f912cdda-5f84-4d8b-d9ed-e5f4ba65e4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.298,RMSE=-34.821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Worse than simple linear regression"
      ],
      "metadata": {
        "id": "Www1kqZTMkE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-linear RUL"
      ],
      "metadata": {
        "id": "klzYEWjrZiXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('trf_reg' ,TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = DecisionTreeRegressor(random_state=42),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':50})))\n",
        "    ])"
      ],
      "metadata": {
        "id": "J42sZdWlFlF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(80,150,1),\n",
        "        \"trf_reg__regressor__criterion\": [\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
        "        \"trf_reg__regressor__splitter\": [\"best\", \"random\"],\n",
        "        \"trf_reg__regressor__max_depth\": [None,100,200,300],\n",
        "        \"trf_reg__regressor__min_samples_split\": [2,5,10,15,20],\n",
        "        \"trf_reg__regressor__min_samples_leaf\": [1,2,5,10,15,20,50,100],\n",
        "        \"trf_reg__regressor__max_features\": [\"sqrt\", \"log2\"],\n",
        "        \"trf_reg__regressor__min_impurity_decrease\": list(np.arange(0,150)/10),\n",
        "        \"trf_reg__regressor__ccp_alpha\": list(np.round(np.linspace(0, 2, 81), decimals=3)) \n",
        "    \n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions)\n",
        "    print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LecVj2kVEJgx",
        "outputId": "c9c714e1-83fc-49fd-f58c-00376eeef415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 98}, 'trf_reg__regressor__splitter': 'best', 'trf_reg__regressor__min_samples_split': 2, 'trf_reg__regressor__min_samples_leaf': 10, 'trf_reg__regressor__min_impurity_decrease': 5.5, 'trf_reg__regressor__max_features': 'sqrt', 'trf_reg__regressor__max_depth': 200, 'trf_reg__regressor__criterion': 'friedman_mse', 'trf_reg__regressor__ccp_alpha': 0.375}\n",
            "Pipeline(steps=[('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=DecisionTreeRegressor(ccp_alpha=0.375,\n",
            "                                                                            criterion='friedman_mse',\n",
            "                                                                            max_depth=200,\n",
            "                                                                            max_features='sqrt',\n",
            "                                                                            min_impurity_decrease=5.5,\n",
            "                                                                            min_samples_leaf=10,\n",
            "                                                                            random_state=42),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7fd35e8e7cb0>,\n",
            "                                                                            kw_args={'a_max': 98,\n",
            "                                                                                     'a_min': 0})))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "\n",
        "```\n",
        "{'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 98}}\n",
        "\n",
        "DecisionTreeRegressor(ccp_alpha=0.375,\n",
        "                    criterion='friedman_mse',\n",
        "                    max_depth=200,\n",
        "                    max_features='sqrt',\n",
        "                    min_impurity_decrease=5.5,\n",
        "                    min_samples_leaf=10,\n",
        "                    random_state=42),\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "941d0KXxMZsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('trf_reg' ,TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = DecisionTreeRegressor(ccp_alpha=0.375,\n",
        "                            criterion='friedman_mse',\n",
        "                            max_depth=200,\n",
        "                            max_features='sqrt',\n",
        "                            min_impurity_decrease=5.5,\n",
        "                            min_samples_leaf=10,\n",
        "                            random_state=42),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':98})))\n",
        "    ])\n",
        "model"
      ],
      "metadata": {
        "id": "e0OEtLzeEgOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27321cbc-4bc8-4d5e-c0d1-88da197d8641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=DecisionTreeRegressor(ccp_alpha=0.375,\n",
              "                                                                            criterion='friedman_mse',\n",
              "                                                                            max_depth=200,\n",
              "                                                                            max_features='sqrt',\n",
              "                                                                            min_impurity_decrease=5.5,\n",
              "                                                                            min_samples_leaf=10,\n",
              "                                                                            random_state=42),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fd35e8e7cb0>,\n",
              "                                                                            kw_args={'a_max': 98,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "eval.show_result_cv(reclipped_y, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa38b155-e8c6-464c-f698-c583f63583dd",
        "id": "8SVqLYhUF3aY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.815,RMSE=-13.536\n",
            "(CV) R2=0.781,RMSE=-14.680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de05e043-000d-4c5a-f12d-2c7d2033a2e1",
        "id": "JoP9s0laF3aU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.819,RMSE=-14.277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best result we had so far in training and in testing"
      ],
      "metadata": {
        "id": "VKSLMt6WOUtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "MQi8MHh20wou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures()),\n",
        "    ('tree_reg'  ,   DecisionTreeRegressor(random_state=42))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4ee0be-7e95-4caf-c2ec-922926c9c501",
        "id": "g3KHHSwr0wow"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures()),\n",
              "                ('tree_reg', DecisionTreeRegressor(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"poly_ft__degree\": [1,2,3],\n",
        "        \"poly_ft__interaction_only\": [False, True],\n",
        "        \"poly_ft__include_bias\": [True, False],\n",
        "        \"tree_reg__criterion\": [\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
        "        \"tree_reg__splitter\": [\"best\", \"random\"],\n",
        "        \"tree_reg__max_depth\": [None,100,200,300],\n",
        "        \"tree_reg__min_samples_split\": [2,5,10,15,20],\n",
        "        \"tree_reg__min_samples_leaf\": [1,2,5,10,15,20,50,100],\n",
        "        \"tree_reg__max_features\": [None, \"sqrt\", \"log2\"],\n",
        "        \"tree_reg__min_impurity_decrease\": list(np.arange(0,150)/10),\n",
        "        \"tree_reg__ccp_alpha\": list(np.round(np.linspace(0, 2, 81), decimals=3)) \n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, \n",
        "                            param_distributions, scorer='r2')\n",
        "    print(model)"
      ],
      "metadata": {
        "id": "datMycLD0wox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "735e4792-b1a1-4468-a773-3574b510f52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "Best params:  {'tree_reg__splitter': 'random', 'tree_reg__min_samples_split': 15, 'tree_reg__min_samples_leaf': 15, 'tree_reg__min_impurity_decrease': 6.9, 'tree_reg__max_features': 'sqrt', 'tree_reg__max_depth': 100, 'tree_reg__criterion': 'squared_error', 'tree_reg__ccp_alpha': 1.025, 'poly_ft__interaction_only': False, 'poly_ft__include_bias': True, 'poly_ft__degree': 3}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
            "                ('tree_reg',\n",
            "                 DecisionTreeRegressor(ccp_alpha=1.025, max_depth=100,\n",
            "                                       max_features='sqrt',\n",
            "                                       min_impurity_decrease=6.9,\n",
            "                                       min_samples_leaf=15,\n",
            "                                       min_samples_split=15, random_state=42,\n",
            "                                       splitter='random'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "PolynomialFeatures(degree=3)\n",
        "DecisionTreeRegressor(ccp_alpha=1.025, max_depth=100,\n",
        "                    max_features='sqrt',\n",
        "                    min_impurity_decrease=6.9,\n",
        "                    min_samples_leaf=15,\n",
        "                    min_samples_split=15, random_state=42,\n",
        "                    splitter='random'))\n",
        "```\n"
      ],
      "metadata": {
        "id": "ELoCa-ue0woy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures(degree=3)),\n",
        "    ('tree_reg'  ,   DecisionTreeRegressor(ccp_alpha=1.025, max_depth=100,\n",
        "                                        max_features='sqrt',\n",
        "                                        min_impurity_decrease=6.9,\n",
        "                                        min_samples_leaf=15,\n",
        "                                        min_samples_split=15, random_state=42,\n",
        "                                        splitter='random'))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf862ca-b889-43bd-d278-2a64ca673e59",
        "id": "7Lqp1b3N0woz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('tree_reg',\n",
              "                 DecisionTreeRegressor(ccp_alpha=1.025, max_depth=100,\n",
              "                                       max_features='sqrt',\n",
              "                                       min_impurity_decrease=6.9,\n",
              "                                       min_samples_leaf=15,\n",
              "                                       min_samples_split=15, random_state=42,\n",
              "                                       splitter='random'))])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "eval.show_result(y_train, model.predict(X_train))\n",
        "eval.show_result_cv(y_train, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90553d9-e342-4315-b849-09273c210c4a",
        "id": "31OBJmT60wo1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.580,RMSE=-44.656\n",
            "(CV) R2=0.550,RMSE=-45.641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval.show_result(y_test, model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bb29b7-7390-4acc-a90b-36aa6293e58b",
        "id": "PWLNXSit0wo2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.311,RMSE=-34.484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No clear benefit from polynomial features in linear RUL, as with the other models. Actually, it worsened the results."
      ],
      "metadata": {
        "id": "9WTjNfG70wo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL"
      ],
      "metadata": {
        "id": "BlwL5EnXQcuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft'  ,   PolynomialFeatures()),\n",
        "    ('trf_reg' ,TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = DecisionTreeRegressor(random_state=42),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':96})))\n",
        "])"
      ],
      "metadata": {
        "id": "CH-5TST3Qkrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"poly_ft__degree\": [1,2,3],\n",
        "        \"poly_ft__interaction_only\": [False, True],\n",
        "        \"poly_ft__include_bias\": [True, False],\n",
        "        \"trf_reg__transformer__kw_args\": search.generate_clip_dicts(70,150,1),\n",
        "        \"trf_reg__regressor__criterion\": [\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
        "        \"trf_reg__regressor__splitter\": [\"best\", \"random\"],\n",
        "        \"trf_reg__regressor__max_depth\": [None,100,200,300],\n",
        "        \"trf_reg__regressor__min_samples_split\": [2,5,10,15,20],\n",
        "        \"trf_reg__regressor__min_samples_leaf\": [1,2,5,10,15,20,50,100],\n",
        "        \"trf_reg__regressor__max_features\": [None, \"sqrt\", \"log2\"],\n",
        "        \"trf_reg__regressor__min_impurity_decrease\": list(np.arange(0,150)/10),\n",
        "        \"trf_reg__regressor__ccp_alpha\": list(np.round(np.linspace(0, 2, 81), decimals=3)) \n",
        "    }\n",
        "    model = search.run_HR_GS(model, X_train, y_train, param_distributions)\n",
        "    print(model)"
      ],
      "metadata": {
        "id": "RKz_WrPIyNZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe1f71c-ba41-42c8-88c0-365f2d396323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 500\n",
            "max_resources_: 20631\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 41\n",
            "n_resources: 500\n",
            "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 14\n",
            "n_resources: 1500\n",
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 5\n",
            "n_resources: 4500\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 13500\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "Best params:  {'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 71}, 'trf_reg__regressor__splitter': 'random', 'trf_reg__regressor__min_samples_split': 20, 'trf_reg__regressor__min_samples_leaf': 2, 'trf_reg__regressor__min_impurity_decrease': 8.5, 'trf_reg__regressor__max_features': None, 'trf_reg__regressor__max_depth': 200, 'trf_reg__regressor__criterion': 'squared_error', 'trf_reg__regressor__ccp_alpha': 1.85, 'poly_ft__interaction_only': False, 'poly_ft__include_bias': True, 'poly_ft__degree': 3}\n",
            "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
            "                ('trf_reg',\n",
            "                 TransformedTargetRegressor(check_inverse=False,\n",
            "                                            regressor=DecisionTreeRegressor(ccp_alpha=1.85,\n",
            "                                                                            max_depth=200,\n",
            "                                                                            min_impurity_decrease=8.5,\n",
            "                                                                            min_samples_leaf=2,\n",
            "                                                                            min_samples_split=20,\n",
            "                                                                            random_state=42,\n",
            "                                                                            splitter='random'),\n",
            "                                            transformer=FunctionTransformer(func=<function clip at 0x7fd35e8e7cb0>,\n",
            "                                                                            kw_args={'a_max': 71,\n",
            "                                                                                     'a_min': 0})))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model:\n",
        "```\n",
        "'trf_reg__transformer__kw_args': {'a_min': 0, 'a_max': 71}\n",
        "PolynomialFeatures(degree=3)\n",
        "DecisionTreeRegressor(ccp_alpha=1.85,\n",
        "                        max_depth=200,\n",
        "                        min_impurity_decrease=8.5,\n",
        "                        min_samples_leaf=2,\n",
        "                        min_samples_split=20,\n",
        "                        random_state=42,\n",
        "                        splitter='random'),\n",
        "```\n"
      ],
      "metadata": {
        "id": "Vup8Svzqyt6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly_ft', PolynomialFeatures(degree=3)),\n",
        "    ('trf_reg' ,TransformedTargetRegressor(\n",
        "        check_inverse=False,\n",
        "        regressor   = DecisionTreeRegressor(ccp_alpha=1.85,\n",
        "                                            max_depth=200,\n",
        "                                            min_impurity_decrease=8.5,\n",
        "                                            min_samples_leaf=2,\n",
        "                                            min_samples_split=20,\n",
        "                                            random_state=42,\n",
        "                                            splitter='random'),\n",
        "        transformer = FunctionTransformer(np.clip, \n",
        "                                          kw_args={'a_min':0,'a_max':71})))\n",
        "])\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLC6mfh4y7vG",
        "outputId": "48a42013-6d38-4757-cfc7-cc9d74eb24e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('poly_ft', PolynomialFeatures(degree=3)),\n",
              "                ('trf_reg',\n",
              "                 TransformedTargetRegressor(check_inverse=False,\n",
              "                                            regressor=DecisionTreeRegressor(ccp_alpha=1.85,\n",
              "                                                                            max_depth=200,\n",
              "                                                                            min_impurity_decrease=8.5,\n",
              "                                                                            min_samples_leaf=2,\n",
              "                                                                            min_samples_split=20,\n",
              "                                                                            random_state=42,\n",
              "                                                                            splitter='random'),\n",
              "                                            transformer=FunctionTransformer(func=<function clip at 0x7fd35e8e7cb0>,\n",
              "                                                                            kw_args={'a_max': 71,\n",
              "                                                                                     'a_min': 0})))])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~3min\n",
        "model.fit(X_train, y_train)\n",
        "reclipped_y =  model['trf_reg'].transformer.transform(y_train)\n",
        "eval.show_result(reclipped_y, model.predict(X_train))\n",
        "eval.show_result_cv(reclipped_y, X_train, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94699b9-fe51-44fc-9222-fa476b8e3ab0",
        "id": "kgQSMjnVy7vJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.772,RMSE=-9.983\n",
            "(CV) R2=0.772,RMSE=-9.954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclipped_y =  model['trf_reg'].transformer.transform(y_test)\n",
        "eval.show_result(reclipped_y, model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16da119-df83-4cb8-b956-942370032212",
        "id": "_WsTCV9qy7vJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.711,RMSE=-12.322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the polynominal features actually worsened the perfomance a little bit, when comparing with not using them and the non-linear RUL."
      ],
      "metadata": {
        "id": "wIzjL0VJ0hfH"
      }
    }
  ]
}