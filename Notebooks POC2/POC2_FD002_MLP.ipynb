{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "QinQ4hWStzHt",
        "boZqFQNlraCh",
        "IIXnBTkfxpCf",
        "SL1dv6EX4NUk"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhcgX2RXC5IPvLKYN9n14+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD002_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "4e343b2e-ce5c-4575-c13c-8fe67d3d7ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.9.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/CMaps/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgkQUCfsWAGK",
        "outputId": "2140ff85-6e23-468f-92a9-e7034cbc9f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(2,folder=folder)\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "e49429f1-cb69-4780-dbbe-ec1553146140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time     op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1  34.9983  0.8400  100.0  449.44  555.32  1358.61   \n",
              "1                1     2  41.9982  0.8408  100.0  445.00  549.90  1353.22   \n",
              "2                1     3  24.9988  0.6218   60.0  462.54  537.31  1256.76   \n",
              "3                1     4  42.0077  0.8416  100.0  445.00  549.51  1354.03   \n",
              "4                1     5  25.0005  0.6203   60.0  462.54  537.07  1257.71   \n",
              "...            ...   ...      ...     ...    ...     ...     ...      ...   \n",
              "53754          260   312  20.0037  0.7000  100.0  491.19  608.79  1495.60   \n",
              "53755          260   313  10.0022  0.2510  100.0  489.05  605.81  1514.32   \n",
              "53756          260   314  25.0041  0.6200   60.0  462.54  537.48  1276.24   \n",
              "53757          260   315  25.0033  0.6220   60.0  462.54  537.84  1272.95   \n",
              "53758          260   316  35.0036  0.8400  100.0  449.44  556.64  1374.61   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13     s_14  s_15  s_16  \\\n",
              "0      1137.23   5.48  ...  183.06  2387.72  8048.56   9.3461  0.02   334   \n",
              "1      1125.78   3.91  ...  130.42  2387.66  8072.30   9.3774  0.02   330   \n",
              "2      1047.45   7.05  ...  164.22  2028.03  7864.87  10.8941  0.02   309   \n",
              "3      1126.38   3.91  ...  130.72  2387.61  8068.66   9.3528  0.02   329   \n",
              "4      1047.93   7.05  ...  164.31  2028.00  7861.23  10.8963  0.02   309   \n",
              "...        ...    ...  ...     ...      ...      ...      ...   ...   ...   \n",
              "53754  1269.51   9.35  ...  314.05  2389.02  8169.64   9.3035  0.03   369   \n",
              "53755  1324.12  10.52  ...  371.22  2388.42  8245.36   8.7586  0.03   374   \n",
              "53756  1057.92   7.05  ...  163.74  2030.33  7971.25  11.0657  0.02   310   \n",
              "53757  1066.30   7.05  ...  164.37  2030.35  7972.47  11.0537  0.02   311   \n",
              "53758  1145.52   5.48  ...  183.09  2390.38  8185.35   9.3998  0.02   338   \n",
              "\n",
              "       s_17    s_18   s_19     s_20  \n",
              "0      2223  100.00  14.73   8.8071  \n",
              "1      2212  100.00  10.41   6.2665  \n",
              "2      1915   84.93  14.08   8.6723  \n",
              "3      2212  100.00  10.59   6.4701  \n",
              "4      1915   84.93  14.13   8.5286  \n",
              "...     ...     ...    ...      ...  \n",
              "53754  2324  100.00  24.36  14.5189  \n",
              "53755  2319  100.00  28.10  16.9454  \n",
              "53756  1915   84.93  14.19   8.5503  \n",
              "53757  1915   84.93  14.05   8.3729  \n",
              "53758  2223  100.00  14.75   8.8446  \n",
              "\n",
              "[53759 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e31981db-1761-4135-ad59-a18402d125d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>183.06</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>130.42</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.22</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>130.72</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.31</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53754</th>\n",
              "      <td>260</td>\n",
              "      <td>312</td>\n",
              "      <td>20.0037</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>608.79</td>\n",
              "      <td>1495.60</td>\n",
              "      <td>1269.51</td>\n",
              "      <td>9.35</td>\n",
              "      <td>...</td>\n",
              "      <td>314.05</td>\n",
              "      <td>2389.02</td>\n",
              "      <td>8169.64</td>\n",
              "      <td>9.3035</td>\n",
              "      <td>0.03</td>\n",
              "      <td>369</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.00</td>\n",
              "      <td>24.36</td>\n",
              "      <td>14.5189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53755</th>\n",
              "      <td>260</td>\n",
              "      <td>313</td>\n",
              "      <td>10.0022</td>\n",
              "      <td>0.2510</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.81</td>\n",
              "      <td>1514.32</td>\n",
              "      <td>1324.12</td>\n",
              "      <td>10.52</td>\n",
              "      <td>...</td>\n",
              "      <td>371.22</td>\n",
              "      <td>2388.42</td>\n",
              "      <td>8245.36</td>\n",
              "      <td>8.7586</td>\n",
              "      <td>0.03</td>\n",
              "      <td>374</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.00</td>\n",
              "      <td>28.10</td>\n",
              "      <td>16.9454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53756</th>\n",
              "      <td>260</td>\n",
              "      <td>314</td>\n",
              "      <td>25.0041</td>\n",
              "      <td>0.6200</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.48</td>\n",
              "      <td>1276.24</td>\n",
              "      <td>1057.92</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>163.74</td>\n",
              "      <td>2030.33</td>\n",
              "      <td>7971.25</td>\n",
              "      <td>11.0657</td>\n",
              "      <td>0.02</td>\n",
              "      <td>310</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.19</td>\n",
              "      <td>8.5503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53757</th>\n",
              "      <td>260</td>\n",
              "      <td>315</td>\n",
              "      <td>25.0033</td>\n",
              "      <td>0.6220</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.84</td>\n",
              "      <td>1272.95</td>\n",
              "      <td>1066.30</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.37</td>\n",
              "      <td>2030.35</td>\n",
              "      <td>7972.47</td>\n",
              "      <td>11.0537</td>\n",
              "      <td>0.02</td>\n",
              "      <td>311</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.05</td>\n",
              "      <td>8.3729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53758</th>\n",
              "      <td>260</td>\n",
              "      <td>316</td>\n",
              "      <td>35.0036</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>556.64</td>\n",
              "      <td>1374.61</td>\n",
              "      <td>1145.52</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>183.09</td>\n",
              "      <td>2390.38</td>\n",
              "      <td>8185.35</td>\n",
              "      <td>9.3998</td>\n",
              "      <td>0.02</td>\n",
              "      <td>338</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8.8446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53759 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e31981db-1761-4135-ad59-a18402d125d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e31981db-1761-4135-ad59-a18402d125d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e31981db-1761-4135-ad59-a18402d125d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "3137f1bd-4955-41e2-c522-5f2040f70d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33991, 26), (259, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test_keep_setting(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "onw4pCwZy-1s",
        "outputId": "2a7f598b-d927-4921-8b16-343ec32047cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3    s_4    s_5  \\\n",
              "0  10.0076  0.2501  100.0  489.05  605.42  1515.00  1325.07  10.52  15.50   \n",
              "1   0.0018  0.0000  100.0  518.67  642.67  1591.67  1418.17  14.62  21.61   \n",
              "2  35.0015  0.8412  100.0  449.44  555.86  1370.62  1135.59   5.48   8.00   \n",
              "3  20.0032  0.7000  100.0  491.19  607.99  1487.94  1257.49   9.35  13.66   \n",
              "4  42.0055  0.8400  100.0  445.00  550.81  1358.95  1140.34   3.91   5.72   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0  393.58  ...  370.87  2388.32  8167.06  8.7456  0.03   371  2319  100.0   \n",
              "1  553.36  ...  521.10  2388.12  8138.12  8.4248  0.03   393  2388  100.0   \n",
              "2  194.58  ...  183.11  2388.07  8071.23  9.3094  0.02   332  2223  100.0   \n",
              "3  334.39  ...  314.88  2388.12  8062.39  9.2349  0.02   365  2324  100.0   \n",
              "4  138.42  ...  130.82  2389.06  8140.94  9.3964  0.02   333  2212  100.0   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  28.30  17.0934  \n",
              "1  38.82  23.3463  \n",
              "2  14.75   8.9589  \n",
              "3  24.22  14.6814  \n",
              "4  10.34   6.3601  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5371888c-e91f-4775-bb05-7969de4b8bfa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0076</td>\n",
              "      <td>0.2501</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.42</td>\n",
              "      <td>1515.00</td>\n",
              "      <td>1325.07</td>\n",
              "      <td>10.52</td>\n",
              "      <td>15.50</td>\n",
              "      <td>393.58</td>\n",
              "      <td>...</td>\n",
              "      <td>370.87</td>\n",
              "      <td>2388.32</td>\n",
              "      <td>8167.06</td>\n",
              "      <td>8.7456</td>\n",
              "      <td>0.03</td>\n",
              "      <td>371</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.0</td>\n",
              "      <td>28.30</td>\n",
              "      <td>17.0934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0018</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.67</td>\n",
              "      <td>1591.67</td>\n",
              "      <td>1418.17</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.36</td>\n",
              "      <td>...</td>\n",
              "      <td>521.10</td>\n",
              "      <td>2388.12</td>\n",
              "      <td>8138.12</td>\n",
              "      <td>8.4248</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.82</td>\n",
              "      <td>23.3463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.0015</td>\n",
              "      <td>0.8412</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.86</td>\n",
              "      <td>1370.62</td>\n",
              "      <td>1135.59</td>\n",
              "      <td>5.48</td>\n",
              "      <td>8.00</td>\n",
              "      <td>194.58</td>\n",
              "      <td>...</td>\n",
              "      <td>183.11</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8071.23</td>\n",
              "      <td>9.3094</td>\n",
              "      <td>0.02</td>\n",
              "      <td>332</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.0</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8.9589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0032</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>607.99</td>\n",
              "      <td>1487.94</td>\n",
              "      <td>1257.49</td>\n",
              "      <td>9.35</td>\n",
              "      <td>13.66</td>\n",
              "      <td>334.39</td>\n",
              "      <td>...</td>\n",
              "      <td>314.88</td>\n",
              "      <td>2388.12</td>\n",
              "      <td>8062.39</td>\n",
              "      <td>9.2349</td>\n",
              "      <td>0.02</td>\n",
              "      <td>365</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.22</td>\n",
              "      <td>14.6814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.0055</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>550.81</td>\n",
              "      <td>1358.95</td>\n",
              "      <td>1140.34</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.72</td>\n",
              "      <td>138.42</td>\n",
              "      <td>...</td>\n",
              "      <td>130.82</td>\n",
              "      <td>2389.06</td>\n",
              "      <td>8140.94</td>\n",
              "      <td>9.3964</td>\n",
              "      <td>0.02</td>\n",
              "      <td>333</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.34</td>\n",
              "      <td>6.3601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5371888c-e91f-4775-bb05-7969de4b8bfa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5371888c-e91f-4775-bb05-7969de4b8bfa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5371888c-e91f-4775-bb05-7969de4b8bfa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "lmFKjQaeip1b",
        "outputId": "8dc2a979-4e64-483c-ab72-bdb02dd7ee08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  148\n",
              "1            1     2  147\n",
              "2            1     3  146\n",
              "3            1     4  145\n",
              "4            1     5  144"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3255aa7e-52e7-4592-acc1-c1f47b18fa0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3255aa7e-52e7-4592-acc1-c1f47b18fa0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3255aa7e-52e7-4592-acc1-c1f47b18fa0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3255aa7e-52e7-4592-acc1-c1f47b18fa0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide_with_settings(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "2c93ee1f-aea6-419a-c565-43292d05263d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  148\n",
              "1  147\n",
              "2  146\n",
              "3  145\n",
              "4  144"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fc99a54-17f7-4d93-9a35-35c4008cf1ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc99a54-17f7-4d93-9a35-35c4008cf1ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fc99a54-17f7-4d93-9a35-35c4008cf1ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fc99a54-17f7-4d93-9a35-35c4008cf1ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "26hK4VWkx1R7",
        "outputId": "f2619413-1d24-4785-9a6d-344907de4673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3   s_4   s_5  \\\n",
              "0  34.9983  0.8400  100.0  449.44  555.32  1358.61  1137.23  5.48  8.00   \n",
              "1  41.9982  0.8408  100.0  445.00  549.90  1353.22  1125.78  3.91  5.71   \n",
              "2  24.9988  0.6218   60.0  462.54  537.31  1256.76  1047.45  7.05  9.02   \n",
              "3  42.0077  0.8416  100.0  445.00  549.51  1354.03  1126.38  3.91  5.71   \n",
              "4  25.0005  0.6203   60.0  462.54  537.07  1257.71  1047.93  7.05  9.03   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13     s_14  s_15  s_16  s_17    s_18  \\\n",
              "0  194.64  ...  183.06  2387.72  8048.56   9.3461  0.02   334  2223  100.00   \n",
              "1  138.51  ...  130.42  2387.66  8072.30   9.3774  0.02   330  2212  100.00   \n",
              "2  175.71  ...  164.22  2028.03  7864.87  10.8941  0.02   309  1915   84.93   \n",
              "3  138.46  ...  130.72  2387.61  8068.66   9.3528  0.02   329  2212  100.00   \n",
              "4  175.05  ...  164.31  2028.00  7861.23  10.8963  0.02   309  1915   84.93   \n",
              "\n",
              "    s_19    s_20  \n",
              "0  14.73  8.8071  \n",
              "1  10.41  6.2665  \n",
              "2  14.08  8.6723  \n",
              "3  10.59  6.4701  \n",
              "4  14.13  8.5286  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d114670-f56a-4f18-a52b-d73b13629e89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>8.00</td>\n",
              "      <td>194.64</td>\n",
              "      <td>...</td>\n",
              "      <td>183.06</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.71</td>\n",
              "      <td>138.51</td>\n",
              "      <td>...</td>\n",
              "      <td>130.42</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.02</td>\n",
              "      <td>175.71</td>\n",
              "      <td>...</td>\n",
              "      <td>164.22</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.71</td>\n",
              "      <td>138.46</td>\n",
              "      <td>...</td>\n",
              "      <td>130.72</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.03</td>\n",
              "      <td>175.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.31</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d114670-f56a-4f18-a52b-d73b13629e89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d114670-f56a-4f18-a52b-d73b13629e89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d114670-f56a-4f18-a52b-d73b13629e89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Construction"
      ],
      "metadata": {
        "id": "SL1dv6EX4NUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "PA_LrxmV4NUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "BV6PD9sl4NUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "83kJj9eJ4NU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[index_cols[1]]+[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import is_finalizing\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class MLPWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "    def clean_cols(self,df):\n",
        "        if(\"unit_number\" in df.columns): del df[\"unit_number\"]\n",
        "        if(\"unit_number\" in df.columns): del df[\"unit_number\"]\n",
        "        if(\"time\" in df.columns): del df[\"time\"]\n",
        "        if((not self.include_settings)): \n",
        "            for col in settings_cols:\n",
        "                if(col in df.columns): del df[col]\n",
        "        return df\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Drop irrelevant column\n",
        "        data = pd.DataFrame(X).copy()\n",
        "        data = self.clean_cols(data)\n",
        "        \n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data)\n",
        "        data = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out())\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "\n",
        "        # Scale the data\n",
        "        data = self.scaler.fit_transform(data)\n",
        "        data = pd.DataFrame(data, \n",
        "                            columns=self.scaler.get_feature_names_out())\n",
        "        X_train = data.copy()\n",
        "        \n",
        "        # Clip and transform labels\n",
        "        data2 = pd.DataFrame(y, columns=[\"RUL\"]).copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = data2\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        INPUT_SHAPE = X_train.shape[1]\n",
        "\n",
        "        # Fit model\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.columns) != len(self.feature_cols)):\n",
        "            X_train = self.transform_features(X)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def transform_features(self, df):\n",
        "        # Drop irrelevant column\n",
        "        data = pd.DataFrame(df).copy()\n",
        "        data = self.clean_cols(data)\n",
        "        \n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.transform(data)\n",
        "        data = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out())\n",
        "        # self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "\n",
        "        # Scale the data\n",
        "        data = self.scaler.transform(data)\n",
        "        data = pd.DataFrame(data, \n",
        "                            columns=self.scaler.get_feature_names_out())\n",
        "        return data\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        X_test = self.transform_features(X)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = pd.DataFrame(y, columns=[\"RUL\"]).copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = data2\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)"
      ],
      "metadata": {
        "id": "-mG7sVkcpALn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = pd.DataFrame(test)\n",
        "    test2 = model.clean_cols(test2)\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2)\n",
        "    test2 = pd.DataFrame(transf, \n",
        "                         columns=model.polyft.get_feature_names_out())\n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2 = model.scaler.transform(test2)\n",
        "    test2 = pd.DataFrame(test2, \n",
        "                         columns=model.polyft.get_feature_names_out())\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 layer4=None, activation4=\"tanh\"    , dropout4=0.1,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model.add(Dense(layer1, input_dim=INPUT_SHAPE, activation=activation1))\n",
        "    model.add(Dropout(dropout1))\n",
        "\n",
        "    # Additional hidden layers\n",
        "    if(layer2 is not None):\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        if (layer3 is not None):\n",
        "            model.add(Dense(layer3, activation=activation3))\n",
        "            model.add(Dropout(dropout3))\n",
        "            if (layer4 is not None):\n",
        "                model.add(Dense(layer4, activation=activation4))\n",
        "                model.add(Dropout(dropout4))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "NbakKD-DlU5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-1 (REDO Some)"
      ],
      "metadata": {
        "id": "DU8TxguXIChd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL (REDO)"
      ],
      "metadata": {
        "id": "zkCJJsiS-J7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.581174610036398  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 117),\n",
        "             ('basemodel__epochs', 42),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__learning_rate', 0.0034318227561347635),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "iWX0RiAL4uGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=117,\n",
        "                           epochs=42,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0034318227561347635,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "id": "xfYRKHQKi3Xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6451efa-5a71-42e8-bbef-56a00085b4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=117, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=42, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='tanh', model__dropout1=0.1, model__layer1=512, model__learning_rate=0.0034318227561347635, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9bf00cde90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9bf00c8650>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SF4CE-ab5IKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23fef5b2-5287-4474-d1b8-312c4d8ce72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               11264     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,777\n",
            "Trainable params: 11,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5468.074, rmse=73.946, r2=-0.169; v_loss=3801.744, v_rmse=61.658, v_r2=0.333; \n",
            "E 2\t: loss=2596.202, rmse=50.953, r2=0.445; v_loss=2822.301, v_rmse=53.125, v_r2=0.505; \n",
            "E 3\t: loss=2211.476, rmse=47.026, r2=0.527; v_loss=2521.757, v_rmse=50.217, v_r2=0.558; \n",
            "E 4\t: loss=2126.377, rmse=46.113, r2=0.545; v_loss=2413.463, v_rmse=49.127, v_r2=0.577; \n",
            "E 5\t: loss=2132.580, rmse=46.180, r2=0.544; v_loss=2506.065, v_rmse=50.061, v_r2=0.560; \n",
            "E 6\t: loss=2111.021, rmse=45.946, r2=0.549; v_loss=2495.270, v_rmse=49.953, v_r2=0.562; \n",
            "E 7\t: loss=2103.740, rmse=45.867, r2=0.550; v_loss=2448.829, v_rmse=49.486, v_r2=0.570; \n",
            "E 8\t: loss=2101.211, rmse=45.839, r2=0.551; v_loss=2386.521, v_rmse=48.852, v_r2=0.581; \n",
            "E 9\t: loss=2102.118, rmse=45.849, r2=0.551; v_loss=2538.626, v_rmse=50.385, v_r2=0.555; \n",
            "E 10\t: loss=2077.306, rmse=45.577, r2=0.556; v_loss=2486.716, v_rmse=49.867, v_r2=0.564; \n",
            "E 11\t: loss=2066.277, rmse=45.456, r2=0.558; v_loss=2449.765, v_rmse=49.495, v_r2=0.570; \n",
            "E 12\t: loss=2060.345, rmse=45.391, r2=0.560; v_loss=2371.140, v_rmse=48.694, v_r2=0.584; \n",
            "E 13\t: loss=2066.698, rmse=45.461, r2=0.558; v_loss=2432.090, v_rmse=49.316, v_r2=0.573; \n",
            "E 14\t: loss=2066.977, rmse=45.464, r2=0.558; v_loss=2385.434, v_rmse=48.841, v_r2=0.581; \n",
            "E 15\t: loss=2038.564, rmse=45.150, r2=0.564; v_loss=2429.439, v_rmse=49.289, v_r2=0.574; \n",
            "E 16\t: loss=2052.497, rmse=45.304, r2=0.561; v_loss=2497.846, v_rmse=49.978, v_r2=0.562; \n",
            "E 17\t: loss=2043.174, rmse=45.201, r2=0.563; v_loss=2359.671, v_rmse=48.576, v_r2=0.586; \n",
            "E 18\t: loss=2047.580, rmse=45.250, r2=0.562; v_loss=2414.572, v_rmse=49.138, v_r2=0.576; \n",
            "E 19\t: loss=2028.443, rmse=45.038, r2=0.566; v_loss=2285.918, v_rmse=47.811, v_r2=0.599; \n",
            "E 20\t: loss=2034.586, rmse=45.106, r2=0.565; v_loss=2385.007, v_rmse=48.837, v_r2=0.582; \n",
            "E 21\t: loss=2035.793, rmse=45.120, r2=0.565; v_loss=2328.419, v_rmse=48.254, v_r2=0.591; \n",
            "E 22\t: loss=2017.653, rmse=44.918, r2=0.569; v_loss=2300.780, v_rmse=47.966, v_r2=0.596; \n",
            "E 23\t: loss=2021.275, rmse=44.959, r2=0.568; v_loss=2383.415, v_rmse=48.820, v_r2=0.582; \n",
            "E 24\t: loss=2013.842, rmse=44.876, r2=0.569; v_loss=2303.141, v_rmse=47.991, v_r2=0.596; \n",
            "E 25\t: loss=2004.792, rmse=44.775, r2=0.571; v_loss=2398.306, v_rmse=48.973, v_r2=0.579; \n",
            "E 26\t: loss=2020.122, rmse=44.946, r2=0.568; v_loss=2359.420, v_rmse=48.574, v_r2=0.586; \n",
            "E 27\t: loss=2003.988, rmse=44.766, r2=0.572; v_loss=2352.895, v_rmse=48.507, v_r2=0.587; \n",
            "E 28\t: loss=1998.806, rmse=44.708, r2=0.573; v_loss=2388.335, v_rmse=48.871, v_r2=0.581; \n",
            "E 29\t: loss=1998.759, rmse=44.707, r2=0.573; v_loss=2323.721, v_rmse=48.205, v_r2=0.592; \n",
            "E 30\t: loss=1997.121, rmse=44.689, r2=0.573; v_loss=2409.189, v_rmse=49.083, v_r2=0.577; \n",
            "E 31\t: loss=1997.985, rmse=44.699, r2=0.573; v_loss=2354.486, v_rmse=48.523, v_r2=0.587; \n",
            "E 32\t: loss=1998.194, rmse=44.701, r2=0.573; v_loss=2334.911, v_rmse=48.321, v_r2=0.590; \n",
            "E 33\t: loss=1999.668, rmse=44.718, r2=0.572; v_loss=2381.154, v_rmse=48.797, v_r2=0.582; \n",
            "E 34\t: loss=1989.106, rmse=44.599, r2=0.575; v_loss=2313.704, v_rmse=48.101, v_r2=0.594; \n",
            "E 35\t: loss=1986.205, rmse=44.567, r2=0.575; v_loss=2320.257, v_rmse=48.169, v_r2=0.593; \n",
            "E 36\t: loss=1987.896, rmse=44.586, r2=0.575; v_loss=2337.277, v_rmse=48.345, v_r2=0.590; \n",
            "E 37\t: loss=1985.022, rmse=44.554, r2=0.576; v_loss=2287.474, v_rmse=47.828, v_r2=0.599; \n",
            "E 38\t: loss=1994.733, rmse=44.662, r2=0.574; v_loss=2364.192, v_rmse=48.623, v_r2=0.585; \n",
            "E 39\t: loss=1981.067, rmse=44.509, r2=0.576; v_loss=2322.411, v_rmse=48.191, v_r2=0.593; \n",
            "E 40\t: loss=1979.677, rmse=44.494, r2=0.577; v_loss=2319.311, v_rmse=48.159, v_r2=0.593; \n",
            "E 41\t: loss=1978.821, rmse=44.484, r2=0.577; v_loss=2332.634, v_rmse=48.297, v_r2=0.591; \n",
            "E 42\t: loss=1982.500, rmse=44.525, r2=0.576; v_loss=2279.124, v_rmse=47.740, v_r2=0.600; \n",
            "Finished: 2022-10-30 11:12:17.299831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "9vLfPZkw5Ixg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d54a7a-1c2e-4487-a080-f2f5b54d9b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.639,RMSE=-32.310\n",
            "Finished: 2022-10-30 11:12:17.444521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "mMYPm8b65n0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8184403480530235  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 40),\n",
        "('basemodel__model__activation1', 'sigmoid'),\n",
        "('basemodel__model__dropout1', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.01),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 80),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "uooUt5Yq5n0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=250,\n",
        "                           model__activation1='sigmoid',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.01,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58906b82-41aa-4213-e0c3-7a995bacea1a",
        "id": "Lj8fIDg15n0X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=250, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='sigmoid', model__dropout1=0.1, model__layer1=512, model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b8004ac90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b80044290>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    clip_y=80, include_settings=True, scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "y1uxSqWy5n0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9647dc-b08c-4ff7-adea-c5ee97a5c2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 512)               12800     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,313\n",
            "Trainable params: 13,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=548.853, rmse=23.428, r2=0.080; v_loss=407.656, v_rmse=20.190, v_r2=0.299; \n",
            "E 2\t: loss=351.107, rmse=18.738, r2=0.412; v_loss=261.609, v_rmse=16.174, v_r2=0.550; \n",
            "E 3\t: loss=241.596, rmse=15.543, r2=0.595; v_loss=198.407, v_rmse=14.086, v_r2=0.659; \n",
            "E 4\t: loss=216.622, rmse=14.718, r2=0.637; v_loss=231.274, v_rmse=15.208, v_r2=0.602; \n",
            "E 5\t: loss=212.186, rmse=14.567, r2=0.645; v_loss=186.701, v_rmse=13.664, v_r2=0.679; \n",
            "E 6\t: loss=207.040, rmse=14.389, r2=0.653; v_loss=187.289, v_rmse=13.685, v_r2=0.678; \n",
            "E 7\t: loss=205.348, rmse=14.330, r2=0.656; v_loss=184.864, v_rmse=13.596, v_r2=0.682; \n",
            "E 8\t: loss=203.356, rmse=14.260, r2=0.659; v_loss=180.310, v_rmse=13.428, v_r2=0.690; \n",
            "E 9\t: loss=201.944, rmse=14.211, r2=0.662; v_loss=187.173, v_rmse=13.681, v_r2=0.678; \n",
            "E 10\t: loss=199.685, rmse=14.131, r2=0.665; v_loss=201.722, v_rmse=14.203, v_r2=0.653; \n",
            "E 11\t: loss=196.868, rmse=14.031, r2=0.670; v_loss=188.547, v_rmse=13.731, v_r2=0.676; \n",
            "E 12\t: loss=197.859, rmse=14.066, r2=0.669; v_loss=178.004, v_rmse=13.342, v_r2=0.694; \n",
            "E 13\t: loss=197.668, rmse=14.059, r2=0.669; v_loss=182.024, v_rmse=13.492, v_r2=0.687; \n",
            "E 14\t: loss=193.278, rmse=13.902, r2=0.676; v_loss=179.210, v_rmse=13.387, v_r2=0.692; \n",
            "E 15\t: loss=194.708, rmse=13.954, r2=0.674; v_loss=177.749, v_rmse=13.332, v_r2=0.694; \n",
            "E 16\t: loss=191.802, rmse=13.849, r2=0.679; v_loss=179.235, v_rmse=13.388, v_r2=0.692; \n",
            "E 17\t: loss=191.522, rmse=13.839, r2=0.679; v_loss=171.749, v_rmse=13.105, v_r2=0.705; \n",
            "E 18\t: loss=189.228, rmse=13.756, r2=0.683; v_loss=172.937, v_rmse=13.151, v_r2=0.703; \n",
            "E 19\t: loss=188.922, rmse=13.745, r2=0.683; v_loss=170.497, v_rmse=13.057, v_r2=0.707; \n",
            "E 20\t: loss=187.090, rmse=13.678, r2=0.687; v_loss=173.281, v_rmse=13.164, v_r2=0.702; \n",
            "E 21\t: loss=186.779, rmse=13.667, r2=0.687; v_loss=183.140, v_rmse=13.533, v_r2=0.685; \n",
            "E 22\t: loss=183.173, rmse=13.534, r2=0.693; v_loss=176.847, v_rmse=13.298, v_r2=0.696; \n",
            "E 23\t: loss=182.701, rmse=13.517, r2=0.694; v_loss=168.196, v_rmse=12.969, v_r2=0.711; \n",
            "E 24\t: loss=182.374, rmse=13.505, r2=0.694; v_loss=162.382, v_rmse=12.743, v_r2=0.721; \n",
            "E 25\t: loss=180.940, rmse=13.451, r2=0.697; v_loss=168.676, v_rmse=12.988, v_r2=0.710; \n",
            "E 26\t: loss=179.937, rmse=13.414, r2=0.699; v_loss=196.739, v_rmse=14.026, v_r2=0.662; \n",
            "E 27\t: loss=178.541, rmse=13.362, r2=0.701; v_loss=189.980, v_rmse=13.783, v_r2=0.673; \n",
            "E 28\t: loss=177.466, rmse=13.322, r2=0.703; v_loss=179.251, v_rmse=13.388, v_r2=0.692; \n",
            "E 29\t: loss=176.306, rmse=13.278, r2=0.705; v_loss=159.992, v_rmse=12.649, v_r2=0.725; \n",
            "E 30\t: loss=173.350, rmse=13.166, r2=0.710; v_loss=186.193, v_rmse=13.645, v_r2=0.680; \n",
            "E 31\t: loss=174.948, rmse=13.227, r2=0.707; v_loss=154.521, v_rmse=12.431, v_r2=0.734; \n",
            "E 32\t: loss=172.000, rmse=13.115, r2=0.712; v_loss=162.239, v_rmse=12.737, v_r2=0.721; \n",
            "E 33\t: loss=171.787, rmse=13.107, r2=0.712; v_loss=171.799, v_rmse=13.107, v_r2=0.705; \n",
            "E 34\t: loss=171.439, rmse=13.093, r2=0.713; v_loss=164.811, v_rmse=12.838, v_r2=0.717; \n",
            "E 35\t: loss=168.937, rmse=12.998, r2=0.717; v_loss=160.879, v_rmse=12.684, v_r2=0.723; \n",
            "E 36\t: loss=167.217, rmse=12.931, r2=0.720; v_loss=154.016, v_rmse=12.410, v_r2=0.735; \n",
            "E 37\t: loss=166.774, rmse=12.914, r2=0.721; v_loss=159.559, v_rmse=12.632, v_r2=0.726; \n",
            "E 38\t: loss=165.894, rmse=12.880, r2=0.722; v_loss=144.927, v_rmse=12.039, v_r2=0.751; \n",
            "E 39\t: loss=164.109, rmse=12.811, r2=0.725; v_loss=160.892, v_rmse=12.684, v_r2=0.723; \n",
            "E 40\t: loss=162.514, rmse=12.748, r2=0.728; v_loss=146.281, v_rmse=12.095, v_r2=0.748; \n",
            "E 41\t: loss=161.576, rmse=12.711, r2=0.729; v_loss=150.742, v_rmse=12.278, v_r2=0.741; \n",
            "E 42\t: loss=160.971, rmse=12.687, r2=0.730; v_loss=144.861, v_rmse=12.036, v_r2=0.751; \n",
            "E 43\t: loss=158.377, rmse=12.585, r2=0.735; v_loss=139.583, v_rmse=11.815, v_r2=0.760; \n",
            "E 44\t: loss=156.242, rmse=12.500, r2=0.738; v_loss=147.696, v_rmse=12.153, v_r2=0.746; \n",
            "E 45\t: loss=157.050, rmse=12.532, r2=0.737; v_loss=138.141, v_rmse=11.753, v_r2=0.762; \n",
            "E 46\t: loss=154.050, rmse=12.412, r2=0.742; v_loss=135.316, v_rmse=11.633, v_r2=0.767; \n",
            "E 47\t: loss=153.364, rmse=12.384, r2=0.743; v_loss=144.755, v_rmse=12.031, v_r2=0.751; \n",
            "E 48\t: loss=151.475, rmse=12.308, r2=0.746; v_loss=130.071, v_rmse=11.405, v_r2=0.776; \n",
            "E 49\t: loss=149.881, rmse=12.243, r2=0.749; v_loss=131.267, v_rmse=11.457, v_r2=0.774; \n",
            "E 50\t: loss=149.284, rmse=12.218, r2=0.750; v_loss=128.096, v_rmse=11.318, v_r2=0.780; \n",
            "E 51\t: loss=148.437, rmse=12.183, r2=0.751; v_loss=134.767, v_rmse=11.609, v_r2=0.768; \n",
            "E 52\t: loss=147.320, rmse=12.138, r2=0.753; v_loss=132.412, v_rmse=11.507, v_r2=0.772; \n",
            "E 53\t: loss=146.138, rmse=12.089, r2=0.755; v_loss=133.179, v_rmse=11.540, v_r2=0.771; \n",
            "E 54\t: loss=146.622, rmse=12.109, r2=0.754; v_loss=128.726, v_rmse=11.346, v_r2=0.779; \n",
            "E 55\t: loss=144.330, rmse=12.014, r2=0.758; v_loss=138.796, v_rmse=11.781, v_r2=0.761; \n",
            "E 56\t: loss=144.095, rmse=12.004, r2=0.759; v_loss=125.276, v_rmse=11.193, v_r2=0.785; \n",
            "E 57\t: loss=143.482, rmse=11.978, r2=0.760; v_loss=125.633, v_rmse=11.209, v_r2=0.784; \n",
            "E 58\t: loss=142.824, rmse=11.951, r2=0.761; v_loss=122.924, v_rmse=11.087, v_r2=0.789; \n",
            "E 59\t: loss=141.734, rmse=11.905, r2=0.763; v_loss=127.655, v_rmse=11.298, v_r2=0.781; \n",
            "E 60\t: loss=140.893, rmse=11.870, r2=0.764; v_loss=120.878, v_rmse=10.994, v_r2=0.792; \n",
            "E 61\t: loss=139.581, rmse=11.814, r2=0.766; v_loss=123.286, v_rmse=11.103, v_r2=0.788; \n",
            "E 62\t: loss=139.303, rmse=11.803, r2=0.767; v_loss=121.593, v_rmse=11.027, v_r2=0.791; \n",
            "E 63\t: loss=139.158, rmse=11.797, r2=0.767; v_loss=166.645, v_rmse=12.909, v_r2=0.713; \n",
            "E 64\t: loss=139.689, rmse=11.819, r2=0.766; v_loss=124.220, v_rmse=11.145, v_r2=0.786; \n",
            "E 65\t: loss=138.323, rmse=11.761, r2=0.768; v_loss=119.814, v_rmse=10.946, v_r2=0.794; \n",
            "E 66\t: loss=137.411, rmse=11.722, r2=0.770; v_loss=120.226, v_rmse=10.965, v_r2=0.793; \n",
            "E 67\t: loss=137.601, rmse=11.730, r2=0.769; v_loss=121.891, v_rmse=11.040, v_r2=0.790; \n",
            "E 68\t: loss=138.047, rmse=11.749, r2=0.769; v_loss=146.973, v_rmse=12.123, v_r2=0.747; \n",
            "E 69\t: loss=135.725, rmse=11.650, r2=0.773; v_loss=124.754, v_rmse=11.169, v_r2=0.785; \n",
            "E 70\t: loss=135.953, rmse=11.660, r2=0.772; v_loss=124.664, v_rmse=11.165, v_r2=0.786; \n",
            "E 71\t: loss=134.992, rmse=11.619, r2=0.774; v_loss=142.011, v_rmse=11.917, v_r2=0.756; \n",
            "E 72\t: loss=136.045, rmse=11.664, r2=0.772; v_loss=123.351, v_rmse=11.106, v_r2=0.788; \n",
            "E 73\t: loss=133.827, rmse=11.568, r2=0.776; v_loss=118.961, v_rmse=10.907, v_r2=0.795; \n",
            "E 74\t: loss=135.566, rmse=11.643, r2=0.773; v_loss=120.222, v_rmse=10.965, v_r2=0.793; \n",
            "E 75\t: loss=133.885, rmse=11.571, r2=0.776; v_loss=116.982, v_rmse=10.816, v_r2=0.799; \n",
            "E 76\t: loss=134.710, rmse=11.606, r2=0.774; v_loss=124.007, v_rmse=11.136, v_r2=0.787; \n",
            "E 77\t: loss=133.162, rmse=11.540, r2=0.777; v_loss=114.242, v_rmse=10.688, v_r2=0.804; \n",
            "E 78\t: loss=132.551, rmse=11.513, r2=0.778; v_loss=118.350, v_rmse=10.879, v_r2=0.797; \n",
            "E 79\t: loss=132.672, rmse=11.518, r2=0.778; v_loss=124.617, v_rmse=11.163, v_r2=0.786; \n",
            "E 80\t: loss=132.902, rmse=11.528, r2=0.777; v_loss=129.986, v_rmse=11.401, v_r2=0.776; \n",
            "E 81\t: loss=133.104, rmse=11.537, r2=0.777; v_loss=115.931, v_rmse=10.767, v_r2=0.801; \n",
            "E 82\t: loss=132.504, rmse=11.511, r2=0.778; v_loss=121.028, v_rmse=11.001, v_r2=0.792; \n",
            "E 83\t: loss=131.053, rmse=11.448, r2=0.780; v_loss=124.785, v_rmse=11.171, v_r2=0.785; \n",
            "E 84\t: loss=130.760, rmse=11.435, r2=0.781; v_loss=117.389, v_rmse=10.835, v_r2=0.798; \n",
            "E 85\t: loss=130.639, rmse=11.430, r2=0.781; v_loss=116.158, v_rmse=10.778, v_r2=0.800; \n",
            "E 86\t: loss=130.831, rmse=11.438, r2=0.781; v_loss=124.678, v_rmse=11.166, v_r2=0.786; \n",
            "E 87\t: loss=130.798, rmse=11.437, r2=0.781; v_loss=117.438, v_rmse=10.837, v_r2=0.798; \n",
            "E 88\t: loss=129.702, rmse=11.389, r2=0.783; v_loss=140.201, v_rmse=11.841, v_r2=0.759; \n",
            "E 89\t: loss=129.498, rmse=11.380, r2=0.783; v_loss=118.950, v_rmse=10.906, v_r2=0.795; \n",
            "E 90\t: loss=129.685, rmse=11.388, r2=0.783; v_loss=112.701, v_rmse=10.616, v_r2=0.806; \n",
            "E 91\t: loss=130.236, rmse=11.412, r2=0.782; v_loss=139.413, v_rmse=11.807, v_r2=0.760; \n",
            "E 92\t: loss=130.026, rmse=11.403, r2=0.782; v_loss=138.625, v_rmse=11.774, v_r2=0.762; \n",
            "E 93\t: loss=128.269, rmse=11.326, r2=0.785; v_loss=117.914, v_rmse=10.859, v_r2=0.797; \n",
            "E 94\t: loss=130.086, rmse=11.406, r2=0.782; v_loss=114.447, v_rmse=10.698, v_r2=0.803; \n",
            "E 95\t: loss=129.378, rmse=11.374, r2=0.783; v_loss=125.756, v_rmse=11.214, v_r2=0.784; \n",
            "E 96\t: loss=128.630, rmse=11.342, r2=0.785; v_loss=128.553, v_rmse=11.338, v_r2=0.779; \n",
            "E 97\t: loss=127.996, rmse=11.314, r2=0.786; v_loss=117.638, v_rmse=10.846, v_r2=0.798; \n",
            "E 98\t: loss=128.656, rmse=11.343, r2=0.784; v_loss=119.464, v_rmse=10.930, v_r2=0.795; \n",
            "E 99\t: loss=128.534, rmse=11.337, r2=0.785; v_loss=118.991, v_rmse=10.908, v_r2=0.795; \n",
            "E 100\t: loss=127.229, rmse=11.280, r2=0.787; v_loss=112.881, v_rmse=10.625, v_r2=0.806; \n",
            "E 101\t: loss=128.672, rmse=11.343, r2=0.784; v_loss=117.564, v_rmse=10.843, v_r2=0.798; \n",
            "E 102\t: loss=127.027, rmse=11.271, r2=0.787; v_loss=113.842, v_rmse=10.670, v_r2=0.804; \n",
            "E 103\t: loss=126.959, rmse=11.268, r2=0.787; v_loss=118.441, v_rmse=10.883, v_r2=0.796; \n",
            "E 104\t: loss=127.022, rmse=11.270, r2=0.787; v_loss=117.028, v_rmse=10.818, v_r2=0.799; \n",
            "E 105\t: loss=126.987, rmse=11.269, r2=0.787; v_loss=115.521, v_rmse=10.748, v_r2=0.801; \n",
            "E 106\t: loss=127.336, rmse=11.284, r2=0.787; v_loss=126.758, v_rmse=11.259, v_r2=0.782; \n",
            "E 107\t: loss=126.340, rmse=11.240, r2=0.788; v_loss=116.131, v_rmse=10.776, v_r2=0.800; \n",
            "E 108\t: loss=125.423, rmse=11.199, r2=0.790; v_loss=112.738, v_rmse=10.618, v_r2=0.806; \n",
            "E 109\t: loss=126.286, rmse=11.238, r2=0.788; v_loss=129.075, v_rmse=11.361, v_r2=0.778; \n",
            "E 110\t: loss=126.772, rmse=11.259, r2=0.788; v_loss=122.891, v_rmse=11.086, v_r2=0.789; \n",
            "E 111\t: loss=125.021, rmse=11.181, r2=0.791; v_loss=113.271, v_rmse=10.643, v_r2=0.805; \n",
            "E 112\t: loss=126.278, rmse=11.237, r2=0.788; v_loss=124.460, v_rmse=11.156, v_r2=0.786; \n",
            "E 113\t: loss=125.454, rmse=11.201, r2=0.790; v_loss=108.316, v_rmse=10.408, v_r2=0.814; \n",
            "E 114\t: loss=124.610, rmse=11.163, r2=0.791; v_loss=119.287, v_rmse=10.922, v_r2=0.795; \n",
            "E 115\t: loss=125.380, rmse=11.197, r2=0.790; v_loss=116.031, v_rmse=10.772, v_r2=0.800; \n",
            "E 116\t: loss=124.594, rmse=11.162, r2=0.791; v_loss=122.949, v_rmse=11.088, v_r2=0.789; \n",
            "E 117\t: loss=124.678, rmse=11.166, r2=0.791; v_loss=111.303, v_rmse=10.550, v_r2=0.809; \n",
            "E 118\t: loss=124.615, rmse=11.163, r2=0.791; v_loss=110.978, v_rmse=10.535, v_r2=0.809; \n",
            "E 119\t: loss=123.650, rmse=11.120, r2=0.793; v_loss=113.467, v_rmse=10.652, v_r2=0.805; \n",
            "E 120\t: loss=124.638, rmse=11.164, r2=0.791; v_loss=123.620, v_rmse=11.118, v_r2=0.787; \n",
            "E 121\t: loss=123.716, rmse=11.123, r2=0.793; v_loss=114.569, v_rmse=10.704, v_r2=0.803; \n",
            "E 122\t: loss=123.810, rmse=11.127, r2=0.793; v_loss=130.694, v_rmse=11.432, v_r2=0.775; \n",
            "E 123\t: loss=124.168, rmse=11.143, r2=0.792; v_loss=115.695, v_rmse=10.756, v_r2=0.801; \n",
            "E 124\t: loss=123.162, rmse=11.098, r2=0.794; v_loss=118.913, v_rmse=10.905, v_r2=0.796; \n",
            "E 125\t: loss=123.216, rmse=11.100, r2=0.794; v_loss=122.250, v_rmse=11.057, v_r2=0.790; \n",
            "E 126\t: loss=123.903, rmse=11.131, r2=0.792; v_loss=119.567, v_rmse=10.935, v_r2=0.794; \n",
            "E 127\t: loss=123.256, rmse=11.102, r2=0.794; v_loss=116.289, v_rmse=10.784, v_r2=0.800; \n",
            "E 128\t: loss=122.386, rmse=11.063, r2=0.795; v_loss=111.431, v_rmse=10.556, v_r2=0.808; \n",
            "E 129\t: loss=121.296, rmse=11.013, r2=0.797; v_loss=113.641, v_rmse=10.660, v_r2=0.805; \n",
            "E 130\t: loss=122.938, rmse=11.088, r2=0.794; v_loss=112.768, v_rmse=10.619, v_r2=0.806; \n",
            "E 131\t: loss=121.657, rmse=11.030, r2=0.796; v_loss=118.325, v_rmse=10.878, v_r2=0.797; \n",
            "E 132\t: loss=122.609, rmse=11.073, r2=0.795; v_loss=109.660, v_rmse=10.472, v_r2=0.811; \n",
            "E 133\t: loss=122.149, rmse=11.052, r2=0.795; v_loss=114.261, v_rmse=10.689, v_r2=0.804; \n",
            "E 134\t: loss=121.797, rmse=11.036, r2=0.796; v_loss=110.689, v_rmse=10.521, v_r2=0.810; \n",
            "Finished: 2022-10-30 11:39:04.625955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Q1waoIXF5n0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65d5add-ade2-46e5-a365-8686c574c0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.829,RMSE=-11.565\n",
            "Finished: 2022-10-30 11:39:04.750040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL (REDO)"
      ],
      "metadata": {
        "id": "X4OKIiMD6X4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.5760357993360262   \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.5527766101177216),\n",
        "             ('basemodel__model__layer1', 61),\n",
        "             ('basemodel__model__learning_rate', 0.008905200618475653),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.168565014223427),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "OUMvs31w6X4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='elu',\n",
        "                           model__dropout1=0.5527766101177216, \n",
        "                           model__layer1=61, \n",
        "                           model__learning_rate=0.008905200618475653,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.168565014223427, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eee7d5a-8794-4a95-de87-876c9c9d2d36",
        "id": "dpKrE34E6X4j"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=50, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='elu', model__dropout1=0.5527766101177216, model__layer1=61, model__learning_rate=0.008905200618475653, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6fe77350>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6fe77510>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.168565014223427, verbose=0),\n",
              "                    include_settings=True, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "HHlBlEju6X4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62cf0708-db5b-430d-a34e-d8d7016b93b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 61)                178425    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 61)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 62        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 178,487\n",
            "Trainable params: 178,487\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=4066.785, rmse=63.771, r2=0.144; v_loss=3132.908, v_rmse=55.972, v_r2=0.368; \n",
            "E 2\t: loss=3205.536, rmse=56.617, r2=0.325; v_loss=2393.167, v_rmse=48.920, v_r2=0.518; \n",
            "E 3\t: loss=3086.243, rmse=55.554, r2=0.350; v_loss=2410.662, v_rmse=49.098, v_r2=0.514; \n",
            "E 4\t: loss=3028.551, rmse=55.032, r2=0.362; v_loss=2337.133, v_rmse=48.344, v_r2=0.529; \n",
            "E 5\t: loss=2918.033, rmse=54.019, r2=0.386; v_loss=2450.358, v_rmse=49.501, v_r2=0.506; \n",
            "E 6\t: loss=2903.972, rmse=53.889, r2=0.389; v_loss=2623.083, v_rmse=51.216, v_r2=0.471; \n",
            "E 7\t: loss=2830.019, rmse=53.198, r2=0.404; v_loss=2283.190, v_rmse=47.783, v_r2=0.540; \n",
            "E 8\t: loss=2794.393, rmse=52.862, r2=0.412; v_loss=2263.665, v_rmse=47.578, v_r2=0.544; \n",
            "E 9\t: loss=2772.011, rmse=52.650, r2=0.416; v_loss=2221.840, v_rmse=47.136, v_r2=0.552; \n",
            "E 10\t: loss=2777.188, rmse=52.699, r2=0.415; v_loss=2254.463, v_rmse=47.481, v_r2=0.546; \n",
            "E 11\t: loss=2707.315, rmse=52.032, r2=0.430; v_loss=2199.479, v_rmse=46.899, v_r2=0.557; \n",
            "E 12\t: loss=2682.323, rmse=51.791, r2=0.435; v_loss=2178.371, v_rmse=46.673, v_r2=0.561; \n",
            "E 13\t: loss=2677.995, rmse=51.749, r2=0.436; v_loss=2323.326, v_rmse=48.201, v_r2=0.532; \n",
            "E 14\t: loss=2653.500, rmse=51.512, r2=0.441; v_loss=2831.515, v_rmse=53.212, v_r2=0.429; \n",
            "E 15\t: loss=2629.515, rmse=51.279, r2=0.446; v_loss=2276.844, v_rmse=47.716, v_r2=0.541; \n",
            "E 16\t: loss=2646.253, rmse=51.442, r2=0.443; v_loss=2248.275, v_rmse=47.416, v_r2=0.547; \n",
            "E 17\t: loss=2631.071, rmse=51.294, r2=0.446; v_loss=2451.739, v_rmse=49.515, v_r2=0.506; \n",
            "E 18\t: loss=2601.689, rmse=51.007, r2=0.452; v_loss=2875.061, v_rmse=53.620, v_r2=0.420; \n",
            "E 19\t: loss=2586.655, rmse=50.859, r2=0.455; v_loss=2185.444, v_rmse=46.749, v_r2=0.559; \n",
            "E 20\t: loss=2577.642, rmse=50.770, r2=0.457; v_loss=2344.640, v_rmse=48.421, v_r2=0.527; \n",
            "E 21\t: loss=2564.951, rmse=50.645, r2=0.460; v_loss=2190.379, v_rmse=46.801, v_r2=0.558; \n",
            "E 22\t: loss=2569.413, rmse=50.689, r2=0.459; v_loss=2152.215, v_rmse=46.392, v_r2=0.566; \n",
            "E 23\t: loss=2539.740, rmse=50.396, r2=0.465; v_loss=2372.495, v_rmse=48.708, v_r2=0.522; \n",
            "E 24\t: loss=2543.514, rmse=50.433, r2=0.465; v_loss=2356.460, v_rmse=48.543, v_r2=0.525; \n",
            "E 25\t: loss=2535.768, rmse=50.356, r2=0.466; v_loss=2281.531, v_rmse=47.765, v_r2=0.540; \n",
            "E 26\t: loss=2553.385, rmse=50.531, r2=0.462; v_loss=2231.366, v_rmse=47.237, v_r2=0.550; \n",
            "E 27\t: loss=2525.166, rmse=50.251, r2=0.468; v_loss=2337.698, v_rmse=48.350, v_r2=0.529; \n",
            "E 28\t: loss=2504.686, rmse=50.047, r2=0.473; v_loss=2357.341, v_rmse=48.552, v_r2=0.525; \n",
            "E 29\t: loss=2539.628, rmse=50.395, r2=0.465; v_loss=2207.084, v_rmse=46.980, v_r2=0.555; \n",
            "E 30\t: loss=2518.312, rmse=50.183, r2=0.470; v_loss=2270.804, v_rmse=47.653, v_r2=0.542; \n",
            "E 31\t: loss=2509.634, rmse=50.096, r2=0.472; v_loss=2675.281, v_rmse=51.723, v_r2=0.461; \n",
            "E 32\t: loss=2503.648, rmse=50.036, r2=0.473; v_loss=2064.282, v_rmse=45.434, v_r2=0.584; \n",
            "E 33\t: loss=2507.823, rmse=50.078, r2=0.472; v_loss=2365.055, v_rmse=48.632, v_r2=0.523; \n",
            "E 34\t: loss=2494.193, rmse=49.942, r2=0.475; v_loss=2274.407, v_rmse=47.691, v_r2=0.542; \n",
            "E 35\t: loss=2528.585, rmse=50.285, r2=0.468; v_loss=2151.499, v_rmse=46.384, v_r2=0.566; \n",
            "E 36\t: loss=2488.874, rmse=49.889, r2=0.476; v_loss=2397.249, v_rmse=48.962, v_r2=0.517; \n",
            "E 37\t: loss=2511.320, rmse=50.113, r2=0.471; v_loss=2255.590, v_rmse=47.493, v_r2=0.545; \n",
            "E 38\t: loss=2486.426, rmse=49.864, r2=0.477; v_loss=2280.152, v_rmse=47.751, v_r2=0.540; \n",
            "E 39\t: loss=2507.307, rmse=50.073, r2=0.472; v_loss=2354.407, v_rmse=48.522, v_r2=0.525; \n",
            "E 40\t: loss=2515.744, rmse=50.157, r2=0.470; v_loss=2085.551, v_rmse=45.668, v_r2=0.580; \n",
            "E 41\t: loss=2489.744, rmse=49.897, r2=0.476; v_loss=2250.545, v_rmse=47.440, v_r2=0.546; \n",
            "E 42\t: loss=2505.916, rmse=50.059, r2=0.472; v_loss=2121.844, v_rmse=46.063, v_r2=0.572; \n",
            "E 43\t: loss=2503.239, rmse=50.032, r2=0.473; v_loss=2185.289, v_rmse=46.747, v_r2=0.559; \n",
            "Finished: 2022-10-30 11:44:40.384963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "XrGQOj3e6X4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac9af5e-7967-4312-d5c6-2ab28d317271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.669,RMSE=-30.927\n",
            "Finished: 2022-10-30 11:44:42.779856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "xUq7j-FC7J6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.746401337342355  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.10000000188658846),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.01),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.9),\n",
        "('clip_y', 80),\n",
        "('include_settings', True),\n",
        "('poly_degree', 2),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "XfyXyuQl7J65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.10000000188658846, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.01,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.9, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51843c6e-68e0-4c91-aa18-8470b26a8a9e",
        "id": "AxhumNq67J7A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=50, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='tanh', model__dropout1=0.10000000188658846, model__layer1=512, model__learning_rate=0.01, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6fbbbf50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6fb43b90>], model__optim=<class 'keras.optimizers.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.9, verbose=0),\n",
              "                    clip_y=80, include_settings=True, poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "3IOHJ_u87J7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed76a72-edc5-4bb4-b51d-22408434da5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 512)               166400    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 166,913\n",
            "Trainable params: 166,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1663.746, rmse=40.789, r2=-1.734; v_loss=581.357, v_rmse=24.111, v_r2=0.021; \n",
            "E 2\t: loss=509.678, rmse=22.576, r2=0.162; v_loss=391.558, v_rmse=19.788, v_r2=0.341; \n",
            "E 3\t: loss=347.597, rmse=18.644, r2=0.429; v_loss=250.452, v_rmse=15.826, v_r2=0.578; \n",
            "E 4\t: loss=276.094, rmse=16.616, r2=0.546; v_loss=231.751, v_rmse=15.223, v_r2=0.610; \n",
            "E 5\t: loss=259.309, rmse=16.103, r2=0.574; v_loss=243.404, v_rmse=15.601, v_r2=0.590; \n",
            "E 6\t: loss=241.726, rmse=15.548, r2=0.603; v_loss=193.521, v_rmse=13.911, v_r2=0.674; \n",
            "E 7\t: loss=248.630, rmse=15.768, r2=0.591; v_loss=221.095, v_rmse=14.869, v_r2=0.628; \n",
            "E 8\t: loss=233.653, rmse=15.286, r2=0.616; v_loss=179.530, v_rmse=13.399, v_r2=0.698; \n",
            "E 9\t: loss=232.751, rmse=15.256, r2=0.618; v_loss=216.251, v_rmse=14.705, v_r2=0.636; \n",
            "E 10\t: loss=235.761, rmse=15.355, r2=0.613; v_loss=230.041, v_rmse=15.167, v_r2=0.613; \n",
            "E 11\t: loss=222.836, rmse=14.928, r2=0.634; v_loss=192.689, v_rmse=13.881, v_r2=0.676; \n",
            "E 12\t: loss=229.905, rmse=15.163, r2=0.622; v_loss=165.393, v_rmse=12.861, v_r2=0.722; \n",
            "E 13\t: loss=230.437, rmse=15.180, r2=0.621; v_loss=182.974, v_rmse=13.527, v_r2=0.692; \n",
            "E 14\t: loss=231.072, rmse=15.201, r2=0.620; v_loss=179.961, v_rmse=13.415, v_r2=0.697; \n",
            "E 15\t: loss=222.153, rmse=14.905, r2=0.635; v_loss=177.633, v_rmse=13.328, v_r2=0.701; \n",
            "E 16\t: loss=215.522, rmse=14.681, r2=0.646; v_loss=243.119, v_rmse=15.592, v_r2=0.591; \n",
            "E 17\t: loss=217.859, rmse=14.760, r2=0.642; v_loss=200.585, v_rmse=14.163, v_r2=0.662; \n",
            "E 18\t: loss=212.840, rmse=14.589, r2=0.650; v_loss=178.358, v_rmse=13.355, v_r2=0.700; \n",
            "E 19\t: loss=216.872, rmse=14.727, r2=0.644; v_loss=155.443, v_rmse=12.468, v_r2=0.738; \n",
            "E 20\t: loss=207.527, rmse=14.406, r2=0.659; v_loss=155.445, v_rmse=12.468, v_r2=0.738; \n",
            "E 21\t: loss=213.224, rmse=14.602, r2=0.650; v_loss=173.765, v_rmse=13.182, v_r2=0.707; \n",
            "E 22\t: loss=201.049, rmse=14.179, r2=0.670; v_loss=182.337, v_rmse=13.503, v_r2=0.693; \n",
            "E 23\t: loss=200.494, rmse=14.160, r2=0.671; v_loss=216.425, v_rmse=14.711, v_r2=0.636; \n",
            "E 24\t: loss=193.498, rmse=13.910, r2=0.682; v_loss=142.693, v_rmse=11.945, v_r2=0.760; \n",
            "E 25\t: loss=191.343, rmse=13.833, r2=0.686; v_loss=166.885, v_rmse=12.918, v_r2=0.719; \n",
            "E 26\t: loss=185.580, rmse=13.623, r2=0.695; v_loss=204.656, v_rmse=14.306, v_r2=0.655; \n",
            "E 27\t: loss=186.545, rmse=13.658, r2=0.693; v_loss=150.448, v_rmse=12.266, v_r2=0.747; \n",
            "E 28\t: loss=190.574, rmse=13.805, r2=0.687; v_loss=158.662, v_rmse=12.596, v_r2=0.733; \n",
            "E 29\t: loss=185.663, rmse=13.626, r2=0.695; v_loss=167.584, v_rmse=12.945, v_r2=0.718; \n",
            "E 30\t: loss=173.098, rmse=13.157, r2=0.716; v_loss=196.749, v_rmse=14.027, v_r2=0.669; \n",
            "E 31\t: loss=180.460, rmse=13.434, r2=0.703; v_loss=165.750, v_rmse=12.874, v_r2=0.721; \n",
            "E 32\t: loss=183.674, rmse=13.553, r2=0.698; v_loss=158.131, v_rmse=12.575, v_r2=0.734; \n",
            "E 33\t: loss=182.061, rmse=13.493, r2=0.701; v_loss=203.027, v_rmse=14.249, v_r2=0.658; \n",
            "E 34\t: loss=179.848, rmse=13.411, r2=0.704; v_loss=175.282, v_rmse=13.239, v_r2=0.705; \n",
            "E 35\t: loss=180.026, rmse=13.417, r2=0.704; v_loss=166.919, v_rmse=12.920, v_r2=0.719; \n",
            "Finished: 2022-10-30 11:47:54.092764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "bQgkkrV47J7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10561f92-d72a-4228-ade3-02c3303c80bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.734,RMSE=-14.426\n",
            "Finished: 2022-10-30 11:47:54.219725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-2 "
      ],
      "metadata": {
        "id": "FDHk5EzS8XuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "w3w40nFu8Xug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5812000406687549  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 502),\n",
        "('basemodel__epochs', 19),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.537010358774788),\n",
        "('basemodel__model__dropout2', 0.639760677232973),\n",
        "('basemodel__model__layer1', 507),\n",
        "('basemodel__model__layer2', 151),\n",
        "('basemodel__model__learning_rate', 0.0055564604418504495),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "Bt8LxsyX8Xun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=502,\n",
        "                           epochs=19,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.537010358774788, \n",
        "                           model__dropout2=0.639760677232973, \n",
        "                           model__layer1=507, \n",
        "                           model__layer2=151, \n",
        "                           model__learning_rate=0.0055564604418504495,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0628a9c-aaab-4944-858a-e1b325fd32ca",
        "id": "AzAbUlFJ8Xuv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=502, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=50, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='relu', model__activation2='elu', model__dropout1=0.537010358774788, model__dropout2=0.63976067723...51, model__learning_rate=0.0055564604418504495, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6fdc6610>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6ffb9890>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                    include_settings=True)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "x0gUTFtS8Xu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049734bd-c534-4e0e-e958-e98f7f176f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 507)               12675     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 507)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 151)               76708     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 151)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 152       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,535\n",
            "Trainable params: 89,535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5569.220, rmse=74.627, r2=-0.191; v_loss=4987.112, v_rmse=70.619, v_r2=0.125; \n",
            "E 2\t: loss=3479.918, rmse=58.991, r2=0.256; v_loss=3224.917, v_rmse=56.788, v_r2=0.434; \n",
            "E 3\t: loss=2583.726, rmse=50.830, r2=0.448; v_loss=2620.705, v_rmse=51.193, v_r2=0.540; \n",
            "E 4\t: loss=2453.642, rmse=49.534, r2=0.475; v_loss=2519.833, v_rmse=50.198, v_r2=0.558; \n",
            "E 5\t: loss=2339.840, rmse=48.372, r2=0.500; v_loss=2512.093, v_rmse=50.121, v_r2=0.559; \n",
            "E 6\t: loss=2317.010, rmse=48.135, r2=0.505; v_loss=2611.509, v_rmse=51.103, v_r2=0.542; \n",
            "E 7\t: loss=2300.160, rmse=47.960, r2=0.508; v_loss=2463.565, v_rmse=49.634, v_r2=0.568; \n",
            "E 8\t: loss=2274.682, rmse=47.694, r2=0.514; v_loss=2497.378, v_rmse=49.974, v_r2=0.562; \n",
            "E 9\t: loss=2273.521, rmse=47.681, r2=0.514; v_loss=2475.584, v_rmse=49.755, v_r2=0.566; \n",
            "E 10\t: loss=2243.613, rmse=47.367, r2=0.520; v_loss=2429.426, v_rmse=49.289, v_r2=0.574; \n",
            "E 11\t: loss=2228.935, rmse=47.212, r2=0.523; v_loss=2524.957, v_rmse=50.249, v_r2=0.557; \n",
            "E 12\t: loss=2243.102, rmse=47.361, r2=0.520; v_loss=2349.951, v_rmse=48.476, v_r2=0.588; \n",
            "E 13\t: loss=2233.330, rmse=47.258, r2=0.523; v_loss=2383.371, v_rmse=48.820, v_r2=0.582; \n",
            "E 14\t: loss=2221.156, rmse=47.129, r2=0.525; v_loss=2310.129, v_rmse=48.064, v_r2=0.595; \n",
            "E 15\t: loss=2262.258, rmse=47.563, r2=0.516; v_loss=2531.504, v_rmse=50.314, v_r2=0.556; \n",
            "E 16\t: loss=2257.809, rmse=47.516, r2=0.517; v_loss=2359.637, v_rmse=48.576, v_r2=0.586; \n",
            "E 17\t: loss=2241.125, rmse=47.341, r2=0.521; v_loss=2504.082, v_rmse=50.041, v_r2=0.561; \n",
            "E 18\t: loss=2233.626, rmse=47.261, r2=0.522; v_loss=2434.617, v_rmse=49.342, v_r2=0.573; \n",
            "E 19\t: loss=2226.638, rmse=47.187, r2=0.524; v_loss=2330.675, v_rmse=48.277, v_r2=0.591; \n",
            "Finished: 2022-10-30 11:53:47.725438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "WTB1R-9-8Xu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4d2619-2564-4dc8-82d1-5b1f80dc2aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.613,RMSE=-33.435\n",
            "Finished: 2022-10-30 11:55:02.868973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "P3IBawiY8XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.806487727981995  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 91),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.8099281594197152),\n",
        "('basemodel__model__dropout2', 0.3275285867415841),\n",
        "('basemodel__model__layer1', 61),\n",
        "('basemodel__model__layer2', 379),\n",
        "('basemodel__model__learning_rate', 0.0017750683313794622),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.41651962978418944),\n",
        "('clip_y', 80),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "95Sz7A0l8XvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=91,\n",
        "                           epochs=250,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.8099281594197152, \n",
        "                           model__dropout2=0.3275285867415841, \n",
        "                           model__layer1=61, \n",
        "                           model__layer2=379, \n",
        "                           model__learning_rate=0.0017750683313794622,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.41651962978418944, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e175e39a-0a7a-48e2-fd98-14692ddbf2e7",
        "id": "8P2llTd78XvH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=91, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=250, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='tanh', model__activation2='elu', model__dropout1=0.8099281594197152, model__dropout2=0.3275285867...learning_rate=0.0017750683313794622, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6e5509d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6e537ed0>], model__optim=<class 'keras.optimizers.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.41651962978418944, verbose=0),\n",
              "                    clip_y=80)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "vh-GouSB8XvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6633765-a985-435e-831f-223852c696f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 61)                1342      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 61)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 379)               23498     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 379)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 380       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,220\n",
            "Trainable params: 25,220\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1240.595, rmse=35.222, r2=-1.095; v_loss=604.731, v_rmse=24.591, v_r2=-0.008; \n",
            "E 2\t: loss=628.811, rmse=25.076, r2=-0.062; v_loss=518.085, v_rmse=22.761, v_r2=0.137; \n",
            "E 3\t: loss=512.060, rmse=22.629, r2=0.135; v_loss=372.525, v_rmse=19.301, v_r2=0.379; \n",
            "E 4\t: loss=408.959, rmse=20.223, r2=0.309; v_loss=343.648, v_rmse=18.538, v_r2=0.427; \n",
            "E 5\t: loss=344.619, rmse=18.564, r2=0.418; v_loss=233.559, v_rmse=15.283, v_r2=0.611; \n",
            "E 6\t: loss=300.361, rmse=17.331, r2=0.493; v_loss=205.121, v_rmse=14.322, v_r2=0.658; \n",
            "E 7\t: loss=279.926, rmse=16.731, r2=0.527; v_loss=210.914, v_rmse=14.523, v_r2=0.649; \n",
            "E 8\t: loss=262.227, rmse=16.193, r2=0.557; v_loss=187.759, v_rmse=13.703, v_r2=0.687; \n",
            "E 9\t: loss=247.245, rmse=15.724, r2=0.582; v_loss=167.287, v_rmse=12.934, v_r2=0.721; \n",
            "E 10\t: loss=235.829, rmse=15.357, r2=0.602; v_loss=162.347, v_rmse=12.742, v_r2=0.729; \n",
            "E 11\t: loss=228.370, rmse=15.112, r2=0.614; v_loss=139.843, v_rmse=11.826, v_r2=0.767; \n",
            "E 12\t: loss=216.916, rmse=14.728, r2=0.634; v_loss=135.054, v_rmse=11.621, v_r2=0.775; \n",
            "E 13\t: loss=208.090, rmse=14.425, r2=0.649; v_loss=155.373, v_rmse=12.465, v_r2=0.741; \n",
            "E 14\t: loss=207.209, rmse=14.395, r2=0.650; v_loss=131.469, v_rmse=11.466, v_r2=0.781; \n",
            "E 15\t: loss=202.178, rmse=14.219, r2=0.659; v_loss=129.681, v_rmse=11.388, v_r2=0.784; \n",
            "E 16\t: loss=198.545, rmse=14.091, r2=0.665; v_loss=156.541, v_rmse=12.512, v_r2=0.739; \n",
            "E 17\t: loss=197.454, rmse=14.052, r2=0.666; v_loss=126.751, v_rmse=11.258, v_r2=0.789; \n",
            "E 18\t: loss=195.095, rmse=13.968, r2=0.670; v_loss=126.722, v_rmse=11.257, v_r2=0.789; \n",
            "E 19\t: loss=193.198, rmse=13.900, r2=0.674; v_loss=126.955, v_rmse=11.267, v_r2=0.788; \n",
            "E 20\t: loss=190.381, rmse=13.798, r2=0.678; v_loss=133.108, v_rmse=11.537, v_r2=0.778; \n",
            "E 21\t: loss=188.699, rmse=13.737, r2=0.681; v_loss=120.149, v_rmse=10.961, v_r2=0.800; \n",
            "E 22\t: loss=184.748, rmse=13.592, r2=0.688; v_loss=121.761, v_rmse=11.035, v_r2=0.797; \n",
            "E 23\t: loss=183.754, rmse=13.556, r2=0.690; v_loss=143.750, v_rmse=11.990, v_r2=0.760; \n",
            "E 24\t: loss=183.108, rmse=13.532, r2=0.691; v_loss=130.031, v_rmse=11.403, v_r2=0.783; \n",
            "E 25\t: loss=181.580, rmse=13.475, r2=0.693; v_loss=128.083, v_rmse=11.317, v_r2=0.787; \n",
            "E 26\t: loss=180.573, rmse=13.438, r2=0.695; v_loss=125.534, v_rmse=11.204, v_r2=0.791; \n",
            "E 27\t: loss=178.386, rmse=13.356, r2=0.699; v_loss=119.504, v_rmse=10.932, v_r2=0.801; \n",
            "E 28\t: loss=177.329, rmse=13.316, r2=0.700; v_loss=123.288, v_rmse=11.104, v_r2=0.795; \n",
            "E 29\t: loss=177.417, rmse=13.320, r2=0.700; v_loss=136.532, v_rmse=11.685, v_r2=0.772; \n",
            "E 30\t: loss=175.500, rmse=13.248, r2=0.704; v_loss=132.162, v_rmse=11.496, v_r2=0.780; \n",
            "E 31\t: loss=174.519, rmse=13.211, r2=0.705; v_loss=123.901, v_rmse=11.131, v_r2=0.794; \n",
            "E 32\t: loss=174.083, rmse=13.194, r2=0.706; v_loss=132.640, v_rmse=11.517, v_r2=0.779; \n",
            "E 33\t: loss=173.230, rmse=13.162, r2=0.707; v_loss=120.440, v_rmse=10.975, v_r2=0.799; \n",
            "E 34\t: loss=173.123, rmse=13.158, r2=0.708; v_loss=165.024, v_rmse=12.846, v_r2=0.725; \n",
            "E 35\t: loss=171.382, rmse=13.091, r2=0.711; v_loss=138.105, v_rmse=11.752, v_r2=0.770; \n",
            "E 36\t: loss=171.655, rmse=13.102, r2=0.710; v_loss=128.827, v_rmse=11.350, v_r2=0.785; \n",
            "E 37\t: loss=171.088, rmse=13.080, r2=0.711; v_loss=131.863, v_rmse=11.483, v_r2=0.780; \n",
            "E 38\t: loss=170.992, rmse=13.076, r2=0.711; v_loss=119.673, v_rmse=10.940, v_r2=0.801; \n",
            "E 39\t: loss=169.430, rmse=13.017, r2=0.714; v_loss=121.520, v_rmse=11.024, v_r2=0.797; \n",
            "E 40\t: loss=170.364, rmse=13.052, r2=0.712; v_loss=122.416, v_rmse=11.064, v_r2=0.796; \n",
            "E 41\t: loss=169.057, rmse=13.002, r2=0.714; v_loss=119.406, v_rmse=10.927, v_r2=0.801; \n",
            "E 42\t: loss=166.884, rmse=12.918, r2=0.718; v_loss=120.035, v_rmse=10.956, v_r2=0.800; \n",
            "E 43\t: loss=168.597, rmse=12.984, r2=0.715; v_loss=119.846, v_rmse=10.947, v_r2=0.800; \n",
            "E 44\t: loss=167.037, rmse=12.924, r2=0.718; v_loss=135.203, v_rmse=11.628, v_r2=0.775; \n",
            "E 45\t: loss=166.930, rmse=12.920, r2=0.718; v_loss=128.392, v_rmse=11.331, v_r2=0.786; \n",
            "E 46\t: loss=168.474, rmse=12.980, r2=0.715; v_loss=122.575, v_rmse=11.071, v_r2=0.796; \n",
            "E 47\t: loss=165.122, rmse=12.850, r2=0.721; v_loss=159.445, v_rmse=12.627, v_r2=0.734; \n",
            "E 48\t: loss=164.827, rmse=12.838, r2=0.722; v_loss=119.828, v_rmse=10.947, v_r2=0.800; \n",
            "E 49\t: loss=165.815, rmse=12.877, r2=0.720; v_loss=125.773, v_rmse=11.215, v_r2=0.790; \n",
            "E 50\t: loss=164.038, rmse=12.808, r2=0.723; v_loss=122.147, v_rmse=11.052, v_r2=0.796; \n",
            "E 51\t: loss=164.330, rmse=12.819, r2=0.722; v_loss=125.681, v_rmse=11.211, v_r2=0.791; \n",
            "E 52\t: loss=164.598, rmse=12.830, r2=0.722; v_loss=126.322, v_rmse=11.239, v_r2=0.789; \n",
            "E 53\t: loss=162.088, rmse=12.731, r2=0.726; v_loss=117.543, v_rmse=10.842, v_r2=0.804; \n",
            "E 54\t: loss=163.089, rmse=12.771, r2=0.725; v_loss=124.000, v_rmse=11.136, v_r2=0.793; \n",
            "E 55\t: loss=163.923, rmse=12.803, r2=0.723; v_loss=124.836, v_rmse=11.173, v_r2=0.792; \n",
            "E 56\t: loss=160.743, rmse=12.678, r2=0.728; v_loss=130.121, v_rmse=11.407, v_r2=0.783; \n",
            "E 57\t: loss=164.159, rmse=12.812, r2=0.723; v_loss=129.676, v_rmse=11.388, v_r2=0.784; \n",
            "E 58\t: loss=162.759, rmse=12.758, r2=0.725; v_loss=122.476, v_rmse=11.067, v_r2=0.796; \n",
            "E 59\t: loss=162.931, rmse=12.764, r2=0.725; v_loss=126.369, v_rmse=11.241, v_r2=0.789; \n",
            "E 60\t: loss=162.237, rmse=12.737, r2=0.726; v_loss=118.038, v_rmse=10.865, v_r2=0.803; \n",
            "E 61\t: loss=163.828, rmse=12.800, r2=0.723; v_loss=117.712, v_rmse=10.850, v_r2=0.804; \n",
            "Finished: 2022-10-30 12:09:13.676117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Sc37islE8XvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afdf67b7-71bc-4b69-eeaf-bfa02c6dac37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9b6e2e38c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.811,RMSE=-12.159\n",
            "Finished: 2022-10-30 12:09:13.792783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "wZocoM5X8XvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5749427963405077  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 108),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'elu'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.6853622426866657),\n",
        "('basemodel__model__dropout2', 0.4181419652000947),\n",
        "('basemodel__model__layer1', 392),\n",
        "('basemodel__model__layer2', 51),\n",
        "('basemodel__model__learning_rate', 0.007788469297925655),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.31679716488321474),\n",
        "('include_settings', True),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "AlgXpCVb8XvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=108,\n",
        "                           epochs=50,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.6853622426866657, \n",
        "                           model__dropout2=0.4181419652000947, \n",
        "                           model__layer1=392, \n",
        "                           model__layer2=51, \n",
        "                           model__learning_rate=0.007788469297925655,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.31679716488321474, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179262d3-c8c9-4f16-ace0-9f1837c3daaf",
        "id": "6TR5_NRP8XvP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=108, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=50, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='elu', model__activation2='elu', model__dropout1=0.6853622426866657, model__dropout2=0.41814196520...l__learning_rate=0.007788469297925655, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6e1a5190>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6e1a5c10>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.31679716488321474, verbose=0),\n",
              "                    poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "kGivi_vW8XvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb60eb4-fd93-4757-f6a0-16c328ee7e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 392)               793408    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 392)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 51)                20043     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 51)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 52        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,503\n",
            "Trainable params: 813,503\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5311.123, rmse=72.877, r2=-0.081; v_loss=2761.043, v_rmse=52.546, v_r2=0.386; \n",
            "E 2\t: loss=3604.473, rmse=60.037, r2=0.266; v_loss=2665.880, v_rmse=51.632, v_r2=0.408; \n",
            "E 3\t: loss=3463.466, rmse=58.851, r2=0.295; v_loss=2850.273, v_rmse=53.388, v_r2=0.367; \n",
            "E 4\t: loss=3324.337, rmse=57.657, r2=0.323; v_loss=2242.456, v_rmse=47.355, v_r2=0.502; \n",
            "E 5\t: loss=3338.207, rmse=57.777, r2=0.321; v_loss=2983.821, v_rmse=54.624, v_r2=0.337; \n",
            "E 6\t: loss=3158.606, rmse=56.201, r2=0.357; v_loss=2375.480, v_rmse=48.739, v_r2=0.472; \n",
            "E 7\t: loss=4151.381, rmse=64.431, r2=0.155; v_loss=3709.638, v_rmse=60.907, v_r2=0.176; \n",
            "E 8\t: loss=4332.141, rmse=65.819, r2=0.118; v_loss=2556.550, v_rmse=50.562, v_r2=0.432; \n",
            "E 9\t: loss=5331.031, rmse=73.014, r2=-0.085; v_loss=3999.843, v_rmse=63.244, v_r2=0.111; \n",
            "E 10\t: loss=9871.984, rmse=99.358, r2=-1.009; v_loss=4959.419, v_rmse=70.423, v_r2=-0.102; \n",
            "E 11\t: loss=5958.449, rmse=77.191, r2=-0.213; v_loss=3985.324, v_rmse=63.129, v_r2=0.114; \n",
            "Finished: 2022-10-30 12:13:14.019332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "W4aA1r2q8XvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276c4773-a815-4bf5-eb11-d5b85aecf21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9b6a7408c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.623,RMSE=-33.018\n",
            "Finished: 2022-10-30 12:13:14.195920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "01ti8j0I8Xva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8061999136353725  \n",
        "Test: 0.\n",
        "``` \n",
        "('basemodel__batch_size', 163),\n",
        "('basemodel__epochs', 32),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__dropout1', 0.1203636705927238),\n",
        "('basemodel__model__dropout2', 0.3108545284702169),\n",
        "('basemodel__model__layer1', 18),\n",
        "('basemodel__model__layer2', 364),\n",
        "('basemodel__model__learning_rate', 0.009076852273996898),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.14877733495106543),\n",
        "('clip_y', 87),\n",
        "('include_settings', True),\n",
        "('poly_degree', 2),\n",
        "('scaler', MinMaxScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "dNgvLPHf8Xvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=87\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=MinMaxScaler(), poly_degree=2,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=163,\n",
        "                           epochs=32,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='relu',\n",
        "                           model__dropout1=0.1203636705927238, \n",
        "                           model__dropout2=0.3108545284702169, \n",
        "                           model__layer1=18, \n",
        "                           model__layer2=364, \n",
        "                           model__learning_rate=0.009076852273996898,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.14877733495106543, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c7a6f6-4997-4043-9452-53158f2d9181",
        "id": "dAWLzDAC8Xvg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=163, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=32, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='selu', model__activation2='relu', model__dropout1=0.1203636705927238, model__dropout2=0.310854528...', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6a73f8d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6a73f950>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.14877733495106543, verbose=0),\n",
              "                    clip_y=87, include_settings=True, poly_degree=2,\n",
              "                    scaler=MinMaxScaler())"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "w4AgmUsB8Xvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df84c3d6-7c44-4302-ff6d-8075c313449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_29 (Dense)            (None, 18)                5850      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 18)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 364)               6916      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 364)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 365       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,131\n",
            "Trainable params: 13,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=834.728, rmse=28.892, r2=-0.133; v_loss=421.497, v_rmse=20.530, v_r2=0.432; \n",
            "E 2\t: loss=387.035, rmse=19.673, r2=0.474; v_loss=263.928, v_rmse=16.246, v_r2=0.644; \n",
            "E 3\t: loss=295.522, rmse=17.191, r2=0.599; v_loss=225.401, v_rmse=15.013, v_r2=0.696; \n",
            "E 4\t: loss=269.840, rmse=16.427, r2=0.634; v_loss=243.154, v_rmse=15.593, v_r2=0.672; \n",
            "E 5\t: loss=254.380, rmse=15.949, r2=0.655; v_loss=199.809, v_rmse=14.135, v_r2=0.731; \n",
            "E 6\t: loss=243.936, rmse=15.618, r2=0.669; v_loss=287.602, v_rmse=16.959, v_r2=0.612; \n",
            "E 7\t: loss=233.084, rmse=15.267, r2=0.684; v_loss=177.429, v_rmse=13.320, v_r2=0.761; \n",
            "E 8\t: loss=233.659, rmse=15.286, r2=0.683; v_loss=185.224, v_rmse=13.610, v_r2=0.750; \n",
            "E 9\t: loss=235.423, rmse=15.344, r2=0.680; v_loss=164.840, v_rmse=12.839, v_r2=0.778; \n",
            "E 10\t: loss=227.761, rmse=15.092, r2=0.691; v_loss=172.279, v_rmse=13.126, v_r2=0.768; \n",
            "E 11\t: loss=234.865, rmse=15.325, r2=0.681; v_loss=189.099, v_rmse=13.751, v_r2=0.745; \n",
            "E 12\t: loss=223.656, rmse=14.955, r2=0.696; v_loss=190.207, v_rmse=13.792, v_r2=0.743; \n",
            "E 13\t: loss=224.706, rmse=14.990, r2=0.695; v_loss=160.974, v_rmse=12.688, v_r2=0.783; \n",
            "E 14\t: loss=221.144, rmse=14.871, r2=0.700; v_loss=178.147, v_rmse=13.347, v_r2=0.760; \n",
            "E 15\t: loss=220.188, rmse=14.839, r2=0.701; v_loss=164.465, v_rmse=12.824, v_r2=0.778; \n",
            "E 16\t: loss=222.975, rmse=14.932, r2=0.697; v_loss=186.738, v_rmse=13.665, v_r2=0.748; \n",
            "E 17\t: loss=221.406, rmse=14.880, r2=0.699; v_loss=176.590, v_rmse=13.289, v_r2=0.762; \n",
            "E 18\t: loss=219.883, rmse=14.828, r2=0.701; v_loss=250.816, v_rmse=15.837, v_r2=0.662; \n",
            "E 19\t: loss=221.733, rmse=14.891, r2=0.699; v_loss=179.459, v_rmse=13.396, v_r2=0.758; \n",
            "E 20\t: loss=212.244, rmse=14.569, r2=0.712; v_loss=165.295, v_rmse=12.857, v_r2=0.777; \n",
            "E 21\t: loss=213.885, rmse=14.625, r2=0.710; v_loss=190.944, v_rmse=13.818, v_r2=0.742; \n",
            "E 22\t: loss=213.197, rmse=14.601, r2=0.711; v_loss=201.863, v_rmse=14.208, v_r2=0.728; \n",
            "E 23\t: loss=207.825, rmse=14.416, r2=0.718; v_loss=221.022, v_rmse=14.867, v_r2=0.702; \n",
            "E 24\t: loss=210.259, rmse=14.500, r2=0.715; v_loss=165.440, v_rmse=12.862, v_r2=0.777; \n",
            "E 25\t: loss=206.016, rmse=14.353, r2=0.720; v_loss=219.570, v_rmse=14.818, v_r2=0.704; \n",
            "E 26\t: loss=207.495, rmse=14.405, r2=0.718; v_loss=174.889, v_rmse=13.225, v_r2=0.764; \n",
            "E 27\t: loss=210.420, rmse=14.506, r2=0.714; v_loss=197.775, v_rmse=14.063, v_r2=0.733; \n",
            "E 28\t: loss=206.062, rmse=14.355, r2=0.720; v_loss=189.941, v_rmse=13.782, v_r2=0.744; \n",
            "E 29\t: loss=206.543, rmse=14.372, r2=0.720; v_loss=254.748, v_rmse=15.961, v_r2=0.656; \n",
            "E 30\t: loss=208.521, rmse=14.440, r2=0.717; v_loss=164.614, v_rmse=12.830, v_r2=0.778; \n",
            "Finished: 2022-10-30 12:15:20.900551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "N-Pj7cIL8Xvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af845183-a753-4623-8ba2-3f3aedbea446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.770,RMSE=-14.709\n",
            "Finished: 2022-10-30 12:15:21.011736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-3 "
      ],
      "metadata": {
        "id": "00TdIEZ6FBx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "kL9N0ocMFBx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5854880998236767    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 200),\n",
        "('basemodel__epochs', 35),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'sigmoid'),\n",
        "('basemodel__model__activation3', 'sigmoid'),\n",
        "('basemodel__model__dropout1', 0.38531894797761335),\n",
        "('basemodel__model__dropout2', 0.2713124052618954),\n",
        "('basemodel__model__dropout3', 0.4032026752250656),\n",
        "('basemodel__model__layer1', 390),\n",
        "('basemodel__model__layer2', 371),\n",
        "('basemodel__model__layer3', 196),\n",
        "('basemodel__model__learning_rate', 0.00476952337213749),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.10948726819576624),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "zmVugjXMFByB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=200,\n",
        "                           epochs=35,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__dropout1=0.38531894797761335, \n",
        "                           model__dropout2=0.2713124052618954, \n",
        "                           model__dropout3=0.4032026752250656, \n",
        "                           model__layer1=390, \n",
        "                           model__layer2=371, \n",
        "                           model__layer3=196, \n",
        "                           model__learning_rate=0.00476952337213749,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.10948726819576624, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7c84dd-9ba7-435d-91db-ab6d51fe9f16",
        "id": "hI5gTmNEFByH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=200, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=35, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='selu', model__activation2='sigmoid', model__activation3='sigmoid', model__dropout1=0.385318947977...ning_rate=0.00476952337213749, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6a07b090>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6a070690>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.10948726819576624, verbose=0),\n",
              "                    include_settings=True)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cfdc7b-c70f-4134-ad5a-fc37ca869a0c",
        "id": "kcvF0xLyFByO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 390)               9750      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 390)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 371)               145061    \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 371)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 196)               72912     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 196)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 197       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227,920\n",
            "Trainable params: 227,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=7800.748, rmse=88.322, r2=-0.666; v_loss=6025.341, v_rmse=77.623, v_r2=-0.080; \n",
            "E 2\t: loss=4783.663, rmse=69.164, r2=-0.021; v_loss=5637.461, v_rmse=75.083, v_r2=-0.011; \n",
            "E 3\t: loss=4241.771, rmse=65.129, r2=0.094; v_loss=3681.119, v_rmse=60.672, v_r2=0.340; \n",
            "E 4\t: loss=2770.492, rmse=52.635, r2=0.408; v_loss=2871.222, v_rmse=53.584, v_r2=0.485; \n",
            "E 5\t: loss=2390.761, rmse=48.895, r2=0.489; v_loss=2765.022, v_rmse=52.583, v_r2=0.504; \n",
            "E 6\t: loss=2254.528, rmse=47.482, r2=0.519; v_loss=2478.826, v_rmse=49.788, v_r2=0.556; \n",
            "E 7\t: loss=2186.992, rmse=46.765, r2=0.533; v_loss=2466.410, v_rmse=49.663, v_r2=0.558; \n",
            "E 8\t: loss=2163.928, rmse=46.518, r2=0.538; v_loss=2401.106, v_rmse=49.001, v_r2=0.570; \n",
            "E 9\t: loss=2142.690, rmse=46.289, r2=0.542; v_loss=2491.466, v_rmse=49.915, v_r2=0.553; \n",
            "E 10\t: loss=2141.955, rmse=46.281, r2=0.543; v_loss=2599.042, v_rmse=50.981, v_r2=0.534; \n",
            "E 11\t: loss=2130.553, rmse=46.158, r2=0.545; v_loss=2445.761, v_rmse=49.455, v_r2=0.562; \n",
            "E 12\t: loss=2166.138, rmse=46.542, r2=0.537; v_loss=2442.265, v_rmse=49.419, v_r2=0.562; \n",
            "E 13\t: loss=2140.554, rmse=46.266, r2=0.543; v_loss=2399.587, v_rmse=48.986, v_r2=0.570; \n",
            "E 14\t: loss=2146.004, rmse=46.325, r2=0.542; v_loss=2513.299, v_rmse=50.133, v_r2=0.549; \n",
            "E 15\t: loss=2145.237, rmse=46.317, r2=0.542; v_loss=2392.071, v_rmse=48.909, v_r2=0.571; \n",
            "E 16\t: loss=2150.906, rmse=46.378, r2=0.541; v_loss=2509.109, v_rmse=50.091, v_r2=0.550; \n",
            "Finished: 2022-10-30 12:30:08.642622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10da4fbb-a1b8-486b-bb5d-c4ac7ef325d3",
        "id": "QG0jhrtKFByS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.639,RMSE=-32.315\n",
            "Finished: 2022-10-30 12:30:08.749556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "1Xs7NWLvFByZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.7984364934573063    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 130),\n",
        "('basemodel__epochs', 47),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.6591215870708264),\n",
        "('basemodel__model__dropout2', 0.3075952959408218),\n",
        "('basemodel__model__dropout3', 0.3971628411684459),\n",
        "('basemodel__model__layer1', 444),\n",
        "('basemodel__model__layer2', 512),\n",
        "('basemodel__model__layer3', 381),\n",
        "('basemodel__model__learning_rate', 0.0035332717086087725),\n",
        "('basemodel__model__optim', keras.optimizer_v2.RMSprop.RMSprop),\n",
        "('basemodel__validation_split', 0.15776882704708337),\n",
        "('clip_y', 80),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "RbLuNAHAFBye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=130,\n",
        "                           epochs=47,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='elu',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.6591215870708264, \n",
        "                           model__dropout2=0.3075952959408218, \n",
        "                           model__dropout3=0.3971628411684459, \n",
        "                           model__layer1=444, \n",
        "                           model__layer2=512, \n",
        "                           model__layer3=381,  \n",
        "                           model__learning_rate=0.0035332717086087725,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.15776882704708337, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85612db9-23b6-4469-b01f-3adf511bfee8",
        "id": "PSnWYxQiFByi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=130, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=47, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='relu', model__activation2='elu', model__activation3='selu', model__dropout1=0.6591215870708264, mo...2717086087725, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b6e6cfa50>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b6e6d6a90>], model__optim=<class 'keras.optimizers.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.15776882704708337, verbose=0),\n",
              "                    clip_y=80, include_settings=True)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca663a1b-1b24-4e42-8ea2-237604fcbf58",
        "id": "wU3RI7KvFByq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 444)               11100     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 444)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 512)               227840    \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 381)               195453    \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 381)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 382       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 434,775\n",
            "Trainable params: 434,775\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=546.261, rmse=23.372, r2=0.083; v_loss=367.668, v_rmse=19.175, v_r2=0.382; \n",
            "E 2\t: loss=317.289, rmse=17.813, r2=0.467; v_loss=287.065, v_rmse=16.943, v_r2=0.518; \n",
            "E 3\t: loss=269.771, rmse=16.425, r2=0.547; v_loss=210.291, v_rmse=14.501, v_r2=0.647; \n",
            "E 4\t: loss=245.030, rmse=15.653, r2=0.588; v_loss=222.409, v_rmse=14.913, v_r2=0.626; \n",
            "E 5\t: loss=225.298, rmse=15.010, r2=0.622; v_loss=219.385, v_rmse=14.812, v_r2=0.631; \n",
            "E 6\t: loss=215.591, rmse=14.683, r2=0.638; v_loss=185.578, v_rmse=13.623, v_r2=0.688; \n",
            "E 7\t: loss=205.824, rmse=14.347, r2=0.654; v_loss=200.963, v_rmse=14.176, v_r2=0.662; \n",
            "E 8\t: loss=198.617, rmse=14.093, r2=0.666; v_loss=263.200, v_rmse=16.223, v_r2=0.558; \n",
            "E 9\t: loss=195.945, rmse=13.998, r2=0.671; v_loss=118.692, v_rmse=10.895, v_r2=0.801; \n",
            "E 10\t: loss=187.025, rmse=13.676, r2=0.686; v_loss=125.846, v_rmse=11.218, v_r2=0.789; \n",
            "E 11\t: loss=185.719, rmse=13.628, r2=0.688; v_loss=145.965, v_rmse=12.082, v_r2=0.755; \n",
            "E 12\t: loss=180.266, rmse=13.426, r2=0.697; v_loss=211.764, v_rmse=14.552, v_r2=0.644; \n",
            "E 13\t: loss=176.875, rmse=13.299, r2=0.703; v_loss=176.863, v_rmse=13.299, v_r2=0.703; \n",
            "E 14\t: loss=172.748, rmse=13.143, r2=0.710; v_loss=180.861, v_rmse=13.448, v_r2=0.696; \n",
            "E 15\t: loss=174.106, rmse=13.195, r2=0.708; v_loss=119.025, v_rmse=10.910, v_r2=0.800; \n",
            "E 16\t: loss=169.555, rmse=13.021, r2=0.715; v_loss=155.492, v_rmse=12.470, v_r2=0.739; \n",
            "E 17\t: loss=169.206, rmse=13.008, r2=0.716; v_loss=146.480, v_rmse=12.103, v_r2=0.754; \n",
            "E 18\t: loss=167.476, rmse=12.941, r2=0.719; v_loss=125.777, v_rmse=11.215, v_r2=0.789; \n",
            "E 19\t: loss=165.326, rmse=12.858, r2=0.722; v_loss=123.569, v_rmse=11.116, v_r2=0.792; \n",
            "E 20\t: loss=165.047, rmse=12.847, r2=0.723; v_loss=146.790, v_rmse=12.116, v_r2=0.753; \n",
            "E 21\t: loss=162.800, rmse=12.759, r2=0.727; v_loss=147.448, v_rmse=12.143, v_r2=0.752; \n",
            "E 22\t: loss=162.318, rmse=12.740, r2=0.727; v_loss=105.419, v_rmse=10.267, v_r2=0.823; \n",
            "E 23\t: loss=160.387, rmse=12.664, r2=0.731; v_loss=121.443, v_rmse=11.020, v_r2=0.796; \n",
            "E 24\t: loss=161.398, rmse=12.704, r2=0.729; v_loss=124.898, v_rmse=11.176, v_r2=0.790; \n",
            "E 25\t: loss=160.116, rmse=12.654, r2=0.731; v_loss=134.187, v_rmse=11.584, v_r2=0.775; \n",
            "E 26\t: loss=158.714, rmse=12.598, r2=0.733; v_loss=132.459, v_rmse=11.509, v_r2=0.777; \n",
            "E 27\t: loss=158.681, rmse=12.597, r2=0.734; v_loss=129.693, v_rmse=11.388, v_r2=0.782; \n",
            "E 28\t: loss=156.078, rmse=12.493, r2=0.738; v_loss=154.565, v_rmse=12.432, v_r2=0.740; \n",
            "E 29\t: loss=157.221, rmse=12.539, r2=0.736; v_loss=137.298, v_rmse=11.717, v_r2=0.769; \n",
            "E 30\t: loss=154.304, rmse=12.422, r2=0.741; v_loss=111.804, v_rmse=10.574, v_r2=0.812; \n",
            "E 31\t: loss=156.373, rmse=12.505, r2=0.737; v_loss=118.750, v_rmse=10.897, v_r2=0.800; \n",
            "E 32\t: loss=155.649, rmse=12.476, r2=0.739; v_loss=143.922, v_rmse=11.997, v_r2=0.758; \n",
            "E 33\t: loss=153.356, rmse=12.384, r2=0.742; v_loss=123.418, v_rmse=11.109, v_r2=0.793; \n",
            "E 34\t: loss=155.244, rmse=12.460, r2=0.739; v_loss=146.828, v_rmse=12.117, v_r2=0.753; \n",
            "E 35\t: loss=155.140, rmse=12.456, r2=0.739; v_loss=139.421, v_rmse=11.808, v_r2=0.766; \n",
            "E 36\t: loss=153.460, rmse=12.388, r2=0.742; v_loss=119.688, v_rmse=10.940, v_r2=0.799; \n",
            "E 37\t: loss=153.851, rmse=12.404, r2=0.742; v_loss=126.963, v_rmse=11.268, v_r2=0.787; \n",
            "E 38\t: loss=155.077, rmse=12.453, r2=0.740; v_loss=115.390, v_rmse=10.742, v_r2=0.806; \n",
            "Finished: 2022-10-30 12:34:54.737873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c07ebac-141f-4454-9635-8598e14940c2",
        "id": "9s8vEev3FByt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.841,RMSE=-11.148\n",
            "Finished: 2022-10-30 12:34:54.867984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "yk8grx_3FByx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5825762286758006    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 341),\n",
        "('basemodel__epochs', 34),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.7525277426098136),\n",
        "('basemodel__model__dropout2', 0.19508775114046617),\n",
        "('basemodel__model__dropout3', 0.1),\n",
        "('basemodel__model__layer1', 409),\n",
        "('basemodel__model__layer2', 185),\n",
        "('basemodel__model__layer3', 306),\n",
        "('basemodel__model__learning_rate', 0.0023786927659858437),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.10918862929162437),\n",
        "('include_settings', True),\n",
        "('poly_degree', 2),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "2TWz2xbfFBy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=341,\n",
        "                           epochs=34,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.7525277426098136, \n",
        "                           model__dropout2=0.19508775114046617, \n",
        "                           model__dropout3=0.1, \n",
        "                           model__layer1=409, \n",
        "                           model__layer2=185, \n",
        "                           model__layer3=306, \n",
        "                           model__learning_rate=0.0023786927659858437,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.10918862929162437, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c6cf37-9ee9-40c8-ee7c-5c9adcd6bd1d",
        "id": "97IkcENqFBy1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=341, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=34, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='tanh', model__activation2='tanh', model__activation3='selu', model__dropout1=0.7525277426098136, m...786927659858437, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b1bb97710>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b1bb8da10>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.10918862929162437, verbose=0),\n",
              "                    include_settings=True, poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8092c0e-d8c4-4768-c568-8003c91e0e21",
        "id": "GGBuOcsxFBy4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_52 (Dense)            (None, 409)               132925    \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 409)               0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 185)               75850     \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 185)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 306)               56916     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 306)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1)                 307       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 265,998\n",
            "Trainable params: 265,998\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=4915.990, rmse=70.114, r2=-0.050; v_loss=3352.546, v_rmse=57.901, v_r2=0.399; \n",
            "E 2\t: loss=2792.144, rmse=52.841, r2=0.404; v_loss=2499.740, v_rmse=49.997, v_r2=0.552; \n",
            "E 3\t: loss=2530.010, rmse=50.299, r2=0.460; v_loss=2406.878, v_rmse=49.060, v_r2=0.568; \n",
            "E 4\t: loss=2427.257, rmse=49.267, r2=0.482; v_loss=2405.824, v_rmse=49.049, v_r2=0.569; \n",
            "E 5\t: loss=2395.258, rmse=48.941, r2=0.489; v_loss=2412.162, v_rmse=49.114, v_r2=0.568; \n",
            "E 6\t: loss=2341.628, rmse=48.390, r2=0.500; v_loss=2410.007, v_rmse=49.092, v_r2=0.568; \n",
            "E 7\t: loss=2329.134, rmse=48.261, r2=0.503; v_loss=2396.885, v_rmse=48.958, v_r2=0.570; \n",
            "E 8\t: loss=2309.542, rmse=48.058, r2=0.507; v_loss=2448.658, v_rmse=49.484, v_r2=0.561; \n",
            "E 9\t: loss=2307.492, rmse=48.036, r2=0.507; v_loss=2377.711, v_rmse=48.762, v_r2=0.574; \n",
            "E 10\t: loss=2277.550, rmse=47.724, r2=0.514; v_loss=2320.414, v_rmse=48.171, v_r2=0.584; \n",
            "E 11\t: loss=2265.430, rmse=47.597, r2=0.516; v_loss=2380.009, v_rmse=48.785, v_r2=0.573; \n",
            "E 12\t: loss=2283.678, rmse=47.788, r2=0.512; v_loss=2456.464, v_rmse=49.563, v_r2=0.560; \n",
            "E 13\t: loss=2273.872, rmse=47.685, r2=0.514; v_loss=2304.788, v_rmse=48.008, v_r2=0.587; \n",
            "E 14\t: loss=2272.824, rmse=47.674, r2=0.515; v_loss=2350.824, v_rmse=48.485, v_r2=0.579; \n",
            "E 15\t: loss=2267.406, rmse=47.617, r2=0.516; v_loss=2372.603, v_rmse=48.709, v_r2=0.575; \n",
            "E 16\t: loss=2246.058, rmse=47.393, r2=0.520; v_loss=2362.865, v_rmse=48.609, v_r2=0.576; \n",
            "E 17\t: loss=2240.238, rmse=47.331, r2=0.522; v_loss=2377.289, v_rmse=48.757, v_r2=0.574; \n",
            "E 18\t: loss=2245.136, rmse=47.383, r2=0.521; v_loss=2440.262, v_rmse=49.399, v_r2=0.562; \n",
            "E 19\t: loss=2242.588, rmse=47.356, r2=0.521; v_loss=2410.024, v_rmse=49.092, v_r2=0.568; \n",
            "E 20\t: loss=2237.539, rmse=47.303, r2=0.522; v_loss=2290.155, v_rmse=47.856, v_r2=0.589; \n",
            "E 21\t: loss=2224.747, rmse=47.167, r2=0.525; v_loss=2269.086, v_rmse=47.635, v_r2=0.593; \n",
            "E 22\t: loss=2224.788, rmse=47.168, r2=0.525; v_loss=2421.474, v_rmse=49.208, v_r2=0.566; \n",
            "E 23\t: loss=2234.814, rmse=47.274, r2=0.523; v_loss=2412.200, v_rmse=49.114, v_r2=0.568; \n",
            "E 24\t: loss=2209.138, rmse=47.001, r2=0.528; v_loss=2345.731, v_rmse=48.433, v_r2=0.579; \n",
            "E 25\t: loss=2221.779, rmse=47.136, r2=0.526; v_loss=2345.119, v_rmse=48.426, v_r2=0.580; \n",
            "E 26\t: loss=2210.252, rmse=47.013, r2=0.528; v_loss=2302.781, v_rmse=47.987, v_r2=0.587; \n",
            "E 27\t: loss=2227.311, rmse=47.194, r2=0.524; v_loss=2367.565, v_rmse=48.658, v_r2=0.576; \n",
            "E 28\t: loss=2200.730, rmse=46.912, r2=0.530; v_loss=2324.762, v_rmse=48.216, v_r2=0.583; \n",
            "E 29\t: loss=2190.019, rmse=46.798, r2=0.532; v_loss=2346.151, v_rmse=48.437, v_r2=0.579; \n",
            "E 30\t: loss=2203.777, rmse=46.944, r2=0.529; v_loss=2355.604, v_rmse=48.535, v_r2=0.578; \n",
            "E 31\t: loss=2195.038, rmse=46.851, r2=0.531; v_loss=2289.965, v_rmse=47.854, v_r2=0.589; \n",
            "E 32\t: loss=2187.090, rmse=46.766, r2=0.533; v_loss=2314.015, v_rmse=48.104, v_r2=0.585; \n",
            "E 33\t: loss=2184.612, rmse=46.740, r2=0.534; v_loss=2251.917, v_rmse=47.454, v_r2=0.596; \n",
            "E 34\t: loss=2200.833, rmse=46.913, r2=0.530; v_loss=2355.958, v_rmse=48.538, v_r2=0.578; \n",
            "Finished: 2022-10-30 12:37:15.873474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f389ba15-56a6-4e3d-8eb8-36d2ac6373af",
        "id": "pNP_HTLyFBy7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.591,RMSE=-34.394\n",
            "Finished: 2022-10-30 12:37:15.996738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "UYgtv941FBy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.791357319322234   \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 88),\n",
        "('basemodel__epochs', 6),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.34493316079151415),\n",
        "('basemodel__model__dropout2', 0.45457085201703984),\n",
        "('basemodel__model__dropout3', 0.5997686385621787),\n",
        "('basemodel__model__layer1', 102),\n",
        "('basemodel__model__layer2', 155),\n",
        "('basemodel__model__layer3', 278),\n",
        "('basemodel__model__learning_rate', 0.008687869782338611),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.4969688376060647),\n",
        "('clip_y', 84),\n",
        "('include_settings', True),\n",
        "('poly_degree', 2),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "WszSSJcHFBy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=84\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=88,\n",
        "                           epochs=50,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.34493316079151415, \n",
        "                           model__dropout2=0.45457085201703984, \n",
        "                           model__dropout3=0.5997686385621787, \n",
        "                           model__layer1=102, \n",
        "                           model__layer2=155, \n",
        "                           model__layer3=278, \n",
        "                           model__learning_rate=0.008687869782338611,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.4969688376060647, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c662510-45de-4bcd-9823-b2323edb0569",
        "id": "5zdwA-JAFBzA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=88, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=50, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='selu', model__activation2='tanh', model__activation3='selu', model__dropout1=0.34493316079151415, m...338611, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b15e7b7d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b15e7bb50>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.4969688376060647, verbose=0),\n",
              "                    clip_y=84, include_settings=True, poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80854255-bc59-4c00-e252-8d0b48c9e152",
        "id": "_7BYEM3iFBzC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 102)               33150     \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 102)               0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 155)               15965     \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 155)               0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 278)               43368     \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 278)               0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 279       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,762\n",
            "Trainable params: 92,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=742.889, rmse=27.256, r2=-0.105; v_loss=617.561, v_rmse=24.851, v_r2=0.088; \n",
            "E 2\t: loss=562.470, rmse=23.716, r2=0.163; v_loss=373.171, v_rmse=19.318, v_r2=0.449; \n",
            "E 3\t: loss=422.808, rmse=20.562, r2=0.371; v_loss=307.168, v_rmse=17.526, v_r2=0.546; \n",
            "E 4\t: loss=346.197, rmse=18.606, r2=0.485; v_loss=200.120, v_rmse=14.146, v_r2=0.704; \n",
            "E 5\t: loss=325.974, rmse=18.055, r2=0.515; v_loss=208.663, v_rmse=14.445, v_r2=0.692; \n",
            "E 6\t: loss=302.312, rmse=17.387, r2=0.550; v_loss=167.431, v_rmse=12.940, v_r2=0.753; \n",
            "E 7\t: loss=282.792, rmse=16.816, r2=0.579; v_loss=183.658, v_rmse=13.552, v_r2=0.729; \n",
            "E 8\t: loss=279.340, rmse=16.713, r2=0.584; v_loss=208.481, v_rmse=14.439, v_r2=0.692; \n",
            "E 9\t: loss=280.330, rmse=16.743, r2=0.583; v_loss=153.141, v_rmse=12.375, v_r2=0.774; \n",
            "E 10\t: loss=273.149, rmse=16.527, r2=0.594; v_loss=206.951, v_rmse=14.386, v_r2=0.694; \n",
            "E 11\t: loss=265.427, rmse=16.292, r2=0.605; v_loss=176.773, v_rmse=13.296, v_r2=0.739; \n",
            "E 12\t: loss=254.471, rmse=15.952, r2=0.621; v_loss=159.938, v_rmse=12.647, v_r2=0.764; \n",
            "E 13\t: loss=265.325, rmse=16.289, r2=0.605; v_loss=162.073, v_rmse=12.731, v_r2=0.761; \n",
            "E 14\t: loss=269.140, rmse=16.405, r2=0.600; v_loss=158.484, v_rmse=12.589, v_r2=0.766; \n",
            "E 15\t: loss=265.926, rmse=16.307, r2=0.604; v_loss=158.013, v_rmse=12.570, v_r2=0.767; \n",
            "E 16\t: loss=261.606, rmse=16.174, r2=0.611; v_loss=175.310, v_rmse=13.240, v_r2=0.741; \n",
            "E 17\t: loss=256.109, rmse=16.003, r2=0.619; v_loss=171.888, v_rmse=13.111, v_r2=0.746; \n",
            "Finished: 2022-10-30 12:59:16.578890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e88aef8-e1e3-4c59-9f7d-b8e114957795",
        "id": "oLf0y74BFBzE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.785,RMSE=-13.710\n",
            "Finished: 2022-10-30 12:59:16.704738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-4 "
      ],
      "metadata": {
        "id": "MfJUDz0oI5zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pb8CuYNOI5zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.5879369617031984    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 319),\n",
        "('basemodel__epochs', 46),\n",
        "('basemodel__model__activation1', 'relu'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__activation4', 'selu'),\n",
        "('basemodel__model__dropout1', 0.683753934762909),\n",
        "('basemodel__model__dropout2', 0.5369622665770732),\n",
        "('basemodel__model__dropout3', 0.658577790408341),\n",
        "('basemodel__model__dropout4', 0.805585273208486),\n",
        "('basemodel__model__layer1', 148),\n",
        "('basemodel__model__layer2', 428),\n",
        "('basemodel__model__layer3', 512),\n",
        "('basemodel__model__layer4', 510),\n",
        "('basemodel__model__learning_rate', 0.000866552772585896),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1501923387205559),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "B5befZCBI5zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=319,\n",
        "                           epochs=46,\n",
        "                           model__activation1='relu',\n",
        "                           model__activation2='selu',\n",
        "                           model__activation3='selu',\n",
        "                           model__activation4='selu',\n",
        "                           model__dropout1=0.683753934762909, \n",
        "                           model__dropout2=0.5369622665770732, \n",
        "                           model__dropout3=0.658577790408341, \n",
        "                           model__dropout4=0.805585273208486, \n",
        "                           model__layer1=148, \n",
        "                           model__layer2=428, \n",
        "                           model__layer3=512, \n",
        "                           model__layer4=510, \n",
        "                           model__learning_rate=0.000866552772585896,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1501923387205559, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6059ac2f-b2c2-4dee-e671-3e82fa819f8f",
        "id": "HjCB0ofWI5zk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=319, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=46, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='relu', model__activation2='selu', model__activation3='selu', model__activation4='selu', model__dro...ning_rate=0.000866552772585896, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b15c236d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b15c23890>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1501923387205559, verbose=0),\n",
              "                    include_settings=True)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caffb385-c49f-4662-ee6a-02e3b14e0d77",
        "id": "WBnAz5ncI5zp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_64 (Dense)            (None, 148)               3700      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 148)               0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 428)               63772     \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 428)               0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 512)               219648    \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 510)               261630    \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 510)               0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 1)                 511       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 549,261\n",
            "Trainable params: 549,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5579.107, rmse=74.693, r2=-0.179; v_loss=4591.935, v_rmse=67.764, v_r2=0.097; \n",
            "E 2\t: loss=3981.148, rmse=63.096, r2=0.159; v_loss=2781.071, v_rmse=52.736, v_r2=0.453; \n",
            "E 3\t: loss=2939.486, rmse=54.217, r2=0.379; v_loss=2267.185, v_rmse=47.615, v_r2=0.554; \n",
            "E 4\t: loss=2615.261, rmse=51.140, r2=0.447; v_loss=2306.133, v_rmse=48.022, v_r2=0.547; \n",
            "E 5\t: loss=2526.552, rmse=50.265, r2=0.466; v_loss=2223.833, v_rmse=47.158, v_r2=0.563; \n",
            "E 6\t: loss=2431.833, rmse=49.314, r2=0.486; v_loss=2155.338, v_rmse=46.426, v_r2=0.576; \n",
            "E 7\t: loss=2425.345, rmse=49.248, r2=0.487; v_loss=2225.818, v_rmse=47.179, v_r2=0.562; \n",
            "E 8\t: loss=2382.595, rmse=48.812, r2=0.496; v_loss=2233.021, v_rmse=47.255, v_r2=0.561; \n",
            "E 9\t: loss=2362.514, rmse=48.606, r2=0.501; v_loss=2133.966, v_rmse=46.195, v_r2=0.581; \n",
            "E 10\t: loss=2377.352, rmse=48.758, r2=0.498; v_loss=2137.340, v_rmse=46.231, v_r2=0.580; \n",
            "E 11\t: loss=2354.146, rmse=48.520, r2=0.503; v_loss=2226.160, v_rmse=47.182, v_r2=0.562; \n",
            "E 12\t: loss=2354.798, rmse=48.526, r2=0.502; v_loss=2186.642, v_rmse=46.762, v_r2=0.570; \n",
            "E 13\t: loss=2343.358, rmse=48.408, r2=0.505; v_loss=2094.517, v_rmse=45.766, v_r2=0.588; \n",
            "E 14\t: loss=2328.251, rmse=48.252, r2=0.508; v_loss=2107.384, v_rmse=45.906, v_r2=0.586; \n",
            "E 15\t: loss=2310.523, rmse=48.068, r2=0.512; v_loss=2177.691, v_rmse=46.666, v_r2=0.572; \n",
            "E 16\t: loss=2325.114, rmse=48.219, r2=0.509; v_loss=2104.696, v_rmse=45.877, v_r2=0.586; \n",
            "E 17\t: loss=2336.032, rmse=48.333, r2=0.506; v_loss=2141.060, v_rmse=46.272, v_r2=0.579; \n",
            "E 18\t: loss=2321.446, rmse=48.181, r2=0.509; v_loss=2113.458, v_rmse=45.972, v_r2=0.585; \n",
            "E 19\t: loss=2327.921, rmse=48.249, r2=0.508; v_loss=2158.679, v_rmse=46.462, v_r2=0.576; \n",
            "E 20\t: loss=2327.051, rmse=48.240, r2=0.508; v_loss=2112.677, v_rmse=45.964, v_r2=0.585; \n",
            "Finished: 2022-10-30 13:04:42.324382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b914073-f885-41e6-e62b-84f94a1710ae",
        "id": "E1ATWFZoI5zt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.640,RMSE=-32.261\n",
            "Finished: 2022-10-30 13:04:42.458726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "qpedH9HzI5zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8031482586558986    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 186),\n",
        "('basemodel__epochs', 48),\n",
        "('basemodel__model__activation1', 'elu'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__activation3', 'sigmoid'),\n",
        "('basemodel__model__activation4', 'relu'),\n",
        "('basemodel__model__dropout1', 0.3192129242485524),\n",
        "('basemodel__model__dropout2', 0.8716266059527173),\n",
        "('basemodel__model__dropout3', 0.9),\n",
        "('basemodel__model__dropout4', 0.1),\n",
        "('basemodel__model__layer1', 182),\n",
        "('basemodel__model__layer2', 505),\n",
        "('basemodel__model__layer3', 478),\n",
        "('basemodel__model__layer4', 16),\n",
        "('basemodel__model__learning_rate', 0.002811460975523156),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1113203480919406),\n",
        "('clip_y', 80),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "chBMqsKDI5zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=80\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=1,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=186,\n",
        "                           epochs=48,\n",
        "                           model__activation1='elu',\n",
        "                           model__activation2='elu',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__activation4='relu',\n",
        "                           model__dropout1=0.3192129242485524, \n",
        "                           model__dropout2=0.8716266059527173, \n",
        "                           model__dropout3=0.9, \n",
        "                           model__dropout4=0.1, \n",
        "                           model__layer1=182, \n",
        "                           model__layer2=505, \n",
        "                           model__layer3=478, \n",
        "                           model__layer4=16, \n",
        "                           model__learning_rate=0.002811460975523156,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1113203480919406, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2944de40-284a-4c9e-b30d-7dbf841ef280",
        "id": "BE54ZRkFI5z3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=186, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=48, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='elu', model__activation2='elu', model__activation3='sigmoid', model__activation4='relu', model__dr...0.002811460975523156, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b159fc250>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b159fc490>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1113203480919406, verbose=0),\n",
              "                    clip_y=80, include_settings=True)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ea9d0f-10f6-4585-fb21-4532091bb3f0",
        "id": "1UX0DFssI5z6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_69 (Dense)            (None, 182)               4550      \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 182)               0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 505)               92415     \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 505)               0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 478)               241868    \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 478)               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 16)                7664      \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 346,514\n",
            "Trainable params: 346,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=693.242, rmse=26.329, r2=-0.162; v_loss=209.552, v_rmse=14.476, v_r2=0.641; \n",
            "E 2\t: loss=302.826, rmse=17.402, r2=0.493; v_loss=128.163, v_rmse=11.321, v_r2=0.780; \n",
            "E 3\t: loss=273.514, rmse=16.538, r2=0.542; v_loss=142.214, v_rmse=11.925, v_r2=0.756; \n",
            "E 4\t: loss=259.840, rmse=16.120, r2=0.565; v_loss=109.942, v_rmse=10.485, v_r2=0.812; \n",
            "E 5\t: loss=258.406, rmse=16.075, r2=0.567; v_loss=120.307, v_rmse=10.968, v_r2=0.794; \n",
            "E 6\t: loss=254.316, rmse=15.947, r2=0.574; v_loss=127.995, v_rmse=11.314, v_r2=0.781; \n",
            "E 7\t: loss=260.087, rmse=16.127, r2=0.564; v_loss=131.610, v_rmse=11.472, v_r2=0.775; \n",
            "E 8\t: loss=251.634, rmse=15.863, r2=0.578; v_loss=152.229, v_rmse=12.338, v_r2=0.739; \n",
            "E 9\t: loss=249.983, rmse=15.811, r2=0.581; v_loss=121.655, v_rmse=11.030, v_r2=0.792; \n",
            "E 10\t: loss=247.748, rmse=15.740, r2=0.585; v_loss=129.543, v_rmse=11.382, v_r2=0.778; \n",
            "E 11\t: loss=244.632, rmse=15.641, r2=0.590; v_loss=121.118, v_rmse=11.005, v_r2=0.793; \n",
            "E 12\t: loss=240.997, rmse=15.524, r2=0.596; v_loss=139.497, v_rmse=11.811, v_r2=0.761; \n",
            "E 13\t: loss=245.999, rmse=15.684, r2=0.588; v_loss=116.129, v_rmse=10.776, v_r2=0.801; \n",
            "E 14\t: loss=237.470, rmse=15.410, r2=0.602; v_loss=129.806, v_rmse=11.393, v_r2=0.778; \n",
            "E 15\t: loss=232.403, rmse=15.245, r2=0.611; v_loss=118.598, v_rmse=10.890, v_r2=0.797; \n",
            "E 16\t: loss=225.587, rmse=15.020, r2=0.622; v_loss=122.033, v_rmse=11.047, v_r2=0.791; \n",
            "E 17\t: loss=223.457, rmse=14.948, r2=0.626; v_loss=131.278, v_rmse=11.458, v_r2=0.775; \n",
            "E 18\t: loss=218.809, rmse=14.792, r2=0.633; v_loss=124.444, v_rmse=11.155, v_r2=0.787; \n",
            "E 19\t: loss=213.132, rmse=14.599, r2=0.643; v_loss=119.359, v_rmse=10.925, v_r2=0.796; \n",
            "E 20\t: loss=207.829, rmse=14.416, r2=0.652; v_loss=119.179, v_rmse=10.917, v_r2=0.796; \n",
            "E 21\t: loss=204.720, rmse=14.308, r2=0.657; v_loss=126.024, v_rmse=11.226, v_r2=0.784; \n",
            "E 22\t: loss=202.763, rmse=14.239, r2=0.660; v_loss=149.403, v_rmse=12.223, v_r2=0.744; \n",
            "E 23\t: loss=203.677, rmse=14.272, r2=0.659; v_loss=136.197, v_rmse=11.670, v_r2=0.767; \n",
            "E 24\t: loss=199.988, rmse=14.142, r2=0.665; v_loss=119.896, v_rmse=10.950, v_r2=0.795; \n",
            "E 25\t: loss=201.357, rmse=14.190, r2=0.663; v_loss=120.928, v_rmse=10.997, v_r2=0.793; \n",
            "E 26\t: loss=200.021, rmse=14.143, r2=0.665; v_loss=161.876, v_rmse=12.723, v_r2=0.723; \n",
            "E 27\t: loss=195.188, rmse=13.971, r2=0.673; v_loss=143.299, v_rmse=11.971, v_r2=0.755; \n",
            "E 28\t: loss=195.709, rmse=13.990, r2=0.672; v_loss=126.072, v_rmse=11.228, v_r2=0.784; \n",
            "E 29\t: loss=195.838, rmse=13.994, r2=0.672; v_loss=146.446, v_rmse=12.101, v_r2=0.749; \n",
            "E 30\t: loss=195.152, rmse=13.970, r2=0.673; v_loss=129.713, v_rmse=11.389, v_r2=0.778; \n",
            "E 31\t: loss=188.581, rmse=13.732, r2=0.684; v_loss=115.796, v_rmse=10.761, v_r2=0.802; \n",
            "E 32\t: loss=192.762, rmse=13.884, r2=0.677; v_loss=128.558, v_rmse=11.338, v_r2=0.780; \n",
            "E 33\t: loss=195.006, rmse=13.964, r2=0.673; v_loss=124.543, v_rmse=11.160, v_r2=0.787; \n",
            "E 34\t: loss=189.573, rmse=13.769, r2=0.682; v_loss=118.642, v_rmse=10.892, v_r2=0.797; \n",
            "E 35\t: loss=187.571, rmse=13.696, r2=0.686; v_loss=112.717, v_rmse=10.617, v_r2=0.807; \n",
            "E 36\t: loss=184.505, rmse=13.583, r2=0.691; v_loss=116.741, v_rmse=10.805, v_r2=0.800; \n",
            "E 37\t: loss=184.481, rmse=13.582, r2=0.691; v_loss=132.460, v_rmse=11.509, v_r2=0.773; \n",
            "E 38\t: loss=182.174, rmse=13.497, r2=0.695; v_loss=114.662, v_rmse=10.708, v_r2=0.804; \n",
            "E 39\t: loss=185.204, rmse=13.609, r2=0.690; v_loss=115.872, v_rmse=10.764, v_r2=0.801; \n",
            "E 40\t: loss=187.426, rmse=13.690, r2=0.686; v_loss=114.007, v_rmse=10.677, v_r2=0.805; \n",
            "E 41\t: loss=185.143, rmse=13.607, r2=0.690; v_loss=109.648, v_rmse=10.471, v_r2=0.812; \n",
            "E 42\t: loss=182.900, rmse=13.524, r2=0.694; v_loss=117.624, v_rmse=10.845, v_r2=0.798; \n",
            "E 43\t: loss=182.567, rmse=13.512, r2=0.694; v_loss=112.322, v_rmse=10.598, v_r2=0.808; \n",
            "Finished: 2022-10-30 13:07:21.933513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b9f604-a728-4738-d858-c04c8439530b",
        "id": "ypPnlb7xI5z_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.839,RMSE=-11.215\n",
            "Finished: 2022-10-30 13:07:57.781519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Linear RUL"
      ],
      "metadata": {
        "id": "CWlv5EFWI50C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5429781834407112    \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 108),\n",
        "('basemodel__epochs', 40),\n",
        "('basemodel__model__activation1', 'sigmoid'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'relu'),\n",
        "('basemodel__model__activation4', 'sigmoid'),\n",
        "('basemodel__model__dropout1', 0.2621650470812381),\n",
        "('basemodel__model__dropout2', 0.1),\n",
        "('basemodel__model__dropout3', 0.5418530339407519),\n",
        "('basemodel__model__dropout4', 0.17380420072855723),\n",
        "('basemodel__model__layer1', 490),\n",
        "('basemodel__model__layer2', 84),\n",
        "('basemodel__model__layer3', 16),\n",
        "('basemodel__model__layer4', 109),\n",
        "('basemodel__model__learning_rate', 0.004902483950446228),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.4284401069475232),\n",
        "('include_settings', True),\n",
        "('poly_degree', 2),\n",
        "('scaler', StandardScaler())\n",
        "```\n"
      ],
      "metadata": {
        "id": "_hRfD2CAI50D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=-1\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=2,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=108,\n",
        "                           epochs=40,\n",
        "                           model__activation1='sigmoid',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='relu',\n",
        "                           model__activation4='sigmoid',\n",
        "                           model__dropout1=0.2621650470812381, \n",
        "                           model__dropout2=0.1, \n",
        "                           model__dropout3=0.5418530339407519, \n",
        "                           model__dropout4=0.17380420072855723, \n",
        "                           model__layer1=490, \n",
        "                           model__layer2=84, \n",
        "                           model__layer3=16, \n",
        "                           model__layer4=109, \n",
        "                           model__learning_rate=0.004902483950446228,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.4284401069475232, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b352cbdd-0ce0-4f9e-bb06-5f6459111904",
        "id": "zdhee-1GI50E"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=108, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=40, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='sigmoid', model__activation2='relu', model__activation3='relu', model__activation4='sigmoid', mode...3950446228, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b0efb3150>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b1582dc50>], model__optim=<class 'keras.optimizers.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.4284401069475232, verbose=0),\n",
              "                    include_settings=True, poly_degree=2)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74a0e63-01c9-4a3e-f4db-57601d095867",
        "id": "vhJBABSwI50I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_74 (Dense)            (None, 490)               159250    \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 490)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 84)                41244     \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 84)                0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 16)                1360      \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 109)               1853      \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 109)               0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 1)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,817\n",
            "Trainable params: 203,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=8549.066, rmse=92.461, r2=-0.728; v_loss=4567.838, v_rmse=67.586, v_r2=-0.000; \n",
            "E 2\t: loss=4986.189, rmse=70.613, r2=-0.008; v_loss=4583.121, v_rmse=67.699, v_r2=-0.003; \n",
            "E 3\t: loss=4978.481, rmse=70.558, r2=-0.006; v_loss=4546.389, v_rmse=67.427, v_r2=0.005; \n",
            "E 4\t: loss=3842.098, rmse=61.985, r2=0.223; v_loss=4233.215, v_rmse=65.063, v_r2=0.073; \n",
            "E 5\t: loss=3124.938, rmse=55.901, r2=0.368; v_loss=2974.162, v_rmse=54.536, v_r2=0.349; \n",
            "E 6\t: loss=2969.067, rmse=54.489, r2=0.400; v_loss=3370.888, v_rmse=58.059, v_r2=0.262; \n",
            "E 7\t: loss=2840.835, rmse=53.299, r2=0.426; v_loss=2293.862, v_rmse=47.894, v_r2=0.498; \n",
            "E 8\t: loss=2754.200, rmse=52.480, r2=0.443; v_loss=2286.074, v_rmse=47.813, v_r2=0.500; \n",
            "E 9\t: loss=2681.556, rmse=51.784, r2=0.458; v_loss=2157.619, v_rmse=46.450, v_r2=0.528; \n",
            "E 10\t: loss=2670.108, rmse=51.673, r2=0.460; v_loss=2187.704, v_rmse=46.773, v_r2=0.521; \n",
            "E 11\t: loss=2653.576, rmse=51.513, r2=0.464; v_loss=2095.003, v_rmse=45.771, v_r2=0.541; \n",
            "E 12\t: loss=2626.802, rmse=51.252, r2=0.469; v_loss=2269.491, v_rmse=47.639, v_r2=0.503; \n",
            "E 13\t: loss=2598.758, rmse=50.978, r2=0.475; v_loss=2168.494, v_rmse=46.567, v_r2=0.525; \n",
            "E 14\t: loss=2589.517, rmse=50.887, r2=0.477; v_loss=2140.385, v_rmse=46.264, v_r2=0.531; \n",
            "E 15\t: loss=2583.060, rmse=50.824, r2=0.478; v_loss=2095.499, v_rmse=45.777, v_r2=0.541; \n",
            "E 16\t: loss=2587.249, rmse=50.865, r2=0.477; v_loss=2411.973, v_rmse=49.112, v_r2=0.472; \n",
            "E 17\t: loss=2565.557, rmse=50.651, r2=0.481; v_loss=1969.943, v_rmse=44.384, v_r2=0.569; \n",
            "E 18\t: loss=2570.061, rmse=50.696, r2=0.481; v_loss=2112.898, v_rmse=45.966, v_r2=0.537; \n",
            "E 19\t: loss=2545.860, rmse=50.457, r2=0.485; v_loss=2103.445, v_rmse=45.863, v_r2=0.540; \n",
            "E 20\t: loss=2546.879, rmse=50.467, r2=0.485; v_loss=2045.173, v_rmse=45.224, v_r2=0.552; \n",
            "E 21\t: loss=2544.153, rmse=50.440, r2=0.486; v_loss=2048.245, v_rmse=45.258, v_r2=0.552; \n",
            "E 22\t: loss=2552.616, rmse=50.523, r2=0.484; v_loss=2127.575, v_rmse=46.126, v_r2=0.534; \n",
            "E 23\t: loss=2538.065, rmse=50.379, r2=0.487; v_loss=2070.660, v_rmse=45.505, v_r2=0.547; \n",
            "E 24\t: loss=2542.681, rmse=50.425, r2=0.486; v_loss=2073.231, v_rmse=45.533, v_r2=0.546; \n",
            "E 25\t: loss=2551.129, rmse=50.509, r2=0.484; v_loss=2054.673, v_rmse=45.328, v_r2=0.550; \n",
            "E 26\t: loss=2568.799, rmse=50.683, r2=0.481; v_loss=2093.594, v_rmse=45.756, v_r2=0.542; \n",
            "E 27\t: loss=2554.032, rmse=50.537, r2=0.484; v_loss=1998.133, v_rmse=44.700, v_r2=0.563; \n",
            "E 28\t: loss=2571.681, rmse=50.712, r2=0.480; v_loss=2059.961, v_rmse=45.387, v_r2=0.549; \n",
            "Finished: 2022-10-30 13:10:29.685260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256e16ce-9088-4cb9-8101-ad61d8ff5b9b",
        "id": "qnwVx-VII50K"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.588,RMSE=-34.518\n",
            "Finished: 2022-10-30 13:11:05.522486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolyFeatures + Non-Linear RUL\n"
      ],
      "metadata": {
        "id": "hz9fq_lWI50L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.7790003439779515  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 291),\n",
        "('basemodel__epochs', 15),\n",
        "('basemodel__model__activation1', 'selu'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'relu'),\n",
        "('basemodel__model__activation4', 'elu'),\n",
        "('basemodel__model__dropout1', 0.43138482141909396),\n",
        "('basemodel__model__dropout2', 0.1),\n",
        "('basemodel__model__dropout3', 0.15985910954002355),\n",
        "('basemodel__model__dropout4', 0.6832796453385808),\n",
        "('basemodel__model__layer1', 466),\n",
        "('basemodel__model__layer2', 194),\n",
        "('basemodel__model__layer3', 345),\n",
        "('basemodel__model__layer4', 98),\n",
        "('basemodel__model__learning_rate', 0.005555768696453825),\n",
        "('basemodel__model__optim',\n",
        "keras.optimizers.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.22076215606341174),\n",
        "('clip_y', 93),\n",
        "('include_settings', True),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler())\n",
        "```"
      ],
      "metadata": {
        "id": "9yBfpDmQI50N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLIP=93\n",
        "\n",
        "model = MLPWrapperRegressor(\n",
        "        clip_y=CLIP, scaler=StandardScaler(), poly_degree=3,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=291,\n",
        "                           epochs=50,\n",
        "                           model__activation1='selu',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='relu',\n",
        "                           model__activation4='elu',\n",
        "                           model__dropout1=0.43138482141909396, \n",
        "                           model__dropout2=0.1, \n",
        "                           model__dropout3=0.15985910954002355, \n",
        "                           model__dropout4=0.6832796453385808, \n",
        "                           model__layer1=466, \n",
        "                           model__layer2=194, \n",
        "                           model__layer3=345, \n",
        "                           model__layer4=98, \n",
        "                           model__learning_rate=0.005555768696453825,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.22076215606341174, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01f6c13-dbbb-482a-bd12-0c377340604c",
        "id": "D8qxuavgI50P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPWrapperRegressor(basemodel=KerasRegressor(batch_size=291, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f9bff274110>, <keras.callbacks.LambdaCallback object at 0x7f9bff278410>], epochs=50, model=<function create_model at 0x7f9bff2b4dd0>, model__activation1='selu', model__activation2='relu', model__activation3='relu', model__activation4='elu', model__drop...53825, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f9b0f18cf10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f9b0effea50>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.22076215606341174, verbose=0),\n",
              "                    clip_y=93, include_settings=True, poly_degree=3)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2241458-485e-4518-c26a-a09d1a1d69f0",
        "id": "TbCjxqHdI50R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_89 (Dense)            (None, 466)               1363050   \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 466)               0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 194)               90598     \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 194)               0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 345)               67275     \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 345)               0         \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 98)                33908     \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 98)                0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 1)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,554,930\n",
            "Trainable params: 1,554,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1339.036, rmse=36.593, r2=-0.540; v_loss=641.546, v_rmse=25.329, v_r2=0.267; \n",
            "E 2\t: loss=589.756, rmse=24.285, r2=0.322; v_loss=275.847, v_rmse=16.609, v_r2=0.685; \n",
            "E 3\t: loss=478.226, rmse=21.868, r2=0.450; v_loss=251.559, v_rmse=15.861, v_r2=0.713; \n",
            "E 4\t: loss=438.724, rmse=20.946, r2=0.495; v_loss=271.651, v_rmse=16.482, v_r2=0.690; \n",
            "E 5\t: loss=409.621, rmse=20.239, r2=0.529; v_loss=243.571, v_rmse=15.607, v_r2=0.722; \n",
            "E 6\t: loss=442.693, rmse=21.040, r2=0.491; v_loss=307.294, v_rmse=17.530, v_r2=0.649; \n",
            "E 7\t: loss=423.359, rmse=20.576, r2=0.513; v_loss=280.351, v_rmse=16.744, v_r2=0.680; \n",
            "E 8\t: loss=403.917, rmse=20.098, r2=0.535; v_loss=239.141, v_rmse=15.464, v_r2=0.727; \n",
            "E 9\t: loss=432.567, rmse=20.798, r2=0.503; v_loss=246.971, v_rmse=15.715, v_r2=0.718; \n",
            "E 10\t: loss=394.300, rmse=19.857, r2=0.547; v_loss=209.389, v_rmse=14.470, v_r2=0.761; \n",
            "E 11\t: loss=390.811, rmse=19.769, r2=0.551; v_loss=252.699, v_rmse=15.897, v_r2=0.711; \n",
            "E 12\t: loss=390.445, rmse=19.760, r2=0.551; v_loss=307.973, v_rmse=17.549, v_r2=0.648; \n",
            "E 13\t: loss=435.352, rmse=20.865, r2=0.499; v_loss=334.530, v_rmse=18.290, v_r2=0.618; \n",
            "E 14\t: loss=560.597, rmse=23.677, r2=0.355; v_loss=278.113, v_rmse=16.677, v_r2=0.682; \n",
            "E 15\t: loss=900.086, rmse=30.001, r2=-0.035; v_loss=786.980, v_rmse=28.053, v_r2=0.101; \n",
            "E 16\t: loss=931.965, rmse=30.528, r2=-0.072; v_loss=532.443, v_rmse=23.075, v_r2=0.392; \n",
            "E 17\t: loss=862.772, rmse=29.373, r2=0.008; v_loss=611.803, v_rmse=24.735, v_r2=0.301; \n",
            "Finished: 2022-10-30 13:21:46.128038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(X_test,model)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_sc))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485ed9b7-879b-457a-bc58-f8c88605f983",
        "id": "Yz7_bVa-I50T"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.707,RMSE=-17.804\n",
            "Finished: 2022-10-30 13:21:46.324982\n"
          ]
        }
      ]
    }
  ]
}