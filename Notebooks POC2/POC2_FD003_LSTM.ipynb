{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "n7MBDuPasy-s",
        "e7-_jqRw3cRa",
        "QinQ4hWStzHt",
        "boZqFQNlraCh"
      ],
      "authorship_tag": "ABX9TyOC54CdL+B3OqF1LPS3+Boc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD003_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "f4f3f9a4-095d-49af-fa56-c4a21cbd0ccc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78e38b4-ce74-4ea2-b33a-61018e653314"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "oVLI86qK9J_9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "D4BClPwS9KAB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4efcc9-e841-4309-9e6f-1e788e6857af",
        "id": "Zfs5m8Xs9KAC"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(3, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "9d1e5fb0-0c18-46d4-c54a-0c90693dc176"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0005  0.0004  100.0  518.67  642.36  1583.23   \n",
              "1                1     2  0.0008 -0.0003  100.0  518.67  642.50  1584.69   \n",
              "2                1     3 -0.0014 -0.0002  100.0  518.67  642.18  1582.35   \n",
              "3                1     4 -0.0020  0.0001  100.0  518.67  642.92  1585.61   \n",
              "4                1     5  0.0016  0.0000  100.0  518.67  641.68  1588.63   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "24715          100   148 -0.0016 -0.0003  100.0  518.67  643.78  1596.01   \n",
              "24716          100   149  0.0034 -0.0003  100.0  518.67  643.29  1596.38   \n",
              "24717          100   150 -0.0016  0.0004  100.0  518.67  643.84  1604.53   \n",
              "24718          100   151 -0.0023  0.0004  100.0  518.67  643.94  1597.56   \n",
              "24719          100   152  0.0000  0.0003  100.0  518.67  643.64  1599.04   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1396.84  14.62  ...  522.31  2388.01  8145.32  8.4246  0.03   391   \n",
              "1      1396.89  14.62  ...  522.42  2388.03  8152.85  8.4403  0.03   392   \n",
              "2      1405.61  14.62  ...  522.03  2388.00  8150.17  8.3901  0.03   391   \n",
              "3      1392.27  14.62  ...  522.49  2388.08  8146.56  8.3878  0.03   392   \n",
              "4      1397.65  14.62  ...  522.58  2388.03  8147.80  8.3869  0.03   392   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "24715  1424.11  14.62  ...  519.66  2388.30  8138.08  8.5036  0.03   394   \n",
              "24716  1429.14  14.62  ...  519.91  2388.28  8144.36  8.5174  0.03   395   \n",
              "24717  1431.41  14.62  ...  519.44  2388.24  8135.95  8.5223  0.03   396   \n",
              "24718  1426.57  14.62  ...  520.01  2388.26  8141.24  8.5148  0.03   395   \n",
              "24719  1436.06  14.62  ...  519.48  2388.24  8136.98  8.5150  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.11  23.3537  \n",
              "1      2388  100.0  38.99  23.4491  \n",
              "2      2388  100.0  38.85  23.3669  \n",
              "3      2388  100.0  38.96  23.2951  \n",
              "4      2388  100.0  39.14  23.4583  \n",
              "...     ...    ...    ...      ...  \n",
              "24715  2388  100.0  38.44  22.9631  \n",
              "24716  2388  100.0  38.50  22.9746  \n",
              "24717  2388  100.0  38.39  23.0682  \n",
              "24718  2388  100.0  38.31  23.0753  \n",
              "24719  2388  100.0  38.56  23.0847  \n",
              "\n",
              "[24720 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.36</td>\n",
              "      <td>1583.23</td>\n",
              "      <td>1396.84</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.31</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>8145.32</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.11</td>\n",
              "      <td>23.3537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.50</td>\n",
              "      <td>1584.69</td>\n",
              "      <td>1396.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8152.85</td>\n",
              "      <td>8.4403</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.18</td>\n",
              "      <td>1582.35</td>\n",
              "      <td>1405.61</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.03</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8150.17</td>\n",
              "      <td>8.3901</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.85</td>\n",
              "      <td>23.3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1585.61</td>\n",
              "      <td>1392.27</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.49</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8146.56</td>\n",
              "      <td>8.3878</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.96</td>\n",
              "      <td>23.2951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.68</td>\n",
              "      <td>1588.63</td>\n",
              "      <td>1397.65</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.58</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8147.80</td>\n",
              "      <td>8.3869</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.14</td>\n",
              "      <td>23.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24715</th>\n",
              "      <td>100</td>\n",
              "      <td>148</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.78</td>\n",
              "      <td>1596.01</td>\n",
              "      <td>1424.11</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.66</td>\n",
              "      <td>2388.30</td>\n",
              "      <td>8138.08</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24716</th>\n",
              "      <td>100</td>\n",
              "      <td>149</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.29</td>\n",
              "      <td>1596.38</td>\n",
              "      <td>1429.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.91</td>\n",
              "      <td>2388.28</td>\n",
              "      <td>8144.36</td>\n",
              "      <td>8.5174</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.50</td>\n",
              "      <td>22.9746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24717</th>\n",
              "      <td>100</td>\n",
              "      <td>150</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.84</td>\n",
              "      <td>1604.53</td>\n",
              "      <td>1431.41</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.44</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8135.95</td>\n",
              "      <td>8.5223</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.39</td>\n",
              "      <td>23.0682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24718</th>\n",
              "      <td>100</td>\n",
              "      <td>151</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.94</td>\n",
              "      <td>1597.56</td>\n",
              "      <td>1426.57</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8141.24</td>\n",
              "      <td>8.5148</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.31</td>\n",
              "      <td>23.0753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24719</th>\n",
              "      <td>100</td>\n",
              "      <td>152</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.64</td>\n",
              "      <td>1599.04</td>\n",
              "      <td>1436.06</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.48</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8136.98</td>\n",
              "      <td>8.5150</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.56</td>\n",
              "      <td>23.0847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24720 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "27ad0265-37ab-43e3-98c1-1c84dfa82809"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16596, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "onw4pCwZy-1s",
        "outputId": "82e1ff5a-1ba1-4d69-fdae-1bb7bb661ba2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.59  1592.40  1409.87  14.62  21.58  560.53  2388.22  9085.50   \n",
              "1  518.67  642.56  1587.42  1409.69  14.62  21.61  553.33  2388.18  9050.97   \n",
              "2  518.67  642.75  1591.93  1417.66  14.62  21.60  563.61  2388.31  9091.69   \n",
              "3  518.67  642.28  1584.68  1406.56  14.62  21.61  552.75  2388.07  9048.23   \n",
              "4  518.67  642.15  1580.59  1397.26  14.62  21.58  553.82  2387.96  9050.89   \n",
              "\n",
              "    s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0  1.31  ...  528.05  2388.23  8158.77  8.2966  0.03   393  2388  100.0   \n",
              "1  1.30  ...  520.90  2388.17  8128.04  8.4514  0.03   392  2388  100.0   \n",
              "2  1.31  ...  531.36  2388.33  8173.56  8.3057  0.03   395  2388  100.0   \n",
              "3  1.30  ...  521.27  2388.09  8133.78  8.4337  0.03   392  2388  100.0   \n",
              "4  1.30  ...  521.74  2387.96  8132.51  8.3900  0.03   390  2388  100.0   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  39.43  23.5679  \n",
              "1  38.83  23.2821  \n",
              "2  39.27  23.6440  \n",
              "3  38.70  23.3804  \n",
              "4  38.89  23.4463  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.59</td>\n",
              "      <td>1592.40</td>\n",
              "      <td>1409.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.58</td>\n",
              "      <td>560.53</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>9085.50</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>528.05</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8158.77</td>\n",
              "      <td>8.2966</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.43</td>\n",
              "      <td>23.5679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.56</td>\n",
              "      <td>1587.42</td>\n",
              "      <td>1409.69</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.33</td>\n",
              "      <td>2388.18</td>\n",
              "      <td>9050.97</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>520.90</td>\n",
              "      <td>2388.17</td>\n",
              "      <td>8128.04</td>\n",
              "      <td>8.4514</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.83</td>\n",
              "      <td>23.2821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.75</td>\n",
              "      <td>1591.93</td>\n",
              "      <td>1417.66</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.60</td>\n",
              "      <td>563.61</td>\n",
              "      <td>2388.31</td>\n",
              "      <td>9091.69</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>531.36</td>\n",
              "      <td>2388.33</td>\n",
              "      <td>8173.56</td>\n",
              "      <td>8.3057</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.27</td>\n",
              "      <td>23.6440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.28</td>\n",
              "      <td>1584.68</td>\n",
              "      <td>1406.56</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.75</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>9048.23</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>521.27</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8133.78</td>\n",
              "      <td>8.4337</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.70</td>\n",
              "      <td>23.3804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1580.59</td>\n",
              "      <td>1397.26</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.58</td>\n",
              "      <td>553.82</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>9050.89</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>8132.51</td>\n",
              "      <td>8.3900</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.89</td>\n",
              "      <td>23.4463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lmFKjQaeip1b",
        "outputId": "517e1497-2800-4456-ac32-e56a85a41fb5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  258\n",
              "1            1     2  257\n",
              "2            1     3  256\n",
              "3            1     4  255\n",
              "4            1     5  254"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "ca696189-e64e-44b8-d56d-f78c3925a586"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  258\n",
              "1  257\n",
              "2  256\n",
              "3  255\n",
              "4  254"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "26hK4VWkx1R7",
        "outputId": "dff0044b-45a4-4ef7-e29e-358b6afebaeb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.36  1583.23  1396.84  14.62  21.61  553.97  2387.96  9062.17   \n",
              "1  518.67  642.50  1584.69  1396.89  14.62  21.61  554.55  2388.00  9061.78   \n",
              "2  518.67  642.18  1582.35  1405.61  14.62  21.61  554.43  2388.03  9070.23   \n",
              "3  518.67  642.92  1585.61  1392.27  14.62  21.61  555.21  2388.00  9064.57   \n",
              "4  518.67  641.68  1588.63  1397.65  14.62  21.61  554.74  2388.04  9076.14   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  522.31  2388.01  8145.32  8.4246  0.03   391  2388  100.0  39.11   \n",
              "1  1.3  ...  522.42  2388.03  8152.85  8.4403  0.03   392  2388  100.0  38.99   \n",
              "2  1.3  ...  522.03  2388.00  8150.17  8.3901  0.03   391  2388  100.0  38.85   \n",
              "3  1.3  ...  522.49  2388.08  8146.56  8.3878  0.03   392  2388  100.0  38.96   \n",
              "4  1.3  ...  522.58  2388.03  8147.80  8.3869  0.03   392  2388  100.0  39.14   \n",
              "\n",
              "      s_20  \n",
              "0  23.3537  \n",
              "1  23.4491  \n",
              "2  23.3669  \n",
              "3  23.2951  \n",
              "4  23.4583  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.36</td>\n",
              "      <td>1583.23</td>\n",
              "      <td>1396.84</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.97</td>\n",
              "      <td>2387.96</td>\n",
              "      <td>9062.17</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.31</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>8145.32</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.11</td>\n",
              "      <td>23.3537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.50</td>\n",
              "      <td>1584.69</td>\n",
              "      <td>1396.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.55</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>9061.78</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8152.85</td>\n",
              "      <td>8.4403</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.18</td>\n",
              "      <td>1582.35</td>\n",
              "      <td>1405.61</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.43</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>9070.23</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.03</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8150.17</td>\n",
              "      <td>8.3901</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.85</td>\n",
              "      <td>23.3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1585.61</td>\n",
              "      <td>1392.27</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>555.21</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>9064.57</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.49</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8146.56</td>\n",
              "      <td>8.3878</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.96</td>\n",
              "      <td>23.2951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.68</td>\n",
              "      <td>1588.63</td>\n",
              "      <td>1397.65</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.74</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9076.14</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.58</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8147.80</td>\n",
              "      <td>8.3869</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.14</td>\n",
              "      <td>23.4583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "RXluaxXx9KAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "pXrknAaH9KAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "PWPu36179KAO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "Zt00Gp3h9KAO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "s5FGWUO39KAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "1YVpDJMZ9KAP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "kuJmsPFz9KAP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "2wQw__yZ9KAQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "Yxeph5PR9KAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "Y6osQMX29KAS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "CaAspZtt9KAS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "aGe9ksS69KAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "gRSH3tdyf8yc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor2(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        data = data.drop(self.feature_cols, axis=1)\n",
        "        \n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        print(all(data.index==transf.index))\n",
        "        data = pd.concat([data,transf], axis=1)\n",
        "        # data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        transf = self.scaler.fit_transform(data[self.feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.scaler.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        data = data.drop(self.feature_cols, axis=1)\n",
        "        data = pd.concat([data,transf], axis=1)\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Kfvjdak-9KAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "3aXzwlaw9KAU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "wulPSyfF9KAU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "hKDJOCJf9KAV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "Vd0hQpw-U_ch"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "5aqms6jMFKti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.7960749287247998  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 53),\n",
        "('basemodel__epochs', 40),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.2519865793617908),\n",
        "('basemodel__model__layer1', 254),\n",
        "('basemodel__model__learning_rate', 0.0026310480233180064),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.268645350331565),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 96)\n",
        "```\n"
      ],
      "metadata": {
        "id": "oGlT7ajZFKtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=96\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=53,\n",
        "                           epochs=40,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.2519865793617908, \n",
        "                           model__layer1=254, \n",
        "                           model__learning_rate=0.0026310480233180064,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.268645350331565, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5e3103-d49b-4c61-9365-b08212183020",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 96, 22)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 254)               281432    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 254)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 281,687\n",
            "Trainable params: 281,687\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=10727.593, rmse=103.574, r2=-0.470; v_loss=6198.444, v_rmse=78.730, v_r2=-0.018; \n",
            "E 2\t: loss=7297.661, rmse=85.426, r2=-0.000; v_loss=5638.025, v_rmse=75.087, v_r2=0.074; \n",
            "E 3\t: loss=6237.677, rmse=78.979, r2=0.145; v_loss=4520.143, v_rmse=67.232, v_r2=0.257; \n",
            "E 4\t: loss=3980.354, rmse=63.090, r2=0.455; v_loss=2869.802, v_rmse=53.571, v_r2=0.529; \n",
            "E 5\t: loss=2327.856, rmse=48.248, r2=0.681; v_loss=2061.174, v_rmse=45.400, v_r2=0.661; \n",
            "E 6\t: loss=1911.884, rmse=43.725, r2=0.738; v_loss=2922.781, v_rmse=54.063, v_r2=0.520; \n",
            "E 7\t: loss=1520.505, rmse=38.994, r2=0.792; v_loss=2200.637, v_rmse=46.911, v_r2=0.639; \n",
            "E 8\t: loss=1240.534, rmse=35.221, r2=0.830; v_loss=2346.279, v_rmse=48.438, v_r2=0.615; \n",
            "E 9\t: loss=1123.534, rmse=33.519, r2=0.846; v_loss=1941.611, v_rmse=44.064, v_r2=0.681; \n",
            "E 10\t: loss=1123.068, rmse=33.512, r2=0.846; v_loss=2356.755, v_rmse=48.546, v_r2=0.613; \n",
            "E 11\t: loss=984.492, rmse=31.377, r2=0.865; v_loss=1493.538, v_rmse=38.646, v_r2=0.755; \n",
            "E 12\t: loss=872.242, rmse=29.534, r2=0.880; v_loss=1643.904, v_rmse=40.545, v_r2=0.730; \n",
            "E 13\t: loss=797.491, rmse=28.240, r2=0.891; v_loss=2377.251, v_rmse=48.757, v_r2=0.609; \n",
            "E 14\t: loss=928.422, rmse=30.470, r2=0.873; v_loss=1911.099, v_rmse=43.716, v_r2=0.686; \n",
            "E 15\t: loss=1018.371, rmse=31.912, r2=0.860; v_loss=1673.589, v_rmse=40.910, v_r2=0.725; \n",
            "E 16\t: loss=870.980, rmse=29.512, r2=0.881; v_loss=1518.437, v_rmse=38.967, v_r2=0.751; \n",
            "E 17\t: loss=942.741, rmse=30.704, r2=0.871; v_loss=1659.612, v_rmse=40.738, v_r2=0.727; \n",
            "E 18\t: loss=991.884, rmse=31.494, r2=0.864; v_loss=2269.377, v_rmse=47.638, v_r2=0.627; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=53, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=40, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__dropout1=0.2519865793617908, model__layer1=254, model__learning_rate=0.0026310480233180064, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027D71E8D700>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027D71CEB160>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.268645350331565, verbose=0),\n",
              "                     seq_length=96)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e7ecff-8744-43b7-fa01-13990c0ef1c9",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.611,RMSE=-25.813\n",
            "Finished: 2022-11-03 07:48:24.070121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.9405557989097725  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 320),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.1),\n",
        "('basemodel__model__layer1', 171),\n",
        "('basemodel__model__learning_rate', 0.003956355423514566),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1402058641858904),\n",
        "('clip_y', 81),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 65)\n",
        "```\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=65\n",
        "CLIP=81\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=320,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=171, \n",
        "                           model__learning_rate=0.003956355423514566,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.1402058641858904, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36P-gmRD6QM",
        "outputId": "8ce7c6cf-7edc-4c15-9c5e-20ed16310642"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 65, 22)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 171)               132696    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 171)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 172       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,868\n",
            "Trainable params: 132,868\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2250.397, rmse=47.438, r2=-2.449; v_loss=1268.301, v_rmse=35.613, v_r2=-0.872; \n",
            "E 2\t: loss=833.248, rmse=28.866, r2=-0.277; v_loss=366.517, v_rmse=19.145, v_r2=0.459; \n",
            "E 3\t: loss=208.818, rmse=14.451, r2=0.680; v_loss=107.585, v_rmse=10.372, v_r2=0.841; \n",
            "E 4\t: loss=112.971, rmse=10.629, r2=0.827; v_loss=116.414, v_rmse=10.790, v_r2=0.828; \n",
            "E 5\t: loss=101.523, rmse=10.076, r2=0.844; v_loss=75.026, v_rmse=8.662, v_r2=0.889; \n",
            "E 6\t: loss=87.791, rmse=9.370, r2=0.865; v_loss=109.235, v_rmse=10.452, v_r2=0.839; \n",
            "E 7\t: loss=77.940, rmse=8.828, r2=0.881; v_loss=75.491, v_rmse=8.689, v_r2=0.889; \n",
            "E 8\t: loss=73.018, rmse=8.545, r2=0.888; v_loss=88.138, v_rmse=9.388, v_r2=0.870; \n",
            "E 9\t: loss=69.296, rmse=8.324, r2=0.894; v_loss=68.125, v_rmse=8.254, v_r2=0.899; \n",
            "E 10\t: loss=64.077, rmse=8.005, r2=0.902; v_loss=86.695, v_rmse=9.311, v_r2=0.872; \n",
            "E 11\t: loss=66.358, rmse=8.146, r2=0.898; v_loss=90.588, v_rmse=9.518, v_r2=0.866; \n",
            "E 12\t: loss=57.728, rmse=7.598, r2=0.912; v_loss=87.797, v_rmse=9.370, v_r2=0.870; \n",
            "E 13\t: loss=52.846, rmse=7.270, r2=0.919; v_loss=78.847, v_rmse=8.880, v_r2=0.884; \n",
            "E 14\t: loss=52.715, rmse=7.260, r2=0.919; v_loss=76.613, v_rmse=8.753, v_r2=0.887; \n",
            "E 15\t: loss=47.051, rmse=6.859, r2=0.928; v_loss=65.603, v_rmse=8.100, v_r2=0.903; \n",
            "E 16\t: loss=46.100, rmse=6.790, r2=0.929; v_loss=58.777, v_rmse=7.667, v_r2=0.913; \n",
            "E 17\t: loss=41.259, rmse=6.423, r2=0.937; v_loss=70.833, v_rmse=8.416, v_r2=0.895; \n",
            "E 18\t: loss=41.555, rmse=6.446, r2=0.936; v_loss=81.875, v_rmse=9.048, v_r2=0.879; \n",
            "E 19\t: loss=38.299, rmse=6.189, r2=0.941; v_loss=53.873, v_rmse=7.340, v_r2=0.920; \n",
            "E 20\t: loss=37.260, rmse=6.104, r2=0.943; v_loss=55.832, v_rmse=7.472, v_r2=0.918; \n",
            "E 21\t: loss=37.428, rmse=6.118, r2=0.943; v_loss=48.439, v_rmse=6.960, v_r2=0.929; \n",
            "E 22\t: loss=32.699, rmse=5.718, r2=0.950; v_loss=85.672, v_rmse=9.256, v_r2=0.874; \n",
            "E 23\t: loss=35.692, rmse=5.974, r2=0.945; v_loss=58.058, v_rmse=7.620, v_r2=0.914; \n",
            "E 24\t: loss=32.499, rmse=5.701, r2=0.950; v_loss=55.109, v_rmse=7.424, v_r2=0.919; \n",
            "E 25\t: loss=32.044, rmse=5.661, r2=0.951; v_loss=106.017, v_rmse=10.296, v_r2=0.844; \n",
            "E 26\t: loss=32.301, rmse=5.683, r2=0.951; v_loss=70.547, v_rmse=8.399, v_r2=0.896; \n",
            "E 27\t: loss=30.940, rmse=5.562, r2=0.953; v_loss=53.448, v_rmse=7.311, v_r2=0.921; \n",
            "E 28\t: loss=28.280, rmse=5.318, r2=0.957; v_loss=77.434, v_rmse=8.800, v_r2=0.886; \n",
            "E 29\t: loss=29.540, rmse=5.435, r2=0.955; v_loss=37.865, v_rmse=6.153, v_r2=0.944; \n",
            "E 30\t: loss=30.392, rmse=5.513, r2=0.953; v_loss=45.789, v_rmse=6.767, v_r2=0.932; \n",
            "E 31\t: loss=26.835, rmse=5.180, r2=0.959; v_loss=61.561, v_rmse=7.846, v_r2=0.909; \n",
            "E 32\t: loss=27.104, rmse=5.206, r2=0.958; v_loss=91.618, v_rmse=9.572, v_r2=0.865; \n",
            "E 33\t: loss=27.580, rmse=5.252, r2=0.958; v_loss=52.521, v_rmse=7.247, v_r2=0.922; \n",
            "E 34\t: loss=26.225, rmse=5.121, r2=0.960; v_loss=57.342, v_rmse=7.572, v_r2=0.915; \n",
            "E 35\t: loss=24.654, rmse=4.965, r2=0.962; v_loss=37.007, v_rmse=6.083, v_r2=0.945; \n",
            "E 36\t: loss=25.530, rmse=5.053, r2=0.961; v_loss=63.585, v_rmse=7.974, v_r2=0.906; \n",
            "E 37\t: loss=25.446, rmse=5.044, r2=0.961; v_loss=22.909, v_rmse=4.786, v_r2=0.966; \n",
            "E 38\t: loss=24.468, rmse=4.947, r2=0.963; v_loss=56.010, v_rmse=7.484, v_r2=0.917; \n",
            "E 39\t: loss=25.190, rmse=5.019, r2=0.961; v_loss=35.627, v_rmse=5.969, v_r2=0.947; \n",
            "E 40\t: loss=23.365, rmse=4.834, r2=0.964; v_loss=42.751, v_rmse=6.538, v_r2=0.937; \n",
            "E 41\t: loss=24.205, rmse=4.920, r2=0.963; v_loss=48.881, v_rmse=6.992, v_r2=0.928; \n",
            "E 42\t: loss=24.026, rmse=4.902, r2=0.963; v_loss=49.302, v_rmse=7.022, v_r2=0.927; \n",
            "E 43\t: loss=22.441, rmse=4.737, r2=0.966; v_loss=53.153, v_rmse=7.291, v_r2=0.922; \n",
            "E 44\t: loss=22.800, rmse=4.775, r2=0.965; v_loss=47.231, v_rmse=6.872, v_r2=0.930; \n",
            "E 45\t: loss=22.543, rmse=4.748, r2=0.965; v_loss=54.812, v_rmse=7.403, v_r2=0.919; \n",
            "E 46\t: loss=22.071, rmse=4.698, r2=0.966; v_loss=58.047, v_rmse=7.619, v_r2=0.914; \n",
            "E 47\t: loss=21.208, rmse=4.605, r2=0.967; v_loss=39.118, v_rmse=6.254, v_r2=0.942; \n",
            "E 48\t: loss=20.276, rmse=4.503, r2=0.969; v_loss=46.078, v_rmse=6.788, v_r2=0.932; \n",
            "E 49\t: loss=20.061, rmse=4.479, r2=0.969; v_loss=79.045, v_rmse=8.891, v_r2=0.883; \n",
            "E 50\t: loss=20.284, rmse=4.504, r2=0.969; v_loss=47.611, v_rmse=6.900, v_r2=0.930; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=320, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=50, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__dropout1=0.1, model__layer1=171, model__learning_rate=0.003956355423514566, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027C55292430>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027C55290250>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.1402058641858904, verbose=0),\n",
              "                     clip_y=81, seq_length=65)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "ef9f018a-9b91-40b1-de32-db91d6f3e2d5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.954,RMSE=-5.472\n",
            "Finished: 2022-11-03 07:50:17.043806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1 "
      ],
      "metadata": {
        "id": "SvWawqOFYvO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "bWDbtK4RYvPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.7565845071829033  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 83),\n",
        "('basemodel__epochs', 31),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__dropout1', 0.24854411808808108),\n",
        "('basemodel__model__dropout2', 0.42830600210145653),\n",
        "('basemodel__model__layer1', 220),\n",
        "('basemodel__model__layer2', 164),\n",
        "('basemodel__model__learning_rate', 0.001141928043462988),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.23166030850146868),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 73)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "18mXMMo2YvPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=73\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=83,\n",
        "                           epochs=31,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout1=0.24854411808808108, \n",
        "                           model__dropout2=0.42830600210145653, \n",
        "                           model__layer1=220, \n",
        "                           model__layer2=164, \n",
        "                           model__learning_rate=0.001141928043462988,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.23166030850146868, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "2EKUQXh0YvPB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd9e1c7-49ec-46bf-b17b-273752ccf074",
        "id": "5uHgjmJZYvPC"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_3 (Masking)         (None, 73, 22)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 220)               213840    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 220)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 164)               36244     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 164)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 250,249\n",
            "Trainable params: 250,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=8436.993, rmse=91.853, r2=-0.111; v_loss=6578.631, v_rmse=81.109, v_r2=0.088; \n",
            "E 2\t: loss=6650.595, rmse=81.551, r2=0.124; v_loss=6237.719, v_rmse=78.979, v_r2=0.135; \n",
            "E 3\t: loss=4764.697, rmse=69.027, r2=0.373; v_loss=3260.925, v_rmse=57.105, v_r2=0.548; \n",
            "E 4\t: loss=2839.260, rmse=53.285, r2=0.626; v_loss=3639.627, v_rmse=60.329, v_r2=0.495; \n",
            "E 5\t: loss=2462.329, rmse=49.622, r2=0.676; v_loss=3029.202, v_rmse=55.038, v_r2=0.580; \n",
            "E 6\t: loss=2337.851, rmse=48.351, r2=0.692; v_loss=4277.784, v_rmse=65.405, v_r2=0.407; \n",
            "E 7\t: loss=2245.751, rmse=47.389, r2=0.704; v_loss=3535.313, v_rmse=59.458, v_r2=0.510; \n",
            "E 8\t: loss=2058.932, rmse=45.375, r2=0.729; v_loss=2489.892, v_rmse=49.899, v_r2=0.655; \n",
            "E 9\t: loss=1880.053, rmse=43.360, r2=0.752; v_loss=2867.315, v_rmse=53.547, v_r2=0.602; \n",
            "E 10\t: loss=1706.124, rmse=41.305, r2=0.775; v_loss=2063.883, v_rmse=45.430, v_r2=0.714; \n",
            "E 11\t: loss=1769.143, rmse=42.061, r2=0.767; v_loss=1981.424, v_rmse=44.513, v_r2=0.725; \n",
            "E 12\t: loss=1566.231, rmse=39.576, r2=0.794; v_loss=3032.139, v_rmse=55.065, v_r2=0.579; \n",
            "E 13\t: loss=1501.892, rmse=38.754, r2=0.802; v_loss=2414.640, v_rmse=49.139, v_r2=0.665; \n",
            "E 14\t: loss=1493.672, rmse=38.648, r2=0.803; v_loss=2068.736, v_rmse=45.483, v_r2=0.713; \n",
            "E 15\t: loss=1421.598, rmse=37.704, r2=0.813; v_loss=1662.679, v_rmse=40.776, v_r2=0.769; \n",
            "E 16\t: loss=1337.077, rmse=36.566, r2=0.824; v_loss=2422.760, v_rmse=49.222, v_r2=0.664; \n",
            "E 17\t: loss=1378.256, rmse=37.125, r2=0.818; v_loss=1597.358, v_rmse=39.967, v_r2=0.778; \n",
            "E 18\t: loss=1272.852, rmse=35.677, r2=0.832; v_loss=1915.890, v_rmse=43.771, v_r2=0.734; \n",
            "E 19\t: loss=1386.502, rmse=37.236, r2=0.817; v_loss=2068.104, v_rmse=45.476, v_r2=0.713; \n",
            "E 20\t: loss=1297.885, rmse=36.026, r2=0.829; v_loss=1961.037, v_rmse=44.284, v_r2=0.728; \n",
            "E 21\t: loss=1236.180, rmse=35.159, r2=0.837; v_loss=1837.094, v_rmse=42.861, v_r2=0.745; \n",
            "E 22\t: loss=1260.621, rmse=35.505, r2=0.834; v_loss=1514.604, v_rmse=38.918, v_r2=0.790; \n",
            "E 23\t: loss=1230.059, rmse=35.072, r2=0.838; v_loss=2637.389, v_rmse=51.356, v_r2=0.634; \n",
            "E 24\t: loss=1271.863, rmse=35.663, r2=0.833; v_loss=1836.524, v_rmse=42.855, v_r2=0.745; \n",
            "E 25\t: loss=1381.698, rmse=37.171, r2=0.818; v_loss=3643.825, v_rmse=60.364, v_r2=0.495; \n",
            "E 26\t: loss=1301.178, rmse=36.072, r2=0.829; v_loss=1555.676, v_rmse=39.442, v_r2=0.784; \n",
            "E 27\t: loss=1112.949, rmse=33.361, r2=0.853; v_loss=1660.232, v_rmse=40.746, v_r2=0.770; \n",
            "E 28\t: loss=1195.970, rmse=34.583, r2=0.843; v_loss=1511.339, v_rmse=38.876, v_r2=0.790; \n",
            "E 29\t: loss=1109.769, rmse=33.313, r2=0.854; v_loss=1520.039, v_rmse=38.988, v_r2=0.789; \n",
            "E 30\t: loss=1139.575, rmse=33.758, r2=0.850; v_loss=1492.432, v_rmse=38.632, v_r2=0.793; \n",
            "E 31\t: loss=1138.143, rmse=33.736, r2=0.850; v_loss=1933.915, v_rmse=43.976, v_r2=0.732; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=83, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=31, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__activation2='selu', model__dropout1=0.24854411808808108, model__dropout...8, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027D7C8BFC40>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027D7C8B7A30>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.23166030850146868, verbose=0),\n",
              "                     scaler=MinMaxScaler(), seq_length=73)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4665c400-8f4d-4878-af04-71217c663067",
        "id": "svjWhd4FYvPD"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.550,RMSE=-27.754\n",
            "Finished: 2022-11-03 07:54:12.029769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "6LznVkFxYvPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.888684501987752  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 118),\n",
        "('basemodel__epochs', 30),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__dropout1', 0.8430541193967747),\n",
        "('basemodel__model__dropout2', 0.5945240280760793),\n",
        "('basemodel__model__layer1', 162),\n",
        "('basemodel__model__layer2', 142),\n",
        "('basemodel__model__learning_rate', 0.002503870405609483),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.6441614026771669),\n",
        "('clip_y', 83),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 86)\n",
        "```\n"
      ],
      "metadata": {
        "id": "KiL-gZkZYvPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=86\n",
        "CLIP=83\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=118,\n",
        "                           epochs=30,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout1=0.8430541193967747, \n",
        "                           model__dropout2=0.5945240280760793, \n",
        "                           model__layer1=162, \n",
        "                           model__layer2=142, \n",
        "                           model__learning_rate=0.002503870405609483,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.6441614026771669, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "tEwHSsUCYvPE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f97f82-f6ce-4d19-fa7d-031d297c0c9a",
        "id": "AMEzooPSYvPF"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_4 (Masking)         (None, 86, 22)            0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 162)               119880    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 162)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 142)               23146     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 142)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 143       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143,169\n",
            "Trainable params: 143,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1571.365, rmse=39.640, r2=-1.272; v_loss=622.251, v_rmse=24.945, v_r2=0.175; \n",
            "E 2\t: loss=603.644, rmse=24.569, r2=0.127; v_loss=363.488, v_rmse=19.065, v_r2=0.518; \n",
            "E 3\t: loss=426.875, rmse=20.661, r2=0.383; v_loss=231.723, v_rmse=15.222, v_r2=0.693; \n",
            "E 4\t: loss=359.071, rmse=18.949, r2=0.481; v_loss=197.991, v_rmse=14.071, v_r2=0.738; \n",
            "E 5\t: loss=312.196, rmse=17.669, r2=0.549; v_loss=179.082, v_rmse=13.382, v_r2=0.763; \n",
            "E 6\t: loss=264.706, rmse=16.270, r2=0.617; v_loss=150.787, v_rmse=12.280, v_r2=0.800; \n",
            "E 7\t: loss=245.708, rmse=15.675, r2=0.645; v_loss=189.575, v_rmse=13.769, v_r2=0.749; \n",
            "E 8\t: loss=220.457, rmse=14.848, r2=0.681; v_loss=132.751, v_rmse=11.522, v_r2=0.824; \n",
            "E 9\t: loss=203.755, rmse=14.274, r2=0.705; v_loss=130.011, v_rmse=11.402, v_r2=0.828; \n",
            "E 10\t: loss=178.904, rmse=13.376, r2=0.741; v_loss=146.744, v_rmse=12.114, v_r2=0.806; \n",
            "E 11\t: loss=173.608, rmse=13.176, r2=0.749; v_loss=107.681, v_rmse=10.377, v_r2=0.857; \n",
            "E 12\t: loss=167.616, rmse=12.947, r2=0.758; v_loss=142.232, v_rmse=11.926, v_r2=0.812; \n",
            "E 13\t: loss=163.921, rmse=12.803, r2=0.763; v_loss=117.698, v_rmse=10.849, v_r2=0.844; \n",
            "E 14\t: loss=161.002, rmse=12.689, r2=0.767; v_loss=143.167, v_rmse=11.965, v_r2=0.810; \n",
            "E 15\t: loss=156.782, rmse=12.521, r2=0.773; v_loss=122.524, v_rmse=11.069, v_r2=0.838; \n",
            "E 16\t: loss=154.793, rmse=12.442, r2=0.776; v_loss=135.694, v_rmse=11.649, v_r2=0.820; \n",
            "E 17\t: loss=151.702, rmse=12.317, r2=0.781; v_loss=127.243, v_rmse=11.280, v_r2=0.831; \n",
            "E 18\t: loss=148.478, rmse=12.185, r2=0.785; v_loss=112.971, v_rmse=10.629, v_r2=0.850; \n",
            "E 19\t: loss=147.815, rmse=12.158, r2=0.786; v_loss=113.838, v_rmse=10.669, v_r2=0.849; \n",
            "E 20\t: loss=136.847, rmse=11.698, r2=0.802; v_loss=101.930, v_rmse=10.096, v_r2=0.865; \n",
            "E 21\t: loss=139.887, rmse=11.827, r2=0.798; v_loss=128.648, v_rmse=11.342, v_r2=0.830; \n",
            "E 22\t: loss=142.164, rmse=11.923, r2=0.794; v_loss=118.709, v_rmse=10.895, v_r2=0.843; \n",
            "E 23\t: loss=139.415, rmse=11.807, r2=0.798; v_loss=109.639, v_rmse=10.471, v_r2=0.855; \n",
            "E 24\t: loss=141.750, rmse=11.906, r2=0.795; v_loss=104.932, v_rmse=10.244, v_r2=0.861; \n",
            "E 25\t: loss=144.039, rmse=12.002, r2=0.792; v_loss=95.436, v_rmse=9.769, v_r2=0.874; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=118, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=30, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__activation2='selu', model__dropout1=0.8430541193967747, model__dropout...03870405609483, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027D7747F820>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027D773D1F10>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.6441614026771669, verbose=0),\n",
              "                     clip_y=83, seq_length=86)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13be6fdb-e88c-4d2c-c3bf-e78fdc98ce2f",
        "id": "WU1dYRTwYvPG"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.856,RMSE=-9.985\n",
            "Finished: 2022-11-03 07:55:28.862760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2 "
      ],
      "metadata": {
        "id": "y28M-FK8zDq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "9Zl5AM1czDq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.6493310087734959  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 199),\n",
        "('basemodel__epochs', 35),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.25434586961869254),\n",
        "('basemodel__model__dropout2', 0.16002400441910994),\n",
        "('basemodel__model__dropout3', 0.35413824342558264),\n",
        "('basemodel__model__layer1', 425),\n",
        "('basemodel__model__layer2', 66),\n",
        "('basemodel__model__layer3', 470),\n",
        "('basemodel__model__learning_rate', 0.0032857714954219377),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.26624246496701254),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 81)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y5_j9VhBzDq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=81\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=199,\n",
        "                           epochs=35,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.25434586961869254, \n",
        "                           model__dropout2=0.16002400441910994,\n",
        "                           model__dropout3=0.35413824342558264, \n",
        "                           model__layer1=425, \n",
        "                           model__layer2=66, \n",
        "                           model__layer3=470, \n",
        "                           model__learning_rate=0.0032857714954219377,\n",
        "                           model__optim=RMSprop,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.26624246496701254, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "yP84kQK2zDq5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e1f358-cf15-46a7-ac2b-7da02171044c",
        "id": "dpx_rNVCzDq6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_7 (Masking)         (None, 81, 22)            0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 425)               761600    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 425)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 66)                28116     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 66)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 470)               31490     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 470)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 471       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 821,677\n",
            "Trainable params: 821,677\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=7662.597, rmse=87.536, r2=-0.007; v_loss=6148.768, v_rmse=78.414, v_r2=0.046; \n",
            "E 2\t: loss=6998.851, rmse=83.659, r2=0.081; v_loss=5675.648, v_rmse=75.337, v_r2=0.119; \n",
            "E 3\t: loss=6690.589, rmse=81.796, r2=0.121; v_loss=6022.241, v_rmse=77.603, v_r2=0.065; \n",
            "E 4\t: loss=6428.333, rmse=80.177, r2=0.155; v_loss=4497.700, v_rmse=67.065, v_r2=0.302; \n",
            "E 5\t: loss=5875.013, rmse=76.649, r2=0.228; v_loss=3845.921, v_rmse=62.015, v_r2=0.403; \n",
            "E 6\t: loss=5879.387, rmse=76.677, r2=0.228; v_loss=3946.673, v_rmse=62.823, v_r2=0.388; \n",
            "E 7\t: loss=5125.420, rmse=71.592, r2=0.327; v_loss=5212.248, v_rmse=72.196, v_r2=0.191; \n",
            "E 8\t: loss=4900.191, rmse=70.001, r2=0.356; v_loss=6761.251, v_rmse=82.227, v_r2=-0.049; \n",
            "E 9\t: loss=4585.322, rmse=67.715, r2=0.398; v_loss=8000.419, v_rmse=89.445, v_r2=-0.242; \n",
            "E 10\t: loss=4138.457, rmse=64.331, r2=0.456; v_loss=8465.375, v_rmse=92.007, v_r2=-0.314; \n",
            "E 11\t: loss=4129.815, rmse=64.264, r2=0.457; v_loss=3555.894, v_rmse=59.631, v_r2=0.448; \n",
            "E 12\t: loss=3747.866, rmse=61.220, r2=0.508; v_loss=3973.528, v_rmse=63.036, v_r2=0.383; \n",
            "E 13\t: loss=3720.282, rmse=60.994, r2=0.511; v_loss=5822.834, v_rmse=76.307, v_r2=0.096; \n",
            "E 14\t: loss=3646.834, rmse=60.389, r2=0.521; v_loss=5692.682, v_rmse=75.450, v_r2=0.117; \n",
            "E 15\t: loss=3528.279, rmse=59.399, r2=0.536; v_loss=5823.058, v_rmse=76.309, v_r2=0.096; \n",
            "E 16\t: loss=3375.399, rmse=58.098, r2=0.557; v_loss=3614.766, v_rmse=60.123, v_r2=0.439; \n",
            "E 17\t: loss=3289.442, rmse=57.354, r2=0.568; v_loss=3835.326, v_rmse=61.930, v_r2=0.405; \n",
            "E 18\t: loss=3032.074, rmse=55.064, r2=0.602; v_loss=5251.093, v_rmse=72.464, v_r2=0.185; \n",
            "E 19\t: loss=2889.045, rmse=53.750, r2=0.620; v_loss=3222.493, v_rmse=56.767, v_r2=0.500; \n",
            "E 20\t: loss=3032.601, rmse=55.069, r2=0.602; v_loss=5704.803, v_rmse=75.530, v_r2=0.115; \n",
            "E 21\t: loss=2754.919, rmse=52.487, r2=0.638; v_loss=2502.646, v_rmse=50.026, v_r2=0.612; \n",
            "E 22\t: loss=2672.558, rmse=51.697, r2=0.649; v_loss=7558.964, v_rmse=86.942, v_r2=-0.173; \n",
            "E 23\t: loss=2548.675, rmse=50.484, r2=0.665; v_loss=3283.865, v_rmse=57.305, v_r2=0.490; \n",
            "E 24\t: loss=2562.507, rmse=50.621, r2=0.663; v_loss=3614.996, v_rmse=60.125, v_r2=0.439; \n",
            "E 25\t: loss=2386.073, rmse=48.847, r2=0.687; v_loss=3811.348, v_rmse=61.736, v_r2=0.409; \n",
            "E 26\t: loss=2377.324, rmse=48.758, r2=0.688; v_loss=4001.332, v_rmse=63.256, v_r2=0.379; \n",
            "E 27\t: loss=2198.357, rmse=46.887, r2=0.711; v_loss=4716.531, v_rmse=68.677, v_r2=0.268; \n",
            "E 28\t: loss=2190.138, rmse=46.799, r2=0.712; v_loss=4920.072, v_rmse=70.143, v_r2=0.236; \n",
            "E 29\t: loss=2170.527, rmse=46.589, r2=0.715; v_loss=2485.960, v_rmse=49.859, v_r2=0.614; \n",
            "E 30\t: loss=2076.773, rmse=45.572, r2=0.727; v_loss=2082.034, v_rmse=45.629, v_r2=0.677; \n",
            "E 31\t: loss=2033.841, rmse=45.098, r2=0.733; v_loss=2542.954, v_rmse=50.428, v_r2=0.605; \n",
            "E 32\t: loss=1970.818, rmse=44.394, r2=0.741; v_loss=4983.372, v_rmse=70.593, v_r2=0.227; \n",
            "E 33\t: loss=1993.819, rmse=44.652, r2=0.738; v_loss=2697.699, v_rmse=51.939, v_r2=0.581; \n",
            "E 34\t: loss=1806.807, rmse=42.507, r2=0.763; v_loss=3132.378, v_rmse=55.968, v_r2=0.514; \n",
            "E 35\t: loss=1827.840, rmse=42.753, r2=0.760; v_loss=2061.585, v_rmse=45.405, v_r2=0.680; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=199, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=35, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__activation2='relu', model__activation3='selu', model__dropout1=0.25434...l__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027DCD4947C0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027DCD494A30>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__second_dense=True, print_summary=True, validation_split=0.26624246496701254, verbose=0),\n",
              "                     scaler=MinMaxScaler(), seq_length=81)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b226fdf4-a470-4b4b-baf9-c444b1238849",
        "id": "qzoIZZmlzDq7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.398,RMSE=-32.126\n",
            "Finished: 2022-11-03 08:05:44.810414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "wrpte1WXzDq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.9051346719630059  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 123),\n",
        "('basemodel__epochs', 33),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.1),\n",
        "('basemodel__model__dropout2', 0.5621274317662914),\n",
        "('basemodel__model__dropout3', 0.20153570533706447),\n",
        "('basemodel__model__layer1', 497),\n",
        "('basemodel__model__layer2', 256),\n",
        "('basemodel__model__layer3', 485),\n",
        "('basemodel__model__learning_rate', 0.00056680506717284),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.6912604506849247),\n",
        "('clip_y', 88),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 61)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-RCr6qz8zDq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=61\n",
        "CLIP=88\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=123,\n",
        "                           epochs=33,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='tanh',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__dropout2=0.5621274317662914,\n",
        "                           model__dropout3=0.20153570533706447, \n",
        "                           model__layer1=497, \n",
        "                           model__layer2=256, \n",
        "                           model__layer3=485, \n",
        "                           model__learning_rate=0.00056680506717284,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.6912604506849247, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "TCGZ2Pr4zDq8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281cb39d-7f1e-4df6-8025-1846743e0627",
        "id": "Fd65WHLTzDq9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_8 (Masking)         (None, 61, 22)            0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 497)               1033760   \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 497)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               127488    \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 485)               124645    \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 485)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 486       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,286,379\n",
            "Trainable params: 1,286,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2780.701, rmse=52.732, r2=-2.814; v_loss=1570.867, v_rmse=39.634, v_r2=-0.916; \n",
            "E 2\t: loss=1446.098, rmse=38.028, r2=-0.983; v_loss=1078.693, v_rmse=32.843, v_r2=-0.316; \n",
            "E 3\t: loss=1014.274, rmse=31.848, r2=-0.391; v_loss=882.708, v_rmse=29.710, v_r2=-0.077; \n",
            "E 4\t: loss=828.613, rmse=28.786, r2=-0.137; v_loss=824.652, v_rmse=28.717, v_r2=-0.006; \n",
            "E 5\t: loss=760.344, rmse=27.574, r2=-0.043; v_loss=821.163, v_rmse=28.656, v_r2=-0.002; \n",
            "E 6\t: loss=739.864, rmse=27.200, r2=-0.015; v_loss=829.692, v_rmse=28.804, v_r2=-0.012; \n",
            "E 7\t: loss=731.692, rmse=27.050, r2=-0.004; v_loss=836.101, v_rmse=28.915, v_r2=-0.020; \n",
            "E 8\t: loss=729.325, rmse=27.006, r2=-0.000; v_loss=839.747, v_rmse=28.978, v_r2=-0.024; \n",
            "E 9\t: loss=706.931, rmse=26.588, r2=0.030; v_loss=636.336, v_rmse=25.226, v_r2=0.224; \n",
            "E 10\t: loss=288.641, rmse=16.989, r2=0.604; v_loss=162.464, v_rmse=12.746, v_r2=0.802; \n",
            "E 11\t: loss=138.187, rmse=11.755, r2=0.810; v_loss=118.408, v_rmse=10.882, v_r2=0.856; \n",
            "E 12\t: loss=76.060, rmse=8.721, r2=0.896; v_loss=132.818, v_rmse=11.525, v_r2=0.838; \n",
            "E 13\t: loss=56.253, rmse=7.500, r2=0.923; v_loss=86.405, v_rmse=9.295, v_r2=0.895; \n",
            "E 14\t: loss=44.527, rmse=6.673, r2=0.939; v_loss=98.346, v_rmse=9.917, v_r2=0.880; \n",
            "E 15\t: loss=36.279, rmse=6.023, r2=0.950; v_loss=63.748, v_rmse=7.984, v_r2=0.922; \n",
            "E 16\t: loss=32.386, rmse=5.691, r2=0.956; v_loss=65.263, v_rmse=8.079, v_r2=0.920; \n",
            "E 17\t: loss=35.240, rmse=5.936, r2=0.952; v_loss=69.420, v_rmse=8.332, v_r2=0.915; \n",
            "E 18\t: loss=26.351, rmse=5.133, r2=0.964; v_loss=64.066, v_rmse=8.004, v_r2=0.922; \n",
            "E 19\t: loss=23.362, rmse=4.833, r2=0.968; v_loss=66.527, v_rmse=8.156, v_r2=0.919; \n",
            "E 20\t: loss=21.226, rmse=4.607, r2=0.971; v_loss=58.664, v_rmse=7.659, v_r2=0.928; \n",
            "E 21\t: loss=20.319, rmse=4.508, r2=0.972; v_loss=54.737, v_rmse=7.398, v_r2=0.933; \n",
            "E 22\t: loss=19.106, rmse=4.371, r2=0.974; v_loss=66.930, v_rmse=8.181, v_r2=0.918; \n",
            "E 23\t: loss=18.319, rmse=4.280, r2=0.975; v_loss=68.921, v_rmse=8.302, v_r2=0.916; \n",
            "E 24\t: loss=17.689, rmse=4.206, r2=0.976; v_loss=67.306, v_rmse=8.204, v_r2=0.918; \n",
            "E 25\t: loss=18.275, rmse=4.275, r2=0.975; v_loss=65.593, v_rmse=8.099, v_r2=0.920; \n",
            "E 26\t: loss=17.287, rmse=4.158, r2=0.976; v_loss=74.840, v_rmse=8.651, v_r2=0.909; \n",
            "E 27\t: loss=14.569, rmse=3.817, r2=0.980; v_loss=68.237, v_rmse=8.261, v_r2=0.917; \n",
            "E 28\t: loss=14.413, rmse=3.796, r2=0.980; v_loss=71.208, v_rmse=8.438, v_r2=0.913; \n",
            "E 29\t: loss=13.944, rmse=3.734, r2=0.981; v_loss=70.204, v_rmse=8.379, v_r2=0.914; \n",
            "E 30\t: loss=14.815, rmse=3.849, r2=0.980; v_loss=71.923, v_rmse=8.481, v_r2=0.912; \n",
            "E 31\t: loss=13.909, rmse=3.730, r2=0.981; v_loss=68.228, v_rmse=8.260, v_r2=0.917; \n",
            "E 32\t: loss=14.216, rmse=3.770, r2=0.981; v_loss=61.892, v_rmse=7.867, v_r2=0.924; \n",
            "E 33\t: loss=13.382, rmse=3.658, r2=0.982; v_loss=69.479, v_rmse=8.335, v_r2=0.915; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=123, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=33, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__activation2='tanh', model__activation3='tanh', model__dropout1=0.1, mod...56680506717284, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027DE098BD90>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027D7C8B2700>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.6912604506849247, verbose=0),\n",
              "                     clip_y=88, seq_length=61)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c892bb-400b-421c-9f74-5c5aa04669a3",
        "id": "O8csd7JVzDq-"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.928,RMSE=-7.554\n",
            "Finished: 2022-11-03 08:07:50.355832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense (TODO)"
      ],
      "metadata": {
        "id": "5z_LZWx32lXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pu0gM_uE2lXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.8175456691305407  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'elu'),\n",
        "('basemodel__model__dropout1', 0.9),\n",
        "('basemodel__model__dropout2', 0.4884546283869159),\n",
        "('basemodel__model__dropout3', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__layer2', 41),\n",
        "('basemodel__model__layer3', 154),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', False),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 100)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HRabKU0p2lXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=100\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           model__second_dense=False,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='elu',\n",
        "                           model__dropout1=0.9, \n",
        "                           model__dropout2=0.4884546283869159,\n",
        "                           model__dropout3=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=41, \n",
        "                           model__layer3=154, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "6BGiwksX2lXG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a4c6af-a8e3-436c-9251-4ce06bbad3d8",
        "id": "Yert7PMH2lXI"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_9 (Masking)         (None, 100, 22)           0         \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 100, 512)          1095680   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 100, 512)          0         \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 41)                90856     \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 41)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 154)               6468      \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 154)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 155       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,193,159\n",
            "Trainable params: 1,193,159\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=13225.341, rmse=115.001, r2=-1.014; v_loss=15955.499, v_rmse=126.315, v_r2=-0.636; \n",
            "E 2\t: loss=8722.196, rmse=93.393, r2=-0.328; v_loss=11709.552, v_rmse=108.211, v_r2=-0.201; \n",
            "E 3\t: loss=6298.980, rmse=79.366, r2=0.041; v_loss=8019.903, v_rmse=89.554, v_r2=0.177; \n",
            "E 4\t: loss=3738.436, rmse=61.143, r2=0.431; v_loss=4797.218, v_rmse=69.262, v_r2=0.508; \n",
            "E 5\t: loss=2521.571, rmse=50.215, r2=0.616; v_loss=3149.564, v_rmse=56.121, v_r2=0.677; \n",
            "E 6\t: loss=1797.339, rmse=42.395, r2=0.726; v_loss=2355.500, v_rmse=48.533, v_r2=0.758; \n",
            "E 7\t: loss=1414.698, rmse=37.612, r2=0.785; v_loss=1681.879, v_rmse=41.011, v_r2=0.827; \n",
            "E 8\t: loss=1136.697, rmse=33.715, r2=0.827; v_loss=1554.448, v_rmse=39.426, v_r2=0.841; \n",
            "E 9\t: loss=1067.673, rmse=32.675, r2=0.837; v_loss=1328.369, v_rmse=36.447, v_r2=0.864; \n",
            "E 10\t: loss=981.027, rmse=31.321, r2=0.851; v_loss=1353.551, v_rmse=36.791, v_r2=0.861; \n",
            "E 11\t: loss=886.538, rmse=29.775, r2=0.865; v_loss=1160.069, v_rmse=34.060, v_r2=0.881; \n",
            "E 12\t: loss=864.428, rmse=29.401, r2=0.868; v_loss=1350.667, v_rmse=36.751, v_r2=0.861; \n",
            "E 13\t: loss=827.251, rmse=28.762, r2=0.874; v_loss=1560.834, v_rmse=39.507, v_r2=0.840; \n",
            "E 14\t: loss=809.221, rmse=28.447, r2=0.877; v_loss=1168.606, v_rmse=34.185, v_r2=0.880; \n",
            "E 15\t: loss=760.256, rmse=27.573, r2=0.884; v_loss=1282.892, v_rmse=35.817, v_r2=0.868; \n",
            "E 16\t: loss=724.465, rmse=26.916, r2=0.890; v_loss=1551.045, v_rmse=39.383, v_r2=0.841; \n",
            "E 17\t: loss=710.338, rmse=26.652, r2=0.892; v_loss=1379.907, v_rmse=37.147, v_r2=0.858; \n",
            "E 18\t: loss=675.152, rmse=25.984, r2=0.897; v_loss=1192.503, v_rmse=34.533, v_r2=0.878; \n",
            "E 19\t: loss=699.094, rmse=26.440, r2=0.894; v_loss=1257.034, v_rmse=35.455, v_r2=0.871; \n",
            "E 20\t: loss=632.364, rmse=25.147, r2=0.904; v_loss=1245.064, v_rmse=35.285, v_r2=0.872; \n",
            "E 21\t: loss=648.597, rmse=25.468, r2=0.901; v_loss=1135.335, v_rmse=33.695, v_r2=0.884; \n",
            "E 22\t: loss=619.923, rmse=24.898, r2=0.906; v_loss=1065.146, v_rmse=32.637, v_r2=0.891; \n",
            "E 23\t: loss=623.631, rmse=24.973, r2=0.905; v_loss=1103.660, v_rmse=33.221, v_r2=0.887; \n",
            "E 24\t: loss=577.475, rmse=24.031, r2=0.912; v_loss=912.997, v_rmse=30.216, v_r2=0.906; \n",
            "E 25\t: loss=563.981, rmse=23.748, r2=0.914; v_loss=1255.509, v_rmse=35.433, v_r2=0.871; \n",
            "E 26\t: loss=559.879, rmse=23.662, r2=0.915; v_loss=954.161, v_rmse=30.890, v_r2=0.902; \n",
            "E 27\t: loss=547.314, rmse=23.395, r2=0.917; v_loss=1036.804, v_rmse=32.199, v_r2=0.894; \n",
            "E 28\t: loss=551.605, rmse=23.486, r2=0.916; v_loss=1494.043, v_rmse=38.653, v_r2=0.847; \n",
            "E 29\t: loss=542.677, rmse=23.295, r2=0.917; v_loss=1193.291, v_rmse=34.544, v_r2=0.878; \n",
            "E 30\t: loss=581.548, rmse=24.115, r2=0.911; v_loss=1697.223, v_rmse=41.197, v_r2=0.826; \n",
            "E 31\t: loss=514.713, rmse=22.687, r2=0.922; v_loss=1320.660, v_rmse=36.341, v_r2=0.865; \n",
            "E 32\t: loss=481.631, rmse=21.946, r2=0.927; v_loss=932.242, v_rmse=30.533, v_r2=0.904; \n",
            "E 33\t: loss=438.617, rmse=20.943, r2=0.933; v_loss=1875.589, v_rmse=43.308, v_r2=0.808; \n",
            "E 34\t: loss=460.896, rmse=21.468, r2=0.930; v_loss=1640.628, v_rmse=40.505, v_r2=0.832; \n",
            "E 35\t: loss=417.923, rmse=20.443, r2=0.936; v_loss=1291.160, v_rmse=35.933, v_r2=0.868; \n",
            "E 36\t: loss=408.968, rmse=20.223, r2=0.938; v_loss=1679.954, v_rmse=40.987, v_r2=0.828; \n",
            "E 37\t: loss=379.783, rmse=19.488, r2=0.942; v_loss=1461.198, v_rmse=38.226, v_r2=0.850; \n",
            "E 38\t: loss=374.626, rmse=19.355, r2=0.943; v_loss=1331.157, v_rmse=36.485, v_r2=0.863; \n",
            "E 39\t: loss=384.806, rmse=19.616, r2=0.941; v_loss=1323.918, v_rmse=36.386, v_r2=0.864; \n",
            "E 40\t: loss=368.451, rmse=19.195, r2=0.944; v_loss=1287.835, v_rmse=35.886, v_r2=0.868; \n",
            "E 41\t: loss=348.429, rmse=18.666, r2=0.947; v_loss=1142.340, v_rmse=33.799, v_r2=0.883; \n",
            "E 42\t: loss=351.155, rmse=18.739, r2=0.947; v_loss=1595.579, v_rmse=39.945, v_r2=0.836; \n",
            "E 43\t: loss=385.982, rmse=19.646, r2=0.941; v_loss=1295.306, v_rmse=35.990, v_r2=0.867; \n",
            "E 44\t: loss=325.115, rmse=18.031, r2=0.950; v_loss=1333.806, v_rmse=36.521, v_r2=0.863; \n",
            "E 45\t: loss=342.857, rmse=18.516, r2=0.948; v_loss=1492.026, v_rmse=38.627, v_r2=0.847; \n",
            "E 46\t: loss=331.554, rmse=18.209, r2=0.950; v_loss=1878.185, v_rmse=43.338, v_r2=0.807; \n",
            "E 47\t: loss=328.540, rmse=18.126, r2=0.950; v_loss=1181.372, v_rmse=34.371, v_r2=0.879; \n",
            "E 48\t: loss=329.338, rmse=18.148, r2=0.950; v_loss=1665.736, v_rmse=40.813, v_r2=0.829; \n",
            "E 49\t: loss=321.895, rmse=17.941, r2=0.951; v_loss=1741.761, v_rmse=41.734, v_r2=0.821; \n",
            "E 50\t: loss=318.241, rmse=17.839, r2=0.952; v_loss=1273.453, v_rmse=35.685, v_r2=0.869; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=50, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__activation2='tanh', model__activation3='elu', model__dropout1=0.9, model...ayer3=154, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027DFB136B20>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027DFB136E50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__second_dense=False, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     seq_length=100)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ada9b4-12ab-435d-bc09-1b8dd0c32b3a",
        "id": "rqyVHO5n2lXK"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=-0.111,RMSE=-43.638\n",
            "Finished: 2022-11-03 08:20:58.048931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "DZEmsy2m2lXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.9399516883374335  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 491),\n",
        "             ('basemodel__epochs', 35),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.269131429819357),\n",
        "             ('basemodel__model__dropout2', 0.1000488406021388),\n",
        "             ('basemodel__model__dropout3', 0.3965483901301635),\n",
        "             ('basemodel__model__layer1', 311),\n",
        "             ('basemodel__model__layer2', 103),\n",
        "             ('basemodel__model__layer3', 397),\n",
        "             ('basemodel__model__learning_rate', 0.004499578015509351),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.3941085696997352),\n",
        "             ('clip_y', 104),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 97)\n",
        "```\n",
        "Modelo muito similar ao FD001 \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5340ZcMG2lXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=97\n",
        "CLIP=104\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=491,\n",
        "                           epochs=35,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.269131429819357, \n",
        "                           model__dropout2=0.1000488406021388,\n",
        "                           model__dropout3=0.3965483901301635, \n",
        "                           model__layer1=311, \n",
        "                           model__layer2=103, \n",
        "                           model__layer3=397, \n",
        "                           model__learning_rate=0.004499578015509351,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=False,\n",
        "                           validation_split=0.3941085696997352, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "njy3V5mz2lXL"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b88478e-28bd-4df5-fc43-c46bad1f3dce",
        "id": "0ZDq9Rf-2lXM"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_10 (Masking)        (None, 97, 22)            0         \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 97, 311)           415496    \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 97, 311)           0         \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 103)               170980    \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 103)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 397)               41288     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 397)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 398       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 628,162\n",
            "Trainable params: 628,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2330.005, rmse=48.270, r2=-0.910; v_loss=1402.501, v_rmse=37.450, v_r2=-0.091; \n",
            "E 2\t: loss=1281.520, rmse=35.798, r2=-0.051; v_loss=1405.480, v_rmse=37.490, v_r2=-0.093; \n",
            "E 3\t: loss=1244.097, rmse=35.272, r2=-0.020; v_loss=1316.822, v_rmse=36.288, v_r2=-0.024; \n",
            "E 4\t: loss=1238.760, rmse=35.196, r2=-0.016; v_loss=1308.344, v_rmse=36.171, v_r2=-0.017; \n",
            "E 5\t: loss=1190.458, rmse=34.503, r2=0.024; v_loss=1216.615, v_rmse=34.880, v_r2=0.054; \n",
            "E 6\t: loss=942.179, rmse=30.695, r2=0.227; v_loss=768.376, v_rmse=27.720, v_r2=0.402; \n",
            "E 7\t: loss=484.068, rmse=22.002, r2=0.603; v_loss=401.867, v_rmse=20.047, v_r2=0.687; \n",
            "E 8\t: loss=269.912, rmse=16.429, r2=0.779; v_loss=189.243, v_rmse=13.757, v_r2=0.853; \n",
            "E 9\t: loss=204.105, rmse=14.287, r2=0.833; v_loss=116.441, v_rmse=10.791, v_r2=0.909; \n",
            "E 10\t: loss=176.297, rmse=13.278, r2=0.855; v_loss=120.554, v_rmse=10.980, v_r2=0.906; \n",
            "E 11\t: loss=134.037, rmse=11.577, r2=0.890; v_loss=81.562, v_rmse=9.031, v_r2=0.937; \n",
            "E 12\t: loss=122.848, rmse=11.084, r2=0.899; v_loss=86.567, v_rmse=9.304, v_r2=0.933; \n",
            "E 13\t: loss=112.557, rmse=10.609, r2=0.908; v_loss=76.777, v_rmse=8.762, v_r2=0.940; \n",
            "E 14\t: loss=92.384, rmse=9.612, r2=0.924; v_loss=67.446, v_rmse=8.213, v_r2=0.948; \n",
            "E 15\t: loss=86.842, rmse=9.319, r2=0.929; v_loss=65.924, v_rmse=8.119, v_r2=0.949; \n",
            "E 16\t: loss=81.913, rmse=9.051, r2=0.933; v_loss=70.622, v_rmse=8.404, v_r2=0.945; \n",
            "E 17\t: loss=70.818, rmse=8.415, r2=0.942; v_loss=58.246, v_rmse=7.632, v_r2=0.955; \n",
            "E 18\t: loss=70.936, rmse=8.422, r2=0.942; v_loss=51.690, v_rmse=7.190, v_r2=0.960; \n",
            "E 19\t: loss=60.962, rmse=7.808, r2=0.950; v_loss=60.368, v_rmse=7.770, v_r2=0.953; \n",
            "E 20\t: loss=59.914, rmse=7.740, r2=0.951; v_loss=51.244, v_rmse=7.158, v_r2=0.960; \n",
            "E 21\t: loss=52.978, rmse=7.279, r2=0.957; v_loss=60.556, v_rmse=7.782, v_r2=0.953; \n",
            "E 22\t: loss=51.865, rmse=7.202, r2=0.957; v_loss=48.839, v_rmse=6.989, v_r2=0.962; \n",
            "E 23\t: loss=49.860, rmse=7.061, r2=0.959; v_loss=56.466, v_rmse=7.514, v_r2=0.956; \n",
            "E 24\t: loss=54.906, rmse=7.410, r2=0.955; v_loss=52.384, v_rmse=7.238, v_r2=0.959; \n",
            "E 25\t: loss=59.820, rmse=7.734, r2=0.951; v_loss=59.364, v_rmse=7.705, v_r2=0.954; \n",
            "E 26\t: loss=47.481, rmse=6.891, r2=0.961; v_loss=56.564, v_rmse=7.521, v_r2=0.956; \n",
            "E 27\t: loss=44.118, rmse=6.642, r2=0.964; v_loss=54.821, v_rmse=7.404, v_r2=0.957; \n",
            "E 28\t: loss=42.918, rmse=6.551, r2=0.965; v_loss=58.337, v_rmse=7.638, v_r2=0.955; \n",
            "E 29\t: loss=38.452, rmse=6.201, r2=0.968; v_loss=47.288, v_rmse=6.877, v_r2=0.963; \n",
            "E 30\t: loss=38.860, rmse=6.234, r2=0.968; v_loss=54.790, v_rmse=7.402, v_r2=0.957; \n",
            "E 31\t: loss=36.989, rmse=6.082, r2=0.970; v_loss=60.346, v_rmse=7.768, v_r2=0.953; \n",
            "E 32\t: loss=38.317, rmse=6.190, r2=0.969; v_loss=50.151, v_rmse=7.082, v_r2=0.961; \n",
            "E 33\t: loss=37.344, rmse=6.111, r2=0.969; v_loss=58.538, v_rmse=7.651, v_r2=0.954; \n",
            "E 34\t: loss=35.643, rmse=5.970, r2=0.971; v_loss=62.209, v_rmse=7.887, v_r2=0.952; \n",
            "E 35\t: loss=37.797, rmse=6.148, r2=0.969; v_loss=54.068, v_rmse=7.353, v_r2=0.958; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=491, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000027C44BBEEB0>, <keras.callbacks.LambdaCallback object at 0x0000027C44BF3D00>], epochs=35, model=<function create_model at 0x0000027C45591E50>, model__activation1='tanh', model__activation2='tanh', model__activation3='selu', model__dropout1=0.26913...578015509351, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000027DE0C5CD30>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000027DE0C5CE50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__second_dense=False, print_summary=True, validation_split=0.3941085696997352, verbose=0),\n",
              "                     clip_y=104, seq_length=97)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ef4db6-ae70-475b-8b15-5875d77d3648",
        "id": "GsrsS-Ga2lXO"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.913,RMSE=-9.882\n",
            "Finished: 2022-11-03 08:23:40.264104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbBSbz9TOag1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}