{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf",
        "nTPBH5fg_sFd"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO993tBIW5N+g7n+pqpUpB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD004_LSTMv2_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "05a801f5-4343-4600-e3ea-235d55024ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604e625a-61e9-45eb-9748-e826c86ea9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "id": "tlp572nXopEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad437aa3-3cb4-4c8a-8267-f04fb4ebc1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(4, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "id": "-yRYxz2hh4xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "a7a873ad-c3e2-4580-8923-c3b68f7f94b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time     op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1  42.0049  0.8400  100.0  445.00  549.68  1343.43   \n",
              "1                1     2  20.0020  0.7002  100.0  491.19  606.07  1477.61   \n",
              "2                1     3  42.0038  0.8409  100.0  445.00  548.95  1343.12   \n",
              "3                1     4  42.0000  0.8400  100.0  445.00  548.70  1341.24   \n",
              "4                1     5  25.0063  0.6207   60.0  462.54  536.10  1255.23   \n",
              "...            ...   ...      ...     ...    ...     ...     ...      ...   \n",
              "61244          249   251   9.9998  0.2500  100.0  489.05  605.33  1516.36   \n",
              "61245          249   252   0.0028  0.0015  100.0  518.67  643.42  1598.92   \n",
              "61246          249   253   0.0029  0.0000  100.0  518.67  643.68  1607.72   \n",
              "61247          249   254  35.0046  0.8400  100.0  449.44  555.77  1381.29   \n",
              "61248          249   255  42.0030  0.8400  100.0  445.00  549.85  1369.75   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13     s_14  s_15  s_16  \\\n",
              "0      1112.93   3.91  ...  129.78  2387.99  8074.83   9.3335  0.02   330   \n",
              "1      1237.50   9.35  ...  312.59  2387.73  8046.13   9.1913  0.02   361   \n",
              "2      1117.05   3.91  ...  129.62  2387.97  8066.62   9.4007  0.02   329   \n",
              "3      1118.03   3.91  ...  129.80  2388.02  8076.05   9.3369  0.02   328   \n",
              "4      1033.59   7.05  ...  164.11  2028.08  7865.80  10.8366  0.02   305   \n",
              "...        ...    ...  ...     ...      ...      ...      ...   ...   ...   \n",
              "61244  1315.28  10.52  ...  380.16  2388.73  8185.69   8.4541  0.03   372   \n",
              "61245  1426.77  14.62  ...  535.02  2388.46  8185.47   8.2221  0.03   396   \n",
              "61246  1430.56  14.62  ...  535.41  2388.48  8193.94   8.2525  0.03   395   \n",
              "61247  1148.18   5.48  ...  187.92  2388.83  8125.64   9.0515  0.02   337   \n",
              "61248  1147.45   3.91  ...  134.32  2388.66  8144.33   9.1207  0.02   333   \n",
              "\n",
              "       s_17    s_18   s_19     s_20  \n",
              "0      2212  100.00  10.62   6.3670  \n",
              "1      2324  100.00  24.37  14.6552  \n",
              "2      2212  100.00  10.48   6.4213  \n",
              "3      2212  100.00  10.54   6.4176  \n",
              "4      1915   84.93  14.03   8.6754  \n",
              "...     ...     ...    ...      ...  \n",
              "61244  2319  100.00  29.11  17.5234  \n",
              "61245  2388  100.00  39.38  23.7151  \n",
              "61246  2388  100.00  39.78  23.8270  \n",
              "61247  2223  100.00  15.26   9.0774  \n",
              "61248  2212  100.00  10.66   6.4341  \n",
              "\n",
              "[61249 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42.0049</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.68</td>\n",
              "      <td>1343.43</td>\n",
              "      <td>1112.93</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>129.78</td>\n",
              "      <td>2387.99</td>\n",
              "      <td>8074.83</td>\n",
              "      <td>9.3335</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.62</td>\n",
              "      <td>6.3670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0020</td>\n",
              "      <td>0.7002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>606.07</td>\n",
              "      <td>1477.61</td>\n",
              "      <td>1237.50</td>\n",
              "      <td>9.35</td>\n",
              "      <td>...</td>\n",
              "      <td>312.59</td>\n",
              "      <td>2387.73</td>\n",
              "      <td>8046.13</td>\n",
              "      <td>9.1913</td>\n",
              "      <td>0.02</td>\n",
              "      <td>361</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.00</td>\n",
              "      <td>24.37</td>\n",
              "      <td>14.6552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>42.0038</td>\n",
              "      <td>0.8409</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>548.95</td>\n",
              "      <td>1343.12</td>\n",
              "      <td>1117.05</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>129.62</td>\n",
              "      <td>2387.97</td>\n",
              "      <td>8066.62</td>\n",
              "      <td>9.4007</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.48</td>\n",
              "      <td>6.4213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>42.0000</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>548.70</td>\n",
              "      <td>1341.24</td>\n",
              "      <td>1118.03</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>129.80</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8076.05</td>\n",
              "      <td>9.3369</td>\n",
              "      <td>0.02</td>\n",
              "      <td>328</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.54</td>\n",
              "      <td>6.4176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>25.0063</td>\n",
              "      <td>0.6207</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>536.10</td>\n",
              "      <td>1255.23</td>\n",
              "      <td>1033.59</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.11</td>\n",
              "      <td>2028.08</td>\n",
              "      <td>7865.80</td>\n",
              "      <td>10.8366</td>\n",
              "      <td>0.02</td>\n",
              "      <td>305</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.03</td>\n",
              "      <td>8.6754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61244</th>\n",
              "      <td>249</td>\n",
              "      <td>251</td>\n",
              "      <td>9.9998</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.33</td>\n",
              "      <td>1516.36</td>\n",
              "      <td>1315.28</td>\n",
              "      <td>10.52</td>\n",
              "      <td>...</td>\n",
              "      <td>380.16</td>\n",
              "      <td>2388.73</td>\n",
              "      <td>8185.69</td>\n",
              "      <td>8.4541</td>\n",
              "      <td>0.03</td>\n",
              "      <td>372</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.00</td>\n",
              "      <td>29.11</td>\n",
              "      <td>17.5234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61245</th>\n",
              "      <td>249</td>\n",
              "      <td>252</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1598.92</td>\n",
              "      <td>1426.77</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>535.02</td>\n",
              "      <td>2388.46</td>\n",
              "      <td>8185.47</td>\n",
              "      <td>8.2221</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.00</td>\n",
              "      <td>39.38</td>\n",
              "      <td>23.7151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61246</th>\n",
              "      <td>249</td>\n",
              "      <td>253</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.68</td>\n",
              "      <td>1607.72</td>\n",
              "      <td>1430.56</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>535.41</td>\n",
              "      <td>2388.48</td>\n",
              "      <td>8193.94</td>\n",
              "      <td>8.2525</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.00</td>\n",
              "      <td>39.78</td>\n",
              "      <td>23.8270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61247</th>\n",
              "      <td>249</td>\n",
              "      <td>254</td>\n",
              "      <td>35.0046</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.77</td>\n",
              "      <td>1381.29</td>\n",
              "      <td>1148.18</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>187.92</td>\n",
              "      <td>2388.83</td>\n",
              "      <td>8125.64</td>\n",
              "      <td>9.0515</td>\n",
              "      <td>0.02</td>\n",
              "      <td>337</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>15.26</td>\n",
              "      <td>9.0774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61248</th>\n",
              "      <td>249</td>\n",
              "      <td>255</td>\n",
              "      <td>42.0030</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.85</td>\n",
              "      <td>1369.75</td>\n",
              "      <td>1147.45</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>134.32</td>\n",
              "      <td>2388.66</td>\n",
              "      <td>8144.33</td>\n",
              "      <td>9.1207</td>\n",
              "      <td>0.02</td>\n",
              "      <td>333</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.66</td>\n",
              "      <td>6.4341</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61249 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "4wtvRNsfuUwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4063ab49-ab53-4932-824f-666c197b8847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((41214, 26), (248, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test_keep_setting(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "id": "onw4pCwZy-1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "e68d1f74-467e-41fd-aaf0-460f79a95228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3   s_4   s_5  \\\n",
              "0  25.0070  0.6214   60.0  462.54  537.66  1264.31  1046.41  7.05  8.99   \n",
              "1  41.9989  0.8400  100.0  445.00  549.96  1354.05  1133.55  3.91  5.72   \n",
              "2  42.0005  0.8401  100.0  445.00  549.47  1341.06  1118.90  3.91  5.69   \n",
              "3  25.0018  0.6207   60.0  462.54  536.06  1253.49  1038.53  7.05  9.00   \n",
              "4  25.0039  0.6200   60.0  462.54  537.36  1263.60  1052.52  7.05  9.03   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13     s_14  s_15  s_16  s_17    s_18  \\\n",
              "0  176.56  ...  166.19  2028.53  7890.31  10.7615  0.02   308  1915   84.93   \n",
              "1  139.03  ...  130.17  2387.72  8073.44   9.3925  0.02   331  2212  100.00   \n",
              "2  139.26  ...  130.73  2388.18  8095.58   9.2974  0.02   330  2212  100.00   \n",
              "3  175.63  ...  164.91  2028.30  7878.63  10.8396  0.02   306  1915   84.93   \n",
              "4  175.53  ...  164.95  2028.24  7873.75  10.9094  0.02   307  1915   84.93   \n",
              "\n",
              "    s_19    s_20  \n",
              "0  14.41  8.6329  \n",
              "1  10.58  6.4325  \n",
              "2  10.61  6.3488  \n",
              "3  14.41  8.5696  \n",
              "4  14.19  8.6248  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25.0070</td>\n",
              "      <td>0.6214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.66</td>\n",
              "      <td>1264.31</td>\n",
              "      <td>1046.41</td>\n",
              "      <td>7.05</td>\n",
              "      <td>8.99</td>\n",
              "      <td>176.56</td>\n",
              "      <td>...</td>\n",
              "      <td>166.19</td>\n",
              "      <td>2028.53</td>\n",
              "      <td>7890.31</td>\n",
              "      <td>10.7615</td>\n",
              "      <td>0.02</td>\n",
              "      <td>308</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.41</td>\n",
              "      <td>8.6329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.9989</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.96</td>\n",
              "      <td>1354.05</td>\n",
              "      <td>1133.55</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.72</td>\n",
              "      <td>139.03</td>\n",
              "      <td>...</td>\n",
              "      <td>130.17</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8073.44</td>\n",
              "      <td>9.3925</td>\n",
              "      <td>0.02</td>\n",
              "      <td>331</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.58</td>\n",
              "      <td>6.4325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42.0005</td>\n",
              "      <td>0.8401</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.47</td>\n",
              "      <td>1341.06</td>\n",
              "      <td>1118.90</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.69</td>\n",
              "      <td>139.26</td>\n",
              "      <td>...</td>\n",
              "      <td>130.73</td>\n",
              "      <td>2388.18</td>\n",
              "      <td>8095.58</td>\n",
              "      <td>9.2974</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.61</td>\n",
              "      <td>6.3488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0018</td>\n",
              "      <td>0.6207</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>536.06</td>\n",
              "      <td>1253.49</td>\n",
              "      <td>1038.53</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.00</td>\n",
              "      <td>175.63</td>\n",
              "      <td>...</td>\n",
              "      <td>164.91</td>\n",
              "      <td>2028.30</td>\n",
              "      <td>7878.63</td>\n",
              "      <td>10.8396</td>\n",
              "      <td>0.02</td>\n",
              "      <td>306</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.41</td>\n",
              "      <td>8.5696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.0039</td>\n",
              "      <td>0.6200</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.36</td>\n",
              "      <td>1263.60</td>\n",
              "      <td>1052.52</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.03</td>\n",
              "      <td>175.53</td>\n",
              "      <td>...</td>\n",
              "      <td>164.95</td>\n",
              "      <td>2028.24</td>\n",
              "      <td>7873.75</td>\n",
              "      <td>10.9094</td>\n",
              "      <td>0.02</td>\n",
              "      <td>307</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.19</td>\n",
              "      <td>8.6248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "id": "lmFKjQaeip1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "6350adfd-6d65-4dfd-be11-27b4bf347bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  320\n",
              "1            1     2  319\n",
              "2            1     3  318\n",
              "3            1     4  317\n",
              "4            1     5  316"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide_with_settings(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "fuAnHn4GxzwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "79fc59da-260b-421f-f576-c69d99380239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  320\n",
              "1  319\n",
              "2  318\n",
              "3  317\n",
              "4  316"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "26hK4VWkx1R7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "19c5001f-c16b-4374-babf-839eb851344a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3   s_4    s_5  \\\n",
              "0  42.0049  0.8400  100.0  445.00  549.68  1343.43  1112.93  3.91   5.70   \n",
              "1  20.0020  0.7002  100.0  491.19  606.07  1477.61  1237.50  9.35  13.61   \n",
              "2  42.0038  0.8409  100.0  445.00  548.95  1343.12  1117.05  3.91   5.69   \n",
              "3  42.0000  0.8400  100.0  445.00  548.70  1341.24  1118.03  3.91   5.70   \n",
              "4  25.0063  0.6207   60.0  462.54  536.10  1255.23  1033.59  7.05   9.00   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13     s_14  s_15  s_16  s_17    s_18  \\\n",
              "0  137.36  ...  129.78  2387.99  8074.83   9.3335  0.02   330  2212  100.00   \n",
              "1  332.10  ...  312.59  2387.73  8046.13   9.1913  0.02   361  2324  100.00   \n",
              "2  138.18  ...  129.62  2387.97  8066.62   9.4007  0.02   329  2212  100.00   \n",
              "3  137.98  ...  129.80  2388.02  8076.05   9.3369  0.02   328  2212  100.00   \n",
              "4  174.82  ...  164.11  2028.08  7865.80  10.8366  0.02   305  1915   84.93   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  10.62   6.3670  \n",
              "1  24.37  14.6552  \n",
              "2  10.48   6.4213  \n",
              "3  10.54   6.4176  \n",
              "4  14.03   8.6754  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42.0049</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.68</td>\n",
              "      <td>1343.43</td>\n",
              "      <td>1112.93</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.70</td>\n",
              "      <td>137.36</td>\n",
              "      <td>...</td>\n",
              "      <td>129.78</td>\n",
              "      <td>2387.99</td>\n",
              "      <td>8074.83</td>\n",
              "      <td>9.3335</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.62</td>\n",
              "      <td>6.3670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.0020</td>\n",
              "      <td>0.7002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>606.07</td>\n",
              "      <td>1477.61</td>\n",
              "      <td>1237.50</td>\n",
              "      <td>9.35</td>\n",
              "      <td>13.61</td>\n",
              "      <td>332.10</td>\n",
              "      <td>...</td>\n",
              "      <td>312.59</td>\n",
              "      <td>2387.73</td>\n",
              "      <td>8046.13</td>\n",
              "      <td>9.1913</td>\n",
              "      <td>0.02</td>\n",
              "      <td>361</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.00</td>\n",
              "      <td>24.37</td>\n",
              "      <td>14.6552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42.0038</td>\n",
              "      <td>0.8409</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>548.95</td>\n",
              "      <td>1343.12</td>\n",
              "      <td>1117.05</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.69</td>\n",
              "      <td>138.18</td>\n",
              "      <td>...</td>\n",
              "      <td>129.62</td>\n",
              "      <td>2387.97</td>\n",
              "      <td>8066.62</td>\n",
              "      <td>9.4007</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.48</td>\n",
              "      <td>6.4213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0000</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>548.70</td>\n",
              "      <td>1341.24</td>\n",
              "      <td>1118.03</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.70</td>\n",
              "      <td>137.98</td>\n",
              "      <td>...</td>\n",
              "      <td>129.80</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8076.05</td>\n",
              "      <td>9.3369</td>\n",
              "      <td>0.02</td>\n",
              "      <td>328</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.54</td>\n",
              "      <td>6.4176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.0063</td>\n",
              "      <td>0.6207</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>536.10</td>\n",
              "      <td>1255.23</td>\n",
              "      <td>1033.59</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.00</td>\n",
              "      <td>174.82</td>\n",
              "      <td>...</td>\n",
              "      <td>164.11</td>\n",
              "      <td>2028.08</td>\n",
              "      <td>7865.80</td>\n",
              "      <td>10.8366</td>\n",
              "      <td>0.02</td>\n",
              "      <td>305</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.03</td>\n",
              "      <td>8.6754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "fploO3cFt7bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=126\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                        #    model__activation2='tanh',\n",
        "                        #    model__dropout2=0.30649418903936865,\n",
        "                           model__layer3=64,\n",
        "                        #    model__activation3='tanh',\n",
        "                        #    model__dropout3=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__second_dense=False,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "YRpXOCjNt7bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h LSTM-1\n",
        "# ~1h30min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"basemodel__model__second_dense\": Categorical([False]),\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"clip_y\": Integer(80,140),\n",
        "        \"include_settings\": Categorical([True]),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        # \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__activation2\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer3\": Integer(16,512),\n",
        "        \"basemodel__model__activation3\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "naisjMVZt7bK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af890de4-ad41-4851-efae-0c9c396398be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=299, basemodel__epochs=16, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.37832769831882285, basemodel__model__dropout2=0.8784755823880607, basemodel__model__dropout3=0.21777529496509485, basemodel__model__layer1=239, basemodel__model__layer2=96, basemodel__model__layer3=51, basemodel__model__learning_rate=0.003135288398552595, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.47249195402621447, clip_y=135, include_settings=True, scaler=StandardScaler(), seq_length=31;, score=-0.003 total time=  53.8s\n",
            "[CV 2/3] END basemodel__batch_size=299, basemodel__epochs=16, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.37832769831882285, basemodel__model__dropout2=0.8784755823880607, basemodel__model__dropout3=0.21777529496509485, basemodel__model__layer1=239, basemodel__model__layer2=96, basemodel__model__layer3=51, basemodel__model__learning_rate=0.003135288398552595, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.47249195402621447, clip_y=135, include_settings=True, scaler=StandardScaler(), seq_length=31;, score=-0.001 total time=  54.4s\n",
            "[CV 3/3] END basemodel__batch_size=299, basemodel__epochs=16, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.37832769831882285, basemodel__model__dropout2=0.8784755823880607, basemodel__model__dropout3=0.21777529496509485, basemodel__model__layer1=239, basemodel__model__layer2=96, basemodel__model__layer3=51, basemodel__model__learning_rate=0.003135288398552595, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.47249195402621447, clip_y=135, include_settings=True, scaler=StandardScaler(), seq_length=31;, score=-0.005 total time=  53.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=481, basemodel__epochs=3, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3709423183013928, basemodel__model__dropout2=0.44418411661841695, basemodel__model__dropout3=0.6181959068948448, basemodel__model__layer1=504, basemodel__model__layer2=147, basemodel__model__layer3=469, basemodel__model__learning_rate=0.0009567274616267933, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.18558967018547545, clip_y=109, include_settings=True, scaler=MinMaxScaler(), seq_length=39;, score=-0.133 total time=  37.9s\n",
            "[CV 2/3] END basemodel__batch_size=481, basemodel__epochs=3, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3709423183013928, basemodel__model__dropout2=0.44418411661841695, basemodel__model__dropout3=0.6181959068948448, basemodel__model__layer1=504, basemodel__model__layer2=147, basemodel__model__layer3=469, basemodel__model__learning_rate=0.0009567274616267933, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.18558967018547545, clip_y=109, include_settings=True, scaler=MinMaxScaler(), seq_length=39;, score=-0.049 total time=  36.6s\n",
            "[CV 3/3] END basemodel__batch_size=481, basemodel__epochs=3, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3709423183013928, basemodel__model__dropout2=0.44418411661841695, basemodel__model__dropout3=0.6181959068948448, basemodel__model__layer1=504, basemodel__model__layer2=147, basemodel__model__layer3=469, basemodel__model__learning_rate=0.0009567274616267933, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.18558967018547545, clip_y=109, include_settings=True, scaler=MinMaxScaler(), seq_length=39;, score=-0.171 total time=  35.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=92, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.7903807955649162, basemodel__model__dropout2=0.689528272166372, basemodel__model__dropout3=0.5162072844576362, basemodel__model__layer1=31, basemodel__model__layer2=39, basemodel__model__layer3=355, basemodel__model__learning_rate=0.004515837368380366, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4543675516613077, clip_y=119, include_settings=True, scaler=MinMaxScaler(), seq_length=95;, score=0.102 total time= 1.2min\n",
            "[CV 2/3] END basemodel__batch_size=92, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.7903807955649162, basemodel__model__dropout2=0.689528272166372, basemodel__model__dropout3=0.5162072844576362, basemodel__model__layer1=31, basemodel__model__layer2=39, basemodel__model__layer3=355, basemodel__model__learning_rate=0.004515837368380366, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4543675516613077, clip_y=119, include_settings=True, scaler=MinMaxScaler(), seq_length=95;, score=0.093 total time= 1.2min\n",
            "[CV 3/3] END basemodel__batch_size=92, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.7903807955649162, basemodel__model__dropout2=0.689528272166372, basemodel__model__dropout3=0.5162072844576362, basemodel__model__layer1=31, basemodel__model__layer2=39, basemodel__model__layer3=355, basemodel__model__learning_rate=0.004515837368380366, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4543675516613077, clip_y=119, include_settings=True, scaler=MinMaxScaler(), seq_length=95;, score=0.080 total time= 1.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=257, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8318172035354746, basemodel__model__dropout2=0.8388053822325453, basemodel__model__dropout3=0.8011653204076767, basemodel__model__layer1=75, basemodel__model__layer2=290, basemodel__model__layer3=231, basemodel__model__learning_rate=0.006014183300430866, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7604644376731784, clip_y=110, include_settings=True, scaler=MinMaxScaler(), seq_length=65;, score=-0.000 total time=  48.8s\n",
            "[CV 2/3] END basemodel__batch_size=257, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8318172035354746, basemodel__model__dropout2=0.8388053822325453, basemodel__model__dropout3=0.8011653204076767, basemodel__model__layer1=75, basemodel__model__layer2=290, basemodel__model__layer3=231, basemodel__model__learning_rate=0.006014183300430866, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7604644376731784, clip_y=110, include_settings=True, scaler=MinMaxScaler(), seq_length=65;, score=-0.001 total time=  53.9s\n",
            "[CV 3/3] END basemodel__batch_size=257, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8318172035354746, basemodel__model__dropout2=0.8388053822325453, basemodel__model__dropout3=0.8011653204076767, basemodel__model__layer1=75, basemodel__model__layer2=290, basemodel__model__layer3=231, basemodel__model__learning_rate=0.006014183300430866, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7604644376731784, clip_y=110, include_settings=True, scaler=MinMaxScaler(), seq_length=65;, score=-0.001 total time=  47.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=482, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5757580762336759, basemodel__model__dropout2=0.6260066324927563, basemodel__model__dropout3=0.6152200950802891, basemodel__model__layer1=383, basemodel__model__layer2=62, basemodel__model__layer3=268, basemodel__model__learning_rate=0.005548371479876849, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8151563678732943, clip_y=96, include_settings=True, scaler=MinMaxScaler(), seq_length=77;, score=0.062 total time= 1.3min\n",
            "[CV 2/3] END basemodel__batch_size=482, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5757580762336759, basemodel__model__dropout2=0.6260066324927563, basemodel__model__dropout3=0.6152200950802891, basemodel__model__layer1=383, basemodel__model__layer2=62, basemodel__model__layer3=268, basemodel__model__learning_rate=0.005548371479876849, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8151563678732943, clip_y=96, include_settings=True, scaler=MinMaxScaler(), seq_length=77;, score=0.116 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=482, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5757580762336759, basemodel__model__dropout2=0.6260066324927563, basemodel__model__dropout3=0.6152200950802891, basemodel__model__layer1=383, basemodel__model__layer2=62, basemodel__model__layer3=268, basemodel__model__learning_rate=0.005548371479876849, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8151563678732943, clip_y=96, include_settings=True, scaler=MinMaxScaler(), seq_length=77;, score=0.117 total time= 1.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=275, basemodel__epochs=5, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6991252193382531, basemodel__model__dropout2=0.3854876951689282, basemodel__model__dropout3=0.7172326762751793, basemodel__model__layer1=177, basemodel__model__layer2=390, basemodel__model__layer3=329, basemodel__model__learning_rate=0.0055662629020329785, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.26865464803687683, clip_y=117, include_settings=True, scaler=MinMaxScaler(), seq_length=78;, score=-0.000 total time=  54.0s\n",
            "[CV 2/3] END basemodel__batch_size=275, basemodel__epochs=5, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6991252193382531, basemodel__model__dropout2=0.3854876951689282, basemodel__model__dropout3=0.7172326762751793, basemodel__model__layer1=177, basemodel__model__layer2=390, basemodel__model__layer3=329, basemodel__model__learning_rate=0.0055662629020329785, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.26865464803687683, clip_y=117, include_settings=True, scaler=MinMaxScaler(), seq_length=78;, score=-0.000 total time=  54.2s\n",
            "[CV 3/3] END basemodel__batch_size=275, basemodel__epochs=5, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6991252193382531, basemodel__model__dropout2=0.3854876951689282, basemodel__model__dropout3=0.7172326762751793, basemodel__model__layer1=177, basemodel__model__layer2=390, basemodel__model__layer3=329, basemodel__model__learning_rate=0.0055662629020329785, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.26865464803687683, clip_y=117, include_settings=True, scaler=MinMaxScaler(), seq_length=78;, score=-0.000 total time=  53.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=410, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8925827115782611, basemodel__model__dropout2=0.3527050836130422, basemodel__model__dropout3=0.8306015861136743, basemodel__model__layer1=404, basemodel__model__layer2=97, basemodel__model__layer3=426, basemodel__model__learning_rate=0.007565109150145261, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3765301552092959, clip_y=132, include_settings=True, scaler=StandardScaler(), seq_length=97;, score=0.308 total time= 3.5min\n",
            "[CV 2/3] END basemodel__batch_size=410, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8925827115782611, basemodel__model__dropout2=0.3527050836130422, basemodel__model__dropout3=0.8306015861136743, basemodel__model__layer1=404, basemodel__model__layer2=97, basemodel__model__layer3=426, basemodel__model__learning_rate=0.007565109150145261, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3765301552092959, clip_y=132, include_settings=True, scaler=StandardScaler(), seq_length=97;, score=0.046 total time= 3.6min\n",
            "[CV 3/3] END basemodel__batch_size=410, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8925827115782611, basemodel__model__dropout2=0.3527050836130422, basemodel__model__dropout3=0.8306015861136743, basemodel__model__layer1=404, basemodel__model__layer2=97, basemodel__model__layer3=426, basemodel__model__learning_rate=0.007565109150145261, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3765301552092959, clip_y=132, include_settings=True, scaler=StandardScaler(), seq_length=97;, score=0.213 total time= 3.6min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=276, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2396724507596764, basemodel__model__dropout2=0.7299552131247278, basemodel__model__dropout3=0.45026593871897413, basemodel__model__layer1=194, basemodel__model__layer2=452, basemodel__model__layer3=292, basemodel__model__learning_rate=0.00419788526933878, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6621551008966282, clip_y=127, include_settings=True, scaler=MinMaxScaler(), seq_length=58;, score=0.264 total time= 1.3min\n",
            "[CV 2/3] END basemodel__batch_size=276, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2396724507596764, basemodel__model__dropout2=0.7299552131247278, basemodel__model__dropout3=0.45026593871897413, basemodel__model__layer1=194, basemodel__model__layer2=452, basemodel__model__layer3=292, basemodel__model__learning_rate=0.00419788526933878, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6621551008966282, clip_y=127, include_settings=True, scaler=MinMaxScaler(), seq_length=58;, score=0.246 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=276, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2396724507596764, basemodel__model__dropout2=0.7299552131247278, basemodel__model__dropout3=0.45026593871897413, basemodel__model__layer1=194, basemodel__model__layer2=452, basemodel__model__layer3=292, basemodel__model__learning_rate=0.00419788526933878, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6621551008966282, clip_y=127, include_settings=True, scaler=MinMaxScaler(), seq_length=58;, score=0.142 total time= 1.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=378, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7735010623895663, basemodel__model__dropout2=0.41813635051819165, basemodel__model__dropout3=0.18218523668258862, basemodel__model__layer1=440, basemodel__model__layer2=208, basemodel__model__layer3=220, basemodel__model__learning_rate=0.002759297044830844, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5099933703366253, clip_y=115, include_settings=True, scaler=StandardScaler(), seq_length=48;, score=0.693 total time= 3.6min\n",
            "[CV 2/3] END basemodel__batch_size=378, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7735010623895663, basemodel__model__dropout2=0.41813635051819165, basemodel__model__dropout3=0.18218523668258862, basemodel__model__layer1=440, basemodel__model__layer2=208, basemodel__model__layer3=220, basemodel__model__learning_rate=0.002759297044830844, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5099933703366253, clip_y=115, include_settings=True, scaler=StandardScaler(), seq_length=48;, score=0.594 total time= 3.6min\n",
            "[CV 3/3] END basemodel__batch_size=378, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7735010623895663, basemodel__model__dropout2=0.41813635051819165, basemodel__model__dropout3=0.18218523668258862, basemodel__model__layer1=440, basemodel__model__layer2=208, basemodel__model__layer3=220, basemodel__model__learning_rate=0.002759297044830844, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5099933703366253, clip_y=115, include_settings=True, scaler=StandardScaler(), seq_length=48;, score=0.698 total time= 3.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=170, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.8553353180616096, basemodel__model__dropout2=0.8022471799355578, basemodel__model__dropout3=0.7388322004854679, basemodel__model__layer1=114, basemodel__model__layer2=424, basemodel__model__layer3=77, basemodel__model__learning_rate=0.006428350335475116, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5682574978432375, clip_y=107, include_settings=True, scaler=StandardScaler(), seq_length=63;, score=0.432 total time= 2.7min\n",
            "[CV 2/3] END basemodel__batch_size=170, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.8553353180616096, basemodel__model__dropout2=0.8022471799355578, basemodel__model__dropout3=0.7388322004854679, basemodel__model__layer1=114, basemodel__model__layer2=424, basemodel__model__layer3=77, basemodel__model__learning_rate=0.006428350335475116, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5682574978432375, clip_y=107, include_settings=True, scaler=StandardScaler(), seq_length=63;, score=0.097 total time= 2.7min\n",
            "[CV 3/3] END basemodel__batch_size=170, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.8553353180616096, basemodel__model__dropout2=0.8022471799355578, basemodel__model__dropout3=0.7388322004854679, basemodel__model__layer1=114, basemodel__model__layer2=424, basemodel__model__layer3=77, basemodel__model__learning_rate=0.006428350335475116, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5682574978432375, clip_y=107, include_settings=True, scaler=StandardScaler(), seq_length=63;, score=0.311 total time= 2.8min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=36, basemodel__epochs=10, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.38836953255059237, basemodel__model__dropout2=0.20048453541453592, basemodel__model__dropout3=0.1, basemodel__model__layer1=238, basemodel__model__layer2=493, basemodel__model__layer3=469, basemodel__model__learning_rate=0.009788656262526537, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8582929008037821, clip_y=84, include_settings=True, scaler=StandardScaler(), seq_length=50;, score=0.152 total time= 2.5min\n",
            "[CV 2/3] END basemodel__batch_size=36, basemodel__epochs=10, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.38836953255059237, basemodel__model__dropout2=0.20048453541453592, basemodel__model__dropout3=0.1, basemodel__model__layer1=238, basemodel__model__layer2=493, basemodel__model__layer3=469, basemodel__model__learning_rate=0.009788656262526537, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8582929008037821, clip_y=84, include_settings=True, scaler=StandardScaler(), seq_length=50;, score=0.207 total time= 2.4min\n",
            "[CV 3/3] END basemodel__batch_size=36, basemodel__epochs=10, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.38836953255059237, basemodel__model__dropout2=0.20048453541453592, basemodel__model__dropout3=0.1, basemodel__model__layer1=238, basemodel__model__layer2=493, basemodel__model__layer3=469, basemodel__model__learning_rate=0.009788656262526537, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8582929008037821, clip_y=84, include_settings=True, scaler=StandardScaler(), seq_length=50;, score=0.181 total time= 2.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=426, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7309270280568189, basemodel__model__dropout2=0.29799541143425723, basemodel__model__dropout3=0.3102143063520742, basemodel__model__layer1=364, basemodel__model__layer2=122, basemodel__model__layer3=383, basemodel__model__learning_rate=0.0010631385889558885, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=115, include_settings=True, scaler=StandardScaler(), seq_length=91;, score=0.454 total time= 4.5min\n",
            "[CV 2/3] END basemodel__batch_size=426, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7309270280568189, basemodel__model__dropout2=0.29799541143425723, basemodel__model__dropout3=0.3102143063520742, basemodel__model__layer1=364, basemodel__model__layer2=122, basemodel__model__layer3=383, basemodel__model__learning_rate=0.0010631385889558885, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=115, include_settings=True, scaler=StandardScaler(), seq_length=91;, score=0.320 total time= 4.5min\n",
            "[CV 3/3] END basemodel__batch_size=426, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7309270280568189, basemodel__model__dropout2=0.29799541143425723, basemodel__model__dropout3=0.3102143063520742, basemodel__model__layer1=364, basemodel__model__layer2=122, basemodel__model__layer3=383, basemodel__model__learning_rate=0.0010631385889558885, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=115, include_settings=True, scaler=StandardScaler(), seq_length=91;, score=0.458 total time= 4.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=117, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.36610246525166745, basemodel__model__dropout3=0.1, basemodel__model__layer1=292, basemodel__model__layer2=271, basemodel__model__layer3=208, basemodel__model__learning_rate=0.0014855422958726728, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=91;, score=0.363 total time=10.5min\n",
            "[CV 2/3] END basemodel__batch_size=117, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.36610246525166745, basemodel__model__dropout3=0.1, basemodel__model__layer1=292, basemodel__model__layer2=271, basemodel__model__layer3=208, basemodel__model__learning_rate=0.0014855422958726728, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=91;, score=0.409 total time=10.4min\n",
            "[CV 3/3] END basemodel__batch_size=117, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.36610246525166745, basemodel__model__dropout3=0.1, basemodel__model__layer1=292, basemodel__model__layer2=271, basemodel__model__layer3=208, basemodel__model__learning_rate=0.0014855422958726728, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=91;, score=0.389 total time=10.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=447, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7609010226767635, basemodel__model__dropout2=0.8102059694113566, basemodel__model__dropout3=0.5876117824491284, basemodel__model__layer1=419, basemodel__model__layer2=175, basemodel__model__layer3=474, basemodel__model__learning_rate=0.006686829336534332, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.30693320000391233, clip_y=130, include_settings=True, scaler=StandardScaler(), seq_length=32;, score=0.588 total time= 4.1min\n",
            "[CV 2/3] END basemodel__batch_size=447, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7609010226767635, basemodel__model__dropout2=0.8102059694113566, basemodel__model__dropout3=0.5876117824491284, basemodel__model__layer1=419, basemodel__model__layer2=175, basemodel__model__layer3=474, basemodel__model__learning_rate=0.006686829336534332, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.30693320000391233, clip_y=130, include_settings=True, scaler=StandardScaler(), seq_length=32;, score=0.461 total time= 3.6min\n",
            "[CV 3/3] END basemodel__batch_size=447, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7609010226767635, basemodel__model__dropout2=0.8102059694113566, basemodel__model__dropout3=0.5876117824491284, basemodel__model__layer1=419, basemodel__model__layer2=175, basemodel__model__layer3=474, basemodel__model__learning_rate=0.006686829336534332, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.30693320000391233, clip_y=130, include_settings=True, scaler=StandardScaler(), seq_length=32;, score=0.541 total time= 4.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=382, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8318368146326681, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=512, basemodel__model__layer2=210, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.849479592819691, clip_y=109, include_settings=True, scaler=StandardScaler(), seq_length=79;, score=-1.297 total time= 4.1min\n",
            "[CV 2/3] END basemodel__batch_size=382, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8318368146326681, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=512, basemodel__model__layer2=210, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.849479592819691, clip_y=109, include_settings=True, scaler=StandardScaler(), seq_length=79;, score=-1.332 total time= 4.1min\n",
            "[CV 3/3] END basemodel__batch_size=382, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8318368146326681, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=512, basemodel__model__layer2=210, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.849479592819691, clip_y=109, include_settings=True, scaler=StandardScaler(), seq_length=79;, score=-0.280 total time= 4.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=371, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.7955738984424251, basemodel__model__layer1=512, basemodel__model__layer2=212, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.35348149448725497, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=54;, score=0.235 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=371, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.7955738984424251, basemodel__model__layer1=512, basemodel__model__layer2=212, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.35348149448725497, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=54;, score=0.337 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=371, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.7955738984424251, basemodel__model__layer1=512, basemodel__model__layer2=212, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.35348149448725497, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=54;, score=0.232 total time= 1.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=450, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8145333249976955, basemodel__model__dropout2=0.4289024842480126, basemodel__model__dropout3=0.1, basemodel__model__layer1=496, basemodel__model__layer2=168, basemodel__model__layer3=254, basemodel__model__learning_rate=0.003118118507191013, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.49238676803302384, clip_y=120, include_settings=True, scaler=StandardScaler(), seq_length=42;, score=0.731 total time= 4.1min\n",
            "[CV 2/3] END basemodel__batch_size=450, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8145333249976955, basemodel__model__dropout2=0.4289024842480126, basemodel__model__dropout3=0.1, basemodel__model__layer1=496, basemodel__model__layer2=168, basemodel__model__layer3=254, basemodel__model__learning_rate=0.003118118507191013, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.49238676803302384, clip_y=120, include_settings=True, scaler=StandardScaler(), seq_length=42;, score=0.589 total time= 4.2min\n",
            "[CV 3/3] END basemodel__batch_size=450, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8145333249976955, basemodel__model__dropout2=0.4289024842480126, basemodel__model__dropout3=0.1, basemodel__model__layer1=496, basemodel__model__layer2=168, basemodel__model__layer3=254, basemodel__model__learning_rate=0.003118118507191013, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.49238676803302384, clip_y=120, include_settings=True, scaler=StandardScaler(), seq_length=42;, score=0.683 total time= 4.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=234, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.21887820155943588, basemodel__model__dropout2=0.5142608893997881, basemodel__model__dropout3=0.9, basemodel__model__layer1=312, basemodel__model__layer2=512, basemodel__model__layer3=205, basemodel__model__learning_rate=0.0036611442582305457, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4999990499961623, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=100;, score=0.145 total time= 4.6min\n",
            "[CV 2/3] END basemodel__batch_size=234, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.21887820155943588, basemodel__model__dropout2=0.5142608893997881, basemodel__model__dropout3=0.9, basemodel__model__layer1=312, basemodel__model__layer2=512, basemodel__model__layer3=205, basemodel__model__learning_rate=0.0036611442582305457, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4999990499961623, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=100;, score=0.490 total time= 4.6min\n",
            "[CV 3/3] END basemodel__batch_size=234, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.21887820155943588, basemodel__model__dropout2=0.5142608893997881, basemodel__model__dropout3=0.9, basemodel__model__layer1=312, basemodel__model__layer2=512, basemodel__model__layer3=205, basemodel__model__learning_rate=0.0036611442582305457, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4999990499961623, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=100;, score=0.521 total time= 4.6min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=481, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.47444201488001936, basemodel__model__dropout3=0.1, basemodel__model__layer1=463, basemodel__model__layer2=35, basemodel__model__layer3=226, basemodel__model__learning_rate=0.003788447071570824, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5027080027849699, clip_y=127, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.434 total time= 2.0min\n",
            "[CV 2/3] END basemodel__batch_size=481, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.47444201488001936, basemodel__model__dropout3=0.1, basemodel__model__layer1=463, basemodel__model__layer2=35, basemodel__model__layer3=226, basemodel__model__learning_rate=0.003788447071570824, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5027080027849699, clip_y=127, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.367 total time= 2.0min\n",
            "[CV 3/3] END basemodel__batch_size=481, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.47444201488001936, basemodel__model__dropout3=0.1, basemodel__model__layer1=463, basemodel__model__layer2=35, basemodel__model__layer3=226, basemodel__model__learning_rate=0.003788447071570824, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5027080027849699, clip_y=127, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.313 total time= 2.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.20563495067726553, basemodel__model__dropout3=0.31850152654971686, basemodel__model__layer1=208, basemodel__model__layer2=336, basemodel__model__layer3=164, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.46140655106702255, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=59;, score=0.683 total time=14.5min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.20563495067726553, basemodel__model__dropout3=0.31850152654971686, basemodel__model__layer1=208, basemodel__model__layer2=336, basemodel__model__layer3=164, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.46140655106702255, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=59;, score=0.589 total time=14.4min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.20563495067726553, basemodel__model__dropout3=0.31850152654971686, basemodel__model__layer1=208, basemodel__model__layer2=336, basemodel__model__layer3=164, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.46140655106702255, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=59;, score=0.625 total time=14.4min\n",
            "Finished: 2022-10-28 17:43:26.156411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "DoElzuDWt7bL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4449775b-6f0a-4eca-d1c1-401f3354892c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6675592008245431\n",
            "OrderedDict([('basemodel__batch_size', 450), ('basemodel__epochs', 48), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'tanh'), ('basemodel__model__activation3', 'elu'), ('basemodel__model__dropout1', 0.8145333249976955), ('basemodel__model__dropout2', 0.4289024842480126), ('basemodel__model__dropout3', 0.1), ('basemodel__model__layer1', 496), ('basemodel__model__layer2', 168), ('basemodel__model__layer3', 254), ('basemodel__model__learning_rate', 0.003118118507191013), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__model__second_dense', False), ('basemodel__validation_split', 0.49238676803302384), ('clip_y', 120), ('include_settings', True), ('scaler', StandardScaler()), ('seq_length', 42)])\n",
            "Finished: 2022-10-28 17:43:26.175418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "NOe_0fxht7bM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "326c9793-b5d6-4764-ee93-24b35569eca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-28 17:43:26.214413\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "id": "aQdCjgKst7bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501b46a2-dcdc-4128-80a5-2c474427637e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 450),\n",
              "             ('basemodel__epochs', 48),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'tanh'),\n",
              "             ('basemodel__model__activation3', 'elu'),\n",
              "             ('basemodel__model__dropout1', 0.8145333249976955),\n",
              "             ('basemodel__model__dropout2', 0.4289024842480126),\n",
              "             ('basemodel__model__dropout3', 0.1),\n",
              "             ('basemodel__model__layer1', 496),\n",
              "             ('basemodel__model__layer2', 168),\n",
              "             ('basemodel__model__layer3', 254),\n",
              "             ('basemodel__model__learning_rate', 0.003118118507191013),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__model__second_dense', False),\n",
              "             ('basemodel__validation_split', 0.49238676803302384),\n",
              "             ('clip_y', 120),\n",
              "             ('include_settings', True),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 42)])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer\n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL \n",
        "\n",
        "Score: 0.565997282764165  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 354),\n",
        "             ('basemodel__epochs', 43),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.3412271023238272),\n",
        "             ('basemodel__model__layer1', 117),\n",
        "             ('basemodel__model__learning_rate', 0.008518900361139942),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.17000957225461616),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 30)\n",
        "```\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.7343157247269209  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 41),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.23186170929942812),\n",
        "             ('basemodel__model__layer1', 333),\n",
        "             ('basemodel__model__learning_rate', 0.0016624190580454845),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.19268056108985515),\n",
        "             ('clip_y', 134),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 30)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ESr-SWV1Dy3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1\n"
      ],
      "metadata": {
        "id": "zSnh2UONQb4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.5081060519759618  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 304),\n",
        "             ('basemodel__epochs', 31),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.3074381764174994),\n",
        "             ('basemodel__model__dropout2', 0.5435400589103845),\n",
        "             ('basemodel__model__layer1', 16),\n",
        "             ('basemodel__model__layer2', 254),\n",
        "             ('basemodel__model__learning_rate', 0.006871390161766782),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.2925386448085039),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 34)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vL2GlZ8KQb4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.730501800938371  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 225),\n",
        "             ('basemodel__epochs', 20),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.3310559320251978),\n",
        "             ('basemodel__model__dropout2', 0.3142813474813816),\n",
        "             ('basemodel__model__layer1', 473),\n",
        "             ('basemodel__model__layer2', 468),\n",
        "             ('basemodel__model__learning_rate', 0.0008125349625551938),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('clip_y', 103),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 65)\n",
        "```\n"
      ],
      "metadata": {
        "id": "B3F5zD55D9Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2 \n"
      ],
      "metadata": {
        "id": "Jygcz0fjrzEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to change the argument: 'second_dense=True'"
      ],
      "metadata": {
        "id": "puLVKoxXEXb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.4975628097395217  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 183),\n",
        "             ('basemodel__epochs', 31),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'elu'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.3224261325682778),\n",
        "             ('basemodel__model__dropout2', 0.45581827067675496),\n",
        "             ('basemodel__model__dropout3', 0.26574521774822357),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 339),\n",
        "             ('basemodel__model__layer3', 50),\n",
        "             ('basemodel__model__learning_rate', 0.0010131951305302183),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.8409177578463917),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 30)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ywnov-HvrzEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.7786741619787652  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 229),\n",
        "             ('basemodel__epochs', 37),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__activation3', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.4312949059884308),\n",
        "             ('basemodel__model__dropout2', 0.3807450679193153),\n",
        "             ('basemodel__model__dropout3', 0.6916033873523364),\n",
        "             ('basemodel__model__layer1', 167),\n",
        "             ('basemodel__model__layer2', 337),\n",
        "             ('basemodel__model__layer3', 289),\n",
        "             ('basemodel__model__learning_rate', 0.0013556548021189216),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.16231298330980526),\n",
        "             ('clip_y', 120),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 33)\n",
        "```\n"
      ],
      "metadata": {
        "id": "W98etTHQrzEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense\n"
      ],
      "metadata": {
        "id": "z2vaL6nDDYF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.4617027829919557  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 107),\n",
        "             ('basemodel__epochs', 24),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.7024252271635242),\n",
        "             ('basemodel__model__dropout2', 0.16380096029242686),\n",
        "             ('basemodel__model__dropout3', 0.30428197114787425),\n",
        "             ('basemodel__model__layer1', 16),\n",
        "             ('basemodel__model__layer2', 161),\n",
        "             ('basemodel__model__layer3', 291),\n",
        "             ('basemodel__model__learning_rate', 0.002733349824393456),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.10395419197584942),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 31)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YD0XcCDuDYF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.6675592008245431  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 450),\n",
        "             ('basemodel__epochs', 48),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.8145333249976955),\n",
        "             ('basemodel__model__dropout2', 0.4289024842480126),\n",
        "             ('basemodel__model__dropout3', 0.1),\n",
        "             ('basemodel__model__layer1', 496),\n",
        "             ('basemodel__model__layer2', 168),\n",
        "             ('basemodel__model__layer3', 254),\n",
        "             ('basemodel__model__learning_rate', 0.003118118507191013),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.49238676803302384),\n",
        "             ('clip_y', 120),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 42)\n",
        "```\n"
      ],
      "metadata": {
        "id": "L5Sg97mcDYF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "outputId": "10771aed-b881-4a8f-84bc-279c86183fd4",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-58-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# Data checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfeature_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_build_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: create_model() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QFBtaiz2Ckgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           \n",
        "                           \n",
        "                           model__layer1=512, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer2=400,\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "\n",
        "                        \n",
        "                           \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_36P-gmRD6QM",
        "outputId": "04f7f7d7-28d1-40ba-97ee-4fd9aa120787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_65 (Masking)        (None, 79, 22)            0         \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 400)               205200    \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 400)               0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301,281\n",
            "Trainable params: 1,301,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=288.566, rmse=16.987, r2=0.735; v_loss=171.738, v_rmse=13.105, v_r2=0.847; \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-62-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         self._fit_keras_model(\n\u001b[0m\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m   1222\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "83699a7e-1744-455e-c836-906b8dc33bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.918,RMSE=-9.668\n",
            "Finished: 2022-10-13 13:15:58.111062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee8uwFhF-E6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}