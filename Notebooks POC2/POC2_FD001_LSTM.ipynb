{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "n7MBDuPasy-s",
        "e7-_jqRw3cRa",
        "QinQ4hWStzHt",
        "boZqFQNlraCh"
      ],
      "authorship_tag": "ABX9TyMGhQ7BAle/tg7YZuzDD8gK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "777fbe96-af6b-4726-e219-aa218588d10d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2f2982-74ad-4b92-cde2-0d526f0fba0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "oVLI86qK9J_9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "D4BClPwS9KAB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a509a6-4c71-470d-f4f8-1c61069cab00",
        "id": "Zfs5m8Xs9KAC"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-yRYxz2hh4xE",
        "outputId": "66064640-e2d6-4130-e7ec-2155c7f7b54b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtvRNsfuUwg",
        "outputId": "01241f00-305a-4be8-d685-0df2ab2c56af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "onw4pCwZy-1s",
        "outputId": "bffc0ea3-68ad-4679-8167-9f6aae6512d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lmFKjQaeip1b",
        "outputId": "3abd9adb-2886-46f6-adad-fe4e51621103"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fuAnHn4GxzwM",
        "outputId": "fe7df46a-123b-4efe-8dc8-ca17507f818d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "26hK4VWkx1R7",
        "outputId": "daff3736-56d2-42e1-a911-99aa42657564"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "RXluaxXx9KAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "pXrknAaH9KAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "PWPu36179KAO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "Zt00Gp3h9KAO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary HyperParameters"
      ],
      "metadata": {
        "id": "s5FGWUO39KAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=[16,32,64,128,256,512]"
      ],
      "metadata": {
        "id": "1YVpDJMZ9KAP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Decay Schedules\n",
        "ED1 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED1\",\n",
        "                       decay_steps=100000, decay_rate=0.96)\n",
        "ED2 = ExponentialDecay(initial_learning_rate=1e-2, name=\"ED2\",\n",
        "                       decay_steps=100000, decay_rate=0.8)\n",
        "ED3 = ExponentialDecay(initial_learning_rate=1e-1, name=\"ED3\",\n",
        "                       decay_steps=100000, decay_rate=0.96)"
      ],
      "metadata": {
        "id": "kuJmsPFz9KAP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of list combinations\n",
        "from itertools import chain, permutations\n",
        "\n",
        "def all_permutations(lst, size):\n",
        "    result = list(chain.from_iterable([permutations(lst, x) for x in range(len(lst)+1)]))\n",
        "    out = []\n",
        "    for r in result:\n",
        "        if (len(r) == size):\n",
        "            out.append(list(r))\n",
        "    return out"
      ],
      "metadata": {
        "id": "2wQw__yZ9KAQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "Yxeph5PR9KAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "Y6osQMX29KAS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "CaAspZtt9KAS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "aGe9ksS69KAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "gRSH3tdyf8yc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor2(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        data = data.drop(self.feature_cols, axis=1)\n",
        "        \n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        print(all(data.index==transf.index))\n",
        "        data = pd.concat([data,transf], axis=1)\n",
        "        # data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        transf = self.scaler.fit_transform(data[self.feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.scaler.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        data = data.drop(self.feature_cols, axis=1)\n",
        "        data = pd.concat([data,transf], axis=1)\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Kfvjdak-9KAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "3aXzwlaw9KAU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "wulPSyfF9KAU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "hKDJOCJf9KAV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "Vd0hQpw-U_ch"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "5aqms6jMFKti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.7965826139501325  \n",
        "Test: 0.706\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.10771222326909816),\n",
        "('basemodel__model__layer1', 505),\n",
        "('basemodel__model__learning_rate', 0.0032806529941975817),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 70)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "oGlT7ajZFKtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=70\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=28,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.10771222326909816, \n",
        "                           model__layer1=505, \n",
        "                           model__learning_rate=0.0032806529941975817,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3d9cf0-bef8-4c2d-8108-436e421ad7f8",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 70, 22)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 505)               1066560   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 505)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 506       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,067,066\n",
            "Trainable params: 1,067,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2093.961, rmse=45.760, r2=0.225; v_loss=3632.012, v_rmse=60.266, v_r2=0.024; \n",
            "E 2\t: loss=1469.139, rmse=38.329, r2=0.456; v_loss=2173.852, v_rmse=46.625, v_r2=0.416; \n",
            "E 3\t: loss=1272.085, rmse=35.666, r2=0.529; v_loss=2284.971, v_rmse=47.801, v_r2=0.386; \n",
            "E 4\t: loss=1100.697, rmse=33.177, r2=0.593; v_loss=1492.256, v_rmse=38.630, v_r2=0.599; \n",
            "E 5\t: loss=929.872, rmse=30.494, r2=0.656; v_loss=1253.812, v_rmse=35.409, v_r2=0.663; \n",
            "E 6\t: loss=842.940, rmse=29.033, r2=0.688; v_loss=1777.913, v_rmse=42.165, v_r2=0.522; \n",
            "E 7\t: loss=784.443, rmse=28.008, r2=0.710; v_loss=2580.095, v_rmse=50.795, v_r2=0.307; \n",
            "E 8\t: loss=739.849, rmse=27.200, r2=0.726; v_loss=1225.323, v_rmse=35.005, v_r2=0.671; \n",
            "E 9\t: loss=691.491, rmse=26.296, r2=0.744; v_loss=1229.664, v_rmse=35.067, v_r2=0.670; \n",
            "E 10\t: loss=648.746, rmse=25.470, r2=0.760; v_loss=936.765, v_rmse=30.607, v_r2=0.748; \n",
            "E 11\t: loss=635.308, rmse=25.205, r2=0.765; v_loss=982.914, v_rmse=31.351, v_r2=0.736; \n",
            "E 12\t: loss=593.313, rmse=24.358, r2=0.780; v_loss=1465.857, v_rmse=38.287, v_r2=0.606; \n",
            "E 13\t: loss=584.757, rmse=24.182, r2=0.784; v_loss=708.291, v_rmse=26.614, v_r2=0.810; \n",
            "E 14\t: loss=568.711, rmse=23.848, r2=0.790; v_loss=628.103, v_rmse=25.062, v_r2=0.831; \n",
            "E 15\t: loss=538.467, rmse=23.205, r2=0.801; v_loss=733.095, v_rmse=27.076, v_r2=0.803; \n",
            "E 16\t: loss=531.541, rmse=23.055, r2=0.803; v_loss=642.370, v_rmse=25.345, v_r2=0.827; \n",
            "E 17\t: loss=531.264, rmse=23.049, r2=0.803; v_loss=1682.828, v_rmse=41.022, v_r2=0.548; \n",
            "E 18\t: loss=521.523, rmse=22.837, r2=0.807; v_loss=667.303, v_rmse=25.832, v_r2=0.821; \n",
            "E 19\t: loss=506.110, rmse=22.497, r2=0.813; v_loss=731.752, v_rmse=27.051, v_r2=0.803; \n",
            "E 20\t: loss=517.819, rmse=22.756, r2=0.808; v_loss=755.912, v_rmse=27.494, v_r2=0.797; \n",
            "E 21\t: loss=490.853, rmse=22.155, r2=0.818; v_loss=676.806, v_rmse=26.015, v_r2=0.818; \n",
            "E 22\t: loss=477.923, rmse=21.861, r2=0.823; v_loss=1451.515, v_rmse=38.099, v_r2=0.610; \n",
            "E 23\t: loss=474.378, rmse=21.780, r2=0.824; v_loss=881.133, v_rmse=29.684, v_r2=0.763; \n",
            "E 24\t: loss=480.842, rmse=21.928, r2=0.822; v_loss=502.258, v_rmse=22.411, v_r2=0.865; \n",
            "E 25\t: loss=485.022, rmse=22.023, r2=0.820; v_loss=1748.815, v_rmse=41.819, v_r2=0.530; \n",
            "E 26\t: loss=456.727, rmse=21.371, r2=0.831; v_loss=520.396, v_rmse=22.812, v_r2=0.860; \n",
            "E 27\t: loss=460.931, rmse=21.469, r2=0.829; v_loss=1183.853, v_rmse=34.407, v_r2=0.682; \n",
            "E 28\t: loss=453.395, rmse=21.293, r2=0.832; v_loss=420.550, v_rmse=20.507, v_r2=0.887; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x000001D0C441EB50>, <keras.callbacks.LambdaCallback object at 0x000001D0C4454BE0>], epochs=28, model=<function create_model at 0x000001D0C44BAF70>, model__activation1='tanh', model__dropout1=0.10771222326909816, model__layer1=505, model__learning_rate=0.0032806529941975817, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x000001D0C449FAF0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x000001D0C44762B0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     scaler=MinMaxScaler(), seq_length=70)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99f3095-c725-4a90-b0c0-abff85d2cb1a",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.807,RMSE=-18.271\n",
            "Finished: 2022-10-19 10:27:27.900561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.9430289602358563  \n",
        "Test: 0.857\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 105),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 68)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36P-gmRD6QM",
        "outputId": "2f3b0316-0061-40f5-edd6-fb8a571d462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_3 (Masking)         (None, 68, 22)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,096,193\n",
            "Trainable params: 1,096,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2982.448, rmse=54.612, r2=-1.419; v_loss=2215.075, v_rmse=47.065, v_r2=-0.774; \n",
            "E 2\t: loss=1623.784, rmse=40.296, r2=-0.317; v_loss=1706.530, v_rmse=41.310, v_r2=-0.367; \n",
            "E 3\t: loss=1197.737, rmse=34.608, r2=0.029; v_loss=1497.697, v_rmse=38.700, v_r2=-0.199; \n",
            "E 4\t: loss=958.397, rmse=30.958, r2=0.223; v_loss=1343.810, v_rmse=36.658, v_r2=-0.076; \n",
            "E 5\t: loss=774.233, rmse=27.825, r2=0.372; v_loss=984.936, v_rmse=31.384, v_r2=0.211; \n",
            "E 6\t: loss=472.650, rmse=21.741, r2=0.617; v_loss=546.742, v_rmse=23.383, v_r2=0.562; \n",
            "E 7\t: loss=302.671, rmse=17.397, r2=0.755; v_loss=322.965, v_rmse=17.971, v_r2=0.741; \n",
            "E 8\t: loss=210.265, rmse=14.501, r2=0.829; v_loss=244.289, v_rmse=15.630, v_r2=0.804; \n",
            "E 9\t: loss=163.712, rmse=12.795, r2=0.867; v_loss=161.370, v_rmse=12.703, v_r2=0.871; \n",
            "E 10\t: loss=119.954, rmse=10.952, r2=0.903; v_loss=134.003, v_rmse=11.576, v_r2=0.893; \n",
            "E 11\t: loss=122.557, rmse=11.071, r2=0.901; v_loss=133.849, v_rmse=11.569, v_r2=0.893; \n",
            "E 12\t: loss=92.088, rmse=9.596, r2=0.925; v_loss=88.262, v_rmse=9.395, v_r2=0.929; \n",
            "E 13\t: loss=81.347, rmse=9.019, r2=0.934; v_loss=77.839, v_rmse=8.823, v_r2=0.938; \n",
            "E 14\t: loss=75.310, rmse=8.678, r2=0.939; v_loss=65.134, v_rmse=8.071, v_r2=0.948; \n",
            "E 15\t: loss=69.507, rmse=8.337, r2=0.944; v_loss=68.467, v_rmse=8.274, v_r2=0.945; \n",
            "E 16\t: loss=66.176, rmse=8.135, r2=0.946; v_loss=89.575, v_rmse=9.464, v_r2=0.928; \n",
            "E 17\t: loss=65.656, rmse=8.103, r2=0.947; v_loss=70.496, v_rmse=8.396, v_r2=0.944; \n",
            "E 18\t: loss=61.586, rmse=7.848, r2=0.950; v_loss=51.289, v_rmse=7.162, v_r2=0.959; \n",
            "E 19\t: loss=59.908, rmse=7.740, r2=0.951; v_loss=58.295, v_rmse=7.635, v_r2=0.953; \n",
            "E 20\t: loss=55.930, rmse=7.479, r2=0.955; v_loss=50.215, v_rmse=7.086, v_r2=0.960; \n",
            "E 21\t: loss=57.646, rmse=7.593, r2=0.953; v_loss=53.539, v_rmse=7.317, v_r2=0.957; \n",
            "E 22\t: loss=55.984, rmse=7.482, r2=0.955; v_loss=47.239, v_rmse=6.873, v_r2=0.962; \n",
            "E 23\t: loss=54.576, rmse=7.388, r2=0.956; v_loss=62.975, v_rmse=7.936, v_r2=0.950; \n",
            "E 24\t: loss=54.185, rmse=7.361, r2=0.956; v_loss=55.870, v_rmse=7.475, v_r2=0.955; \n",
            "E 25\t: loss=56.578, rmse=7.522, r2=0.954; v_loss=54.440, v_rmse=7.378, v_r2=0.956; \n",
            "E 26\t: loss=52.954, rmse=7.277, r2=0.957; v_loss=49.817, v_rmse=7.058, v_r2=0.960; \n",
            "E 27\t: loss=50.986, rmse=7.140, r2=0.959; v_loss=63.619, v_rmse=7.976, v_r2=0.949; \n",
            "E 28\t: loss=53.836, rmse=7.337, r2=0.956; v_loss=65.039, v_rmse=8.065, v_r2=0.948; \n",
            "E 29\t: loss=51.266, rmse=7.160, r2=0.958; v_loss=49.043, v_rmse=7.003, v_r2=0.961; \n",
            "E 30\t: loss=50.529, rmse=7.108, r2=0.959; v_loss=49.954, v_rmse=7.068, v_r2=0.960; \n",
            "E 31\t: loss=51.051, rmse=7.145, r2=0.959; v_loss=67.456, v_rmse=8.213, v_r2=0.946; \n",
            "E 32\t: loss=49.074, rmse=7.005, r2=0.960; v_loss=80.333, v_rmse=8.963, v_r2=0.936; \n",
            "E 33\t: loss=50.404, rmse=7.100, r2=0.959; v_loss=77.496, v_rmse=8.803, v_r2=0.938; \n",
            "E 34\t: loss=49.055, rmse=7.004, r2=0.960; v_loss=50.703, v_rmse=7.121, v_r2=0.959; \n",
            "E 35\t: loss=47.616, rmse=6.900, r2=0.961; v_loss=59.109, v_rmse=7.688, v_r2=0.953; \n",
            "E 36\t: loss=48.214, rmse=6.944, r2=0.961; v_loss=43.517, v_rmse=6.597, v_r2=0.965; \n",
            "E 37\t: loss=49.488, rmse=7.035, r2=0.960; v_loss=52.871, v_rmse=7.271, v_r2=0.958; \n",
            "E 38\t: loss=48.587, rmse=6.970, r2=0.961; v_loss=47.855, v_rmse=6.918, v_r2=0.962; \n",
            "E 39\t: loss=48.213, rmse=6.944, r2=0.961; v_loss=44.330, v_rmse=6.658, v_r2=0.964; \n",
            "E 40\t: loss=48.061, rmse=6.933, r2=0.961; v_loss=56.976, v_rmse=7.548, v_r2=0.954; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000247B9A42760>, <keras.callbacks.LambdaCallback object at 0x00000247B9AC3D00>], epochs=50, model=<function create_model at 0x00000247B9B5CB80>, model__activation1='tanh', model__dropout1=0.1, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000247CA9147C0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000248EA003AC0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     clip_y=105, scaler=MinMaxScaler(), seq_length=68)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "02417a5a-662e-4369-f4e5-8a8cf3f3c413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.869,RMSE=-12.909\n",
            "Finished: 2022-10-16 07:46:45.185856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1"
      ],
      "metadata": {
        "id": "SvWawqOFYvO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "bWDbtK4RYvPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.8521617501513421  \n",
        "Test: 0.793\n",
        "```\n",
        "('basemodel__batch_size', 239),\n",
        "('basemodel__epochs', 45),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__dropout1', 0.8360008606718795),\n",
        "('basemodel__model__dropout2', 0.8326359552620336),\n",
        "('basemodel__model__layer1', 493),\n",
        "('basemodel__model__layer2', 469),\n",
        "('basemodel__model__learning_rate', 0.0013568819509124186),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1967801723709445),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 74)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "18mXMMo2YvPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=74\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=239,\n",
        "                           epochs=45,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__dropout1=0.8360008606718795, \n",
        "                           model__dropout2=0.8326359552620336, \n",
        "                           model__layer1=493, \n",
        "                           model__layer2=469, \n",
        "                           model__learning_rate=0.0013568819509124186,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1967801723709445, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "2EKUQXh0YvPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52946ea0-d3d5-4eee-b6ea-94f635e6a707",
        "id": "5uHgjmJZYvPC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 74, 22)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 493)               1017552   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 493)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 469)               231686    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 469)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 470       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,249,708\n",
            "Trainable params: 1,249,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2721.398, rmse=52.167, r2=-0.111; v_loss=3049.229, v_rmse=55.220, v_r2=0.184; \n",
            "E 2\t: loss=1426.339, rmse=37.767, r2=0.418; v_loss=2281.288, v_rmse=47.763, v_r2=0.389; \n",
            "E 3\t: loss=1187.548, rmse=34.461, r2=0.515; v_loss=1950.685, v_rmse=44.167, v_r2=0.478; \n",
            "E 4\t: loss=1101.703, rmse=33.192, r2=0.550; v_loss=1748.322, v_rmse=41.813, v_r2=0.532; \n",
            "E 5\t: loss=984.472, rmse=31.376, r2=0.598; v_loss=1444.184, v_rmse=38.002, v_r2=0.613; \n",
            "E 6\t: loss=844.556, rmse=29.061, r2=0.655; v_loss=1110.438, v_rmse=33.323, v_r2=0.703; \n",
            "E 7\t: loss=738.586, rmse=27.177, r2=0.698; v_loss=808.535, v_rmse=28.435, v_r2=0.784; \n",
            "E 8\t: loss=731.587, rmse=27.048, r2=0.701; v_loss=739.132, v_rmse=27.187, v_r2=0.802; \n",
            "E 9\t: loss=686.618, rmse=26.203, r2=0.720; v_loss=603.122, v_rmse=24.559, v_r2=0.839; \n",
            "E 10\t: loss=625.926, rmse=25.019, r2=0.744; v_loss=428.100, v_rmse=20.691, v_r2=0.885; \n",
            "E 11\t: loss=593.926, rmse=24.371, r2=0.757; v_loss=500.614, v_rmse=22.374, v_r2=0.866; \n",
            "E 12\t: loss=629.177, rmse=25.083, r2=0.743; v_loss=497.126, v_rmse=22.296, v_r2=0.867; \n",
            "E 13\t: loss=580.272, rmse=24.089, r2=0.763; v_loss=718.226, v_rmse=26.800, v_r2=0.808; \n",
            "E 14\t: loss=570.658, rmse=23.888, r2=0.767; v_loss=378.745, v_rmse=19.461, v_r2=0.899; \n",
            "E 15\t: loss=550.960, rmse=23.473, r2=0.775; v_loss=435.865, v_rmse=20.877, v_r2=0.883; \n",
            "E 16\t: loss=560.576, rmse=23.676, r2=0.771; v_loss=948.325, v_rmse=30.795, v_r2=0.746; \n",
            "E 17\t: loss=595.176, rmse=24.396, r2=0.757; v_loss=547.284, v_rmse=23.394, v_r2=0.854; \n",
            "E 18\t: loss=523.061, rmse=22.871, r2=0.786; v_loss=810.776, v_rmse=28.474, v_r2=0.783; \n",
            "E 19\t: loss=535.381, rmse=23.138, r2=0.781; v_loss=427.783, v_rmse=20.683, v_r2=0.885; \n",
            "E 20\t: loss=487.960, rmse=22.090, r2=0.801; v_loss=314.580, v_rmse=17.736, v_r2=0.916; \n",
            "E 21\t: loss=481.336, rmse=21.939, r2=0.803; v_loss=353.945, v_rmse=18.813, v_r2=0.905; \n",
            "E 22\t: loss=475.789, rmse=21.813, r2=0.806; v_loss=324.817, v_rmse=18.023, v_r2=0.913; \n",
            "E 23\t: loss=454.765, rmse=21.325, r2=0.814; v_loss=293.180, v_rmse=17.123, v_r2=0.922; \n",
            "E 24\t: loss=468.520, rmse=21.645, r2=0.809; v_loss=373.612, v_rmse=19.329, v_r2=0.900; \n",
            "E 25\t: loss=479.419, rmse=21.896, r2=0.804; v_loss=377.195, v_rmse=19.422, v_r2=0.899; \n",
            "E 26\t: loss=455.310, rmse=21.338, r2=0.814; v_loss=300.542, v_rmse=17.336, v_r2=0.920; \n",
            "E 27\t: loss=469.611, rmse=21.671, r2=0.808; v_loss=387.978, v_rmse=19.697, v_r2=0.896; \n",
            "E 28\t: loss=435.679, rmse=20.873, r2=0.822; v_loss=330.940, v_rmse=18.192, v_r2=0.911; \n",
            "E 29\t: loss=439.870, rmse=20.973, r2=0.820; v_loss=365.294, v_rmse=19.113, v_r2=0.902; \n",
            "E 30\t: loss=458.431, rmse=21.411, r2=0.813; v_loss=387.967, v_rmse=19.697, v_r2=0.896; \n",
            "E 31\t: loss=449.871, rmse=21.210, r2=0.816; v_loss=385.490, v_rmse=19.634, v_r2=0.897; \n",
            "E 32\t: loss=437.567, rmse=20.918, r2=0.821; v_loss=301.145, v_rmse=17.354, v_r2=0.919; \n",
            "E 33\t: loss=403.795, rmse=20.095, r2=0.835; v_loss=341.337, v_rmse=18.475, v_r2=0.909; \n",
            "E 34\t: loss=431.613, rmse=20.775, r2=0.824; v_loss=407.754, v_rmse=20.193, v_r2=0.891; \n",
            "E 35\t: loss=415.093, rmse=20.374, r2=0.830; v_loss=328.591, v_rmse=18.127, v_r2=0.912; \n",
            "E 36\t: loss=403.548, rmse=20.089, r2=0.835; v_loss=358.622, v_rmse=18.937, v_r2=0.904; \n",
            "E 37\t: loss=419.594, rmse=20.484, r2=0.829; v_loss=301.316, v_rmse=17.358, v_r2=0.919; \n",
            "E 38\t: loss=417.036, rmse=20.421, r2=0.830; v_loss=559.979, v_rmse=23.664, v_r2=0.850; \n",
            "E 39\t: loss=435.395, rmse=20.866, r2=0.822; v_loss=332.459, v_rmse=18.233, v_r2=0.911; \n",
            "E 40\t: loss=419.385, rmse=20.479, r2=0.829; v_loss=313.870, v_rmse=17.716, v_r2=0.916; \n",
            "E 41\t: loss=409.252, rmse=20.230, r2=0.833; v_loss=517.277, v_rmse=22.744, v_r2=0.862; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=239, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000197C771EB80>, <keras.callbacks.LambdaCallback object at 0x00000197C7753BE0>], epochs=45, model=<function create_model at 0x00000197C90B6EE0>, model__activation1='tanh', model__activation2='relu', model__dropout1=0.8360008606718795, model__dropout...r2=469, model__learning_rate=0.0013568819509124186, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000197C7AAFC40>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000197C92950D0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1967801723709445, verbose=0),\n",
              "                     seq_length=74)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d429112-803d-4c55-fc1d-c4e2e00a0843",
        "id": "svjWhd4FYvPD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.793,RMSE=-18.928\n",
            "Finished: 2022-10-16 08:19:44.587007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "6LznVkFxYvPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.917847894602053  \n",
        "Test: 0.883\n",
        "```\n",
        "('basemodel__batch_size', 174),\n",
        "('basemodel__epochs', 21),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'selu'),\n",
        "('basemodel__model__dropout1', 0.5157104351784535),\n",
        "('basemodel__model__dropout2', 0.7126675967759073),\n",
        "('basemodel__model__layer1', 125),\n",
        "('basemodel__model__layer2', 386),\n",
        "('basemodel__model__learning_rate', 0.0017804516876459917),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.23205313885059345),\n",
        "('clip_y', 140),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 80)\n",
        "```\n"
      ],
      "metadata": {
        "id": "KiL-gZkZYvPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=80\n",
        "CLIP=140\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=174,\n",
        "                           epochs=21,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout1=0.5157104351784535, \n",
        "                           model__dropout2=0.7126675967759073, \n",
        "                           model__layer1=125, \n",
        "                           model__layer2=386, \n",
        "                           model__learning_rate=0.0017804516876459917,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.23205313885059345, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "tEwHSsUCYvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1c0e28-c509-46cc-d4d9-50112003f55d",
        "id": "AMEzooPSYvPF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 80, 22)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 125)               74000     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 125)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 386)               48636     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 386)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,023\n",
            "Trainable params: 123,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2039.539, rmse=45.161, r2=-0.199; v_loss=1358.758, v_rmse=36.861, v_r2=0.365; \n",
            "E 2\t: loss=703.401, rmse=26.522, r2=0.586; v_loss=799.613, v_rmse=28.277, v_r2=0.626; \n",
            "E 3\t: loss=557.290, rmse=23.607, r2=0.672; v_loss=764.354, v_rmse=27.647, v_r2=0.643; \n",
            "E 4\t: loss=499.155, rmse=22.342, r2=0.706; v_loss=712.040, v_rmse=26.684, v_r2=0.667; \n",
            "E 5\t: loss=472.438, rmse=21.736, r2=0.722; v_loss=540.095, v_rmse=23.240, v_r2=0.748; \n",
            "E 6\t: loss=408.930, rmse=20.222, r2=0.760; v_loss=433.801, v_rmse=20.828, v_r2=0.797; \n",
            "E 7\t: loss=327.316, rmse=18.092, r2=0.808; v_loss=234.598, v_rmse=15.317, v_r2=0.890; \n",
            "E 8\t: loss=290.886, rmse=17.055, r2=0.829; v_loss=233.447, v_rmse=15.279, v_r2=0.891; \n",
            "E 9\t: loss=259.619, rmse=16.113, r2=0.847; v_loss=241.909, v_rmse=15.553, v_r2=0.887; \n",
            "E 10\t: loss=229.232, rmse=15.140, r2=0.865; v_loss=179.287, v_rmse=13.390, v_r2=0.916; \n",
            "E 11\t: loss=204.551, rmse=14.302, r2=0.880; v_loss=152.195, v_rmse=12.337, v_r2=0.929; \n",
            "E 12\t: loss=201.773, rmse=14.205, r2=0.881; v_loss=192.834, v_rmse=13.886, v_r2=0.910; \n",
            "E 13\t: loss=183.495, rmse=13.546, r2=0.892; v_loss=149.442, v_rmse=12.225, v_r2=0.930; \n",
            "E 14\t: loss=167.473, rmse=12.941, r2=0.902; v_loss=138.964, v_rmse=11.788, v_r2=0.935; \n",
            "E 15\t: loss=171.544, rmse=13.097, r2=0.899; v_loss=146.008, v_rmse=12.083, v_r2=0.932; \n",
            "E 16\t: loss=192.886, rmse=13.888, r2=0.887; v_loss=134.393, v_rmse=11.593, v_r2=0.937; \n",
            "E 17\t: loss=162.054, rmse=12.730, r2=0.905; v_loss=135.225, v_rmse=11.629, v_r2=0.937; \n",
            "E 18\t: loss=150.156, rmse=12.254, r2=0.912; v_loss=123.085, v_rmse=11.094, v_r2=0.942; \n",
            "E 19\t: loss=159.084, rmse=12.613, r2=0.906; v_loss=103.725, v_rmse=10.185, v_r2=0.952; \n",
            "E 20\t: loss=145.855, rmse=12.077, r2=0.914; v_loss=117.418, v_rmse=10.836, v_r2=0.945; \n",
            "E 21\t: loss=137.448, rmse=11.724, r2=0.919; v_loss=115.687, v_rmse=10.756, v_r2=0.946; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=174, callbacks=[<keras.callbacks.EarlyStopping object at 0x00000197C771EB80>, <keras.callbacks.LambdaCallback object at 0x00000197C7753BE0>], epochs=21, model=<function create_model at 0x00000197C90B6EE0>, model__activation1='tanh', model__activation2='selu', model__dropout1=0.5157104351784535, model__dropout...__learning_rate=0.0017804516876459917, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000197D6A3C430>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000019787C863A0>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.23205313885059345, verbose=0),\n",
              "                     clip_y=140, seq_length=80)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4e97fa-2c54-4b34-ce8f-aad0202e4172",
        "id": "WU1dYRTwYvPG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.883,RMSE=-14.201\n",
            "Finished: 2022-10-16 08:20:41.062244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2"
      ],
      "metadata": {
        "id": "y28M-FK8zDq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "9Zl5AM1czDq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.7968129295270682  \n",
        "Test: 0.767\n",
        "```\n",
        "('basemodel__batch_size', 33),\n",
        "('basemodel__epochs', 32),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.22285374911306066),\n",
        "('basemodel__model__dropout2', 0.7374780395679955),\n",
        "('basemodel__model__dropout3', 0.3869949529630097),\n",
        "('basemodel__model__layer1', 224),\n",
        "('basemodel__model__layer2', 512),\n",
        "('basemodel__model__layer3', 396),\n",
        "('basemodel__model__learning_rate', 0.0006807885804241826),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.6313983549045777),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 95)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y5_j9VhBzDq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=95\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=33,\n",
        "                           epochs=32,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.22285374911306066, \n",
        "                           model__dropout2=0.7374780395679955,\n",
        "                           model__dropout3=0.3869949529630097, \n",
        "                           model__layer1=224, \n",
        "                           model__layer2=512, \n",
        "                           model__layer3=396, \n",
        "                           model__learning_rate=0.0006807885804241826,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.6313983549045777, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "yP84kQK2zDq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017057cd-1c86-4c7f-8126-c53bed1d7106",
        "id": "dpx_rNVCzDq6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 95, 22)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 224)               221312    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 224)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               115200    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 396)               203148    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 396)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 397       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 540,057\n",
            "Trainable params: 540,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1405.871, rmse=37.495, r2=0.100; v_loss=2284.027, v_rmse=47.791, v_r2=0.155; \n",
            "E 2\t: loss=998.887, rmse=31.605, r2=0.361; v_loss=2177.207, v_rmse=46.661, v_r2=0.195; \n",
            "E 3\t: loss=820.525, rmse=28.645, r2=0.475; v_loss=1842.546, v_rmse=42.925, v_r2=0.318; \n",
            "E 4\t: loss=558.836, rmse=23.640, r2=0.642; v_loss=2085.063, v_rmse=45.662, v_r2=0.229; \n",
            "E 5\t: loss=471.286, rmse=21.709, r2=0.698; v_loss=1351.481, v_rmse=36.762, v_r2=0.500; \n",
            "E 6\t: loss=438.484, rmse=20.940, r2=0.719; v_loss=1337.982, v_rmse=36.578, v_r2=0.505; \n",
            "E 7\t: loss=376.254, rmse=19.397, r2=0.759; v_loss=1400.497, v_rmse=37.423, v_r2=0.482; \n",
            "E 8\t: loss=354.505, rmse=18.828, r2=0.773; v_loss=1232.157, v_rmse=35.102, v_r2=0.544; \n",
            "E 9\t: loss=290.536, rmse=17.045, r2=0.814; v_loss=1470.038, v_rmse=38.341, v_r2=0.456; \n",
            "E 10\t: loss=250.063, rmse=15.813, r2=0.840; v_loss=899.396, v_rmse=29.990, v_r2=0.667; \n",
            "E 11\t: loss=220.384, rmse=14.845, r2=0.859; v_loss=878.398, v_rmse=29.638, v_r2=0.675; \n",
            "E 12\t: loss=229.901, rmse=15.163, r2=0.853; v_loss=753.394, v_rmse=27.448, v_r2=0.721; \n",
            "E 13\t: loss=228.520, rmse=15.117, r2=0.854; v_loss=748.150, v_rmse=27.352, v_r2=0.723; \n",
            "E 14\t: loss=187.853, rmse=13.706, r2=0.880; v_loss=780.725, v_rmse=27.941, v_r2=0.711; \n",
            "E 15\t: loss=165.999, rmse=12.884, r2=0.894; v_loss=743.714, v_rmse=27.271, v_r2=0.725; \n",
            "E 16\t: loss=144.119, rmse=12.005, r2=0.908; v_loss=828.699, v_rmse=28.787, v_r2=0.693; \n",
            "E 17\t: loss=186.504, rmse=13.657, r2=0.881; v_loss=913.914, v_rmse=30.231, v_r2=0.662; \n",
            "E 18\t: loss=169.094, rmse=13.004, r2=0.892; v_loss=1080.849, v_rmse=32.876, v_r2=0.600; \n",
            "E 19\t: loss=166.898, rmse=12.919, r2=0.893; v_loss=973.230, v_rmse=31.197, v_r2=0.640; \n",
            "E 20\t: loss=141.032, rmse=11.876, r2=0.910; v_loss=961.654, v_rmse=31.011, v_r2=0.644; \n",
            "E 21\t: loss=164.205, rmse=12.814, r2=0.895; v_loss=717.128, v_rmse=26.779, v_r2=0.735; \n",
            "E 22\t: loss=143.733, rmse=11.989, r2=0.908; v_loss=992.340, v_rmse=31.501, v_r2=0.633; \n",
            "E 23\t: loss=139.622, rmse=11.816, r2=0.911; v_loss=800.118, v_rmse=28.286, v_r2=0.704; \n",
            "E 24\t: loss=131.650, rmse=11.474, r2=0.916; v_loss=651.280, v_rmse=25.520, v_r2=0.759; \n",
            "E 25\t: loss=141.530, rmse=11.897, r2=0.909; v_loss=948.171, v_rmse=30.792, v_r2=0.649; \n",
            "E 26\t: loss=132.959, rmse=11.531, r2=0.915; v_loss=585.781, v_rmse=24.203, v_r2=0.783; \n",
            "E 27\t: loss=111.870, rmse=10.577, r2=0.928; v_loss=662.985, v_rmse=25.749, v_r2=0.755; \n",
            "E 28\t: loss=162.991, rmse=12.767, r2=0.896; v_loss=625.365, v_rmse=25.007, v_r2=0.769; \n",
            "E 29\t: loss=119.508, rmse=10.932, r2=0.923; v_loss=623.233, v_rmse=24.965, v_r2=0.769; \n",
            "E 30\t: loss=111.481, rmse=10.558, r2=0.929; v_loss=645.536, v_rmse=25.407, v_r2=0.761; \n",
            "E 31\t: loss=118.313, rmse=10.877, r2=0.924; v_loss=928.797, v_rmse=30.476, v_r2=0.656; \n",
            "E 32\t: loss=133.694, rmse=11.563, r2=0.914; v_loss=730.894, v_rmse=27.035, v_r2=0.730; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=33, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=32, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='relu', model__activation3='selu', model__dropout1=0.222853..._rate=0.0006807885804241826, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000021373F822E0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000021373FA2B50>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.6313983549045777, verbose=0),\n",
              "                     scaler=MinMaxScaler(), seq_length=95)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a15d68-75fb-49d4-f004-4faf037bbe9f",
        "id": "qzoIZZmlzDq7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.767,RMSE=-20.064\n",
            "Finished: 2022-10-17 13:42:24.798953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "wrpte1WXzDq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.8303738924314298  \n",
        "Test: 0.724\n",
        "```\n",
        "('basemodel__batch_size', 70),\n",
        "('basemodel__epochs', 45),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'relu'),\n",
        "('basemodel__model__activation3', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.677716159846799),\n",
        "('basemodel__model__dropout2', 0.2905479330833355),\n",
        "('basemodel__model__dropout3', 0.25279167191355223),\n",
        "('basemodel__model__layer1', 177),\n",
        "('basemodel__model__layer2', 470),\n",
        "('basemodel__model__layer3', 221),\n",
        "('basemodel__model__learning_rate', 0.009128147835708741),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.643380976472796),\n",
        "('clip_y', 98),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 58)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-RCr6qz8zDq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=58\n",
        "CLIP=98\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=70,\n",
        "                           epochs=45,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='relu',\n",
        "                           model__activation3='tanh',\n",
        "                           model__dropout1=0.677716159846799, \n",
        "                           model__dropout2=0.2905479330833355,\n",
        "                           model__dropout3=0.25279167191355223, \n",
        "                           model__layer1=177, \n",
        "                           model__layer2=470, \n",
        "                           model__layer3=221, \n",
        "                           model__learning_rate=0.009128147835708741,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.643380976472796, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "TCGZ2Pr4zDq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc10519-28fc-4955-e157-c832971be1fd",
        "id": "Fd65WHLTzDq9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_2 (Masking)         (None, 58, 22)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 177)               141600    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 177)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 470)               83660     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 470)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 221)               104091    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 221)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 222       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 329,573\n",
            "Trainable params: 329,573\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=916.736, rmse=30.278, r2=0.142; v_loss=636.404, v_rmse=25.227, v_r2=0.414; \n",
            "E 2\t: loss=289.095, rmse=17.003, r2=0.730; v_loss=328.619, v_rmse=18.128, v_r2=0.697; \n",
            "E 3\t: loss=236.314, rmse=15.373, r2=0.779; v_loss=286.056, v_rmse=16.913, v_r2=0.736; \n",
            "E 4\t: loss=206.042, rmse=14.354, r2=0.807; v_loss=599.695, v_rmse=24.489, v_r2=0.447; \n",
            "E 5\t: loss=190.136, rmse=13.789, r2=0.822; v_loss=458.307, v_rmse=21.408, v_r2=0.578; \n",
            "E 6\t: loss=175.191, rmse=13.236, r2=0.836; v_loss=202.988, v_rmse=14.247, v_r2=0.813; \n",
            "E 7\t: loss=172.022, rmse=13.116, r2=0.839; v_loss=219.702, v_rmse=14.822, v_r2=0.798; \n",
            "E 8\t: loss=161.633, rmse=12.713, r2=0.849; v_loss=188.178, v_rmse=13.718, v_r2=0.827; \n",
            "E 9\t: loss=150.945, rmse=12.286, r2=0.859; v_loss=158.764, v_rmse=12.600, v_r2=0.854; \n",
            "E 10\t: loss=146.535, rmse=12.105, r2=0.863; v_loss=240.224, v_rmse=15.499, v_r2=0.779; \n",
            "E 11\t: loss=151.835, rmse=12.322, r2=0.858; v_loss=225.860, v_rmse=15.029, v_r2=0.792; \n",
            "E 12\t: loss=156.146, rmse=12.496, r2=0.854; v_loss=392.014, v_rmse=19.799, v_r2=0.639; \n",
            "E 13\t: loss=143.312, rmse=11.971, r2=0.866; v_loss=522.510, v_rmse=22.858, v_r2=0.519; \n",
            "E 14\t: loss=144.943, rmse=12.039, r2=0.864; v_loss=230.998, v_rmse=15.199, v_r2=0.787; \n",
            "E 15\t: loss=133.207, rmse=11.542, r2=0.875; v_loss=266.659, v_rmse=16.330, v_r2=0.754; \n",
            "E 16\t: loss=133.587, rmse=11.558, r2=0.875; v_loss=206.270, v_rmse=14.362, v_r2=0.810; \n",
            "E 17\t: loss=138.282, rmse=11.759, r2=0.871; v_loss=195.867, v_rmse=13.995, v_r2=0.820; \n",
            "E 18\t: loss=144.583, rmse=12.024, r2=0.865; v_loss=234.814, v_rmse=15.324, v_r2=0.784; \n",
            "E 19\t: loss=148.964, rmse=12.205, r2=0.861; v_loss=249.625, v_rmse=15.800, v_r2=0.770; \n",
            "E 20\t: loss=133.826, rmse=11.568, r2=0.875; v_loss=207.715, v_rmse=14.412, v_r2=0.809; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=70, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=45, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='relu', model__activation3='tanh', model__dropout1=0.677716...learning_rate=0.009128147835708741, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000212181858E0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000021373F82880>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, print_summary=True, validation_split=0.643380976472796, verbose=0),\n",
              "                     clip_y=98, seq_length=58)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM3mTOqS2Hsb",
        "outputId": "fbb151df-6c30-4531-e170-806f74e5cd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8099047216294826"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b3f08b-230e-4387-db6f-2b8414cfb4bf",
        "id": "O8csd7JVzDq-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.724,RMSE=-17.624\n",
            "Finished: 2022-10-17 13:48:04.292748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense"
      ],
      "metadata": {
        "id": "5z_LZWx32lXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pu0gM_uE2lXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.8491646332519348  \n",
        "Test: 0.705\n",
        "```\n",
        "('basemodel__batch_size', 325),\n",
        "('basemodel__epochs', 37),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'sigmoid'),\n",
        "('basemodel__model__dropout1', 0.5999695396702547),\n",
        "('basemodel__model__dropout2', 0.2824705080924561),\n",
        "('basemodel__model__dropout3', 0.5749415465530767),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__layer2', 58),\n",
        "('basemodel__model__layer3', 438),\n",
        "('basemodel__model__learning_rate', 0.007448084633524131),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.10991019995076438),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 93)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRabKU0p2lXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=93\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           model__second_dense=False,\n",
        "                           batch_size=325,\n",
        "                           epochs=37,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__dropout1=0.5999695396702547, \n",
        "                           model__dropout2=0.2824705080924561,\n",
        "                           model__dropout3=0.5749415465530767, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=58, \n",
        "                           model__layer3=438, \n",
        "                           model__learning_rate=0.007448084633524131,\n",
        "                           model__optim=RMSprop,\n",
        "                           validation_split=0.10991019995076438, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "6BGiwksX2lXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc691d6f-f325-474e-84d7-68e26275d900",
        "id": "Yert7PMH2lXI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_12 (Masking)        (None, 93, 22)            0         \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 93, 512)           1095680   \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 93, 512)           0         \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 58)                132472    \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 58)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 438)               25842     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 438)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 439       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,254,433\n",
            "Trainable params: 1,254,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2721.290, rmse=52.166, r2=-0.262; v_loss=4047.846, v_rmse=63.623, v_r2=-0.120; \n",
            "E 2\t: loss=1905.843, rmse=43.656, r2=0.116; v_loss=2401.246, v_rmse=49.003, v_r2=0.336; \n",
            "E 3\t: loss=1101.921, rmse=33.195, r2=0.489; v_loss=1917.062, v_rmse=43.784, v_r2=0.470; \n",
            "E 4\t: loss=887.307, rmse=29.788, r2=0.589; v_loss=1644.637, v_rmse=40.554, v_r2=0.545; \n",
            "E 5\t: loss=834.097, rmse=28.881, r2=0.613; v_loss=1332.995, v_rmse=36.510, v_r2=0.631; \n",
            "E 6\t: loss=713.254, rmse=26.707, r2=0.669; v_loss=1480.933, v_rmse=38.483, v_r2=0.590; \n",
            "E 7\t: loss=629.795, rmse=25.096, r2=0.708; v_loss=867.776, v_rmse=29.458, v_r2=0.760; \n",
            "E 8\t: loss=552.432, rmse=23.504, r2=0.744; v_loss=768.155, v_rmse=27.716, v_r2=0.787; \n",
            "E 9\t: loss=578.573, rmse=24.054, r2=0.732; v_loss=701.640, v_rmse=26.488, v_r2=0.806; \n",
            "E 10\t: loss=523.049, rmse=22.870, r2=0.758; v_loss=713.102, v_rmse=26.704, v_r2=0.803; \n",
            "E 11\t: loss=487.148, rmse=22.071, r2=0.774; v_loss=937.106, v_rmse=30.612, v_r2=0.741; \n",
            "E 12\t: loss=524.140, rmse=22.894, r2=0.757; v_loss=1061.649, v_rmse=32.583, v_r2=0.706; \n",
            "E 13\t: loss=491.818, rmse=22.177, r2=0.772; v_loss=879.516, v_rmse=29.657, v_r2=0.757; \n",
            "E 14\t: loss=464.821, rmse=21.560, r2=0.784; v_loss=638.455, v_rmse=25.268, v_r2=0.823; \n",
            "E 15\t: loss=424.594, rmse=20.606, r2=0.803; v_loss=757.172, v_rmse=27.517, v_r2=0.790; \n",
            "E 16\t: loss=479.048, rmse=21.887, r2=0.778; v_loss=487.134, v_rmse=22.071, v_r2=0.865; \n",
            "E 17\t: loss=461.493, rmse=21.482, r2=0.786; v_loss=429.709, v_rmse=20.729, v_r2=0.881; \n",
            "E 18\t: loss=389.887, rmse=19.746, r2=0.819; v_loss=771.484, v_rmse=27.776, v_r2=0.787; \n",
            "E 19\t: loss=401.155, rmse=20.029, r2=0.814; v_loss=568.866, v_rmse=23.851, v_r2=0.843; \n",
            "E 20\t: loss=381.237, rmse=19.525, r2=0.823; v_loss=628.132, v_rmse=25.063, v_r2=0.826; \n",
            "E 21\t: loss=361.187, rmse=19.005, r2=0.833; v_loss=831.189, v_rmse=28.830, v_r2=0.770; \n",
            "E 22\t: loss=332.259, rmse=18.228, r2=0.846; v_loss=508.256, v_rmse=22.545, v_r2=0.859; \n",
            "E 23\t: loss=321.840, rmse=17.940, r2=0.851; v_loss=518.494, v_rmse=22.770, v_r2=0.857; \n",
            "E 24\t: loss=347.725, rmse=18.647, r2=0.839; v_loss=522.387, v_rmse=22.856, v_r2=0.855; \n",
            "E 25\t: loss=335.911, rmse=18.328, r2=0.844; v_loss=691.583, v_rmse=26.298, v_r2=0.809; \n",
            "E 26\t: loss=329.239, rmse=18.145, r2=0.847; v_loss=397.400, v_rmse=19.935, v_r2=0.890; \n",
            "E 27\t: loss=327.393, rmse=18.094, r2=0.848; v_loss=514.070, v_rmse=22.673, v_r2=0.858; \n",
            "E 28\t: loss=248.485, rmse=15.763, r2=0.885; v_loss=553.334, v_rmse=23.523, v_r2=0.847; \n",
            "E 29\t: loss=277.555, rmse=16.660, r2=0.871; v_loss=693.343, v_rmse=26.331, v_r2=0.808; \n",
            "E 30\t: loss=266.812, rmse=16.334, r2=0.876; v_loss=522.436, v_rmse=22.857, v_r2=0.855; \n",
            "E 31\t: loss=234.167, rmse=15.303, r2=0.891; v_loss=577.956, v_rmse=24.041, v_r2=0.840; \n",
            "E 32\t: loss=269.557, rmse=16.418, r2=0.875; v_loss=597.692, v_rmse=24.448, v_r2=0.835; \n",
            "E 33\t: loss=256.714, rmse=16.022, r2=0.881; v_loss=636.576, v_rmse=25.230, v_r2=0.824; \n",
            "E 34\t: loss=232.965, rmse=15.263, r2=0.892; v_loss=513.629, v_rmse=22.663, v_r2=0.858; \n",
            "E 35\t: loss=219.655, rmse=14.821, r2=0.898; v_loss=496.648, v_rmse=22.286, v_r2=0.863; \n",
            "E 36\t: loss=215.094, rmse=14.666, r2=0.900; v_loss=392.753, v_rmse=19.818, v_r2=0.891; \n",
            "E 37\t: loss=213.731, rmse=14.620, r2=0.901; v_loss=450.947, v_rmse=21.236, v_r2=0.875; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=325, callbacks=[<keras.callbacks.EarlyStopping object at 0x000002120880ADC0>, <keras.callbacks.LambdaCallback object at 0x0000021208813CD0>], epochs=37, model=<function create_model at 0x000002123A5289D0>, model__activation1='tanh', model__activation2='tanh', model__activation3='sigmoid', model__dropout1=0.59...7448084633524131, model__loss='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x00000213797A3340>, <tensorflow_addons.metrics.r_square.RSquare object at 0x00000213797A35E0>], model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, model__second_dense=False, print_summary=True, validation_split=0.10991019995076438, verbose=0),\n",
              "                     seq_length=93)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a462c48-1d66-4722-bd1c-0e92f1a4e93c",
        "id": "rqyVHO5n2lXK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 44 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002137B8040D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "R2=0.690,RMSE=-23.143\n",
            "Finished: 2022-10-17 14:28:43.900502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "DZEmsy2m2lXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.9505741887137583  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 491),\n",
        "('basemodel__epochs', 35),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.269131429819357),\n",
        "('basemodel__model__dropout2', 0.1000488406021388),\n",
        "('basemodel__model__dropout3', 0.3965483901301635),\n",
        "('basemodel__model__layer1', 311),\n",
        "('basemodel__model__layer2', 103),\n",
        "('basemodel__model__layer3', 397),\n",
        "('basemodel__model__learning_rate', 0.004499578015509351),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.24810164977060487),\n",
        "('clip_y', 102),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 82)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5340ZcMG2lXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=82\n",
        "CLIP=102\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           model__second_dense=False,\n",
        "                           batch_size=491,\n",
        "                           epochs=35,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.269131429819357, \n",
        "                           model__dropout2=0.1000488406021388,\n",
        "                           model__dropout3=0.3965483901301635, \n",
        "                           model__layer1=311, \n",
        "                           model__layer2=103, \n",
        "                           model__layer3=397, \n",
        "                           model__learning_rate=0.004499578015509351,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.24810164977060487, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "njy3V5mz2lXL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0c32e8-1aec-40d1-82d1-2e02a111a02b",
        "id": "0ZDq9Rf-2lXM"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 82, 22)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 82, 311)           415496    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 82, 311)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 103)               170980    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 103)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 397)               41288     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 397)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 398       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 628,162\n",
            "Trainable params: 628,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1812.454, rmse=42.573, r2=-0.593; v_loss=1336.743, v_rmse=36.562, v_r2=-0.109; \n",
            "E 2\t: loss=1180.472, rmse=34.358, r2=-0.038; v_loss=1223.409, v_rmse=34.977, v_r2=-0.015; \n",
            "E 3\t: loss=1141.539, rmse=33.787, r2=-0.003; v_loss=1216.463, v_rmse=34.878, v_r2=-0.009; \n",
            "E 4\t: loss=1115.885, rmse=33.405, r2=0.019; v_loss=1192.453, v_rmse=34.532, v_r2=0.011; \n",
            "E 5\t: loss=1062.938, rmse=32.603, r2=0.066; v_loss=1133.818, v_rmse=33.672, v_r2=0.059; \n",
            "E 6\t: loss=952.511, rmse=30.863, r2=0.163; v_loss=976.881, v_rmse=31.255, v_r2=0.190; \n",
            "E 7\t: loss=749.395, rmse=27.375, r2=0.341; v_loss=901.906, v_rmse=30.032, v_r2=0.252; \n",
            "E 8\t: loss=624.638, rmse=24.993, r2=0.451; v_loss=1325.637, v_rmse=36.409, v_r2=-0.100; \n",
            "E 9\t: loss=646.436, rmse=25.425, r2=0.432; v_loss=795.210, v_rmse=28.199, v_r2=0.340; \n",
            "E 10\t: loss=458.717, rmse=21.418, r2=0.597; v_loss=400.681, v_rmse=20.017, v_r2=0.668; \n",
            "E 11\t: loss=370.343, rmse=19.244, r2=0.674; v_loss=450.156, v_rmse=21.217, v_r2=0.627; \n",
            "E 12\t: loss=327.460, rmse=18.096, r2=0.712; v_loss=314.701, v_rmse=17.740, v_r2=0.739; \n",
            "E 13\t: loss=299.003, rmse=17.292, r2=0.737; v_loss=275.673, v_rmse=16.603, v_r2=0.771; \n",
            "E 14\t: loss=559.104, rmse=23.645, r2=0.509; v_loss=1131.292, v_rmse=33.635, v_r2=0.061; \n",
            "E 15\t: loss=584.494, rmse=24.176, r2=0.486; v_loss=457.438, v_rmse=21.388, v_r2=0.620; \n",
            "E 16\t: loss=311.722, rmse=17.656, r2=0.726; v_loss=178.170, v_rmse=13.348, v_r2=0.852; \n",
            "E 17\t: loss=208.566, rmse=14.442, r2=0.817; v_loss=183.753, v_rmse=13.556, v_r2=0.848; \n",
            "E 18\t: loss=232.459, rmse=15.247, r2=0.796; v_loss=180.455, v_rmse=13.433, v_r2=0.850; \n",
            "E 19\t: loss=136.378, rmse=11.678, r2=0.880; v_loss=149.703, v_rmse=12.235, v_r2=0.876; \n",
            "E 20\t: loss=141.896, rmse=11.912, r2=0.875; v_loss=85.164, v_rmse=9.228, v_r2=0.929; \n",
            "E 21\t: loss=94.380, rmse=9.715, r2=0.917; v_loss=73.771, v_rmse=8.589, v_r2=0.939; \n",
            "E 22\t: loss=113.766, rmse=10.666, r2=0.900; v_loss=68.343, v_rmse=8.267, v_r2=0.943; \n",
            "E 23\t: loss=87.929, rmse=9.377, r2=0.923; v_loss=90.665, v_rmse=9.522, v_r2=0.925; \n",
            "E 24\t: loss=84.789, rmse=9.208, r2=0.925; v_loss=58.674, v_rmse=7.660, v_r2=0.951; \n",
            "E 25\t: loss=76.191, rmse=8.729, r2=0.933; v_loss=62.795, v_rmse=7.924, v_r2=0.948; \n",
            "E 26\t: loss=73.703, rmse=8.585, r2=0.935; v_loss=73.227, v_rmse=8.557, v_r2=0.939; \n",
            "E 27\t: loss=70.851, rmse=8.417, r2=0.938; v_loss=68.982, v_rmse=8.306, v_r2=0.943; \n",
            "E 28\t: loss=74.988, rmse=8.660, r2=0.934; v_loss=59.098, v_rmse=7.688, v_r2=0.951; \n",
            "E 29\t: loss=72.659, rmse=8.524, r2=0.936; v_loss=57.653, v_rmse=7.593, v_r2=0.952; \n",
            "E 30\t: loss=63.075, rmse=7.942, r2=0.945; v_loss=58.422, v_rmse=7.643, v_r2=0.952; \n",
            "E 31\t: loss=63.946, rmse=7.997, r2=0.944; v_loss=50.855, v_rmse=7.131, v_r2=0.958; \n",
            "E 32\t: loss=68.927, rmse=8.302, r2=0.939; v_loss=76.561, v_rmse=8.750, v_r2=0.936; \n",
            "E 33\t: loss=65.500, rmse=8.093, r2=0.942; v_loss=51.903, v_rmse=7.204, v_r2=0.957; \n",
            "E 34\t: loss=59.777, rmse=7.732, r2=0.947; v_loss=52.885, v_rmse=7.272, v_r2=0.956; \n",
            "E 35\t: loss=58.093, rmse=7.622, r2=0.949; v_loss=51.581, v_rmse=7.182, v_r2=0.957; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=491, callbacks=[<keras.callbacks.EarlyStopping object at 0x0000016C2080D040>, <keras.callbacks.LambdaCallback object at 0x0000016C20814D30>], epochs=35, model=<function create_model at 0x0000016C2087EEE0>, model__activation1='tanh', model__activation2='tanh', model__activation3='selu', model__dropout1=0.26913...s='mse', model__metrics=[<keras.metrics.RootMeanSquaredError object at 0x0000016C58CEA7C0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x0000016C4A313190>], model__optim=<class 'keras.optimizer_v2.adam.Adam'>, model__second_dense=False, print_summary=True, validation_split=0.24810164977060487, verbose=0),\n",
              "                     clip_y=102, scaler=MinMaxScaler(), seq_length=82)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b15821e-f4bc-4689-ff13-9ca51105ee56",
        "id": "GsrsS-Ga2lXO"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.944,RMSE=-8.219\n",
            "Finished: 2022-11-03 08:26:57.822115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJrVr_AmPIe0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}