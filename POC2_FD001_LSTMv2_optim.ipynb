{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "Q4QwyfhXs_hv",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf",
        "nTPBH5fg_sFd",
        "ppByl3wN_W05"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNUn6mvfLbuhZC9WCd6WGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_LSTMv2_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "6abbef15-6454-4042-ad72-135fe70c2aa9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5082f75d-ebc8-4623-e97e-3d1b60cb11b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "id": "tlp572nXopEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee9afef-a9ed-4046-be10-83e715e6d061"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "id": "-yRYxz2hh4xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "dcdbf487-c5e8-4fbc-bad4-b132c3078f73"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "4wtvRNsfuUwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2077c021-a27c-40e3-f1de-0d6b8b4fbb25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "id": "onw4pCwZy-1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "86df76e0-e14b-4171-ec7a-a45c7a0ae5cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "id": "lmFKjQaeip1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "11ce77d3-09bf-4489-c7af-74c408b2be9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "fuAnHn4GxzwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "70e5d74e-3c8f-4bef-d3cc-9b1ff3b36db2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "26hK4VWkx1R7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "04f6695f-6d8e-4332-c50f-b432c1f18819"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, dropout=0.1, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "Jowfppg9HG3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "cxz0nz9mHJ2v"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h LSTM-1\n",
        "# ~1h30min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        # \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\n",
        "                                                      \"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        # \"basemodel__model__layer3\": Integer(16,512),\n",
        "        # \"basemodel__model__activation3\": Categorical([\"tanh\"]),\n",
        "        # \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI-MbGPrHsB0",
        "outputId": "f795e5d5-cf03-43bd-d5c9-593be3ca81e3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=246, basemodel__epochs=16, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.2782692076165699, basemodel__model__dropout2=0.7130615682331511, basemodel__model__layer1=129, basemodel__model__layer2=456, basemodel__model__learning_rate=0.005130424597861229, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.22713226169872008, scaler=MinMaxScaler(), seq_length=70;, score=0.529 total time=  17.7s\n",
            "[CV 2/3] END basemodel__batch_size=246, basemodel__epochs=16, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.2782692076165699, basemodel__model__dropout2=0.7130615682331511, basemodel__model__layer1=129, basemodel__model__layer2=456, basemodel__model__learning_rate=0.005130424597861229, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.22713226169872008, scaler=MinMaxScaler(), seq_length=70;, score=0.554 total time=  16.8s\n",
            "[CV 3/3] END basemodel__batch_size=246, basemodel__epochs=16, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.2782692076165699, basemodel__model__dropout2=0.7130615682331511, basemodel__model__layer1=129, basemodel__model__layer2=456, basemodel__model__learning_rate=0.005130424597861229, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.22713226169872008, scaler=MinMaxScaler(), seq_length=70;, score=0.514 total time=  17.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=362, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.3292616720560928, basemodel__model__dropout2=0.3759009411524562, basemodel__model__layer1=228, basemodel__model__layer2=460, basemodel__model__learning_rate=0.001000041013033688, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8101116138022078, scaler=StandardScaler(), seq_length=50;, score=0.689 total time=  16.6s\n",
            "[CV 2/3] END basemodel__batch_size=362, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.3292616720560928, basemodel__model__dropout2=0.3759009411524562, basemodel__model__layer1=228, basemodel__model__layer2=460, basemodel__model__learning_rate=0.001000041013033688, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8101116138022078, scaler=StandardScaler(), seq_length=50;, score=0.606 total time=  16.4s\n",
            "[CV 3/3] END basemodel__batch_size=362, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.3292616720560928, basemodel__model__dropout2=0.3759009411524562, basemodel__model__layer1=228, basemodel__model__layer2=460, basemodel__model__learning_rate=0.001000041013033688, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8101116138022078, scaler=StandardScaler(), seq_length=50;, score=0.310 total time=  17.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=311, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8106103972403556, basemodel__model__dropout2=0.8666426015446991, basemodel__model__layer1=495, basemodel__model__layer2=500, basemodel__model__learning_rate=0.0022596695210593976, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.17401349098654162, scaler=StandardScaler(), seq_length=64;, score=0.804 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=311, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8106103972403556, basemodel__model__dropout2=0.8666426015446991, basemodel__model__layer1=495, basemodel__model__layer2=500, basemodel__model__learning_rate=0.0022596695210593976, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.17401349098654162, scaler=StandardScaler(), seq_length=64;, score=0.829 total time=  58.3s\n",
            "[CV 3/3] END basemodel__batch_size=311, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8106103972403556, basemodel__model__dropout2=0.8666426015446991, basemodel__model__layer1=495, basemodel__model__layer2=500, basemodel__model__learning_rate=0.0022596695210593976, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.17401349098654162, scaler=StandardScaler(), seq_length=64;, score=0.792 total time= 1.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=471, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.15658997035830186, basemodel__model__dropout2=0.2252800385673941, basemodel__model__layer1=36, basemodel__model__layer2=88, basemodel__model__learning_rate=0.0028545653370614077, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7697463622620817, scaler=MinMaxScaler(), seq_length=55;, score=0.445 total time=  17.2s\n",
            "[CV 2/3] END basemodel__batch_size=471, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.15658997035830186, basemodel__model__dropout2=0.2252800385673941, basemodel__model__layer1=36, basemodel__model__layer2=88, basemodel__model__learning_rate=0.0028545653370614077, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7697463622620817, scaler=MinMaxScaler(), seq_length=55;, score=0.448 total time=  16.9s\n",
            "[CV 3/3] END basemodel__batch_size=471, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.15658997035830186, basemodel__model__dropout2=0.2252800385673941, basemodel__model__layer1=36, basemodel__model__layer2=88, basemodel__model__learning_rate=0.0028545653370614077, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7697463622620817, scaler=MinMaxScaler(), seq_length=55;, score=0.366 total time=  16.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=318, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7300805100794876, basemodel__model__dropout2=0.13645666834244718, basemodel__model__layer1=411, basemodel__model__layer2=235, basemodel__model__learning_rate=0.007839003952473613, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3809752143672337, scaler=MinMaxScaler(), seq_length=47;, score=-0.011 total time=  19.1s\n",
            "[CV 2/3] END basemodel__batch_size=318, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7300805100794876, basemodel__model__dropout2=0.13645666834244718, basemodel__model__layer1=411, basemodel__model__layer2=235, basemodel__model__learning_rate=0.007839003952473613, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3809752143672337, scaler=MinMaxScaler(), seq_length=47;, score=-0.002 total time=  19.0s\n",
            "[CV 3/3] END basemodel__batch_size=318, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7300805100794876, basemodel__model__dropout2=0.13645666834244718, basemodel__model__layer1=411, basemodel__model__layer2=235, basemodel__model__learning_rate=0.007839003952473613, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3809752143672337, scaler=MinMaxScaler(), seq_length=47;, score=-0.008 total time=  19.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=117, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.19136464170366607, basemodel__model__dropout2=0.23326975949346906, basemodel__model__layer1=69, basemodel__model__layer2=173, basemodel__model__learning_rate=0.0024779565585648874, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.828703813064561, scaler=MinMaxScaler(), seq_length=90;, score=0.208 total time=  10.9s\n",
            "[CV 2/3] END basemodel__batch_size=117, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.19136464170366607, basemodel__model__dropout2=0.23326975949346906, basemodel__model__layer1=69, basemodel__model__layer2=173, basemodel__model__learning_rate=0.0024779565585648874, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.828703813064561, scaler=MinMaxScaler(), seq_length=90;, score=0.182 total time=  10.4s\n",
            "[CV 3/3] END basemodel__batch_size=117, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.19136464170366607, basemodel__model__dropout2=0.23326975949346906, basemodel__model__layer1=69, basemodel__model__layer2=173, basemodel__model__learning_rate=0.0024779565585648874, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.828703813064561, scaler=MinMaxScaler(), seq_length=90;, score=0.229 total time=  10.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=336, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.2550650721434745, basemodel__model__dropout2=0.775327743380955, basemodel__model__layer1=246, basemodel__model__layer2=506, basemodel__model__learning_rate=0.004287296036842112, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.34608214393743225, scaler=MinMaxScaler(), seq_length=49;, score=0.679 total time=  19.1s\n",
            "[CV 2/3] END basemodel__batch_size=336, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.2550650721434745, basemodel__model__dropout2=0.775327743380955, basemodel__model__layer1=246, basemodel__model__layer2=506, basemodel__model__learning_rate=0.004287296036842112, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.34608214393743225, scaler=MinMaxScaler(), seq_length=49;, score=0.646 total time=  18.7s\n",
            "[CV 3/3] END basemodel__batch_size=336, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.2550650721434745, basemodel__model__dropout2=0.775327743380955, basemodel__model__layer1=246, basemodel__model__layer2=506, basemodel__model__learning_rate=0.004287296036842112, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.34608214393743225, scaler=MinMaxScaler(), seq_length=49;, score=0.498 total time=  18.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=375, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.4547409343807598, basemodel__model__dropout2=0.35967416816171316, basemodel__model__layer1=467, basemodel__model__layer2=303, basemodel__model__learning_rate=0.005686652128242183, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.33819490584327433, scaler=MinMaxScaler(), seq_length=71;, score=-0.019 total time=  30.1s\n",
            "[CV 2/3] END basemodel__batch_size=375, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.4547409343807598, basemodel__model__dropout2=0.35967416816171316, basemodel__model__layer1=467, basemodel__model__layer2=303, basemodel__model__learning_rate=0.005686652128242183, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.33819490584327433, scaler=MinMaxScaler(), seq_length=71;, score=-0.000 total time=  38.0s\n",
            "[CV 3/3] END basemodel__batch_size=375, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.4547409343807598, basemodel__model__dropout2=0.35967416816171316, basemodel__model__layer1=467, basemodel__model__layer2=303, basemodel__model__learning_rate=0.005686652128242183, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.33819490584327433, scaler=MinMaxScaler(), seq_length=71;, score=-0.009 total time=  37.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=476, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.8310049074746814, basemodel__model__dropout2=0.7115754069258861, basemodel__model__layer1=270, basemodel__model__layer2=467, basemodel__model__learning_rate=0.0021045240530885704, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.18895564570687998, scaler=MinMaxScaler(), seq_length=71;, score=0.362 total time=  13.0s\n",
            "[CV 2/3] END basemodel__batch_size=476, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.8310049074746814, basemodel__model__dropout2=0.7115754069258861, basemodel__model__layer1=270, basemodel__model__layer2=467, basemodel__model__learning_rate=0.0021045240530885704, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.18895564570687998, scaler=MinMaxScaler(), seq_length=71;, score=0.364 total time=  12.9s\n",
            "[CV 3/3] END basemodel__batch_size=476, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.8310049074746814, basemodel__model__dropout2=0.7115754069258861, basemodel__model__layer1=270, basemodel__model__layer2=467, basemodel__model__learning_rate=0.0021045240530885704, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.18895564570687998, scaler=MinMaxScaler(), seq_length=71;, score=0.378 total time=  12.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=324, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.2839830277773371, basemodel__model__dropout2=0.11095054334815374, basemodel__model__layer1=205, basemodel__model__layer2=264, basemodel__model__learning_rate=0.0010164192584030938, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3796899534974202, scaler=StandardScaler(), seq_length=46;, score=0.652 total time=  35.8s\n",
            "[CV 2/3] END basemodel__batch_size=324, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.2839830277773371, basemodel__model__dropout2=0.11095054334815374, basemodel__model__layer1=205, basemodel__model__layer2=264, basemodel__model__learning_rate=0.0010164192584030938, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3796899534974202, scaler=StandardScaler(), seq_length=46;, score=0.725 total time=  30.2s\n",
            "[CV 3/3] END basemodel__batch_size=324, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.2839830277773371, basemodel__model__dropout2=0.11095054334815374, basemodel__model__layer1=205, basemodel__model__layer2=264, basemodel__model__learning_rate=0.0010164192584030938, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3796899534974202, scaler=StandardScaler(), seq_length=46;, score=0.607 total time=  36.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.10000000000000005, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=-0.903 total time=   7.3s\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.10000000000000005, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=-0.981 total time=   7.0s\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.10000000000000005, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=-1.275 total time=   7.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=30;, score=-0.667 total time= 4.0min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=30;, score=-0.941 total time= 4.1min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=30;, score=-0.657 total time= 4.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=299, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5082392510207336, basemodel__model__dropout2=0.6551574325939005, basemodel__model__layer1=322, basemodel__model__layer2=360, basemodel__model__learning_rate=0.0025334759378577956, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=53;, score=0.810 total time=  51.7s\n",
            "[CV 2/3] END basemodel__batch_size=299, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5082392510207336, basemodel__model__dropout2=0.6551574325939005, basemodel__model__layer1=322, basemodel__model__layer2=360, basemodel__model__learning_rate=0.0025334759378577956, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=53;, score=0.793 total time=  58.4s\n",
            "[CV 3/3] END basemodel__batch_size=299, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5082392510207336, basemodel__model__dropout2=0.6551574325939005, basemodel__model__layer1=322, basemodel__model__layer2=360, basemodel__model__learning_rate=0.0025334759378577956, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=53;, score=0.805 total time=  46.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=316, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.002524276971826806, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.16827884566147688, scaler=MinMaxScaler(), seq_length=95;, score=0.154 total time=   9.8s\n",
            "[CV 2/3] END basemodel__batch_size=316, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.002524276971826806, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.16827884566147688, scaler=MinMaxScaler(), seq_length=95;, score=0.115 total time=   9.5s\n",
            "[CV 3/3] END basemodel__batch_size=316, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.002524276971826806, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.16827884566147688, scaler=MinMaxScaler(), seq_length=95;, score=0.167 total time=   9.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=30;, score=0.651 total time= 1.3min\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=30;, score=0.616 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=30;, score=0.548 total time= 1.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=384, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7954607138884567, basemodel__model__dropout2=0.655775371283409, basemodel__model__layer1=314, basemodel__model__layer2=410, basemodel__model__learning_rate=0.0007715289723159044, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11123705752939014, scaler=StandardScaler(), seq_length=42;, score=0.723 total time=  53.3s\n",
            "[CV 2/3] END basemodel__batch_size=384, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7954607138884567, basemodel__model__dropout2=0.655775371283409, basemodel__model__layer1=314, basemodel__model__layer2=410, basemodel__model__learning_rate=0.0007715289723159044, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11123705752939014, scaler=StandardScaler(), seq_length=42;, score=0.766 total time=  52.1s\n",
            "[CV 3/3] END basemodel__batch_size=384, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7954607138884567, basemodel__model__dropout2=0.655775371283409, basemodel__model__layer1=314, basemodel__model__layer2=410, basemodel__model__learning_rate=0.0007715289723159044, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11123705752939014, scaler=StandardScaler(), seq_length=42;, score=0.655 total time=  53.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=292, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8946527003099772, basemodel__model__dropout2=0.8978533161789427, basemodel__model__layer1=512, basemodel__model__layer2=492, basemodel__model__learning_rate=0.0019549497180228912, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11247698328475338, scaler=StandardScaler(), seq_length=67;, score=0.758 total time= 1.6min\n",
            "[CV 2/3] END basemodel__batch_size=292, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8946527003099772, basemodel__model__dropout2=0.8978533161789427, basemodel__model__layer1=512, basemodel__model__layer2=492, basemodel__model__learning_rate=0.0019549497180228912, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11247698328475338, scaler=StandardScaler(), seq_length=67;, score=0.841 total time= 1.8min\n",
            "[CV 3/3] END basemodel__batch_size=292, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8946527003099772, basemodel__model__dropout2=0.8978533161789427, basemodel__model__layer1=512, basemodel__model__layer2=492, basemodel__model__learning_rate=0.0019549497180228912, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11247698328475338, scaler=StandardScaler(), seq_length=67;, score=0.794 total time= 1.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=322, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7654566644965795, basemodel__model__dropout2=0.8918762059361097, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0029537001282117126, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.16767728524352427, scaler=StandardScaler(), seq_length=63;, score=0.762 total time= 1.2min\n",
            "[CV 2/3] END basemodel__batch_size=322, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7654566644965795, basemodel__model__dropout2=0.8918762059361097, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0029537001282117126, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.16767728524352427, scaler=StandardScaler(), seq_length=63;, score=0.820 total time= 1.0min\n",
            "[CV 3/3] END basemodel__batch_size=322, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7654566644965795, basemodel__model__dropout2=0.8918762059361097, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0029537001282117126, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.16767728524352427, scaler=StandardScaler(), seq_length=63;, score=0.814 total time= 1.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=239, basemodel__epochs=45, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8360008606718795, basemodel__model__dropout2=0.8326359552620336, basemodel__model__layer1=493, basemodel__model__layer2=469, basemodel__model__learning_rate=0.0013568819509124186, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1967801723709445, scaler=StandardScaler(), seq_length=74;, score=0.811 total time= 1.7min\n",
            "[CV 2/3] END basemodel__batch_size=239, basemodel__epochs=45, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8360008606718795, basemodel__model__dropout2=0.8326359552620336, basemodel__model__layer1=493, basemodel__model__layer2=469, basemodel__model__learning_rate=0.0013568819509124186, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1967801723709445, scaler=StandardScaler(), seq_length=74;, score=0.864 total time= 1.2min\n",
            "[CV 3/3] END basemodel__batch_size=239, basemodel__epochs=45, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8360008606718795, basemodel__model__dropout2=0.8326359552620336, basemodel__model__layer1=493, basemodel__model__layer2=469, basemodel__model__learning_rate=0.0013568819509124186, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1967801723709445, scaler=StandardScaler(), seq_length=74;, score=0.882 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=168, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6771114651028548, basemodel__model__dropout2=0.820490704437118, basemodel__model__layer1=512, basemodel__model__layer2=449, basemodel__model__learning_rate=0.0022337180446465794, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23921110022140304, scaler=StandardScaler(), seq_length=83;, score=0.844 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=168, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6771114651028548, basemodel__model__dropout2=0.820490704437118, basemodel__model__layer1=512, basemodel__model__layer2=449, basemodel__model__learning_rate=0.0022337180446465794, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23921110022140304, scaler=StandardScaler(), seq_length=83;, score=0.859 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=168, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6771114651028548, basemodel__model__dropout2=0.820490704437118, basemodel__model__layer1=512, basemodel__model__layer2=449, basemodel__model__learning_rate=0.0022337180446465794, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23921110022140304, scaler=StandardScaler(), seq_length=83;, score=0.804 total time= 1.9min\n",
            "Finished: 2022-10-14 15:46:45.820176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SSmZxJKlUNFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0e51e6-8776-4927-eb38-db009973ecbc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8521617501513421\n",
            "OrderedDict([('basemodel__batch_size', 239), ('basemodel__epochs', 45), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'relu'), ('basemodel__model__dropout1', 0.8360008606718795), ('basemodel__model__dropout2', 0.8326359552620336), ('basemodel__model__layer1', 493), ('basemodel__model__layer2', 469), ('basemodel__model__learning_rate', 0.0013568819509124186), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__validation_split', 0.1967801723709445), ('scaler', StandardScaler()), ('seq_length', 74)])\n",
            "Finished: 2022-10-14 15:46:46.687155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "0HUnMESRVitn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "47d28001-83b9-4886-ad84-aa3e288d54b6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-14 15:46:46.716151\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8QiZ9pWmSb0",
        "outputId": "ce962afc-8f63-4091-a786-319dd014d2d6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 239),\n",
              "             ('basemodel__epochs', 45),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'relu'),\n",
              "             ('basemodel__model__dropout1', 0.8360008606718795),\n",
              "             ('basemodel__model__dropout2', 0.8326359552620336),\n",
              "             ('basemodel__model__layer1', 493),\n",
              "             ('basemodel__model__layer2', 469),\n",
              "             ('basemodel__model__learning_rate', 0.0013568819509124186),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__validation_split', 0.1967801723709445),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 74)])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=129\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5AEsyUg3tqcf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h LSTM-1\n",
        "# ~1h30min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\n",
        "                                                      \"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        # \"basemodel__model__layer3\": Integer(16,512),\n",
        "        # \"basemodel__model__activation3\": Categorical([\"tanh\"]),\n",
        "        # \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eea4490-cb48-4066-c8a4-2c86ff10d861",
        "id": "X0Jwj6hxtqch"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=356, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.7287998226914775, basemodel__model__dropout2=0.7846037714235101, basemodel__model__layer1=114, basemodel__model__layer2=104, basemodel__model__learning_rate=0.005690598904542505, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8712913250344952, clip_y=113, scaler=StandardScaler(), seq_length=59;, score=0.744 total time=  18.3s\n",
            "[CV 2/3] END basemodel__batch_size=356, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.7287998226914775, basemodel__model__dropout2=0.7846037714235101, basemodel__model__layer1=114, basemodel__model__layer2=104, basemodel__model__learning_rate=0.005690598904542505, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8712913250344952, clip_y=113, scaler=StandardScaler(), seq_length=59;, score=0.616 total time=  20.1s\n",
            "[CV 3/3] END basemodel__batch_size=356, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.7287998226914775, basemodel__model__dropout2=0.7846037714235101, basemodel__model__layer1=114, basemodel__model__layer2=104, basemodel__model__learning_rate=0.005690598904542505, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8712913250344952, clip_y=113, scaler=StandardScaler(), seq_length=59;, score=0.680 total time=  21.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=370, basemodel__epochs=31, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.6095488418131296, basemodel__model__dropout2=0.3950016878944115, basemodel__model__layer1=341, basemodel__model__layer2=99, basemodel__model__learning_rate=0.004128329086635118, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7626250244557428, clip_y=86, scaler=MinMaxScaler(), seq_length=89;, score=0.273 total time=  13.8s\n",
            "[CV 2/3] END basemodel__batch_size=370, basemodel__epochs=31, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.6095488418131296, basemodel__model__dropout2=0.3950016878944115, basemodel__model__layer1=341, basemodel__model__layer2=99, basemodel__model__learning_rate=0.004128329086635118, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7626250244557428, clip_y=86, scaler=MinMaxScaler(), seq_length=89;, score=0.098 total time=  22.2s\n",
            "[CV 3/3] END basemodel__batch_size=370, basemodel__epochs=31, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.6095488418131296, basemodel__model__dropout2=0.3950016878944115, basemodel__model__layer1=341, basemodel__model__layer2=99, basemodel__model__learning_rate=0.004128329086635118, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7626250244557428, clip_y=86, scaler=MinMaxScaler(), seq_length=89;, score=0.253 total time=  21.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=148, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8833280175953142, basemodel__model__dropout2=0.46021652974404037, basemodel__model__layer1=480, basemodel__model__layer2=476, basemodel__model__learning_rate=0.009761079620178737, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.42973179851735166, clip_y=129, scaler=MinMaxScaler(), seq_length=61;, score=0.066 total time=  46.7s\n",
            "[CV 2/3] END basemodel__batch_size=148, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8833280175953142, basemodel__model__dropout2=0.46021652974404037, basemodel__model__layer1=480, basemodel__model__layer2=476, basemodel__model__learning_rate=0.009761079620178737, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.42973179851735166, clip_y=129, scaler=MinMaxScaler(), seq_length=61;, score=0.001 total time=  46.2s\n",
            "[CV 3/3] END basemodel__batch_size=148, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8833280175953142, basemodel__model__dropout2=0.46021652974404037, basemodel__model__layer1=480, basemodel__model__layer2=476, basemodel__model__learning_rate=0.009761079620178737, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.42973179851735166, clip_y=129, scaler=MinMaxScaler(), seq_length=61;, score=-0.166 total time=  46.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=125, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6625431508854215, basemodel__model__dropout2=0.7466428206030936, basemodel__model__layer1=272, basemodel__model__layer2=488, basemodel__model__learning_rate=0.0009096369859532438, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8361529928300497, clip_y=105, scaler=StandardScaler(), seq_length=57;, score=0.830 total time=  21.4s\n",
            "[CV 2/3] END basemodel__batch_size=125, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6625431508854215, basemodel__model__dropout2=0.7466428206030936, basemodel__model__layer1=272, basemodel__model__layer2=488, basemodel__model__learning_rate=0.0009096369859532438, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8361529928300497, clip_y=105, scaler=StandardScaler(), seq_length=57;, score=0.603 total time=  21.1s\n",
            "[CV 3/3] END basemodel__batch_size=125, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6625431508854215, basemodel__model__dropout2=0.7466428206030936, basemodel__model__layer1=272, basemodel__model__layer2=488, basemodel__model__learning_rate=0.0009096369859532438, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8361529928300497, clip_y=105, scaler=StandardScaler(), seq_length=57;, score=0.634 total time=  21.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=167, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.713506642014669, basemodel__model__dropout2=0.21863146978924006, basemodel__model__layer1=40, basemodel__model__layer2=229, basemodel__model__learning_rate=0.005835234626150986, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7943460717606484, clip_y=93, scaler=MinMaxScaler(), seq_length=69;, score=0.556 total time=  21.6s\n",
            "[CV 2/3] END basemodel__batch_size=167, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.713506642014669, basemodel__model__dropout2=0.21863146978924006, basemodel__model__layer1=40, basemodel__model__layer2=229, basemodel__model__learning_rate=0.005835234626150986, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7943460717606484, clip_y=93, scaler=MinMaxScaler(), seq_length=69;, score=0.599 total time=  25.4s\n",
            "[CV 3/3] END basemodel__batch_size=167, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.713506642014669, basemodel__model__dropout2=0.21863146978924006, basemodel__model__layer1=40, basemodel__model__layer2=229, basemodel__model__learning_rate=0.005835234626150986, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7943460717606484, clip_y=93, scaler=MinMaxScaler(), seq_length=69;, score=0.606 total time=  25.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=379, basemodel__epochs=14, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.8263455630179263, basemodel__model__dropout2=0.8336882212501703, basemodel__model__layer1=143, basemodel__model__layer2=212, basemodel__model__learning_rate=0.0021395974679037544, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2741742309666515, clip_y=134, scaler=MinMaxScaler(), seq_length=60;, score=0.326 total time=  13.6s\n",
            "[CV 2/3] END basemodel__batch_size=379, basemodel__epochs=14, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.8263455630179263, basemodel__model__dropout2=0.8336882212501703, basemodel__model__layer1=143, basemodel__model__layer2=212, basemodel__model__learning_rate=0.0021395974679037544, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2741742309666515, clip_y=134, scaler=MinMaxScaler(), seq_length=60;, score=0.378 total time=  13.5s\n",
            "[CV 3/3] END basemodel__batch_size=379, basemodel__epochs=14, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.8263455630179263, basemodel__model__dropout2=0.8336882212501703, basemodel__model__layer1=143, basemodel__model__layer2=212, basemodel__model__learning_rate=0.0021395974679037544, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2741742309666515, clip_y=134, scaler=MinMaxScaler(), seq_length=60;, score=0.276 total time=  13.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=227, basemodel__epochs=14, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.1551097491553966, basemodel__model__dropout2=0.6141774882768062, basemodel__model__layer1=268, basemodel__model__layer2=368, basemodel__model__learning_rate=0.002915045532549771, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6520544723314255, clip_y=128, scaler=MinMaxScaler(), seq_length=65;, score=0.727 total time=  17.3s\n",
            "[CV 2/3] END basemodel__batch_size=227, basemodel__epochs=14, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.1551097491553966, basemodel__model__dropout2=0.6141774882768062, basemodel__model__layer1=268, basemodel__model__layer2=368, basemodel__model__learning_rate=0.002915045532549771, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6520544723314255, clip_y=128, scaler=MinMaxScaler(), seq_length=65;, score=0.709 total time=  17.8s\n",
            "[CV 3/3] END basemodel__batch_size=227, basemodel__epochs=14, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.1551097491553966, basemodel__model__dropout2=0.6141774882768062, basemodel__model__layer1=268, basemodel__model__layer2=368, basemodel__model__learning_rate=0.002915045532549771, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6520544723314255, clip_y=128, scaler=MinMaxScaler(), seq_length=65;, score=0.628 total time=  17.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=284, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.28952391919477416, basemodel__model__dropout2=0.525837539597043, basemodel__model__layer1=401, basemodel__model__layer2=27, basemodel__model__learning_rate=0.001899465087711235, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.6287010740221957, clip_y=88, scaler=MinMaxScaler(), seq_length=72;, score=0.447 total time=  55.8s\n",
            "[CV 2/3] END basemodel__batch_size=284, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.28952391919477416, basemodel__model__dropout2=0.525837539597043, basemodel__model__layer1=401, basemodel__model__layer2=27, basemodel__model__learning_rate=0.001899465087711235, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.6287010740221957, clip_y=88, scaler=MinMaxScaler(), seq_length=72;, score=0.548 total time=  41.5s\n",
            "[CV 3/3] END basemodel__batch_size=284, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.28952391919477416, basemodel__model__dropout2=0.525837539597043, basemodel__model__layer1=401, basemodel__model__layer2=27, basemodel__model__learning_rate=0.001899465087711235, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.6287010740221957, clip_y=88, scaler=MinMaxScaler(), seq_length=72;, score=0.587 total time=  55.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=205, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7202857201564918, basemodel__model__dropout2=0.6368146332829594, basemodel__model__layer1=442, basemodel__model__layer2=114, basemodel__model__learning_rate=0.006637924350375669, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4784383646433097, clip_y=88, scaler=MinMaxScaler(), seq_length=47;, score=0.156 total time= 1.3min\n",
            "[CV 2/3] END basemodel__batch_size=205, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7202857201564918, basemodel__model__dropout2=0.6368146332829594, basemodel__model__layer1=442, basemodel__model__layer2=114, basemodel__model__learning_rate=0.006637924350375669, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4784383646433097, clip_y=88, scaler=MinMaxScaler(), seq_length=47;, score=0.800 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=205, basemodel__epochs=48, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7202857201564918, basemodel__model__dropout2=0.6368146332829594, basemodel__model__layer1=442, basemodel__model__layer2=114, basemodel__model__learning_rate=0.006637924350375669, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4784383646433097, clip_y=88, scaler=MinMaxScaler(), seq_length=47;, score=0.460 total time=  55.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=270, basemodel__epochs=26, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.734464863271174, basemodel__model__dropout2=0.8883292052251093, basemodel__model__layer1=92, basemodel__model__layer2=351, basemodel__model__learning_rate=0.003001005537925642, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.26855829794867137, clip_y=125, scaler=StandardScaler(), seq_length=71;, score=0.733 total time=  20.4s\n",
            "[CV 2/3] END basemodel__batch_size=270, basemodel__epochs=26, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.734464863271174, basemodel__model__dropout2=0.8883292052251093, basemodel__model__layer1=92, basemodel__model__layer2=351, basemodel__model__learning_rate=0.003001005537925642, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.26855829794867137, clip_y=125, scaler=StandardScaler(), seq_length=71;, score=0.880 total time=  20.4s\n",
            "[CV 3/3] END basemodel__batch_size=270, basemodel__epochs=26, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.734464863271174, basemodel__model__dropout2=0.8883292052251093, basemodel__model__layer1=92, basemodel__model__layer2=351, basemodel__model__learning_rate=0.003001005537925642, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.26855829794867137, clip_y=125, scaler=StandardScaler(), seq_length=71;, score=0.871 total time=  20.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=218, basemodel__epochs=15, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.7310157500201289, basemodel__model__dropout2=0.9, basemodel__model__layer1=97, basemodel__model__layer2=478, basemodel__model__learning_rate=0.001569393350920775, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=129, scaler=StandardScaler(), seq_length=75;, score=0.897 total time=  17.4s\n",
            "[CV 2/3] END basemodel__batch_size=218, basemodel__epochs=15, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.7310157500201289, basemodel__model__dropout2=0.9, basemodel__model__layer1=97, basemodel__model__layer2=478, basemodel__model__learning_rate=0.001569393350920775, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=129, scaler=StandardScaler(), seq_length=75;, score=0.861 total time=  17.4s\n",
            "[CV 3/3] END basemodel__batch_size=218, basemodel__epochs=15, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.7310157500201289, basemodel__model__dropout2=0.9, basemodel__model__layer1=97, basemodel__model__layer2=478, basemodel__model__learning_rate=0.001569393350920775, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=129, scaler=StandardScaler(), seq_length=75;, score=0.883 total time=  17.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=188, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7178565888693615, basemodel__model__dropout2=0.5147831724273324, basemodel__model__layer1=123, basemodel__model__layer2=390, basemodel__model__learning_rate=0.002332642908654127, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.22009879780005423, clip_y=140, scaler=StandardScaler(), seq_length=86;, score=0.863 total time=  18.7s\n",
            "[CV 2/3] END basemodel__batch_size=188, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7178565888693615, basemodel__model__dropout2=0.5147831724273324, basemodel__model__layer1=123, basemodel__model__layer2=390, basemodel__model__learning_rate=0.002332642908654127, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.22009879780005423, clip_y=140, scaler=StandardScaler(), seq_length=86;, score=0.856 total time=  18.6s\n",
            "[CV 3/3] END basemodel__batch_size=188, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7178565888693615, basemodel__model__dropout2=0.5147831724273324, basemodel__model__layer1=123, basemodel__model__layer2=390, basemodel__model__learning_rate=0.002332642908654127, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.22009879780005423, clip_y=140, scaler=StandardScaler(), seq_length=86;, score=0.835 total time=  18.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=237, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7644475973778535, basemodel__model__dropout2=0.20728861733139817, basemodel__model__layer1=512, basemodel__model__layer2=398, basemodel__model__learning_rate=0.00202127720584082, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=140, scaler=StandardScaler(), seq_length=100;, score=-0.776 total time=   9.3s\n",
            "[CV 2/3] END basemodel__batch_size=237, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7644475973778535, basemodel__model__dropout2=0.20728861733139817, basemodel__model__layer1=512, basemodel__model__layer2=398, basemodel__model__learning_rate=0.00202127720584082, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=140, scaler=StandardScaler(), seq_length=100;, score=-0.716 total time=   9.6s\n",
            "[CV 3/3] END basemodel__batch_size=237, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7644475973778535, basemodel__model__dropout2=0.20728861733139817, basemodel__model__layer1=512, basemodel__model__layer2=398, basemodel__model__learning_rate=0.00202127720584082, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, clip_y=140, scaler=StandardScaler(), seq_length=100;, score=-0.816 total time=   9.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.22735517071673322, basemodel__model__dropout2=0.13950631419240028, basemodel__model__layer1=89, basemodel__model__layer2=258, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.747 total time=  18.8s\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.22735517071673322, basemodel__model__dropout2=0.13950631419240028, basemodel__model__layer1=89, basemodel__model__layer2=258, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.505 total time=  18.5s\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.22735517071673322, basemodel__model__dropout2=0.13950631419240028, basemodel__model__layer1=89, basemodel__model__layer2=258, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.9, clip_y=80, scaler=StandardScaler(), seq_length=100;, score=0.661 total time=  18.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=140, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.6584925307084479, basemodel__model__dropout2=0.40983881706053926, basemodel__model__layer1=104, basemodel__model__layer2=461, basemodel__model__learning_rate=0.001197855535909161, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=138, scaler=StandardScaler(), seq_length=93;, score=0.170 total time=   7.6s\n",
            "[CV 2/3] END basemodel__batch_size=140, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.6584925307084479, basemodel__model__dropout2=0.40983881706053926, basemodel__model__layer1=104, basemodel__model__layer2=461, basemodel__model__learning_rate=0.001197855535909161, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=138, scaler=StandardScaler(), seq_length=93;, score=0.151 total time=   8.0s\n",
            "[CV 3/3] END basemodel__batch_size=140, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.6584925307084479, basemodel__model__dropout2=0.40983881706053926, basemodel__model__layer1=104, basemodel__model__layer2=461, basemodel__model__learning_rate=0.001197855535909161, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, clip_y=138, scaler=StandardScaler(), seq_length=93;, score=0.093 total time=   7.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=166, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.5330551411201159, basemodel__model__dropout2=0.10368497001934424, basemodel__model__layer1=49, basemodel__model__layer2=474, basemodel__model__learning_rate=0.0010164699124613832, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8065680691719694, clip_y=131, scaler=StandardScaler(), seq_length=62;, score=0.464 total time=  17.7s\n",
            "[CV 2/3] END basemodel__batch_size=166, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.5330551411201159, basemodel__model__dropout2=0.10368497001934424, basemodel__model__layer1=49, basemodel__model__layer2=474, basemodel__model__learning_rate=0.0010164699124613832, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8065680691719694, clip_y=131, scaler=StandardScaler(), seq_length=62;, score=0.387 total time=  17.7s\n",
            "[CV 3/3] END basemodel__batch_size=166, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.5330551411201159, basemodel__model__dropout2=0.10368497001934424, basemodel__model__layer1=49, basemodel__model__layer2=474, basemodel__model__learning_rate=0.0010164699124613832, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8065680691719694, clip_y=131, scaler=StandardScaler(), seq_length=62;, score=0.311 total time=  17.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=196, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6570201539609017, basemodel__model__dropout2=0.6187560452416495, basemodel__model__layer1=101, basemodel__model__layer2=376, basemodel__model__learning_rate=0.0020229884479010017, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.2296441210220304, clip_y=137, scaler=StandardScaler(), seq_length=85;, score=0.883 total time=  21.3s\n",
            "[CV 2/3] END basemodel__batch_size=196, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6570201539609017, basemodel__model__dropout2=0.6187560452416495, basemodel__model__layer1=101, basemodel__model__layer2=376, basemodel__model__learning_rate=0.0020229884479010017, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.2296441210220304, clip_y=137, scaler=StandardScaler(), seq_length=85;, score=0.891 total time=  20.8s\n",
            "[CV 3/3] END basemodel__batch_size=196, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6570201539609017, basemodel__model__dropout2=0.6187560452416495, basemodel__model__layer1=101, basemodel__model__layer2=376, basemodel__model__learning_rate=0.0020229884479010017, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.2296441210220304, clip_y=137, scaler=StandardScaler(), seq_length=85;, score=0.904 total time=  21.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=203, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6651157443098066, basemodel__model__dropout2=0.7039898186277506, basemodel__model__layer1=111, basemodel__model__layer2=358, basemodel__model__learning_rate=0.00240583173791593, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.15721460514716115, clip_y=136, scaler=StandardScaler(), seq_length=87;, score=0.883 total time=  21.7s\n",
            "[CV 2/3] END basemodel__batch_size=203, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6651157443098066, basemodel__model__dropout2=0.7039898186277506, basemodel__model__layer1=111, basemodel__model__layer2=358, basemodel__model__learning_rate=0.00240583173791593, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.15721460514716115, clip_y=136, scaler=StandardScaler(), seq_length=87;, score=0.904 total time=  21.5s\n",
            "[CV 3/3] END basemodel__batch_size=203, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6651157443098066, basemodel__model__dropout2=0.7039898186277506, basemodel__model__layer1=111, basemodel__model__layer2=358, basemodel__model__learning_rate=0.00240583173791593, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.15721460514716115, clip_y=136, scaler=StandardScaler(), seq_length=87;, score=0.888 total time=  21.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=203, basemodel__epochs=21, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.1578053372195795, basemodel__model__dropout2=0.6508994003642828, basemodel__model__layer1=145, basemodel__model__layer2=249, basemodel__model__learning_rate=0.002448754314283336, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5845471268255349, clip_y=116, scaler=MinMaxScaler(), seq_length=30;, score=0.852 total time=  18.7s\n",
            "[CV 2/3] END basemodel__batch_size=203, basemodel__epochs=21, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.1578053372195795, basemodel__model__dropout2=0.6508994003642828, basemodel__model__layer1=145, basemodel__model__layer2=249, basemodel__model__learning_rate=0.002448754314283336, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5845471268255349, clip_y=116, scaler=MinMaxScaler(), seq_length=30;, score=0.711 total time=  18.8s\n",
            "[CV 3/3] END basemodel__batch_size=203, basemodel__epochs=21, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.1578053372195795, basemodel__model__dropout2=0.6508994003642828, basemodel__model__layer1=145, basemodel__model__layer2=249, basemodel__model__learning_rate=0.002448754314283336, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5845471268255349, clip_y=116, scaler=MinMaxScaler(), seq_length=30;, score=0.699 total time=  18.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=174, basemodel__epochs=21, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5157104351784535, basemodel__model__dropout2=0.7126675967759073, basemodel__model__layer1=125, basemodel__model__layer2=386, basemodel__model__learning_rate=0.0017804516876459917, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23205313885059345, clip_y=140, scaler=StandardScaler(), seq_length=80;, score=0.915 total time=  21.7s\n",
            "[CV 2/3] END basemodel__batch_size=174, basemodel__epochs=21, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5157104351784535, basemodel__model__dropout2=0.7126675967759073, basemodel__model__layer1=125, basemodel__model__layer2=386, basemodel__model__learning_rate=0.0017804516876459917, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23205313885059345, clip_y=140, scaler=StandardScaler(), seq_length=80;, score=0.920 total time=  21.7s\n",
            "[CV 3/3] END basemodel__batch_size=174, basemodel__epochs=21, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5157104351784535, basemodel__model__dropout2=0.7126675967759073, basemodel__model__layer1=125, basemodel__model__layer2=386, basemodel__model__learning_rate=0.0017804516876459917, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.23205313885059345, clip_y=140, scaler=StandardScaler(), seq_length=80;, score=0.919 total time=  21.7s\n",
            "Finished: 2022-10-14 16:11:08.753822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730fbbfc-2a6a-4834-daab-708e75b41828",
        "id": "ZmwFkYmatqcj"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.917847894602053\n",
            "OrderedDict([('basemodel__batch_size', 174), ('basemodel__epochs', 21), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'selu'), ('basemodel__model__dropout1', 0.5157104351784535), ('basemodel__model__dropout2', 0.7126675967759073), ('basemodel__model__layer1', 125), ('basemodel__model__layer2', 386), ('basemodel__model__learning_rate', 0.0017804516876459917), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__validation_split', 0.23205313885059345), ('clip_y', 140), ('scaler', StandardScaler()), ('seq_length', 80)])\n",
            "Finished: 2022-10-14 16:11:08.773798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "de8abe8e-f19e-4d4e-e3dc-c73c8c740836",
        "id": "Xps8Zhw_tqcj"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-14 16:11:08.807819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEYCAYAAACZaxt6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtCUlEQVR4nO3de5xVdb3/8ddnGBjkJvfhLlqkohkCmRdEECVFC7WrcRLLEk+aZnXS87OLdbKjmdnxZIlHLUqSzLuFihKKlFqAJBdBREVgYIBhhuE6cvn8/lhr42bYe2bvWXvPmtn7/Xw81mOvy/e79mcvNvsza63v+n7N3REREYmiJO4ARESk9VMyERGRyJRMREQkMiUTERGJTMlEREQiUzIREZHIlExEJCNmdqmZzYs7DmmZlEykIJjZF8xsvpltN7P1ZvaUmY2KO65iZWbPm9lX4o5Dmo+SibR6ZvZN4BfAT4ByYBDwK2BijGEdxMxK445BJJ+UTKRVM7PDgR8BV7r7I+6+w933uPuT7v4fYZkyM/uFmVWE0y/MrCzcNsbM1prZt8xsY3hW86Vw28lmtsHM2iS934Vm9lo4X2Jm15vZKjOrMrMHzax7uG2wmbmZXWZm7wJ/NbM2ZnabmW02s7fN7KqwTGnis5jZvWEM68zsx4n3TlxiMrOfmVl1WP/cpLi6m9lvws9XbWaPJW0738wWmVmNmf3dzE5o4Hi6mV1tZm+Fcd5qZil/J8zsVDP7p5ltDV9PDdffBJwO/DI8U/xl9v+y0toomUhrdwrQHni0gTI3ACcDw4CPACcB303a3gc4HOgPXAbcaWbd3P1lYAdwZlLZLwB/COevBi4AzgD6AdXAnfXe+wzgWODjwFeBc8M4hod1k00D9gIfBE4ExgPJl4o+BqwAegI/Be41Mwu3/R7oABwH9AZuBzCz4cB9wBSgBzAVeCKRTNO4EBgZxjgR+HL9AmHS/AtwR7jfnwN/MbMe7n4D8CJwlbt3cverGngvKRTurklTq52AScCGRsqsAiYkLX8ceCecHwPsAkqTtm8ETg7nfwzcF853JkguR4TLrwPjkur1BfYApcBgwIGjkrb/FZiStHxWWKaU4PJcHXBY0vaLgTnh/KXAm0nbOoR1+4Tvux/oluKz/xr4r3rrVgBnpDlWDpyTtPw1YHZSDPPC+S8C/6hX9yXg0nD+eeArcX8/NDXfpOu40tpVAT3NrNTd96Yp0w9YnbS8Olx3YB/16u4EOoXzfwD+bmb/DlwELHT3xL6OAB41s/1JdfcRJIaENfXiWJNm2xFAW2D9+ycblNQrsyEx4+47w3KdgO7AFnev5lBHAJPN7OtJ69px8OevL/k96x+r5M+yut661QRnd1KEdJlLWruXgN0ceskoWQXBj2rCoHBdo9x9GcGP5LkcfIkLgh/dc929a9LU3t3XJe8iaX49MCBpeWC9fdUBPZP21cXdj8sgzDVAdzPrmmbbTfVi7ODuDzSwv+S40h2r+sc0UTbx2dUdeZFRMpFWzd23At8nuM9xgZl1MLO2Znaumf00LPYA8F0z62VmPcPy92fxNn8guD8yGvhT0vq7gJvM7AiAcP8NtSB7ELjGzPqHP/zXJX2O9cAs4DYz6xLe3P+AmZ3RWHBh3aeAX5lZt/Dzjw43/x9whZl9zAIdzew8M+vcwC7/I9zPQOAa4I8pyswEPhQ2yS41s88BQ4E/h9srgaMai10Kh5KJtHru/nPgmwQ31TcR/DV+FfBYWOTHwHzgNWAxsDBcl6kHCO6t/NXdNyet/x/gCWCWmW0DXia4SZ7O/xEkjNeAVwl+kPcSXBoDuITgEtQygpv5DxHcD8nEFwnu1ywnuOfzDQB3n09w4/+X4T7fJLj30ZDHgQXAIoKb7PfWL+DuVcD5wLcILjV+Bzg/6fj8D/DpsGXZHRl+BmnFzF1noyJxCJv23uXu9S8XxcbMHBji7m/GHYu0LjozEWkmZnaYmU0ILwv1B35Aw02aRVoNJROR5mPADwkuN71K0LT4+7FGJJIjuswlIiKR6cxEREQiK9qHFnv27OmDBw+OO4yUduzYQceOHeMOIy3FF43ii0bxRRclxgULFmx2916HbIj7Efy4phEjRnhLNWfOnLhDaJDii0bxRaP4oosSIzDfU/ym6jKXiIhEpmQiIiKRKZmIiEhkSiYiIhKZkomIiERWtE2Dm2LW3GVMnT6PjVW19O7RhSmTRjF+9NBWU19EJF+UTDI0a+4ybrlrFnV1wRhKlZtrueWuWQAZ/aDHXV9EJJ+UTDI0dfq8Az/kCXV1e/nJnU/z0MxXG63/xtuV7N27/6B16erX1tbyh6fXHbQuXf2p0+cpmYhI7JRMMrSxqjbl+r1797Ns5fom7zdt/codGdWv3FzLvn37adNGt79EJD5KJhnq3aMLlZsPTSjdDu/Af33rE43W/95tT1K9dWdG9V9dtIgThw3LqD7A5668h4snjuT8cSdQ1k7/pCLS/PTLk6Epk0YddM8CoKyslK9fOoZhxw1soGbg65eOybh+zaZVh6xLVb+0TQmHtW/Lhk213H7PX7nvjy/xqQkn8pnzhtO5Y/umflQRkawpmWQocV+iqa2p8lX/zNOOYfa85dz/6Cu8vaaK+/74dx54/J+cf+aHmXThSfTs3qkJn1ZEJDtKJlkYP3popJvd+ar/8TOGMn70sbzy6tv87uFXeG35Ov40cyGPPLOIcacdw+RPfYwjBvRo8vuKiDRGyaRAmBknDz+Kk4cfxesr1/Pbh17m7wtWMWvuMp59cRknn3gkx3ygDzPnLI38nEvl5lrKH3ij1T1nE3d9kUKmZFKAjh3Sl1v+80LerdjC7x95hedeXM5LC9/mpYVvHyhTubmW/77zGV5/cwPDhg5odJ+Llq3lsWf+xZ69+1p8/aVvVmPt38j7++s5H5H3Fe2wvSNHjvT58+fHHUZKzz//PGPGjMnZ/qqqd3Dx1+9l5673crZPCZT37MLDUy/Pqk6u/31zTfFF09Ljg2gxmtkCdx9Zf73OTIpAj24d2bU7fSI5adjgRvfxj0XvtJr6W7ZsoXv37s3y/umePxIpNkomRSLdczLlPbvw8+99utH6n5pyd6upn+qvrny9f+8eXRqtK1IM9Nh0kZgyaRRlZQf/7VBWVsqUSaNUvxnqixQ6nZkUiVw+51K5uZbyni3jOZvmrn/n716gqnoHJSXGdVeM1813kZCSSRHJ1XMuTb1511Kf08mm/hknf4izvvALDDjz1KObvC+RQqPLXCJZKGtXSveuHdm336ncvC3ucERajNiTiZl1N7NnzWxl+NotRZmjzWxR0lRrZt/ItL5ILvXtfTgAayqqY45EpOWIPZkA1wOz3X0IMDtcPoi7r3D3Ye4+DBgB7AQezbS+SC71Kw+SybsVW2KORKTlaAnJZCIwLZyfBlzQSPlxwCp3X93E+iKRDOwbnPzqzETkfbE/AW9mNe7eNWm52t3TXqoys/uAhe7+y2zrm9nlwOUA5eXlI2bMmJGbD5Fj27dvp1Onltvbb7HH99obW3jwmbf44KAuXDrxQ1nXL/bjF5Xiiy5KjGPHjk35BDzunvcJeA5YkmKaCNTUK1vdwH7aAZuB8qR1GddPnkaMGOEt1Zw5c+IOoUHFHt+KVRv8tItu9c9deU+T6hf78YtK8UUXJUZgvqf4TW2WpsHufla6bWZWaWZ93X29mfUFNjawq3MJzkoqk9ZlU18ksv59ugJBZ4/79zslJRZvQCItQEu4Z/IEMDmcnww83kDZi4EHItQXiaxjhzK6dGrPnj372Fy9Pe5wRFqElpBMbgbONrOVwNnhMmbWz8xmJgqZWYdw+yOZ1BfJp0Tz4LXrdRNeBFrAE/DuXkXQQqv++gpgQtLyTuCQ4QLT1RfJp37lh7PirUreXbeF4ccPijsckdi1hDMTkVZnQKJ5sM5MRAAlE5EmGdgvSCZr19fEG4hIC6FkItIEg/oHg29VVG6NORKRlkHJRKQJ+pd3BWDDpq2J55tEipqSiUgTdO1yGIe1b8uu3Xuoqd0VdzgisVMyEWkCM6NPr6B58LrKmniDEWkBlExEmuhA78Hr1HuwiJKJSBMN6NsVUO/BIqBkItJkia7o9RS8iJKJSJOpebDI+5RMRJoo8RT8+o1KJiJKJiJN1LNbJ9q2bUPt9t3s2FkXdzgisVIyEWmikhKjvGcXANZtqIk3GJGYKZmIRNA/0TxYN+GlyCmZiETQL+xWZY2eNZEip2QiEkGi92B1RS/FTslEJAI1DxYJKJmIRDBQzYNFACUTkUjKe3WhTYlRVb2Duro9cYcjEhslE5EIStuU0KtHZwAqdHYiRUzJRCSivr2D5sHq8FGKmZKJSET9+nQF4N0KNQ+W4qVkIhLRwLAr+rXra2KNQyROSiYiEQ3qFzQPVpcqUsyUTEQiSjy4qObBUsyUTEQi6hfegN9UtY29e/fFHI1IPJRMRCIqK2tLj24d2bffqdy8Le5wRGKhZCKSAweaB6uPLilSSiYiOdAv0RW9eg+WIqVkIpIDiT661urMRIpUxsnEzD5jZp3D+e+a2SNmNjx/oYm0HgPVPFiKXDZnJt9z921mNgr4ODAN+HV+whJpXQaFzYPVP5cUq2ySSaLN43nAr939caBd1ADMrLuZPWtmK8PXbinKHG1mi5KmWjP7RrjtRjNbl7RtQtSYRLLVP+xSZcOmWvbv93iDEYlBNslknZndDXwOmGlmZVnWT+d6YLa7DwFmh8sHcfcV7j7M3YcBI4CdwKNJRW5PbHf3mTmISSQrHTuU0aVTe/bs2UdV9fa4wxFpdtkkg88ATwHj3b0G6AZ8OwcxTCS4ZEb4ekEj5ccBq9x9dQ7eWyRn+vTuAqh5sBQnc2/4lNzMtgGJQlZ/3t27RArArMbduyYtV7v7IZe6krbfByx091+GyzcClwK1wHzgW+6e8n+zmV0OXA5QXl4+YsaMGVFCz5vt27fTqVOnuMNIS/Gl9sBTq1j6ZjWfHDuIk47vnbacjl80ii+6KDGOHTt2gbuPPGSDu+d9Ap4DlqSYJgI19cpWN7CfdsBmoDxpXTnQhuAs6ybgvkxiGjFihLdUc+bMiTuEBim+1O66f66fdtGtfsdv/tpgOR2/aBRfdFFiBOZ7it/U0ialpiy5+1nptplZpZn1dff1ZtYX2NjArs4lOCupTNr3gXkz+z/gz7mIWSRbiQ4f1TxYilGj90zMbFvYempbiqk2BzE8AUwO5ycDjzdQ9mLggXrx9U1avJDgjEek2Q3qHzxrUlGp5sFSfBo9M3H3znmO4WbgQTO7DHiX4EY/ZtYPuMfdJ4TLHYCzgSn16v/UzIYR3Mt5J8V2kWbRv7wrEHRF7+6YWbwBiTSjrC5zhc+ADAHaJ9a5+9woAbh7FUELrfrrK4AJScs7gR4pyn0xyvuL5ErXLodxWPu27Nq9h63bdtG1S4e4QxJpNtl0p/IVYC7wDPDD8PXG/IQl0vqYGX16BR0+rtV9Eyky2Txncg3wUWC1u48FTgQ25SUqkVYq0XvwGvUeLEUmm2Sy2913A5hZmbsvB47OT1girdOAsFuVdyv04KIUl2zumaw1s67AY8CzZlYNVOQjKJHWKtE8eO0GJRMpLhknE3e/MJy90czmAIcDT+clKpFWalDYFX3FBjUPluLSpIcW3f2FXAciUggGhGcmGzYpmUhxyaY117TwMldiuVvYT5aIhHp260Tbtm3Yum03O3e9F3c4Is0mmxvwJ3jQWzAAHnSmeGLOIxJpxUpKjPKeQd+n6lZFikk2yaQkeeAqM+tOEy+TiRSyRPPg1RVqHizFI5tkcBvwdzN7iKDrks8S9NIrIkkS3aroWRMpJtm05vqdmc0HziQYy+Qid1+Wt8hEWqkDzYPX18QbiEgzyuoyVZg8lEBEGpBoHryusibeQESaUS7GcBeRJIkzk/Ub1TxYioeSiUiOlffsTEmJsaVmB3Xv7Y07HJFmkc1zJmea2b1mdpuZfcnMRphZWT6DE2mNSkvb0LtHZ9x1diLFI5szk/sJhsR9GTgK+D6wNB9BibR2fXsHzYPfVYsuKRLZ3IB/090fDef/lI9gRApFvz5deXXpGtasV4ePUhyyOTN5wcyuNY1FKtKogX27ArBGXdFLkcjmzOQ44HjgOjNbACwCFrm7zlJE6jnQe7CaB0uRyOahxYsAzOww3k8sH0OXvEQOkWgeXFGpG/BSHLLuW8vddwHzw0lEUugX3oDfVLWNvfv2U9pGrfClsOkbLpIHZWVt6dG1I/v2O5WbauMORyTvlExE8qRP76ArerXokmKQUTKxwMB8ByNSSPr36QrAGnVFL0Ugo2Ti7g48lt9QRArLgAPJRGcmUviyucz1spl9NG+RiBSYQf17AOo9WIpDNq25xgJXmNk7wA6CMU3c3U/IR2Aird0gNQ+WIpJNMjk3b1GIFKDEPZPKTbXs3++UlKjzCClc2Vzmehc4HZjs7qsJhu4tz0tUIgWgY4cyunRqz3t79lFVvT3ucETyKptk8ivgFODicHkbcGfOIxIpIInmwWs31MQbiEieZZNMPubuVwK7Ady9GmiXl6hECkT/8q6AuqKXwpdNMtljZm0ILm9hZr2A/XmJSqRAHHjWRA8uSoHLJpncATwK9Dazm4B5wH/nJSqRApHoPXitkokUuGx6DZ4edj0/jqBZ8AXu/nrUAMysO/BHYDDwDvDZ8BJa/XLXAl8hODNaDHzJ3XdnWl8kDoP6J7qiV/NgKWzZjAF/i7svd/c73f2X7v66md2SgxiuB2a7+xBgdrhc/737A1cDI939eKAN8PlM64vEJXGZa8OmWoKOJEQKUzaXuc5OsS4Xz55MBKaF89OAC9KUKwUOM7NSoANQkWV9kWbXtcthHNa+LTt3vcfWbbviDkckb6yxv5bM7N+BrwFHAauSNnUG/ubu/xYpALMad++atFzt7t1SlLsGuAnYBcxy90nZ1A+3XQ5cDlBeXj5ixowZUULPm+3bt9OpU6e4w0hL8WXnjulL2LhlN1M+cwwD+3RqcfHVp/iiaenxQbQYx44du8DdRx6ywd0bnIAngSMImgQfkTR1b6xu0j6eA5akmCYCNfXKVqeo3w34K9ALaEvQ6eS/hdsarZ9qGjFihLdUc+bMiTuEBim+7HznJ4/4aRfd6jP/utjdW1589Sm+aFp6fO7RYgTme4rf1ExuwH8gfF0B1BLcfAeCm+fu3mgDenc/K902M6s0s77uvt7M+gIbUxQ7C3jb3TeFdR4BTgXuBzKpLxKbAWoeLEUgk3smdwFPA0cDC+pNuRi69wlgcjg/GXg8RZl3gZPNrIOZGUGLstezqC8Sm8R48EomUsgaTSbufoe7Hwv8xt2Pcvcjk6ajchDDzcDZZraS4Cb/zQBm1s/MZoYxvAI8BCwkaBZcAtzdUH2RliLxrMl6NQ+WApbNcyb/bmbdgCFA+6T1c6ME4O5VBGca9ddXABOSln8A/CDT+iItxYDwzGT9RiUTKVwZJxMz+wpwDTAAWAScDLwEnJmXyEQKRM9unWhb2oat23azc9d7cYcjkhfZPGdyDfBRYLW7jwVOBDblJSqRAlJSYpT3CnoPXqfeg6VAZZNMdrv7bgAzK3P35QQ35UWkEf3CrujfrVDvwVKYskkma82sK8EzHs+a2eO8/xS6iDQg0a2KkokUqmxuwF8Yzt5oZnOAwwmaDItIIwYmeg+uqOHIXh1ijkYk97IZA/4Ad38h14GIFLJE8+CKjTUEXcuJFJZsLnOJSBMlHlxUV/RSqJRMRJpBec/OlJQYW2p2sGevBiiVwpN1MjGzjuHwvSKSodLSNvTu0Rl3qK6tizsckZxrNJmYWYmZfcHM/mJmG4HlwHozW2pmt5rZkPyHKdL69el9OABVNbtjjkQk9zI5M5lD0HPwfwJ93H2gu/cGTgdeBm42s0hjmogUg0Tz4E3VSiZSeDJpzXWWu++pvzLsev5h4GEza5vzyEQKzMAwmWyp0WUuKTyZ9Bq8B8DMfhF2/562jIikN6h/0Dy4aquSiRSebG7AbweeMLOOAGY23sz+lp+wRArPgL5B8+CabUomUngyTibu/l3gAeB5M5sHfAu4Pl+BiRSa11euB6C69j0+NWUqs+YuizkikdzJpgv6ccBXgR1AX+Ayd1+Rr8BECsmsucv4+b2zDyxXbt7GLXfNAmD86KFxhSWSM9lc5roB+J67jwE+DfzRzDSWiUgGpk6fR13d3oPW1dXtZer0eTFFJJJb2XT0eGbS/GIzO5egNdep+QhMpJBsrKrNar1Ia5PJQ4vpWnCtJxwuN10ZEQn07tElq/UirU1GDy2a2dfNbFDySjNrB5xiZtOAyXmJTqRATJk0irKygy8EtC1tw5RJo2KKSCS3MrnMdQ7wZeABMzsSqAHaA22AWcDt7r4oXwGKFILETfap0+dRuTm4tHXUwB66+S4FI5Nkcou7X2NmvwX2AD2BXe5ek8/ARArN+NFDGT96KI89+Qy3TVvMW2uq2LZjN507to87NJHIMrnMNS58fdHd97j7eiUSkabr2rmMDx/dnz179/HcvOVxhyOSE5kkk6fN7CWgj5l92cxGmJn+lBKJ4NwxxwHw9PNLY45EJDcy6Zvr28AkYB9wJPA9YHHYBf0f8xyfSEEaN+oY2rVtw9I31lNRWRN3OCKRZfTQoru/RdB78Pfc/QJ3HwJ8DLg9r9GJFKgOh7Xj1JEfAOAvf10SczQi0WXzBPzqcJCs/2dm3we+CYzPU1wiBe+8sccDMGvu67h7zNGIRJNNMnkcmAjsJeifKzGJSBN8dNhguh3egfUbt7L0jYq4wxGJJOPuVIAB7n5O3iIRKTKlbUoYd9rRPDTzVZ58bjHHH90/7pBEmiybM5O/m9mH8xaJSBE678zgv9QLr6zkvT17Gykt0nJlk0xGAQvMbIWZvWZmi83stXwFJlIMhhzZm8EDerB9Rx1/m78q7nBEmiybZHIuMITgpvsngPPDVxGJ4Jwzgi5V/jJbrbqk9cpmpMXVqaaoAZhZdzN71sxWhq/d0pS7Nny2ZYmZPZB4cNLMbjSzdWa2KJwmRI1JpDmdM/Y4zIx/vraardt2xR2OSJNk0gX9vPB1m5nVhq+JKReDMVwPzA6fXZlNiqGAzaw/cDUw0t2PJ+hk8vNJRW5392HhNDMHMYk0m57dOnHicQPYt28/z7ygoXyldcrkCfhR4Wtnd+8SviamXAzGMBGYFs5PAy5IU64UOMzMSoEOgNpSSsGYED5zou5VpLXK+DKXmY00s0fMbGF4A/61HN2ALw8H2koMuNW7fgF3Xwf8DHgXWA9sdfdZSUWuCuO5L91lMpGWbMwpH6J9WVveeHsj71ZsiTsckaxZpk/emtkK4D+AxcD+xPpM7puY2XNAnxSbbgCmuXvXpLLV7n5QQggTxMPA5wjGU/kT8JC7329m5cBmwIH/Avq6+5fTxHE5cDlAeXn5iBkzZjQWeiy2b99Op06d4g4jLcUXTbr4HnzmLV57YwujhpdzzmkDY4gs0FqPX0vR0uODaDGOHTt2gbuPPGSDu2c0AfMyLZvNBKwgSAAAfYEVKcp8Brg3afkS4Fcpyg0GlmTyviNGjPCWas6cOXGH0CDFF026+P75r3f8tItu9Qu/+mvft29/8waVpLUev5aipcfnHi1GYL6n+E3NpmnwD8zsHjO72MwuSkxNSm0He4L3h/2dTNBtS33vAiebWYdwvPlxwOsAZtY3qdyFgNpXSqs0/PhB9OjWkY1V21m0bG3c4YhkJZtk8iVgGMEwvp/g/WdNoroZONvMVgJnh8uYWT8zmwng7q8ADwELCS6zlQB3h/V/mvQA5Vjg2hzEJNLsSkqM8acfC8CfZ+t5YGldsumb6yPunvPuVNy9ivdHc0xeXwFMSFr+AfCDFOW+mOuYROJy/rgP88AT83nxH29SV7eHsrK2cYckkpFszkxeNrOheYtERDhiQA8+OLgXu3bv4YVXVsYdjkjGsu2ba5H65hLJr8SQvjM1aJa0Itlc5lL38yLN4ONnDOVXv3uBhUvXsKVmB927dow7JJFGxd43l4gcrGuXDow84Qj273c9ES+tRjaXuUSkmUw4M+he5ann1VeXtA5KJiIt0OknfZCOh7Xj7TWbWbV6U9zhiDRKyUSkBWrXtpTRJw8B4M+zF8ccjUjjlExEWqjzxwWPdT03bzn79u1vpLRIvJRMRFqoE47pT59eXajeupMFi9+NOxyRBimZiLRQZsbZB7pX0aUuadmUTERasMSlrr/NX8XOXe/FHI1IekomIi1Y/z5dOfaDfah7by9z/r4i7nBE0lIyEWnhDnSvMkcPMErLpWQi0sKddfqxtC1tw2vL17Kpalvc4YikpGQi0sJ16dSek4YNxh1mzlHnj9IyKZmItALnhd2rPP3CssQQ1SItipKJSCtw6oij6NypPWsqqnnjrcq4wxE5RDZd0ItITEpL2zBkcC8WLlnDZd+5n/KeXZgyaRTjR2c+Xt2sucuYOn0eG6tq6d2j9dav3FxL+QNvNPv7S8OUTERagVlzl7FkRcWB5crNtdz8q2fYUrOT00/6YKP1X/zHm9z9hxd5b8++RutXbd3Nug01Ta4f9f2bq/4td80CUELJESvW668jR470+fPnxx1GSs8//zxjxoyJO4y0FF80TYnvU1PupnJzbX4CKmLlPbvw8NTLc7rPlv79g2gxmtkCdx9Zf73OTERagY1V6RNJec/Ojdav3Jy+SXH9+rt319G+fVmT60d9/+asX7m5FnfHzBrdhzRMyUSkFejdo0vKM5NM/7JOd2aTqn6qv1qzqR/1/ZuzPsDVP3iQ67/2cfr36drofiQ9teYSaQWmTBpFWdnBf/uVlZUyZdIo1W9i/dLSEsratuHVpWu45NrfMv3RV9TVfwQ6MxFpBRI3iZvaGqmQ6ldurs26NVu69x95whH8bOqzzP3Hm/z6/hd57m8ruOGqc/jg4N4Z7Vfep2Qi0kqMHz00UsujQqnf1JvH6d7/J9ddwNxXVvKzu59l5dsbuew/fs/nJ36Uyz53Ku3a6icyU7rMJSJFb/THhvCHOy7j/DM/zL79zvRH/8EXv/Fb/rVsbdyhtRpKJiIiQKeOZVx/5ce544efpV/54azbUMNV35/BLb9+RmPJZEDncCIiSYYfP4jf/+JL3DPjbzz45HyefG4xf5//FuNOP4YXXloZWw8AudpHviiZiIjUU9aulCsvOYPxpx/DTf/7NG+u3sSDTy44sD3bJ+hnzV3GLXfNoq5ub5Pq52of+aRkIiKSxpAjy7nn1i9y/qV3sn1n3UHb6ur2ctMvn+Y3f3rpoPU7d+5k6sOrDlpXUbn1kGbH6eqnk24fU6fPUzIREWnpStuUsGNXXcpt+/btZ01F9SHrq2pSl8+0fjYa6h2hOSmZiIg0Il0PBD26deT273/6oHX//Od8PvrRg7uuuvZHD1FVvSOj+umk20fvHl0yqp9vSiYiIo2YMmnUQfcrIHgC/8pLzuCoQb0OKvvuW4cdsu7KS87IuH46qfbRpsQy7gUg32JvGmxm3c3sWTNbGb52S1PuGjNbYmZLzewb2dYXEWmq8aOHct0V4ynv2QWzoE+w664Yn9UT+FHq199Hwr79zr59LaPn95ZwZnI9MNvdbzaz68Pl65ILmNnxwFeBk4D3gKfN7C/uvjKT+iIiUcXdA0D9fTz45wXc8Zs5/OzuZzn6A70zPsPJl9jPTICJwLRwfhpwQYoyxwIvu/tOd98LvABcmEV9EZGC8pnzhjP2lA9R995err/5sdgfrIx9cCwzq3H3rknL1e7erV6ZY4HHgVOAXcBsYL67fz2T+knbLgcuBygvLx8xY8aMXH+cnNi+fTudOnWKO4y0FF80ii8axfe+9/bs41czlrG5po5jjuzKpPM+kNHYLFFiHDt2bMrBsXD3vE/Ac8CSFNNEoKZe2eo0+7gMWAjMBe4Cbg/XZ1S//jRixAhvqebMmRN3CA1SfNEovmgU38HeWbPZz7r4F37aRbf69EdfyahOlBgJ/pA/5De1WS5zuftZ7n58iulxoNLM+gKErxvT7ONedx/u7qOBLcDKcFNG9UVECtERA3pw3dfGAzB1+ossWromljhawj2TJ4DJ4fxkgstZhzCz3uHrIOAi4IFs6ouIFKqzRh3Lp849kX37ne/d9iTVWw99HiXfWkIyuRk428xWAmeHy5hZPzObmVTuYTNbBjwJXOnu1Q3VFxEpJl+/dAxDh/SheutObvjp4+xt5lEjY08m7l7l7uPcfUj4uiVcX+HuE5LKne7uQ939I+4+u7H6IiLFpLS0DT/5zgUc3rk9ry2v4K7fz23W9489mYiISG707N6JH37zE5gZM56cz9xXVjZeKUeUTERECsjIE47gK58/FYAf/+9TrNsQrSPJTCmZiIgUmEs+dTInn3gkO3e9x/U3P0Zd3Z68v6eSiYhIgTEzfnDtefTp1YW311Tx06nP5v09lUxERApQ547t+cl3JtK2bRueeWEZjz2zKK/vp2QiIlKgPnRUOddediYA/3PfHJav2pC392oJvQaLiEiefPLsj7B4eQVPPb+Ub/7oT7Qva8fGqm2UP/AGUyaNytmQvzozEREpcN+ecja9uneidnsdG6u2AVC5uZZb7prFrLnLcvIeSiYiIgWurF0pqTqIr6vby9Tp83LyHkomIiJFoKpme8r1G6sOHdu+KZRMRESKQO8eXbJany0lExGRIjBl0ijKyg5uc1VWVsqUSaNysn+15hIRKQKJVltTp8+jcnMt5T275LQ1l5KJiEiRGD96KONHD+X5559nzJgxOd23LnOJiEhkSiYiIhKZkomIiESmZCIiIpEpmYiISGTmqZ6xLwJmtglYHXccafQENscdRAMUXzSKLxrFF12UGI9w9171VxZtMmnJzGy+u4+MO450FF80ii8axRddPmLUZS4REYlMyURERCJTMmmZ7o47gEYovmgUXzSKL7qcx6h7JiIiEpnOTEREJDIlExERiUzJJCZmNtDM5pjZ62a21MyuSVFmjJltNbNF4fT9Zo7xHTNbHL73/BTbzczuMLM3zew1MxvejLEdnXRcFplZrZl9o16ZZj1+ZnafmW00syVJ67qb2bNmtjJ87Zam7jlmtiI8ltc3Y3y3mtny8N/vUTPrmqZug9+FPMZ3o5mtS/o3nJCmblzH749Jsb1jZovS1G2O45fyN6XZvoPurimGCegLDA/nOwNvAEPrlRkD/DnGGN8BejawfQLwFGDAycArMcXZBthA8DBVbMcPGA0MB5YkrfspcH04fz1wS5r4VwFHAe2Af9X/LuQxvvFAaTh/S6r4Mvku5DG+G4FvZ/DvH8vxq7f9NuD7MR6/lL8pzfUd1JlJTNx9vbsvDOe3Aa8D/eONKmsTgd954GWgq5n1jSGOccAqd4+1RwN3nwtsqbd6IjAtnJ8GXJCi6knAm+7+lru/B8wI6+U9Pnef5e57w8WXgQG5ft9MpTl+mYjt+CWYmQGfBR7I9ftmqoHflGb5DiqZtABmNhg4EXglxeZTzOxfZvaUmR3XvJHhwCwzW2Bml6fY3h9Yk7S8lngS4udJ/584zuMHUO7u6yH4zw70TlGmpRzHLxOcaabS2Hchn64KL8Pdl+YSTUs4fqcDle6+Ms32Zj1+9X5TmuU7qGQSMzPrBDwMfMPda+ttXkhw6eYjwP8CjzVzeKe5+3DgXOBKMxtdb7ulqNOsbc3NrB3wSeBPKTbHffwy1RKO4w3AXmB6miKNfRfy5dfAB4BhwHqCS0n1xX78gItp+Kyk2Y5fI78paaulWJfVMVQyiZGZtSX4R5/u7o/U3+7ute6+PZyfCbQ1s57NFZ+7V4SvG4FHCU6Fk60FBiYtDwAqmie6A84FFrp7Zf0NcR+/UGXi0l/4ujFFmViPo5lNBs4HJnl4Ab2+DL4LeeHule6+z933A/+X5n3jPn6lwEXAH9OVaa7jl+Y3pVm+g0omMQmvsd4LvO7uP09Tpk9YDjM7ieDfq6qZ4utoZp0T8wQ3apfUK/YEcIkFTga2Jk6nm1HavwjjPH5JngAmh/OTgcdTlPknMMTMjgzPtD4f1ss7MzsHuA74pLvvTFMmk+9CvuJLvgd3YZr3je34hc4Clrv72lQbm+v4NfCb0jzfwXy2LtDUYMuLUQSnka8Bi8JpAnAFcEVY5ipgKUHLipeBU5sxvqPC9/1XGMMN4frk+Ay4k6AVyGJgZDMfww4EyeHwpHWxHT+CpLYe2EPwl95lQA9gNrAyfO0elu0HzEyqO4Gg9c2qxLFupvjeJLhWnvgO3lU/vnTfhWaK7/fhd+s1gh+3vi3p+IXrf5v4ziWVjeP4pftNaZbvoLpTERGRyHSZS0REIlMyERGRyJRMREQkMiUTERGJTMlEREQiUzIREZHIlExERCQyJRMpGmbmZnZb0vK3zezGHOx3cPIYF/lkZleH41Wk60Mr0/1sTzUv0lRKJlJM6oCLYuifq0FhdzSZ/l/8GjDB3SflMyaRbCmZSDHZC9wNXJu8sv6ZReKMJVy/3MzuMbMlZjbdzM4ys7+Fo9Yld9ZXambTwq7SHzKzDuG+/s3M/mHBCHtTzaxN0nu+bma/IujdeGC9mL4ZvucSC0eQNLO7CLrmeMLMDvoM4fZLwvf/l5n9Plz3WNjt+dLGuj4P+5D6S1h/iZl9LkWZR83sx2b2opltMLOzGtqnFA8lEyk2dwKTzOzwDMt/EPgf4ATgGOALBH0gfRv4f0nljgbudvcTgFrga2Z2LPA5gu7HhwH7gEn16vzO3U/0pIG9zGwE8CXgYwQjWH7VzE509ysIenId6+63JwdpwVgtNwBnetDlfmIY6C+7+whgJHC1mfVo4LOeA1S4+0fc/Xjg6RRljgdq3P10grMknSEJoGQiRcaD8R1+B1ydYZW33X2xB12gLwVme9Ch3WJgcFK5Ne7+t3D+foKEMw4YAfzTgrHBxxGcWSSs9mCEyvpGAY+6+w4PutB/hGDwpYacCTzk7pvDz5kYEfBqM0t0dDkQGNLAPhYDZ5nZLWZ2urtvTd4Ynm0dDiQSWSlQ00hcUiRK4w5AJAa/ILi09JtweS8H/2HVPmm+Lml+f9Lyfg7+/1O/x1Qn6FV5mrv/Z5o4dqRZn2qgosZY/RjMbAxB9+inuPtOM3uegz/bQdz9jfCsaALw32Y2y91/lFTkOGCBu+8Ll0+gmbqil5ZPZyZSdMK/2h8k6OIcoBLobWY9zKyMYKCobA0ys1PC+YuBeQTdfX/azHoDmFl3Mzsig33NBS4wsw7h+BcXAi82Umc28NnEZSwz605wFlEdJpJjCC6ZpWVm/YCd7n4/8DNgeL0ixxN0a55wAkF35yI6M5GidRvBeCe4+x4z+xHBeNlvA8ubsL/XgclmNpVg3Ihfhz/i3yUY+7uEYByMK4HVDewHd19oZr8F/hGuusfdX22kzlIzuwl4wcz2Aa8CU4ArzOw1YAXBpa6GfBi41cz2h7H+e4rtryQtH4/OTCSk8UxERCQyXeYSEZHIlExERCQyJRMREYlMyURERCJTMhERkciUTEREJDIlExERiez/A4nlmHccGFxNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4046b4-e7e7-488c-f9ef-d02640fa571b",
        "id": "fMbatLG-tqck"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 174),\n",
              "             ('basemodel__epochs', 21),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'selu'),\n",
              "             ('basemodel__model__dropout1', 0.5157104351784535),\n",
              "             ('basemodel__model__dropout2', 0.7126675967759073),\n",
              "             ('basemodel__model__layer1', 125),\n",
              "             ('basemodel__model__layer2', 386),\n",
              "             ('basemodel__model__learning_rate', 0.0017804516876459917),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__validation_split', 0.23205313885059345),\n",
              "             ('clip_y', 140),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 80)])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,poly_degree=2,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "t9AMXKXG69dj"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h LSTM-1\n",
        "# ~1h30min LSTM-2\n",
        "# ~1h LSTM-Dense-1\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        # \"clip_y\": Integer(80,140),\n",
        "        \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\n",
        "                                                      \"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        # \"basemodel__model__layer3\": Integer(16,512),\n",
        "        # \"basemodel__model__activation3\": Categorical([\"tanh\"]),\n",
        "        # \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb62da86-87c4-4a2e-bb78-417c250cdfc8",
        "id": "bU92N5HP69dl"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=182, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6684450428807318, basemodel__model__dropout2=0.6570181673206175, basemodel__model__layer1=314, basemodel__model__layer2=175, basemodel__model__learning_rate=0.0002294077317567093, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1364522493681177, poly_degree=3, scaler=StandardScaler(), seq_length=79;, score=-0.104 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=182, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6684450428807318, basemodel__model__dropout2=0.6570181673206175, basemodel__model__layer1=314, basemodel__model__layer2=175, basemodel__model__learning_rate=0.0002294077317567093, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1364522493681177, poly_degree=3, scaler=StandardScaler(), seq_length=79;, score=-0.194 total time= 1.9min\n",
            "[CV 3/3] END basemodel__batch_size=182, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.6684450428807318, basemodel__model__dropout2=0.6570181673206175, basemodel__model__layer1=314, basemodel__model__layer2=175, basemodel__model__learning_rate=0.0002294077317567093, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1364522493681177, poly_degree=3, scaler=StandardScaler(), seq_length=79;, score=-0.122 total time= 1.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=330, basemodel__epochs=27, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5840619694211598, basemodel__model__dropout2=0.3536146443159782, basemodel__model__layer1=360, basemodel__model__layer2=382, basemodel__model__learning_rate=0.0017591525384268944, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.26148795256547086, poly_degree=3, scaler=MinMaxScaler(), seq_length=81;, score=0.854 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=330, basemodel__epochs=27, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5840619694211598, basemodel__model__dropout2=0.3536146443159782, basemodel__model__layer1=360, basemodel__model__layer2=382, basemodel__model__learning_rate=0.0017591525384268944, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.26148795256547086, poly_degree=3, scaler=MinMaxScaler(), seq_length=81;, score=0.910 total time= 1.1min\n",
            "[CV 3/3] END basemodel__batch_size=330, basemodel__epochs=27, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5840619694211598, basemodel__model__dropout2=0.3536146443159782, basemodel__model__layer1=360, basemodel__model__layer2=382, basemodel__model__learning_rate=0.0017591525384268944, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.26148795256547086, poly_degree=3, scaler=MinMaxScaler(), seq_length=81;, score=0.862 total time= 1.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=435, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5223119716552876, basemodel__model__dropout2=0.8958010471848109, basemodel__model__layer1=471, basemodel__model__layer2=366, basemodel__model__learning_rate=0.00879421647884038, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7491728715447293, poly_degree=2, scaler=MinMaxScaler(), seq_length=86;, score=0.056 total time=  45.8s\n",
            "[CV 2/3] END basemodel__batch_size=435, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5223119716552876, basemodel__model__dropout2=0.8958010471848109, basemodel__model__layer1=471, basemodel__model__layer2=366, basemodel__model__learning_rate=0.00879421647884038, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7491728715447293, poly_degree=2, scaler=MinMaxScaler(), seq_length=86;, score=0.273 total time=  45.2s\n",
            "[CV 3/3] END basemodel__batch_size=435, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5223119716552876, basemodel__model__dropout2=0.8958010471848109, basemodel__model__layer1=471, basemodel__model__layer2=366, basemodel__model__learning_rate=0.00879421647884038, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.7491728715447293, poly_degree=2, scaler=MinMaxScaler(), seq_length=86;, score=0.428 total time=  46.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=41, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.8007495335533903, basemodel__model__dropout2=0.42803167263292163, basemodel__model__layer1=49, basemodel__model__layer2=280, basemodel__model__learning_rate=0.002795146584141956, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.345742984764708, poly_degree=2, scaler=StandardScaler(), seq_length=45;, score=0.561 total time= 2.1min\n",
            "[CV 2/3] END basemodel__batch_size=41, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.8007495335533903, basemodel__model__dropout2=0.42803167263292163, basemodel__model__layer1=49, basemodel__model__layer2=280, basemodel__model__learning_rate=0.002795146584141956, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.345742984764708, poly_degree=2, scaler=StandardScaler(), seq_length=45;, score=0.508 total time= 2.1min\n",
            "[CV 3/3] END basemodel__batch_size=41, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.8007495335533903, basemodel__model__dropout2=0.42803167263292163, basemodel__model__layer1=49, basemodel__model__layer2=280, basemodel__model__learning_rate=0.002795146584141956, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.345742984764708, poly_degree=2, scaler=StandardScaler(), seq_length=45;, score=0.508 total time= 2.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=247, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8094980998135372, basemodel__model__dropout2=0.44414773896112447, basemodel__model__layer1=429, basemodel__model__layer2=291, basemodel__model__learning_rate=0.005566199606072513, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8205054813555436, poly_degree=2, scaler=StandardScaler(), seq_length=52;, score=0.655 total time=  37.8s\n",
            "[CV 2/3] END basemodel__batch_size=247, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8094980998135372, basemodel__model__dropout2=0.44414773896112447, basemodel__model__layer1=429, basemodel__model__layer2=291, basemodel__model__learning_rate=0.005566199606072513, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8205054813555436, poly_degree=2, scaler=StandardScaler(), seq_length=52;, score=0.603 total time=  36.9s\n",
            "[CV 3/3] END basemodel__batch_size=247, basemodel__epochs=17, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8094980998135372, basemodel__model__dropout2=0.44414773896112447, basemodel__model__layer1=429, basemodel__model__layer2=291, basemodel__model__learning_rate=0.005566199606072513, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8205054813555436, poly_degree=2, scaler=StandardScaler(), seq_length=52;, score=0.487 total time=  37.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=241, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.16182221664875976, basemodel__model__dropout2=0.28740733523498024, basemodel__model__layer1=511, basemodel__model__layer2=181, basemodel__model__learning_rate=0.00954160315836252, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8493176895896238, poly_degree=2, scaler=StandardScaler(), seq_length=73;, score=0.641 total time=  50.7s\n",
            "[CV 2/3] END basemodel__batch_size=241, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.16182221664875976, basemodel__model__dropout2=0.28740733523498024, basemodel__model__layer1=511, basemodel__model__layer2=181, basemodel__model__learning_rate=0.00954160315836252, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8493176895896238, poly_degree=2, scaler=StandardScaler(), seq_length=73;, score=0.464 total time=  52.0s\n",
            "[CV 3/3] END basemodel__batch_size=241, basemodel__epochs=18, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.16182221664875976, basemodel__model__dropout2=0.28740733523498024, basemodel__model__layer1=511, basemodel__model__layer2=181, basemodel__model__learning_rate=0.00954160315836252, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.8493176895896238, poly_degree=2, scaler=StandardScaler(), seq_length=73;, score=0.351 total time=  50.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=412, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7091750428081358, basemodel__model__dropout2=0.39209351399600734, basemodel__model__layer1=92, basemodel__model__layer2=352, basemodel__model__learning_rate=0.007911925666877245, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4769678071866106, poly_degree=2, scaler=MinMaxScaler(), seq_length=99;, score=0.568 total time=  31.9s\n",
            "[CV 2/3] END basemodel__batch_size=412, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7091750428081358, basemodel__model__dropout2=0.39209351399600734, basemodel__model__layer1=92, basemodel__model__layer2=352, basemodel__model__learning_rate=0.007911925666877245, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4769678071866106, poly_degree=2, scaler=MinMaxScaler(), seq_length=99;, score=0.557 total time=  31.5s\n",
            "[CV 3/3] END basemodel__batch_size=412, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=sigmoid, basemodel__model__dropout1=0.7091750428081358, basemodel__model__dropout2=0.39209351399600734, basemodel__model__layer1=92, basemodel__model__layer2=352, basemodel__model__learning_rate=0.007911925666877245, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.4769678071866106, poly_degree=2, scaler=MinMaxScaler(), seq_length=99;, score=0.527 total time=  30.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=137, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5353377504977703, basemodel__model__dropout2=0.2651143167647805, basemodel__model__layer1=37, basemodel__model__layer2=169, basemodel__model__learning_rate=0.007365665573703649, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8282004512046042, poly_degree=3, scaler=MinMaxScaler(), seq_length=93;, score=0.587 total time=  35.9s\n",
            "[CV 2/3] END basemodel__batch_size=137, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5353377504977703, basemodel__model__dropout2=0.2651143167647805, basemodel__model__layer1=37, basemodel__model__layer2=169, basemodel__model__learning_rate=0.007365665573703649, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8282004512046042, poly_degree=3, scaler=MinMaxScaler(), seq_length=93;, score=0.493 total time=  48.4s\n",
            "[CV 3/3] END basemodel__batch_size=137, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5353377504977703, basemodel__model__dropout2=0.2651143167647805, basemodel__model__layer1=37, basemodel__model__layer2=169, basemodel__model__learning_rate=0.007365665573703649, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8282004512046042, poly_degree=3, scaler=MinMaxScaler(), seq_length=93;, score=-0.169 total time=  36.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=315, basemodel__epochs=12, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5271814738908966, basemodel__model__dropout2=0.760948090925533, basemodel__model__layer1=407, basemodel__model__layer2=129, basemodel__model__learning_rate=0.006030705408173919, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5378662406174342, poly_degree=3, scaler=MinMaxScaler(), seq_length=60;, score=0.561 total time=  34.3s\n",
            "[CV 2/3] END basemodel__batch_size=315, basemodel__epochs=12, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5271814738908966, basemodel__model__dropout2=0.760948090925533, basemodel__model__layer1=407, basemodel__model__layer2=129, basemodel__model__learning_rate=0.006030705408173919, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5378662406174342, poly_degree=3, scaler=MinMaxScaler(), seq_length=60;, score=0.272 total time=  34.1s\n",
            "[CV 3/3] END basemodel__batch_size=315, basemodel__epochs=12, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5271814738908966, basemodel__model__dropout2=0.760948090925533, basemodel__model__layer1=407, basemodel__model__layer2=129, basemodel__model__learning_rate=0.006030705408173919, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5378662406174342, poly_degree=3, scaler=MinMaxScaler(), seq_length=60;, score=0.475 total time=  33.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=42, basemodel__epochs=8, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7818056749807186, basemodel__model__dropout2=0.23073998100144028, basemodel__model__layer1=28, basemodel__model__layer2=488, basemodel__model__learning_rate=0.008567520571554488, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5519595132357996, poly_degree=2, scaler=MinMaxScaler(), seq_length=72;, score=-0.567 total time=  29.9s\n",
            "[CV 2/3] END basemodel__batch_size=42, basemodel__epochs=8, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7818056749807186, basemodel__model__dropout2=0.23073998100144028, basemodel__model__layer1=28, basemodel__model__layer2=488, basemodel__model__learning_rate=0.008567520571554488, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5519595132357996, poly_degree=2, scaler=MinMaxScaler(), seq_length=72;, score=-0.444 total time=  29.4s\n",
            "[CV 3/3] END basemodel__batch_size=42, basemodel__epochs=8, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.7818056749807186, basemodel__model__dropout2=0.23073998100144028, basemodel__model__layer1=28, basemodel__model__layer2=488, basemodel__model__learning_rate=0.008567520571554488, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.5519595132357996, poly_degree=2, scaler=MinMaxScaler(), seq_length=72;, score=-0.277 total time=  30.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=248, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6334210612434881, basemodel__model__dropout2=0.7624341639322648, basemodel__model__layer1=30, basemodel__model__layer2=283, basemodel__model__learning_rate=0.0064763336083128445, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1254667375836757, poly_degree=3, scaler=MinMaxScaler(), seq_length=30;, score=0.421 total time=  31.4s\n",
            "[CV 2/3] END basemodel__batch_size=248, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6334210612434881, basemodel__model__dropout2=0.7624341639322648, basemodel__model__layer1=30, basemodel__model__layer2=283, basemodel__model__learning_rate=0.0064763336083128445, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1254667375836757, poly_degree=3, scaler=MinMaxScaler(), seq_length=30;, score=0.402 total time=  36.0s\n",
            "[CV 3/3] END basemodel__batch_size=248, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.6334210612434881, basemodel__model__dropout2=0.7624341639322648, basemodel__model__layer1=30, basemodel__model__layer2=283, basemodel__model__learning_rate=0.0064763336083128445, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1254667375836757, poly_degree=3, scaler=MinMaxScaler(), seq_length=30;, score=0.477 total time=  35.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=220, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5768400267163486, basemodel__model__dropout2=0.7832794977137297, basemodel__model__layer1=421, basemodel__model__layer2=491, basemodel__model__learning_rate=0.008889908673728063, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3936117113915363, poly_degree=2, scaler=MinMaxScaler(), seq_length=30;, score=0.670 total time=  45.2s\n",
            "[CV 2/3] END basemodel__batch_size=220, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5768400267163486, basemodel__model__dropout2=0.7832794977137297, basemodel__model__layer1=421, basemodel__model__layer2=491, basemodel__model__learning_rate=0.008889908673728063, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3936117113915363, poly_degree=2, scaler=MinMaxScaler(), seq_length=30;, score=0.642 total time=  38.5s\n",
            "[CV 3/3] END basemodel__batch_size=220, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5768400267163486, basemodel__model__dropout2=0.7832794977137297, basemodel__model__layer1=421, basemodel__model__layer2=491, basemodel__model__learning_rate=0.008889908673728063, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3936117113915363, poly_degree=2, scaler=MinMaxScaler(), seq_length=30;, score=0.536 total time=  44.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=395, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5904246309321496, basemodel__model__dropout2=0.3463162437109924, basemodel__model__layer1=338, basemodel__model__layer2=301, basemodel__model__learning_rate=0.0006259632598228296, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.2585874558828829, poly_degree=3, scaler=MinMaxScaler(), seq_length=83;, score=0.838 total time=  55.8s\n",
            "[CV 2/3] END basemodel__batch_size=395, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5904246309321496, basemodel__model__dropout2=0.3463162437109924, basemodel__model__layer1=338, basemodel__model__layer2=301, basemodel__model__learning_rate=0.0006259632598228296, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.2585874558828829, poly_degree=3, scaler=MinMaxScaler(), seq_length=83;, score=0.886 total time=  55.3s\n",
            "[CV 3/3] END basemodel__batch_size=395, basemodel__epochs=23, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5904246309321496, basemodel__model__dropout2=0.3463162437109924, basemodel__model__layer1=338, basemodel__model__layer2=301, basemodel__model__learning_rate=0.0006259632598228296, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.2585874558828829, poly_degree=3, scaler=MinMaxScaler(), seq_length=83;, score=0.844 total time=  55.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=223, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.5750773445906904, basemodel__model__dropout2=0.35993152651078775, basemodel__model__layer1=404, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0036057782954511714, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.26639243031527976, poly_degree=3, scaler=MinMaxScaler(), seq_length=77;, score=0.828 total time= 1.7min\n",
            "[CV 2/3] END basemodel__batch_size=223, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.5750773445906904, basemodel__model__dropout2=0.35993152651078775, basemodel__model__layer1=404, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0036057782954511714, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.26639243031527976, poly_degree=3, scaler=MinMaxScaler(), seq_length=77;, score=0.821 total time= 1.6min\n",
            "[CV 3/3] END basemodel__batch_size=223, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.5750773445906904, basemodel__model__dropout2=0.35993152651078775, basemodel__model__layer1=404, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0036057782954511714, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.26639243031527976, poly_degree=3, scaler=MinMaxScaler(), seq_length=77;, score=0.813 total time= 1.8min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=411, basemodel__epochs=13, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8987473743014833, basemodel__model__dropout2=0.6822862590965832, basemodel__model__layer1=79, basemodel__model__layer2=478, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1608723575624243, poly_degree=2, scaler=StandardScaler(), seq_length=77;, score=-0.767 total time=  22.3s\n",
            "[CV 2/3] END basemodel__batch_size=411, basemodel__epochs=13, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8987473743014833, basemodel__model__dropout2=0.6822862590965832, basemodel__model__layer1=79, basemodel__model__layer2=478, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1608723575624243, poly_degree=2, scaler=StandardScaler(), seq_length=77;, score=-0.566 total time=  22.3s\n",
            "[CV 3/3] END basemodel__batch_size=411, basemodel__epochs=13, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.8987473743014833, basemodel__model__dropout2=0.6822862590965832, basemodel__model__layer1=79, basemodel__model__layer2=478, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1608723575624243, poly_degree=2, scaler=StandardScaler(), seq_length=77;, score=-0.591 total time=  22.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.44209030335018107, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, poly_degree=3, scaler=MinMaxScaler(), seq_length=56;, score=-2.082 total time=  14.4s\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.44209030335018107, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, poly_degree=3, scaler=MinMaxScaler(), seq_length=56;, score=-2.067 total time=  14.1s\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.44209030335018107, basemodel__model__layer1=16, basemodel__model__layer2=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, poly_degree=3, scaler=MinMaxScaler(), seq_length=56;, score=-2.079 total time=  14.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=319, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.5796187057930274, basemodel__model__dropout2=0.2627039179687393, basemodel__model__layer1=443, basemodel__model__layer2=458, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.17919114849996967, poly_degree=3, scaler=MinMaxScaler(), seq_length=93;, score=0.785 total time= 1.4min\n",
            "[CV 2/3] END basemodel__batch_size=319, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.5796187057930274, basemodel__model__dropout2=0.2627039179687393, basemodel__model__layer1=443, basemodel__model__layer2=458, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.17919114849996967, poly_degree=3, scaler=MinMaxScaler(), seq_length=93;, score=0.852 total time= 1.4min\n",
            "[CV 3/3] END basemodel__batch_size=319, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=elu, basemodel__model__dropout1=0.5796187057930274, basemodel__model__dropout2=0.2627039179687393, basemodel__model__layer1=443, basemodel__model__layer2=458, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.17919114849996967, poly_degree=3, scaler=MinMaxScaler(), seq_length=93;, score=0.844 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=494, basemodel__epochs=2, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.29001892701719656, basemodel__model__dropout2=0.9, basemodel__model__layer1=72, basemodel__model__layer2=69, basemodel__model__learning_rate=0.006499790674644977, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3219211093135251, poly_degree=3, scaler=MinMaxScaler(), seq_length=36;, score=0.049 total time=  11.3s\n",
            "[CV 2/3] END basemodel__batch_size=494, basemodel__epochs=2, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.29001892701719656, basemodel__model__dropout2=0.9, basemodel__model__layer1=72, basemodel__model__layer2=69, basemodel__model__learning_rate=0.006499790674644977, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3219211093135251, poly_degree=3, scaler=MinMaxScaler(), seq_length=36;, score=0.035 total time=  11.4s\n",
            "[CV 3/3] END basemodel__batch_size=494, basemodel__epochs=2, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.29001892701719656, basemodel__model__dropout2=0.9, basemodel__model__layer1=72, basemodel__model__layer2=69, basemodel__model__learning_rate=0.006499790674644977, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3219211093135251, poly_degree=3, scaler=MinMaxScaler(), seq_length=36;, score=0.042 total time=  11.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=216, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5833545322201824, basemodel__model__dropout2=0.6945082703215778, basemodel__model__layer1=219, basemodel__model__layer2=350, basemodel__model__learning_rate=0.009594843355440188, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4926133062522654, poly_degree=3, scaler=MinMaxScaler(), seq_length=33;, score=0.574 total time=  25.0s\n",
            "[CV 2/3] END basemodel__batch_size=216, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5833545322201824, basemodel__model__dropout2=0.6945082703215778, basemodel__model__layer1=219, basemodel__model__layer2=350, basemodel__model__learning_rate=0.009594843355440188, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4926133062522654, poly_degree=3, scaler=MinMaxScaler(), seq_length=33;, score=0.652 total time=  41.5s\n",
            "[CV 3/3] END basemodel__batch_size=216, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=selu, basemodel__model__dropout1=0.5833545322201824, basemodel__model__dropout2=0.6945082703215778, basemodel__model__layer1=219, basemodel__model__layer2=350, basemodel__model__learning_rate=0.009594843355440188, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4926133062522654, poly_degree=3, scaler=MinMaxScaler(), seq_length=33;, score=0.521 total time=  27.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=438, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5932918082470587, basemodel__model__dropout2=0.5812366219529713, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, poly_degree=2, scaler=MinMaxScaler(), seq_length=84;, score=0.243 total time=  35.5s\n",
            "[CV 2/3] END basemodel__batch_size=438, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5932918082470587, basemodel__model__dropout2=0.5812366219529713, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, poly_degree=2, scaler=MinMaxScaler(), seq_length=84;, score=0.223 total time=  34.6s\n",
            "[CV 3/3] END basemodel__batch_size=438, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=relu, basemodel__model__dropout1=0.5932918082470587, basemodel__model__dropout2=0.5812366219529713, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, poly_degree=2, scaler=MinMaxScaler(), seq_length=84;, score=0.234 total time=  33.9s\n",
            "Finished: 2022-10-14 17:06:35.879710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801a62d8-c332-4c0e-aead-7a09f5783b73",
        "id": "6nMKD1uG69dm"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8751657917165176\n",
            "OrderedDict([('basemodel__batch_size', 330), ('basemodel__epochs', 27), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'relu'), ('basemodel__model__dropout1', 0.5840619694211598), ('basemodel__model__dropout2', 0.3536146443159782), ('basemodel__model__layer1', 360), ('basemodel__model__layer2', 382), ('basemodel__model__learning_rate', 0.0017591525384268944), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__validation_split', 0.26148795256547086), ('poly_degree', 3), ('scaler', MinMaxScaler()), ('seq_length', 81)])\n",
            "Finished: 2022-10-14 17:06:35.888686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "93764f26-5ea7-46ac-c900-1625b1f6f78e",
        "id": "d1WsvLf-69dn"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-14 17:06:35.923687\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a352e537-0319-45c3-e4b4-7bfc196b656f",
        "id": "teJzqsQW69do"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 330),\n",
              "             ('basemodel__epochs', 27),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'relu'),\n",
              "             ('basemodel__model__dropout1', 0.5840619694211598),\n",
              "             ('basemodel__model__dropout2', 0.3536146443159782),\n",
              "             ('basemodel__model__layer1', 360),\n",
              "             ('basemodel__model__layer2', 382),\n",
              "             ('basemodel__model__learning_rate', 0.0017591525384268944),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__validation_split', 0.26148795256547086),\n",
              "             ('poly_degree', 3),\n",
              "             ('scaler', MinMaxScaler()),\n",
              "             ('seq_length', 81)])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer\n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7965826139501325  \n",
        "Test: 0.706\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.10771222326909816),\n",
        "('basemodel__model__layer1', 505),\n",
        "('basemodel__model__learning_rate', 0.0032806529941975817),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 70)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.9430289602358563  \n",
        "Test: 0.857\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 105),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 68)\n",
        "```\n",
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.8254078138058109  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 43),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.12031183587891998),\n",
        "('basemodel__model__layer1', 291),\n",
        "('basemodel__model__learning_rate', 0.0005169281218693581),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 61)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.8183215542558463  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 118),\n",
        "             ('basemodel__epochs', 32),\n",
        "             ('basemodel__model__activation', 'tanh'),\n",
        "             ('basemodel__model__dropout', 0.3795770073881617),\n",
        "             ('basemodel__model__layer1', 432),\n",
        "             ('basemodel__model__learning_rate', 0.00806882152030281),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.7235243202098837),\n",
        "             ('clip_y', 105),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 79)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1\n"
      ],
      "metadata": {
        "id": "zSnh2UONQb4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.8521617501513421  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 239),\n",
        "             ('basemodel__epochs', 45),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.8360008606718795),\n",
        "             ('basemodel__model__dropout2', 0.8326359552620336),\n",
        "             ('basemodel__model__layer1', 493),\n",
        "             ('basemodel__model__layer2', 469),\n",
        "             ('basemodel__model__learning_rate', 0.0013568819509124186),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1967801723709445),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 74)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.917847894602053  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 174),\n",
        "             ('basemodel__epochs', 21),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.5157104351784535),\n",
        "             ('basemodel__model__dropout2', 0.7126675967759073),\n",
        "             ('basemodel__model__layer1', 125),\n",
        "             ('basemodel__model__layer2', 386),\n",
        "             ('basemodel__model__learning_rate', 0.0017804516876459917),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.23205313885059345),\n",
        "             ('clip_y', 140),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 80)\n",
        "```\n",
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.8751657917165176  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 330),\n",
        "             ('basemodel__epochs', 27),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.5840619694211598),\n",
        "             ('basemodel__model__dropout2', 0.3536146443159782),\n",
        "             ('basemodel__model__layer1', 360),\n",
        "             ('basemodel__model__layer2', 382),\n",
        "             ('basemodel__model__learning_rate', 0.0017591525384268944),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.26148795256547086),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 81)\n",
        "```\n",
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.  \n",
        "Test: 0.\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vL2GlZ8KQb4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "outputId": "10771aed-b881-4a8f-84bc-279c86183fd4",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-58-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# Data checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfeature_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_build_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: create_model() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QFBtaiz2Ckgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           \n",
        "                           \n",
        "                           model__layer1=512, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer2=400,\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "\n",
        "                        \n",
        "                           \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_36P-gmRD6QM",
        "outputId": "04f7f7d7-28d1-40ba-97ee-4fd9aa120787"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_65 (Masking)        (None, 79, 22)            0         \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 400)               205200    \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 400)               0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301,281\n",
            "Trainable params: 1,301,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=288.566, rmse=16.987, r2=0.735; v_loss=171.738, v_rmse=13.105, v_r2=0.847; \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-62-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         self._fit_keras_model(\n\u001b[0m\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m   1222\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "83699a7e-1744-455e-c836-906b8dc33bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.918,RMSE=-9.668\n",
            "Finished: 2022-10-13 13:15:58.111062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee8uwFhF-E6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}