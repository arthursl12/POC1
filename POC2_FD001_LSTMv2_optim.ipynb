{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "Q4QwyfhXs_hv",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJKy96Z0HIOehbnvw9g8Mp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD001_LSTMv2_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "d79f519a-7ab3-45bc-da73-76bba21e3bb1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba49b262-dfc6-493e-cf9d-4ec1e85abb60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "id": "tlp572nXopEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4665062-c87c-4c28-c429-aa8dee49498a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(1, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "id": "-yRYxz2hh4xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "9ca1cbb6-b420-4edf-f3f9-a3612b72ecb2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time    op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
              "1                1     2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
              "2                1     3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
              "3                1     4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
              "4                1     5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
              "...            ...   ...     ...     ...    ...     ...     ...      ...   \n",
              "20626          100   196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98   \n",
              "20627          100   197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50   \n",
              "20628          100   198  0.0004  0.0000  100.0  518.67  643.42  1602.46   \n",
              "20629          100   199 -0.0011  0.0003  100.0  518.67  643.23  1605.26   \n",
              "20630          100   200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13    s_14  s_15  s_16  \\\n",
              "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
              "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
              "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
              "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
              "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
              "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
              "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03   397   \n",
              "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03   395   \n",
              "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03   398   \n",
              "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03   395   \n",
              "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03   396   \n",
              "\n",
              "       s_17   s_18   s_19     s_20  \n",
              "0      2388  100.0  39.06  23.4190  \n",
              "1      2388  100.0  39.00  23.4236  \n",
              "2      2388  100.0  38.95  23.3442  \n",
              "3      2388  100.0  38.88  23.3739  \n",
              "4      2388  100.0  38.90  23.4044  \n",
              "...     ...    ...    ...      ...  \n",
              "20626  2388  100.0  38.49  22.9735  \n",
              "20627  2388  100.0  38.30  23.1594  \n",
              "20628  2388  100.0  38.44  22.9333  \n",
              "20629  2388  100.0  38.29  23.0640  \n",
              "20630  2388  100.0  38.37  23.0522  \n",
              "\n",
              "[20631 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20626</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.49</td>\n",
              "      <td>1597.98</td>\n",
              "      <td>1428.63</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.49</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.60</td>\n",
              "      <td>8.4956</td>\n",
              "      <td>0.03</td>\n",
              "      <td>397</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.49</td>\n",
              "      <td>22.9735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.54</td>\n",
              "      <td>1604.50</td>\n",
              "      <td>1433.58</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.68</td>\n",
              "      <td>2388.22</td>\n",
              "      <td>8136.50</td>\n",
              "      <td>8.5139</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.30</td>\n",
              "      <td>23.1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1602.46</td>\n",
              "      <td>1428.18</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>520.01</td>\n",
              "      <td>2388.24</td>\n",
              "      <td>8141.05</td>\n",
              "      <td>8.5646</td>\n",
              "      <td>0.03</td>\n",
              "      <td>398</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.44</td>\n",
              "      <td>22.9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.23</td>\n",
              "      <td>1605.26</td>\n",
              "      <td>1426.53</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.67</td>\n",
              "      <td>2388.23</td>\n",
              "      <td>8139.29</td>\n",
              "      <td>8.5389</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.29</td>\n",
              "      <td>23.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>-0.0032</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.85</td>\n",
              "      <td>1600.38</td>\n",
              "      <td>1432.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>519.30</td>\n",
              "      <td>2388.26</td>\n",
              "      <td>8137.33</td>\n",
              "      <td>8.5036</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.37</td>\n",
              "      <td>23.0522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20631 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "e7-_jqRw3cRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "def train_val_split(train):\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
        "    for idx_train, idx_val in gss.split(train,groups=train[\"unit_number\"]):\n",
        "        # print('train_split_engines', train.iloc[idx_train]['unit_number'].unique(), '\\n')\n",
        "        # print('validate_split_engines', train.iloc[idx_val]['unit_number'].unique(), '\\n')\n",
        "\n",
        "        df_train = train.iloc[idx_train].copy()\n",
        "        df_val = train.iloc[idx_val].copy()\n",
        "\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "_FBiCeewvW-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_val_split(train)"
      ],
      "metadata": {
        "id": "beWX66gdvs0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_train, y_t_train = proc.X_y_train_divide(df_train)\n",
        "X_t_val, y_t_val = proc.X_y_train_divide(df_val)"
      ],
      "metadata": {
        "id": "0PTNitwkvwE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "4wtvRNsfuUwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5c69f6-e8f9-455f-81f1-fd2cd86015cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13096, 26), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "id": "onw4pCwZy-1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "c96c9a21-0a13-4e9d-c423-ac2793559dc2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  642.58  1581.22  1398.91  14.62  21.61  554.42  2388.08  9056.40   \n",
              "1  518.67  642.55  1586.59  1410.83  14.62  21.61  553.52  2388.10  9044.77   \n",
              "2  518.67  642.88  1589.75  1418.89  14.62  21.61  552.59  2388.16  9049.26   \n",
              "3  518.67  642.78  1594.53  1406.88  14.62  21.61  552.64  2388.13  9051.30   \n",
              "4  518.67  642.27  1589.94  1419.36  14.62  21.61  553.29  2388.10  9053.99   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.79  2388.06  8130.11  8.4024  0.03   393  2388  100.0  38.81   \n",
              "1  1.3  ...  521.74  2388.09  8126.90  8.4505  0.03   391  2388  100.0  38.81   \n",
              "2  1.3  ...  520.83  2388.14  8131.46  8.4119  0.03   395  2388  100.0  38.93   \n",
              "3  1.3  ...  521.88  2388.11  8133.64  8.4634  0.03   395  2388  100.0  38.58   \n",
              "4  1.3  ...  521.00  2388.15  8125.74  8.4362  0.03   394  2388  100.0  38.75   \n",
              "\n",
              "      s_20  \n",
              "0  23.3552  \n",
              "1  23.2618  \n",
              "2  23.2740  \n",
              "3  23.2581  \n",
              "4  23.4117  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.58</td>\n",
              "      <td>1581.22</td>\n",
              "      <td>1398.91</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.42</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9056.40</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.79</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8130.11</td>\n",
              "      <td>8.4024</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.55</td>\n",
              "      <td>1586.59</td>\n",
              "      <td>1410.83</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.52</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9044.77</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.74</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8126.90</td>\n",
              "      <td>8.4505</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.88</td>\n",
              "      <td>1589.75</td>\n",
              "      <td>1418.89</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.59</td>\n",
              "      <td>2388.16</td>\n",
              "      <td>9049.26</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>520.83</td>\n",
              "      <td>2388.14</td>\n",
              "      <td>8131.46</td>\n",
              "      <td>8.4119</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.93</td>\n",
              "      <td>23.2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.78</td>\n",
              "      <td>1594.53</td>\n",
              "      <td>1406.88</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>552.64</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9051.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.88</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>8133.64</td>\n",
              "      <td>8.4634</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.58</td>\n",
              "      <td>23.2581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.27</td>\n",
              "      <td>1589.94</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.29</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9053.99</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.00</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8125.74</td>\n",
              "      <td>8.4362</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.75</td>\n",
              "      <td>23.4117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "id": "lmFKjQaeip1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "fda02256-d461-4b49-83d9-a2960404ff01"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  191\n",
              "1            1     2  190\n",
              "2            1     3  189\n",
              "3            1     4  188\n",
              "4            1     5  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "fuAnHn4GxzwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "631132e8-0067-4c33-d7a0-672e56625ac3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  191\n",
              "1  190\n",
              "2  189\n",
              "3  188\n",
              "4  187"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "26hK4VWkx1R7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "dff3d556-3109-463a-8765-a480d1c3cc5b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      s_0     s_1      s_2      s_3    s_4    s_5     s_6      s_7      s_8  \\\n",
              "0  518.67  641.82  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   \n",
              "1  518.67  642.15  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   \n",
              "2  518.67  642.35  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   \n",
              "3  518.67  642.35  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   \n",
              "4  518.67  642.37  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   \n",
              "\n",
              "   s_9  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18   s_19  \\\n",
              "0  1.3  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06   \n",
              "1  1.3  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00   \n",
              "2  1.3  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95   \n",
              "3  1.3  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88   \n",
              "4  1.3  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90   \n",
              "\n",
              "      s_20  \n",
              "0  23.4190  \n",
              "1  23.4236  \n",
              "2  23.3442  \n",
              "3  23.3739  \n",
              "4  23.4044  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>s_7</th>\n",
              "      <th>s_8</th>\n",
              "      <th>s_9</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(LSTM(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "Jowfppg9HG3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "                           model__layer3=64,\n",
        "                           model__activation3='tanh',\n",
        "                           model__dropout3=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__second_dense=False,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "cxz0nz9mHJ2v"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1h LSTM-1\n",
        "# ~1h30min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        # \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        # \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__activation2\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer3\": Integer(16,512),\n",
        "        \"basemodel__model__activation3\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI-MbGPrHsB0",
        "outputId": "2e279b11-bee4-4175-b4d4-fb03c1ef37a0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=197, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.43230302537496235, basemodel__model__dropout2=0.7388209803445348, basemodel__model__dropout3=0.11336335507518822, basemodel__model__layer1=319, basemodel__model__layer2=364, basemodel__model__layer3=485, basemodel__model__learning_rate=0.006410885201360994, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5254950057605193, scaler=MinMaxScaler(), seq_length=86;, score=-0.145 total time=  44.2s\n",
            "[CV 2/3] END basemodel__batch_size=197, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.43230302537496235, basemodel__model__dropout2=0.7388209803445348, basemodel__model__dropout3=0.11336335507518822, basemodel__model__layer1=319, basemodel__model__layer2=364, basemodel__model__layer3=485, basemodel__model__learning_rate=0.006410885201360994, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5254950057605193, scaler=MinMaxScaler(), seq_length=86;, score=0.297 total time=  44.5s\n",
            "[CV 3/3] END basemodel__batch_size=197, basemodel__epochs=11, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.43230302537496235, basemodel__model__dropout2=0.7388209803445348, basemodel__model__dropout3=0.11336335507518822, basemodel__model__layer1=319, basemodel__model__layer2=364, basemodel__model__layer3=485, basemodel__model__learning_rate=0.006410885201360994, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.5254950057605193, scaler=MinMaxScaler(), seq_length=86;, score=0.336 total time=  43.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=294, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4511352400459935, basemodel__model__dropout2=0.5862997989384048, basemodel__model__dropout3=0.48213366313950945, basemodel__model__layer1=167, basemodel__model__layer2=231, basemodel__model__layer3=221, basemodel__model__learning_rate=0.0017898085496123855, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.21671269146408476, scaler=MinMaxScaler(), seq_length=41;, score=0.757 total time=  50.3s\n",
            "[CV 2/3] END basemodel__batch_size=294, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4511352400459935, basemodel__model__dropout2=0.5862997989384048, basemodel__model__dropout3=0.48213366313950945, basemodel__model__layer1=167, basemodel__model__layer2=231, basemodel__model__layer3=221, basemodel__model__learning_rate=0.0017898085496123855, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.21671269146408476, scaler=MinMaxScaler(), seq_length=41;, score=0.766 total time=  52.2s\n",
            "[CV 3/3] END basemodel__batch_size=294, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4511352400459935, basemodel__model__dropout2=0.5862997989384048, basemodel__model__dropout3=0.48213366313950945, basemodel__model__layer1=167, basemodel__model__layer2=231, basemodel__model__layer3=221, basemodel__model__learning_rate=0.0017898085496123855, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.21671269146408476, scaler=MinMaxScaler(), seq_length=41;, score=0.712 total time=  49.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=471, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.6646458676834175, basemodel__model__dropout2=0.548361169029554, basemodel__model__dropout3=0.8455910649248702, basemodel__model__layer1=412, basemodel__model__layer2=451, basemodel__model__layer3=322, basemodel__model__learning_rate=0.00010973204617219238, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4737749341435308, scaler=MinMaxScaler(), seq_length=61;, score=-1.266 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=471, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.6646458676834175, basemodel__model__dropout2=0.548361169029554, basemodel__model__dropout3=0.8455910649248702, basemodel__model__layer1=412, basemodel__model__layer2=451, basemodel__model__layer3=322, basemodel__model__learning_rate=0.00010973204617219238, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4737749341435308, scaler=MinMaxScaler(), seq_length=61;, score=-1.274 total time= 2.0min\n",
            "[CV 3/3] END basemodel__batch_size=471, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.6646458676834175, basemodel__model__dropout2=0.548361169029554, basemodel__model__dropout3=0.8455910649248702, basemodel__model__layer1=412, basemodel__model__layer2=451, basemodel__model__layer3=322, basemodel__model__learning_rate=0.00010973204617219238, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4737749341435308, scaler=MinMaxScaler(), seq_length=61;, score=-1.287 total time= 2.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=421, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.8996230558165496, basemodel__model__dropout2=0.225900887438739, basemodel__model__dropout3=0.7823776999978126, basemodel__model__layer1=454, basemodel__model__layer2=255, basemodel__model__layer3=182, basemodel__model__learning_rate=0.006025238575442951, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.7901709119649518, scaler=MinMaxScaler(), seq_length=49;, score=0.230 total time=  52.5s\n",
            "[CV 2/3] END basemodel__batch_size=421, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.8996230558165496, basemodel__model__dropout2=0.225900887438739, basemodel__model__dropout3=0.7823776999978126, basemodel__model__layer1=454, basemodel__model__layer2=255, basemodel__model__layer3=182, basemodel__model__learning_rate=0.006025238575442951, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.7901709119649518, scaler=MinMaxScaler(), seq_length=49;, score=-0.001 total time=  35.0s\n",
            "[CV 3/3] END basemodel__batch_size=421, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.8996230558165496, basemodel__model__dropout2=0.225900887438739, basemodel__model__dropout3=0.7823776999978126, basemodel__model__layer1=454, basemodel__model__layer2=255, basemodel__model__layer3=182, basemodel__model__learning_rate=0.006025238575442951, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.7901709119649518, scaler=MinMaxScaler(), seq_length=49;, score=0.295 total time=  52.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=286, basemodel__epochs=4, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.17056568318396803, basemodel__model__dropout2=0.37384512405951786, basemodel__model__dropout3=0.7957484788860745, basemodel__model__layer1=220, basemodel__model__layer2=84, basemodel__model__layer3=345, basemodel__model__learning_rate=0.004891908946076134, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4684857870141833, scaler=MinMaxScaler(), seq_length=73;, score=0.266 total time=  17.6s\n",
            "[CV 2/3] END basemodel__batch_size=286, basemodel__epochs=4, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.17056568318396803, basemodel__model__dropout2=0.37384512405951786, basemodel__model__dropout3=0.7957484788860745, basemodel__model__layer1=220, basemodel__model__layer2=84, basemodel__model__layer3=345, basemodel__model__learning_rate=0.004891908946076134, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4684857870141833, scaler=MinMaxScaler(), seq_length=73;, score=0.225 total time=  17.6s\n",
            "[CV 3/3] END basemodel__batch_size=286, basemodel__epochs=4, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.17056568318396803, basemodel__model__dropout2=0.37384512405951786, basemodel__model__dropout3=0.7957484788860745, basemodel__model__layer1=220, basemodel__model__layer2=84, basemodel__model__layer3=345, basemodel__model__learning_rate=0.004891908946076134, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.4684857870141833, scaler=MinMaxScaler(), seq_length=73;, score=0.059 total time=  17.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=134, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.5352813382264392, basemodel__model__dropout2=0.6699336830625604, basemodel__model__dropout3=0.799173690878957, basemodel__model__layer1=142, basemodel__model__layer2=468, basemodel__model__layer3=18, basemodel__model__learning_rate=0.003056372152446774, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11339881213834577, scaler=StandardScaler(), seq_length=74;, score=-0.262 total time= 2.9min\n",
            "[CV 2/3] END basemodel__batch_size=134, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.5352813382264392, basemodel__model__dropout2=0.6699336830625604, basemodel__model__dropout3=0.799173690878957, basemodel__model__layer1=142, basemodel__model__layer2=468, basemodel__model__layer3=18, basemodel__model__learning_rate=0.003056372152446774, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11339881213834577, scaler=StandardScaler(), seq_length=74;, score=-0.208 total time= 2.4min\n",
            "[CV 3/3] END basemodel__batch_size=134, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.5352813382264392, basemodel__model__dropout2=0.6699336830625604, basemodel__model__dropout3=0.799173690878957, basemodel__model__layer1=142, basemodel__model__layer2=468, basemodel__model__layer3=18, basemodel__model__learning_rate=0.003056372152446774, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.11339881213834577, scaler=StandardScaler(), seq_length=74;, score=-0.247 total time= 2.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=327, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.6277571377857365, basemodel__model__dropout2=0.2881193860271919, basemodel__model__dropout3=0.5776717975242857, basemodel__model__layer1=489, basemodel__model__layer2=115, basemodel__model__layer3=398, basemodel__model__learning_rate=0.007295481083310846, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2268697317654014, scaler=StandardScaler(), seq_length=82;, score=0.818 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=327, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.6277571377857365, basemodel__model__dropout2=0.2881193860271919, basemodel__model__dropout3=0.5776717975242857, basemodel__model__layer1=489, basemodel__model__layer2=115, basemodel__model__layer3=398, basemodel__model__learning_rate=0.007295481083310846, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2268697317654014, scaler=StandardScaler(), seq_length=82;, score=0.792 total time= 1.9min\n",
            "[CV 3/3] END basemodel__batch_size=327, basemodel__epochs=35, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.6277571377857365, basemodel__model__dropout2=0.2881193860271919, basemodel__model__dropout3=0.5776717975242857, basemodel__model__layer1=489, basemodel__model__layer2=115, basemodel__model__layer3=398, basemodel__model__learning_rate=0.007295481083310846, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2268697317654014, scaler=StandardScaler(), seq_length=82;, score=0.771 total time= 1.8min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=194, basemodel__epochs=47, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.24106109486064997, basemodel__model__dropout2=0.42048409797841246, basemodel__model__dropout3=0.25365197585310795, basemodel__model__layer1=146, basemodel__model__layer2=506, basemodel__model__layer3=457, basemodel__model__learning_rate=0.009425887601505128, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.22118693050940544, scaler=StandardScaler(), seq_length=40;, score=0.691 total time= 2.1min\n",
            "[CV 2/3] END basemodel__batch_size=194, basemodel__epochs=47, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.24106109486064997, basemodel__model__dropout2=0.42048409797841246, basemodel__model__dropout3=0.25365197585310795, basemodel__model__layer1=146, basemodel__model__layer2=506, basemodel__model__layer3=457, basemodel__model__learning_rate=0.009425887601505128, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.22118693050940544, scaler=StandardScaler(), seq_length=40;, score=0.722 total time= 1.4min\n",
            "[CV 3/3] END basemodel__batch_size=194, basemodel__epochs=47, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.24106109486064997, basemodel__model__dropout2=0.42048409797841246, basemodel__model__dropout3=0.25365197585310795, basemodel__model__layer1=146, basemodel__model__layer2=506, basemodel__model__layer3=457, basemodel__model__learning_rate=0.009425887601505128, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.22118693050940544, scaler=StandardScaler(), seq_length=40;, score=0.591 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=45, basemodel__epochs=13, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8730577741441089, basemodel__model__dropout2=0.2261849675968008, basemodel__model__dropout3=0.7286394446892809, basemodel__model__layer1=360, basemodel__model__layer2=280, basemodel__model__layer3=363, basemodel__model__learning_rate=0.006649990369312322, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8968416024379414, scaler=MinMaxScaler(), seq_length=87;, score=0.249 total time=  57.2s\n",
            "[CV 2/3] END basemodel__batch_size=45, basemodel__epochs=13, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8730577741441089, basemodel__model__dropout2=0.2261849675968008, basemodel__model__dropout3=0.7286394446892809, basemodel__model__layer1=360, basemodel__model__layer2=280, basemodel__model__layer3=363, basemodel__model__learning_rate=0.006649990369312322, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8968416024379414, scaler=MinMaxScaler(), seq_length=87;, score=0.235 total time=  58.4s\n",
            "[CV 3/3] END basemodel__batch_size=45, basemodel__epochs=13, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.8730577741441089, basemodel__model__dropout2=0.2261849675968008, basemodel__model__dropout3=0.7286394446892809, basemodel__model__layer1=360, basemodel__model__layer2=280, basemodel__model__layer3=363, basemodel__model__learning_rate=0.006649990369312322, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.8968416024379414, scaler=MinMaxScaler(), seq_length=87;, score=0.190 total time=  57.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=307, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.8658585380904228, basemodel__model__dropout2=0.3943327130572556, basemodel__model__dropout3=0.5277033986752562, basemodel__model__layer1=52, basemodel__model__layer2=321, basemodel__model__layer3=282, basemodel__model__learning_rate=0.007590805155026862, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6717961179732711, scaler=MinMaxScaler(), seq_length=33;, score=0.596 total time=  52.9s\n",
            "[CV 2/3] END basemodel__batch_size=307, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.8658585380904228, basemodel__model__dropout2=0.3943327130572556, basemodel__model__dropout3=0.5277033986752562, basemodel__model__layer1=52, basemodel__model__layer2=321, basemodel__model__layer3=282, basemodel__model__learning_rate=0.007590805155026862, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6717961179732711, scaler=MinMaxScaler(), seq_length=33;, score=0.519 total time=  44.0s\n",
            "[CV 3/3] END basemodel__batch_size=307, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.8658585380904228, basemodel__model__dropout2=0.3943327130572556, basemodel__model__dropout3=0.5277033986752562, basemodel__model__layer1=52, basemodel__model__layer2=321, basemodel__model__layer3=282, basemodel__model__learning_rate=0.007590805155026862, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6717961179732711, scaler=MinMaxScaler(), seq_length=33;, score=0.441 total time=  25.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=201, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.5777899567984156, basemodel__model__layer1=505, basemodel__model__layer2=153, basemodel__model__layer3=512, basemodel__model__learning_rate=0.004555730039824892, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=-0.014 total time=  18.1s\n",
            "[CV 2/3] END basemodel__batch_size=201, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.5777899567984156, basemodel__model__layer1=505, basemodel__model__layer2=153, basemodel__model__layer3=512, basemodel__model__learning_rate=0.004555730039824892, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=-0.003 total time=  17.4s\n",
            "[CV 3/3] END basemodel__batch_size=201, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.5777899567984156, basemodel__model__layer1=505, basemodel__model__layer2=153, basemodel__model__layer3=512, basemodel__model__learning_rate=0.004555730039824892, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=-0.005 total time=  17.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=412, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.44619708948618053, basemodel__model__layer1=16, basemodel__model__layer2=237, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0022044445474189707, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3626254272212742, scaler=MinMaxScaler(), seq_length=30;, score=-0.084 total time=  23.3s\n",
            "[CV 2/3] END basemodel__batch_size=412, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.44619708948618053, basemodel__model__layer1=16, basemodel__model__layer2=237, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0022044445474189707, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3626254272212742, scaler=MinMaxScaler(), seq_length=30;, score=0.252 total time=  45.1s\n",
            "[CV 3/3] END basemodel__batch_size=412, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.44619708948618053, basemodel__model__layer1=16, basemodel__model__layer2=237, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0022044445474189707, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.3626254272212742, scaler=MinMaxScaler(), seq_length=30;, score=-0.064 total time=  23.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=484, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2002242557161614, basemodel__model__dropout2=0.3568586437213773, basemodel__model__dropout3=0.3565954898802617, basemodel__model__layer1=114, basemodel__model__layer2=265, basemodel__model__layer3=305, basemodel__model__learning_rate=0.001912944751032797, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.39439699132576744, scaler=MinMaxScaler(), seq_length=75;, score=0.271 total time=  23.1s\n",
            "[CV 2/3] END basemodel__batch_size=484, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2002242557161614, basemodel__model__dropout2=0.3568586437213773, basemodel__model__dropout3=0.3565954898802617, basemodel__model__layer1=114, basemodel__model__layer2=265, basemodel__model__layer3=305, basemodel__model__learning_rate=0.001912944751032797, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.39439699132576744, scaler=MinMaxScaler(), seq_length=75;, score=0.280 total time=  23.5s\n",
            "[CV 3/3] END basemodel__batch_size=484, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.2002242557161614, basemodel__model__dropout2=0.3568586437213773, basemodel__model__dropout3=0.3565954898802617, basemodel__model__layer1=114, basemodel__model__layer2=265, basemodel__model__layer3=305, basemodel__model__learning_rate=0.001912944751032797, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.39439699132576744, scaler=MinMaxScaler(), seq_length=75;, score=0.306 total time=  23.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=387, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.6347381343631459, basemodel__model__dropout2=0.2978286897642042, basemodel__model__dropout3=0.5677132463741212, basemodel__model__layer1=427, basemodel__model__layer2=344, basemodel__model__layer3=431, basemodel__model__learning_rate=0.007889262328554407, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.15916389368423978, scaler=StandardScaler(), seq_length=55;, score=0.714 total time= 2.6min\n",
            "[CV 2/3] END basemodel__batch_size=387, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.6347381343631459, basemodel__model__dropout2=0.2978286897642042, basemodel__model__dropout3=0.5677132463741212, basemodel__model__layer1=427, basemodel__model__layer2=344, basemodel__model__layer3=431, basemodel__model__learning_rate=0.007889262328554407, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.15916389368423978, scaler=StandardScaler(), seq_length=55;, score=0.694 total time= 2.4min\n",
            "[CV 3/3] END basemodel__batch_size=387, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.6347381343631459, basemodel__model__dropout2=0.2978286897642042, basemodel__model__dropout3=0.5677132463741212, basemodel__model__layer1=427, basemodel__model__layer2=344, basemodel__model__layer3=431, basemodel__model__learning_rate=0.007889262328554407, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.15916389368423978, scaler=StandardScaler(), seq_length=55;, score=0.639 total time= 2.8min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=160, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.3705800022785669, basemodel__model__dropout2=0.511031939212743, basemodel__model__dropout3=0.505012875390786, basemodel__model__layer1=360, basemodel__model__layer2=213, basemodel__model__layer3=290, basemodel__model__learning_rate=0.0038208619917410687, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2446192954360025, scaler=StandardScaler(), seq_length=55;, score=0.757 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=160, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.3705800022785669, basemodel__model__dropout2=0.511031939212743, basemodel__model__dropout3=0.505012875390786, basemodel__model__layer1=360, basemodel__model__layer2=213, basemodel__model__layer3=290, basemodel__model__learning_rate=0.0038208619917410687, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2446192954360025, scaler=StandardScaler(), seq_length=55;, score=0.695 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=160, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.3705800022785669, basemodel__model__dropout2=0.511031939212743, basemodel__model__dropout3=0.505012875390786, basemodel__model__layer1=360, basemodel__model__layer2=213, basemodel__model__layer3=290, basemodel__model__learning_rate=0.0038208619917410687, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.2446192954360025, scaler=StandardScaler(), seq_length=55;, score=0.653 total time= 1.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=239, basemodel__epochs=8, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.6898402185577723, basemodel__model__dropout2=0.5338177593994042, basemodel__model__dropout3=0.3494148700617057, basemodel__model__layer1=328, basemodel__model__layer2=301, basemodel__model__layer3=227, basemodel__model__learning_rate=0.007166822883446992, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6316883273142115, scaler=MinMaxScaler(), seq_length=47;, score=0.013 total time=  26.9s\n",
            "[CV 2/3] END basemodel__batch_size=239, basemodel__epochs=8, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.6898402185577723, basemodel__model__dropout2=0.5338177593994042, basemodel__model__dropout3=0.3494148700617057, basemodel__model__layer1=328, basemodel__model__layer2=301, basemodel__model__layer3=227, basemodel__model__learning_rate=0.007166822883446992, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6316883273142115, scaler=MinMaxScaler(), seq_length=47;, score=0.012 total time=  26.7s\n",
            "[CV 3/3] END basemodel__batch_size=239, basemodel__epochs=8, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.6898402185577723, basemodel__model__dropout2=0.5338177593994042, basemodel__model__dropout3=0.3494148700617057, basemodel__model__layer1=328, basemodel__model__layer2=301, basemodel__model__layer3=227, basemodel__model__learning_rate=0.007166822883446992, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__validation_split=0.6316883273142115, scaler=MinMaxScaler(), seq_length=47;, score=-0.009 total time=  28.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=319, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.5958087331343939, basemodel__model__dropout2=0.2857382279491676, basemodel__model__dropout3=0.5822158703911061, basemodel__model__layer1=337, basemodel__model__layer2=444, basemodel__model__layer3=272, basemodel__model__learning_rate=0.0069804113902697884, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.49283016389121503, scaler=MinMaxScaler(), seq_length=38;, score=0.612 total time= 1.3min\n",
            "[CV 2/3] END basemodel__batch_size=319, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.5958087331343939, basemodel__model__dropout2=0.2857382279491676, basemodel__model__dropout3=0.5822158703911061, basemodel__model__layer1=337, basemodel__model__layer2=444, basemodel__model__layer3=272, basemodel__model__learning_rate=0.0069804113902697884, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.49283016389121503, scaler=MinMaxScaler(), seq_length=38;, score=0.621 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=319, basemodel__epochs=29, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.5958087331343939, basemodel__model__dropout2=0.2857382279491676, basemodel__model__dropout3=0.5822158703911061, basemodel__model__layer1=337, basemodel__model__layer2=444, basemodel__model__layer3=272, basemodel__model__learning_rate=0.0069804113902697884, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.49283016389121503, scaler=MinMaxScaler(), seq_length=38;, score=0.454 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=325, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.5999695396702547, basemodel__model__dropout2=0.2824705080924561, basemodel__model__dropout3=0.5749415465530767, basemodel__model__layer1=512, basemodel__model__layer2=58, basemodel__model__layer3=438, basemodel__model__learning_rate=0.007448084633524131, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.10991019995076438, scaler=StandardScaler(), seq_length=93;, score=0.836 total time= 2.0min\n",
            "[CV 2/3] END basemodel__batch_size=325, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.5999695396702547, basemodel__model__dropout2=0.2824705080924561, basemodel__model__dropout3=0.5749415465530767, basemodel__model__layer1=512, basemodel__model__layer2=58, basemodel__model__layer3=438, basemodel__model__learning_rate=0.007448084633524131, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.10991019995076438, scaler=StandardScaler(), seq_length=93;, score=0.858 total time= 2.0min\n",
            "[CV 3/3] END basemodel__batch_size=325, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.5999695396702547, basemodel__model__dropout2=0.2824705080924561, basemodel__model__dropout3=0.5749415465530767, basemodel__model__layer1=512, basemodel__model__layer2=58, basemodel__model__layer3=438, basemodel__model__learning_rate=0.007448084633524131, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.10991019995076438, scaler=StandardScaler(), seq_length=93;, score=0.854 total time= 2.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=316, basemodel__epochs=38, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.5044545515075356, basemodel__model__dropout2=0.32630445939259334, basemodel__model__dropout3=0.5719448609546804, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__layer3=470, basemodel__model__learning_rate=0.007592062453361027, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=0.887 total time= 2.0min\n",
            "[CV 2/3] END basemodel__batch_size=316, basemodel__epochs=38, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.5044545515075356, basemodel__model__dropout2=0.32630445939259334, basemodel__model__dropout3=0.5719448609546804, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__layer3=470, basemodel__model__learning_rate=0.007592062453361027, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=0.770 total time= 2.0min\n",
            "[CV 3/3] END basemodel__batch_size=316, basemodel__epochs=38, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.5044545515075356, basemodel__model__dropout2=0.32630445939259334, basemodel__model__dropout3=0.5719448609546804, basemodel__model__layer1=512, basemodel__model__layer2=16, basemodel__model__layer3=470, basemodel__model__learning_rate=0.007592062453361027, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=StandardScaler(), seq_length=100;, score=0.805 total time= 2.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=145, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3023200947783141, basemodel__model__dropout2=0.42795913778639827, basemodel__model__dropout3=0.5781986102741947, basemodel__model__layer1=512, basemodel__model__layer2=443, basemodel__model__layer3=417, basemodel__model__learning_rate=0.007270622509356574, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=37;, score=0.476 total time=  46.8s\n",
            "[CV 2/3] END basemodel__batch_size=145, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3023200947783141, basemodel__model__dropout2=0.42795913778639827, basemodel__model__dropout3=0.5781986102741947, basemodel__model__layer1=512, basemodel__model__layer2=443, basemodel__model__layer3=417, basemodel__model__learning_rate=0.007270622509356574, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=37;, score=0.459 total time=  45.8s\n",
            "[CV 3/3] END basemodel__batch_size=145, basemodel__epochs=6, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.3023200947783141, basemodel__model__dropout2=0.42795913778639827, basemodel__model__dropout3=0.5781986102741947, basemodel__model__layer1=512, basemodel__model__layer2=443, basemodel__model__layer3=417, basemodel__model__learning_rate=0.007270622509356574, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__validation_split=0.1, scaler=MinMaxScaler(), seq_length=37;, score=0.435 total time=  44.4s\n",
            "Finished: 2022-10-16 16:49:09.264965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "SSmZxJKlUNFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05efac3b-9a7e-4ce3-d110-a0f41d7e50e1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8491646332519348\n",
            "OrderedDict([('basemodel__batch_size', 325), ('basemodel__epochs', 37), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'tanh'), ('basemodel__model__activation3', 'sigmoid'), ('basemodel__model__dropout1', 0.5999695396702547), ('basemodel__model__dropout2', 0.2824705080924561), ('basemodel__model__dropout3', 0.5749415465530767), ('basemodel__model__layer1', 512), ('basemodel__model__layer2', 58), ('basemodel__model__layer3', 438), ('basemodel__model__learning_rate', 0.007448084633524131), ('basemodel__model__optim', <class 'keras.optimizer_v2.rmsprop.RMSprop'>), ('basemodel__validation_split', 0.10991019995076438), ('scaler', StandardScaler()), ('seq_length', 93)])\n",
            "Finished: 2022-10-16 16:49:10.481612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "id": "0HUnMESRVitn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "53b09f48-c375-4952-d3de-df6dcde4642c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-16 16:49:10.513635\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8QiZ9pWmSb0",
        "outputId": "3ab25d22-4a51-4443-d96b-4795eeea9601"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 325),\n",
              "             ('basemodel__epochs', 37),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'tanh'),\n",
              "             ('basemodel__model__activation3', 'sigmoid'),\n",
              "             ('basemodel__model__dropout1', 0.5999695396702547),\n",
              "             ('basemodel__model__dropout2', 0.2824705080924561),\n",
              "             ('basemodel__model__dropout3', 0.5749415465530767),\n",
              "             ('basemodel__model__layer1', 512),\n",
              "             ('basemodel__model__layer2', 58),\n",
              "             ('basemodel__model__layer3', 438),\n",
              "             ('basemodel__model__learning_rate', 0.007448084633524131),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
              "             ('basemodel__validation_split', 0.10991019995076438),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 93)])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer\n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7965826139501325  \n",
        "Test: 0.706\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.10771222326909816),\n",
        "('basemodel__model__layer1', 505),\n",
        "('basemodel__model__learning_rate', 0.0032806529941975817),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 70)\n",
        "```\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.9430289602358563  \n",
        "Test: 0.857\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.1),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('clip_y', 105),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 68)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ESr-SWV1Dy3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.8254078138058109  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 43),\n",
        "('basemodel__model__activation', 'tanh'),\n",
        "('basemodel__model__dropout', 0.12031183587891998),\n",
        "('basemodel__model__layer1', 291),\n",
        "('basemodel__model__learning_rate', 0.0005169281218693581),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('poly_degree', 3),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 61)\n",
        "```\n"
      ],
      "metadata": {
        "id": "0CW_mllpD0gP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.8183215542558463  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 118),\n",
        "             ('basemodel__epochs', 32),\n",
        "             ('basemodel__model__activation', 'tanh'),\n",
        "             ('basemodel__model__dropout', 0.3795770073881617),\n",
        "             ('basemodel__model__layer1', 432),\n",
        "             ('basemodel__model__learning_rate', 0.00806882152030281),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.7235243202098837),\n",
        "             ('clip_y', 105),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yMvVSJBGD1vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1\n"
      ],
      "metadata": {
        "id": "zSnh2UONQb4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.8521617501513421  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 239),\n",
        "             ('basemodel__epochs', 45),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.8360008606718795),\n",
        "             ('basemodel__model__dropout2', 0.8326359552620336),\n",
        "             ('basemodel__model__layer1', 493),\n",
        "             ('basemodel__model__layer2', 469),\n",
        "             ('basemodel__model__learning_rate', 0.0013568819509124186),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1967801723709445),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 74)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vL2GlZ8KQb4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.917847894602053  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 174),\n",
        "             ('basemodel__epochs', 21),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.5157104351784535),\n",
        "             ('basemodel__model__dropout2', 0.7126675967759073),\n",
        "             ('basemodel__model__layer1', 125),\n",
        "             ('basemodel__model__layer2', 386),\n",
        "             ('basemodel__model__learning_rate', 0.0017804516876459917),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.23205313885059345),\n",
        "             ('clip_y', 140),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 80)\n",
        "```\n"
      ],
      "metadata": {
        "id": "B3F5zD55D9Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Linear RUL + Poly\n",
        "Score: 0.8751657917165176  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 330),\n",
        "             ('basemodel__epochs', 27),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.5840619694211598),\n",
        "             ('basemodel__model__dropout2', 0.3536146443159782),\n",
        "             ('basemodel__model__layer1', 360),\n",
        "             ('basemodel__model__layer2', 382),\n",
        "             ('basemodel__model__learning_rate', 0.0017591525384268944),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.26148795256547086),\n",
        "             ('poly_degree', 3),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 81)\n",
        "```\n"
      ],
      "metadata": {
        "id": "xm2OWXQdD--y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL + Poly\n",
        "Score: 0.9051284444957921  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 509),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__dropout2', 0.6005182679835956),\n",
        "             ('basemodel__model__layer1', 195),\n",
        "             ('basemodel__model__layer2', 41),\n",
        "             ('basemodel__model__learning_rate', 0.0012817938927923201),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.31333644945401407),\n",
        "             ('clip_y', 80),\n",
        "             ('poly_degree', 2),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 100)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-Ehn2OV_D_yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2\n"
      ],
      "metadata": {
        "id": "Jygcz0fjrzEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to change the argument: 'second_dense=True'"
      ],
      "metadata": {
        "id": "puLVKoxXEXb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.7968129295270682  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 33),\n",
        "             ('basemodel__epochs', 32),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.22285374911306066),\n",
        "             ('basemodel__model__dropout2', 0.7374780395679955),\n",
        "             ('basemodel__model__dropout3', 0.3869949529630097),\n",
        "             ('basemodel__model__layer1', 224),\n",
        "             ('basemodel__model__layer2', 512),\n",
        "             ('basemodel__model__layer3', 396),\n",
        "             ('basemodel__model__learning_rate', 0.0006807885804241826),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.6313983549045777),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 95)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ywnov-HvrzEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.8303738924314298  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 70),\n",
        "             ('basemodel__epochs', 45),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'relu'),\n",
        "             ('basemodel__model__activation3', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.677716159846799),\n",
        "             ('basemodel__model__dropout2', 0.2905479330833355),\n",
        "             ('basemodel__model__dropout3', 0.25279167191355223),\n",
        "             ('basemodel__model__layer1', 177),\n",
        "             ('basemodel__model__layer2', 470),\n",
        "             ('basemodel__model__layer3', 221),\n",
        "             ('basemodel__model__learning_rate', 0.009128147835708741),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.643380976472796),\n",
        "             ('clip_y', 98),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 58)\n",
        "```\n"
      ],
      "metadata": {
        "id": "W98etTHQrzEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense\n"
      ],
      "metadata": {
        "id": "z2vaL6nDDYF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.8491646332519348  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 325),\n",
        "             ('basemodel__epochs', 37),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.5999695396702547),\n",
        "             ('basemodel__model__dropout2', 0.2824705080924561),\n",
        "             ('basemodel__model__dropout3', 0.5749415465530767),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__layer2', 58),\n",
        "             ('basemodel__model__layer3', 438),\n",
        "             ('basemodel__model__learning_rate', 0.007448084633524131),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__validation_split', 0.10991019995076438),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 93)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YD0XcCDuDYF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.  \n",
        "Test: 0.\n",
        "```\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "L5Sg97mcDYF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "outputId": "10771aed-b881-4a8f-84bc-279c86183fd4",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-58-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# Data checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfeature_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_build_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: create_model() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QFBtaiz2Ckgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           \n",
        "                           \n",
        "                           model__layer1=512, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer2=400,\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "\n",
        "                        \n",
        "                           \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_36P-gmRD6QM",
        "outputId": "04f7f7d7-28d1-40ba-97ee-4fd9aa120787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_65 (Masking)        (None, 79, 22)            0         \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 400)               205200    \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 400)               0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301,281\n",
            "Trainable params: 1,301,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=288.566, rmse=16.987, r2=0.735; v_loss=171.738, v_rmse=13.105, v_r2=0.847; \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-62-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         self._fit_keras_model(\n\u001b[0m\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m   1222\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "83699a7e-1744-455e-c836-906b8dc33bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.918,RMSE=-9.668\n",
            "Finished: 2022-10-13 13:15:58.111062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee8uwFhF-E6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}