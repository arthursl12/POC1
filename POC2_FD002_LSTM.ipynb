{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "wbuPiXILHHLC",
        "Pnwfsl-aHHLM",
        "ePNldoX9HHLP",
        "MIxpl_deHHLT",
        "6EAk29FIHHLU",
        "y1r4pfQgHHLW",
        "jN9jMcE-HHLX",
        "ApGlTbAtHHLY",
        "nTPBH5fg_sFd",
        "f3Or3dZbB5Pr",
        "DvHTMj_9_xss",
        "9mjReYMmM08s",
        "Z7Z5u9Bu_Q4x",
        "TAC6RVwbHHLg",
        "DZEmsy2m2lXL"
      ],
      "authorship_tag": "ABX9TyNgLM3F+HZglx+fPX46cQ+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD002_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "wbuPiXILHHLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543d5a96-835d-4fc2-d0ea-feb5be87af34",
        "id": "xgrLxZBAHHLE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.9.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.13.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "WxPjchtEHHLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "NGG29VypHHLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "Eyei4ajQHHLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "wHAvW_6rHHLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "HfbMAckfHHLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "-4FxQFdYHHLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "Pnwfsl-aHHLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "id": "tlp572nXopEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6a57ee-a3bf-4db4-f02f-7982481273c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "QdvXViGaHHLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "bDxH33UkHHLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "ePNldoX9HHLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "zdGT4L4KHHLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(2, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "6a15a8ce-e90a-4d4a-aa43-fadc8e935a5e",
        "id": "UoXlCtisHHLS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time     op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1  34.9983  0.8400  100.0  449.44  555.32  1358.61   \n",
              "1                1     2  41.9982  0.8408  100.0  445.00  549.90  1353.22   \n",
              "2                1     3  24.9988  0.6218   60.0  462.54  537.31  1256.76   \n",
              "3                1     4  42.0077  0.8416  100.0  445.00  549.51  1354.03   \n",
              "4                1     5  25.0005  0.6203   60.0  462.54  537.07  1257.71   \n",
              "...            ...   ...      ...     ...    ...     ...     ...      ...   \n",
              "53754          260   312  20.0037  0.7000  100.0  491.19  608.79  1495.60   \n",
              "53755          260   313  10.0022  0.2510  100.0  489.05  605.81  1514.32   \n",
              "53756          260   314  25.0041  0.6200   60.0  462.54  537.48  1276.24   \n",
              "53757          260   315  25.0033  0.6220   60.0  462.54  537.84  1272.95   \n",
              "53758          260   316  35.0036  0.8400  100.0  449.44  556.64  1374.61   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13     s_14  s_15  s_16  \\\n",
              "0      1137.23   5.48  ...  183.06  2387.72  8048.56   9.3461  0.02   334   \n",
              "1      1125.78   3.91  ...  130.42  2387.66  8072.30   9.3774  0.02   330   \n",
              "2      1047.45   7.05  ...  164.22  2028.03  7864.87  10.8941  0.02   309   \n",
              "3      1126.38   3.91  ...  130.72  2387.61  8068.66   9.3528  0.02   329   \n",
              "4      1047.93   7.05  ...  164.31  2028.00  7861.23  10.8963  0.02   309   \n",
              "...        ...    ...  ...     ...      ...      ...      ...   ...   ...   \n",
              "53754  1269.51   9.35  ...  314.05  2389.02  8169.64   9.3035  0.03   369   \n",
              "53755  1324.12  10.52  ...  371.22  2388.42  8245.36   8.7586  0.03   374   \n",
              "53756  1057.92   7.05  ...  163.74  2030.33  7971.25  11.0657  0.02   310   \n",
              "53757  1066.30   7.05  ...  164.37  2030.35  7972.47  11.0537  0.02   311   \n",
              "53758  1145.52   5.48  ...  183.09  2390.38  8185.35   9.3998  0.02   338   \n",
              "\n",
              "       s_17    s_18   s_19     s_20  \n",
              "0      2223  100.00  14.73   8.8071  \n",
              "1      2212  100.00  10.41   6.2665  \n",
              "2      1915   84.93  14.08   8.6723  \n",
              "3      2212  100.00  10.59   6.4701  \n",
              "4      1915   84.93  14.13   8.5286  \n",
              "...     ...     ...    ...      ...  \n",
              "53754  2324  100.00  24.36  14.5189  \n",
              "53755  2319  100.00  28.10  16.9454  \n",
              "53756  1915   84.93  14.19   8.5503  \n",
              "53757  1915   84.93  14.05   8.3729  \n",
              "53758  2223  100.00  14.75   8.8446  \n",
              "\n",
              "[53759 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1045cc76-49be-4c09-9965-0b1e2abf805c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>183.06</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>130.42</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.22</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>130.72</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.31</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53754</th>\n",
              "      <td>260</td>\n",
              "      <td>312</td>\n",
              "      <td>20.0037</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>608.79</td>\n",
              "      <td>1495.60</td>\n",
              "      <td>1269.51</td>\n",
              "      <td>9.35</td>\n",
              "      <td>...</td>\n",
              "      <td>314.05</td>\n",
              "      <td>2389.02</td>\n",
              "      <td>8169.64</td>\n",
              "      <td>9.3035</td>\n",
              "      <td>0.03</td>\n",
              "      <td>369</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.00</td>\n",
              "      <td>24.36</td>\n",
              "      <td>14.5189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53755</th>\n",
              "      <td>260</td>\n",
              "      <td>313</td>\n",
              "      <td>10.0022</td>\n",
              "      <td>0.2510</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.81</td>\n",
              "      <td>1514.32</td>\n",
              "      <td>1324.12</td>\n",
              "      <td>10.52</td>\n",
              "      <td>...</td>\n",
              "      <td>371.22</td>\n",
              "      <td>2388.42</td>\n",
              "      <td>8245.36</td>\n",
              "      <td>8.7586</td>\n",
              "      <td>0.03</td>\n",
              "      <td>374</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.00</td>\n",
              "      <td>28.10</td>\n",
              "      <td>16.9454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53756</th>\n",
              "      <td>260</td>\n",
              "      <td>314</td>\n",
              "      <td>25.0041</td>\n",
              "      <td>0.6200</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.48</td>\n",
              "      <td>1276.24</td>\n",
              "      <td>1057.92</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>163.74</td>\n",
              "      <td>2030.33</td>\n",
              "      <td>7971.25</td>\n",
              "      <td>11.0657</td>\n",
              "      <td>0.02</td>\n",
              "      <td>310</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.19</td>\n",
              "      <td>8.5503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53757</th>\n",
              "      <td>260</td>\n",
              "      <td>315</td>\n",
              "      <td>25.0033</td>\n",
              "      <td>0.6220</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.84</td>\n",
              "      <td>1272.95</td>\n",
              "      <td>1066.30</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.37</td>\n",
              "      <td>2030.35</td>\n",
              "      <td>7972.47</td>\n",
              "      <td>11.0537</td>\n",
              "      <td>0.02</td>\n",
              "      <td>311</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.05</td>\n",
              "      <td>8.3729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53758</th>\n",
              "      <td>260</td>\n",
              "      <td>316</td>\n",
              "      <td>35.0036</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>556.64</td>\n",
              "      <td>1374.61</td>\n",
              "      <td>1145.52</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>183.09</td>\n",
              "      <td>2390.38</td>\n",
              "      <td>8185.35</td>\n",
              "      <td>9.3998</td>\n",
              "      <td>0.02</td>\n",
              "      <td>338</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8.8446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53759 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1045cc76-49be-4c09-9965-0b1e2abf805c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1045cc76-49be-4c09-9965-0b1e2abf805c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1045cc76-49be-4c09-9965-0b1e2abf805c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "MIxpl_deHHLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "6EAk29FIHHLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6adba3a2-2f86-4c95-e004-a75ab28da1c6",
        "id": "fZRG6FZxHHLU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33991, 26), (259, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test_keep_setting(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "37299404-f84e-4e9b-f5cb-3322f4c47c08",
        "id": "u8TAq9vFHHLV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3    s_4    s_5  \\\n",
              "0  10.0076  0.2501  100.0  489.05  605.42  1515.00  1325.07  10.52  15.50   \n",
              "1   0.0018  0.0000  100.0  518.67  642.67  1591.67  1418.17  14.62  21.61   \n",
              "2  35.0015  0.8412  100.0  449.44  555.86  1370.62  1135.59   5.48   8.00   \n",
              "3  20.0032  0.7000  100.0  491.19  607.99  1487.94  1257.49   9.35  13.66   \n",
              "4  42.0055  0.8400  100.0  445.00  550.81  1358.95  1140.34   3.91   5.72   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0  393.58  ...  370.87  2388.32  8167.06  8.7456  0.03   371  2319  100.0   \n",
              "1  553.36  ...  521.10  2388.12  8138.12  8.4248  0.03   393  2388  100.0   \n",
              "2  194.58  ...  183.11  2388.07  8071.23  9.3094  0.02   332  2223  100.0   \n",
              "3  334.39  ...  314.88  2388.12  8062.39  9.2349  0.02   365  2324  100.0   \n",
              "4  138.42  ...  130.82  2389.06  8140.94  9.3964  0.02   333  2212  100.0   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  28.30  17.0934  \n",
              "1  38.82  23.3463  \n",
              "2  14.75   8.9589  \n",
              "3  24.22  14.6814  \n",
              "4  10.34   6.3601  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-520cf8af-7ad1-4195-8623-dd812cc6d6d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0076</td>\n",
              "      <td>0.2501</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.42</td>\n",
              "      <td>1515.00</td>\n",
              "      <td>1325.07</td>\n",
              "      <td>10.52</td>\n",
              "      <td>15.50</td>\n",
              "      <td>393.58</td>\n",
              "      <td>...</td>\n",
              "      <td>370.87</td>\n",
              "      <td>2388.32</td>\n",
              "      <td>8167.06</td>\n",
              "      <td>8.7456</td>\n",
              "      <td>0.03</td>\n",
              "      <td>371</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.0</td>\n",
              "      <td>28.30</td>\n",
              "      <td>17.0934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0018</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.67</td>\n",
              "      <td>1591.67</td>\n",
              "      <td>1418.17</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.36</td>\n",
              "      <td>...</td>\n",
              "      <td>521.10</td>\n",
              "      <td>2388.12</td>\n",
              "      <td>8138.12</td>\n",
              "      <td>8.4248</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.82</td>\n",
              "      <td>23.3463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.0015</td>\n",
              "      <td>0.8412</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.86</td>\n",
              "      <td>1370.62</td>\n",
              "      <td>1135.59</td>\n",
              "      <td>5.48</td>\n",
              "      <td>8.00</td>\n",
              "      <td>194.58</td>\n",
              "      <td>...</td>\n",
              "      <td>183.11</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8071.23</td>\n",
              "      <td>9.3094</td>\n",
              "      <td>0.02</td>\n",
              "      <td>332</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.0</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8.9589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0032</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>607.99</td>\n",
              "      <td>1487.94</td>\n",
              "      <td>1257.49</td>\n",
              "      <td>9.35</td>\n",
              "      <td>13.66</td>\n",
              "      <td>334.39</td>\n",
              "      <td>...</td>\n",
              "      <td>314.88</td>\n",
              "      <td>2388.12</td>\n",
              "      <td>8062.39</td>\n",
              "      <td>9.2349</td>\n",
              "      <td>0.02</td>\n",
              "      <td>365</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.22</td>\n",
              "      <td>14.6814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.0055</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>550.81</td>\n",
              "      <td>1358.95</td>\n",
              "      <td>1140.34</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.72</td>\n",
              "      <td>138.42</td>\n",
              "      <td>...</td>\n",
              "      <td>130.82</td>\n",
              "      <td>2389.06</td>\n",
              "      <td>8140.94</td>\n",
              "      <td>9.3964</td>\n",
              "      <td>0.02</td>\n",
              "      <td>333</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.34</td>\n",
              "      <td>6.3601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-520cf8af-7ad1-4195-8623-dd812cc6d6d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-520cf8af-7ad1-4195-8623-dd812cc6d6d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-520cf8af-7ad1-4195-8623-dd812cc6d6d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "byXM_HFgHHLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "y1r4pfQgHHLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "f1d9670e-c82f-403b-ddc6-3ec8fa101caa",
        "id": "9sVQVvdZHHLW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  148\n",
              "1            1     2  147\n",
              "2            1     3  146\n",
              "3            1     4  145\n",
              "4            1     5  144"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a5d82c6-609d-4fc3-add2-e59b4fc9a6e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a5d82c6-609d-4fc3-add2-e59b4fc9a6e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a5d82c6-609d-4fc3-add2-e59b4fc9a6e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a5d82c6-609d-4fc3-add2-e59b4fc9a6e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "jN9jMcE-HHLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide_with_settings(train)"
      ],
      "metadata": {
        "id": "Itm_P5tIHHLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "bbc12661-dcb0-477c-feda-3c87d0cc253b",
        "id": "rbdgnmCTHHLY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  148\n",
              "1  147\n",
              "2  146\n",
              "3  145\n",
              "4  144"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c82de156-d675-40ae-85b8-0b7760dde891\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c82de156-d675-40ae-85b8-0b7760dde891')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c82de156-d675-40ae-85b8-0b7760dde891 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c82de156-d675-40ae-85b8-0b7760dde891');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "13c1fb91-0331-4eb2-9d84-7adf8b76cbf9",
        "id": "WD5RRgu6HHLY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3   s_4   s_5  \\\n",
              "0  34.9983  0.8400  100.0  449.44  555.32  1358.61  1137.23  5.48  8.00   \n",
              "1  41.9982  0.8408  100.0  445.00  549.90  1353.22  1125.78  3.91  5.71   \n",
              "2  24.9988  0.6218   60.0  462.54  537.31  1256.76  1047.45  7.05  9.02   \n",
              "3  42.0077  0.8416  100.0  445.00  549.51  1354.03  1126.38  3.91  5.71   \n",
              "4  25.0005  0.6203   60.0  462.54  537.07  1257.71  1047.93  7.05  9.03   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13     s_14  s_15  s_16  s_17    s_18  \\\n",
              "0  194.64  ...  183.06  2387.72  8048.56   9.3461  0.02   334  2223  100.00   \n",
              "1  138.51  ...  130.42  2387.66  8072.30   9.3774  0.02   330  2212  100.00   \n",
              "2  175.71  ...  164.22  2028.03  7864.87  10.8941  0.02   309  1915   84.93   \n",
              "3  138.46  ...  130.72  2387.61  8068.66   9.3528  0.02   329  2212  100.00   \n",
              "4  175.05  ...  164.31  2028.00  7861.23  10.8963  0.02   309  1915   84.93   \n",
              "\n",
              "    s_19    s_20  \n",
              "0  14.73  8.8071  \n",
              "1  10.41  6.2665  \n",
              "2  14.08  8.6723  \n",
              "3  10.59  6.4701  \n",
              "4  14.13  8.5286  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa43e7c3-f899-4083-ac9e-3b4408fb277e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>8.00</td>\n",
              "      <td>194.64</td>\n",
              "      <td>...</td>\n",
              "      <td>183.06</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.71</td>\n",
              "      <td>138.51</td>\n",
              "      <td>...</td>\n",
              "      <td>130.42</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.02</td>\n",
              "      <td>175.71</td>\n",
              "      <td>...</td>\n",
              "      <td>164.22</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.71</td>\n",
              "      <td>138.46</td>\n",
              "      <td>...</td>\n",
              "      <td>130.72</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.03</td>\n",
              "      <td>175.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.31</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa43e7c3-f899-4083-ac9e-3b4408fb277e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa43e7c3-f899-4083-ac9e-3b4408fb277e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa43e7c3-f899-4083-ac9e-3b4408fb277e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "ApGlTbAtHHLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "-QVCTdsbHHLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "LvBdvzyGHHLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "2aaP3NDdHHLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "TAC6RVwbHHLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer "
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "5aqms6jMFKti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5816177553633815  \n",
        "Test: 0.625\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 35),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.9),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.1),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 100)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "oGlT7ajZFKtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=100\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=35,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.9, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9cc8be-1f02-4529-a926-2fe31e0bf3b0",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 100, 25)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512)               1101824   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,102,337\n",
            "Trainable params: 1,102,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3586.621, rmse=59.888, r2=-0.647; v_loss=4061.905, v_rmse=63.733, v_r2=-0.391; \n",
            "E 2\t: loss=2453.961, rmse=49.537, r2=-0.127; v_loss=3340.924, v_rmse=57.801, v_r2=-0.144; \n",
            "E 3\t: loss=2150.387, rmse=46.372, r2=0.013; v_loss=3040.207, v_rmse=55.138, v_r2=-0.041; \n",
            "E 4\t: loss=1994.440, rmse=44.659, r2=0.084; v_loss=2860.264, v_rmse=53.481, v_r2=0.020; \n",
            "E 5\t: loss=1930.457, rmse=43.937, r2=0.114; v_loss=2755.708, v_rmse=52.495, v_r2=0.056; \n",
            "E 6\t: loss=1891.491, rmse=43.491, r2=0.132; v_loss=2738.138, v_rmse=52.327, v_r2=0.062; \n",
            "E 7\t: loss=1866.885, rmse=43.207, r2=0.143; v_loss=2611.075, v_rmse=51.099, v_r2=0.106; \n",
            "E 8\t: loss=1801.488, rmse=42.444, r2=0.173; v_loss=2604.590, v_rmse=51.035, v_r2=0.108; \n",
            "E 9\t: loss=1544.090, rmse=39.295, r2=0.291; v_loss=1831.932, v_rmse=42.801, v_r2=0.373; \n",
            "E 10\t: loss=1324.554, rmse=36.394, r2=0.392; v_loss=1603.098, v_rmse=40.039, v_r2=0.451; \n",
            "E 11\t: loss=1301.805, rmse=36.081, r2=0.402; v_loss=1518.395, v_rmse=38.967, v_r2=0.480; \n",
            "E 12\t: loss=1168.958, rmse=34.190, r2=0.463; v_loss=1384.932, v_rmse=37.215, v_r2=0.526; \n",
            "E 13\t: loss=1126.278, rmse=33.560, r2=0.483; v_loss=1210.031, v_rmse=34.785, v_r2=0.586; \n",
            "E 14\t: loss=1041.994, rmse=32.280, r2=0.522; v_loss=1244.709, v_rmse=35.280, v_r2=0.574; \n",
            "E 15\t: loss=970.492, rmse=31.153, r2=0.554; v_loss=1482.259, v_rmse=38.500, v_r2=0.492; \n",
            "E 16\t: loss=929.713, rmse=30.491, r2=0.573; v_loss=859.373, v_rmse=29.315, v_r2=0.706; \n",
            "E 17\t: loss=916.090, rmse=30.267, r2=0.579; v_loss=1039.917, v_rmse=32.248, v_r2=0.644; \n",
            "E 18\t: loss=870.524, rmse=29.505, r2=0.600; v_loss=1081.125, v_rmse=32.880, v_r2=0.630; \n",
            "E 19\t: loss=847.245, rmse=29.107, r2=0.611; v_loss=1197.459, v_rmse=34.604, v_r2=0.590; \n",
            "E 20\t: loss=781.459, rmse=27.955, r2=0.641; v_loss=996.602, v_rmse=31.569, v_r2=0.659; \n",
            "E 21\t: loss=759.655, rmse=27.562, r2=0.651; v_loss=715.234, v_rmse=26.744, v_r2=0.755; \n",
            "E 22\t: loss=769.253, rmse=27.735, r2=0.647; v_loss=908.992, v_rmse=30.149, v_r2=0.689; \n",
            "E 23\t: loss=684.187, rmse=26.157, r2=0.686; v_loss=687.284, v_rmse=26.216, v_r2=0.765; \n",
            "E 24\t: loss=698.687, rmse=26.433, r2=0.679; v_loss=692.384, v_rmse=26.313, v_r2=0.763; \n",
            "E 25\t: loss=635.190, rmse=25.203, r2=0.708; v_loss=775.456, v_rmse=27.847, v_r2=0.734; \n",
            "E 26\t: loss=661.146, rmse=25.713, r2=0.696; v_loss=901.216, v_rmse=30.020, v_r2=0.691; \n",
            "E 27\t: loss=605.464, rmse=24.606, r2=0.722; v_loss=961.048, v_rmse=31.001, v_r2=0.671; \n",
            "E 28\t: loss=596.891, rmse=24.431, r2=0.726; v_loss=1361.703, v_rmse=36.901, v_r2=0.534; \n",
            "E 29\t: loss=560.843, rmse=23.682, r2=0.743; v_loss=861.982, v_rmse=29.360, v_r2=0.705; \n",
            "E 30\t: loss=596.722, rmse=24.428, r2=0.726; v_loss=654.918, v_rmse=25.591, v_r2=0.776; \n",
            "E 31\t: loss=529.731, rmse=23.016, r2=0.757; v_loss=791.406, v_rmse=28.132, v_r2=0.729; \n",
            "E 32\t: loss=524.283, rmse=22.897, r2=0.759; v_loss=778.541, v_rmse=27.902, v_r2=0.733; \n",
            "E 33\t: loss=483.681, rmse=21.993, r2=0.778; v_loss=881.898, v_rmse=29.697, v_r2=0.698; \n",
            "E 34\t: loss=464.513, rmse=21.553, r2=0.787; v_loss=1154.444, v_rmse=33.977, v_r2=0.605; \n",
            "E 35\t: loss=448.337, rmse=21.174, r2=0.794; v_loss=689.765, v_rmse=26.263, v_r2=0.764; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fd7e8fdd450>, <keras.callbacks.LambdaCallback object at 0x7fd7e8fdda90>], epochs=35, model=<function create_model at 0x7fd7e8f44560>, model__activation1='tanh', model__dropout1=0.9, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7fd7e9021810>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fd842bc3850>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.1, verbose=0),\n",
              "                     include_settings=True, seq_length=100)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6c3301-cee3-48ff-fe3d-0e2b1b1e9f92",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.625,RMSE=-32.923\n",
            "Finished: 2022-10-25 19:55:52.973003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL (More Epochs)"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.6487511063058244  \n",
        "Test: 0.835\n",
        "```\n",
        "('basemodel__batch_size', 262),\n",
        "('basemodel__epochs', 50),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__dropout1', 0.9),\n",
        "('basemodel__model__layer1', 512),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__validation_split', 0.13191782981852057),\n",
        "('clip_y', 140),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 75)\n",
        "```\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=75\n",
        "CLIP=140\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=262,\n",
        "                           epochs=70,\n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.9, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.13191782981852057, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36P-gmRD6QM",
        "outputId": "71353cac-c669-446d-8d0e-ac801d30f917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_2 (Masking)         (None, 75, 25)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 512)               1101824   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,102,337\n",
            "Trainable params: 1,102,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=5544.692, rmse=74.463, r2=-1.991; v_loss=5043.817, v_rmse=71.020, v_r2=-1.467; \n",
            "E 2\t: loss=3876.520, rmse=62.262, r2=-1.091; v_loss=3990.112, v_rmse=63.167, v_r2=-0.952; \n",
            "E 3\t: loss=3268.443, rmse=57.170, r2=-0.763; v_loss=3541.568, v_rmse=59.511, v_r2=-0.732; \n",
            "E 4\t: loss=2941.911, rmse=54.239, r2=-0.587; v_loss=3214.264, v_rmse=56.694, v_r2=-0.572; \n",
            "E 5\t: loss=2695.168, rmse=51.915, r2=-0.454; v_loss=2965.885, v_rmse=54.460, v_r2=-0.451; \n",
            "E 6\t: loss=2500.107, rmse=50.001, r2=-0.349; v_loss=2754.942, v_rmse=52.488, v_r2=-0.348; \n",
            "E 7\t: loss=2342.105, rmse=48.395, r2=-0.263; v_loss=2584.180, v_rmse=50.835, v_r2=-0.264; \n",
            "E 8\t: loss=2206.135, rmse=46.970, r2=-0.190; v_loss=2443.513, v_rmse=49.432, v_r2=-0.195; \n",
            "E 9\t: loss=2082.249, rmse=45.632, r2=-0.123; v_loss=2326.027, v_rmse=48.229, v_r2=-0.138; \n",
            "E 10\t: loss=1980.391, rmse=44.502, r2=-0.068; v_loss=2216.940, v_rmse=47.084, v_r2=-0.084; \n",
            "E 11\t: loss=1889.232, rmse=43.465, r2=-0.019; v_loss=2125.564, v_rmse=46.104, v_r2=-0.040; \n",
            "E 12\t: loss=1813.351, rmse=42.583, r2=0.022; v_loss=2050.394, v_rmse=45.281, v_r2=-0.003; \n",
            "E 13\t: loss=1741.358, rmse=41.730, r2=0.061; v_loss=1973.210, v_rmse=44.421, v_r2=0.035; \n",
            "E 14\t: loss=1681.441, rmse=41.005, r2=0.093; v_loss=1917.359, v_rmse=43.788, v_r2=0.062; \n",
            "E 15\t: loss=1621.997, rmse=40.274, r2=0.125; v_loss=1854.594, v_rmse=43.065, v_r2=0.093; \n",
            "E 16\t: loss=1579.755, rmse=39.746, r2=0.148; v_loss=1821.770, v_rmse=42.682, v_r2=0.109; \n",
            "E 17\t: loss=1537.630, rmse=39.213, r2=0.171; v_loss=1789.924, v_rmse=42.307, v_r2=0.124; \n",
            "E 18\t: loss=1481.365, rmse=38.488, r2=0.201; v_loss=1660.558, v_rmse=40.750, v_r2=0.188; \n",
            "E 19\t: loss=1355.099, rmse=36.812, r2=0.269; v_loss=1412.307, v_rmse=37.581, v_r2=0.309; \n",
            "E 20\t: loss=1187.936, rmse=34.466, r2=0.359; v_loss=1386.588, v_rmse=37.237, v_r2=0.322; \n",
            "E 21\t: loss=1119.865, rmse=33.464, r2=0.396; v_loss=1166.923, v_rmse=34.160, v_r2=0.429; \n",
            "E 22\t: loss=1050.062, rmse=32.405, r2=0.434; v_loss=1102.163, v_rmse=33.199, v_r2=0.461; \n",
            "E 23\t: loss=1002.873, rmse=31.668, r2=0.459; v_loss=1013.824, v_rmse=31.841, v_r2=0.504; \n",
            "E 24\t: loss=933.241, rmse=30.549, r2=0.497; v_loss=1035.889, v_rmse=32.185, v_r2=0.493; \n",
            "E 25\t: loss=897.188, rmse=29.953, r2=0.516; v_loss=952.371, v_rmse=30.861, v_r2=0.534; \n",
            "E 26\t: loss=869.899, rmse=29.494, r2=0.531; v_loss=871.827, v_rmse=29.527, v_r2=0.574; \n",
            "E 27\t: loss=833.595, rmse=28.872, r2=0.550; v_loss=862.593, v_rmse=29.370, v_r2=0.578; \n",
            "E 28\t: loss=823.354, rmse=28.694, r2=0.556; v_loss=901.726, v_rmse=30.029, v_r2=0.559; \n",
            "E 29\t: loss=780.431, rmse=27.936, r2=0.579; v_loss=847.241, v_rmse=29.107, v_r2=0.586; \n",
            "E 30\t: loss=766.937, rmse=27.694, r2=0.586; v_loss=751.160, v_rmse=27.407, v_r2=0.633; \n",
            "E 31\t: loss=742.776, rmse=27.254, r2=0.599; v_loss=779.838, v_rmse=27.926, v_r2=0.619; \n",
            "E 32\t: loss=733.581, rmse=27.085, r2=0.604; v_loss=660.595, v_rmse=25.702, v_r2=0.677; \n",
            "E 33\t: loss=707.211, rmse=26.593, r2=0.619; v_loss=827.116, v_rmse=28.760, v_r2=0.595; \n",
            "E 34\t: loss=718.509, rmse=26.805, r2=0.612; v_loss=646.865, v_rmse=25.434, v_r2=0.684; \n",
            "E 35\t: loss=665.979, rmse=25.807, r2=0.641; v_loss=750.833, v_rmse=27.401, v_r2=0.633; \n",
            "E 36\t: loss=688.291, rmse=26.235, r2=0.629; v_loss=630.024, v_rmse=25.100, v_r2=0.692; \n",
            "E 37\t: loss=646.960, rmse=25.435, r2=0.651; v_loss=598.781, v_rmse=24.470, v_r2=0.707; \n",
            "E 38\t: loss=636.597, rmse=25.231, r2=0.657; v_loss=602.493, v_rmse=24.546, v_r2=0.705; \n",
            "E 39\t: loss=632.218, rmse=25.144, r2=0.659; v_loss=573.588, v_rmse=23.950, v_r2=0.719; \n",
            "E 40\t: loss=616.112, rmse=24.822, r2=0.668; v_loss=533.507, v_rmse=23.098, v_r2=0.739; \n",
            "E 41\t: loss=589.768, rmse=24.285, r2=0.682; v_loss=584.147, v_rmse=24.169, v_r2=0.714; \n",
            "E 42\t: loss=584.016, rmse=24.166, r2=0.685; v_loss=666.228, v_rmse=25.811, v_r2=0.674; \n",
            "E 43\t: loss=583.292, rmse=24.151, r2=0.685; v_loss=560.221, v_rmse=23.669, v_r2=0.726; \n",
            "E 44\t: loss=571.929, rmse=23.915, r2=0.691; v_loss=565.170, v_rmse=23.773, v_r2=0.724; \n",
            "E 45\t: loss=568.014, rmse=23.833, r2=0.694; v_loss=541.025, v_rmse=23.260, v_r2=0.735; \n",
            "E 46\t: loss=554.232, rmse=23.542, r2=0.701; v_loss=519.579, v_rmse=22.794, v_r2=0.746; \n",
            "E 47\t: loss=554.540, rmse=23.549, r2=0.701; v_loss=532.987, v_rmse=23.087, v_r2=0.739; \n",
            "E 48\t: loss=528.775, rmse=22.995, r2=0.715; v_loss=479.559, v_rmse=21.899, v_r2=0.765; \n",
            "E 49\t: loss=515.609, rmse=22.707, r2=0.722; v_loss=454.660, v_rmse=21.323, v_r2=0.778; \n",
            "E 50\t: loss=510.907, rmse=22.603, r2=0.724; v_loss=476.192, v_rmse=21.822, v_r2=0.767; \n",
            "E 51\t: loss=505.903, rmse=22.492, r2=0.727; v_loss=470.770, v_rmse=21.697, v_r2=0.770; \n",
            "E 52\t: loss=495.276, rmse=22.255, r2=0.733; v_loss=505.502, v_rmse=22.483, v_r2=0.753; \n",
            "E 53\t: loss=476.364, rmse=21.826, r2=0.743; v_loss=495.837, v_rmse=22.267, v_r2=0.757; \n",
            "E 54\t: loss=469.975, rmse=21.679, r2=0.746; v_loss=436.021, v_rmse=20.881, v_r2=0.787; \n",
            "E 55\t: loss=460.204, rmse=21.452, r2=0.752; v_loss=489.090, v_rmse=22.115, v_r2=0.761; \n",
            "E 56\t: loss=451.584, rmse=21.250, r2=0.756; v_loss=445.810, v_rmse=21.114, v_r2=0.782; \n",
            "E 57\t: loss=437.850, rmse=20.925, r2=0.764; v_loss=384.310, v_rmse=19.604, v_r2=0.812; \n",
            "E 58\t: loss=447.185, rmse=21.147, r2=0.759; v_loss=433.427, v_rmse=20.819, v_r2=0.788; \n",
            "E 59\t: loss=439.068, rmse=20.954, r2=0.763; v_loss=402.695, v_rmse=20.067, v_r2=0.803; \n",
            "E 60\t: loss=425.065, rmse=20.617, r2=0.771; v_loss=432.657, v_rmse=20.800, v_r2=0.788; \n",
            "E 61\t: loss=422.820, rmse=20.563, r2=0.772; v_loss=443.095, v_rmse=21.050, v_r2=0.783; \n",
            "E 62\t: loss=402.682, rmse=20.067, r2=0.783; v_loss=408.154, v_rmse=20.203, v_r2=0.800; \n",
            "E 63\t: loss=407.261, rmse=20.181, r2=0.780; v_loss=398.386, v_rmse=19.960, v_r2=0.805; \n",
            "E 64\t: loss=399.125, rmse=19.978, r2=0.785; v_loss=403.329, v_rmse=20.083, v_r2=0.803; \n",
            "E 65\t: loss=394.353, rmse=19.858, r2=0.787; v_loss=340.964, v_rmse=18.465, v_r2=0.833; \n",
            "E 66\t: loss=372.580, rmse=19.302, r2=0.799; v_loss=405.762, v_rmse=20.144, v_r2=0.802; \n",
            "E 67\t: loss=398.764, rmse=19.969, r2=0.785; v_loss=369.020, v_rmse=19.210, v_r2=0.820; \n",
            "E 68\t: loss=368.768, rmse=19.203, r2=0.801; v_loss=448.898, v_rmse=21.187, v_r2=0.780; \n",
            "E 69\t: loss=368.129, rmse=19.187, r2=0.801; v_loss=398.695, v_rmse=19.967, v_r2=0.805; \n",
            "E 70\t: loss=355.034, rmse=18.842, r2=0.808; v_loss=410.122, v_rmse=20.251, v_r2=0.799; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=262, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fd7e8fdd450>, <keras.callbacks.LambdaCallback object at 0x7fd7e8fdda90>], epochs=70, model=<function create_model at 0x7fd7e8f44560>, model__activation1='tanh', model__dropout1=0.9, model__layer1=512, model__learning_rate=0.0001, model__loss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7fd77cac6110>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fd77ccf5050>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, print_summary=True, validation_split=0.13191782981852057, verbose=0),\n",
              "                     clip_y=140, include_settings=True, seq_length=75)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "3f88882a-adf6-46fe-b960-47d2a8db156e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.835,RMSE=-19.010\n",
            "Finished: 2022-10-25 20:10:53.361820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1 "
      ],
      "metadata": {
        "id": "SvWawqOFYvO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "bWDbtK4RYvPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Score: 0.5709418653283571  \n",
        "Test: 0.730\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 43),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.4523423204279986),\n",
        "('basemodel__model__dropout2', 0.6519444578987227),\n",
        "('basemodel__model__layer1', 492),\n",
        "('basemodel__model__layer2', 53),\n",
        "('basemodel__model__learning_rate', 0.0001),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.22182563254238585),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 53)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "18mXMMo2YvPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=53\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=43,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.4523423204279986, \n",
        "                           model__dropout2=0.6519444578987227, \n",
        "                           model__layer1=492, \n",
        "                           model__layer2=53, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.22182563254238585, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "2EKUQXh0YvPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5855126-16e2-44b1-f45f-eeb1ea01fcb2",
        "id": "5uHgjmJZYvPC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_3 (Masking)         (None, 53, 25)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 492)               1019424   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 492)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 53)                26129     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 53)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 54        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,045,607\n",
            "Trainable params: 1,045,607\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=4088.569, rmse=63.942, r2=-0.249; v_loss=2034.055, v_rmse=45.100, v_r2=0.359; \n",
            "E 2\t: loss=2618.864, rmse=51.175, r2=0.200; v_loss=1905.447, v_rmse=43.651, v_r2=0.400; \n",
            "E 3\t: loss=2556.082, rmse=50.558, r2=0.219; v_loss=1887.067, v_rmse=43.440, v_r2=0.406; \n",
            "E 4\t: loss=2517.140, rmse=50.171, r2=0.231; v_loss=1795.536, v_rmse=42.374, v_r2=0.435; \n",
            "E 5\t: loss=2257.600, rmse=47.514, r2=0.310; v_loss=1542.431, v_rmse=39.274, v_r2=0.514; \n",
            "E 6\t: loss=2070.388, rmse=45.502, r2=0.367; v_loss=1360.650, v_rmse=36.887, v_r2=0.571; \n",
            "E 7\t: loss=1969.041, rmse=44.374, r2=0.398; v_loss=1272.229, v_rmse=35.668, v_r2=0.599; \n",
            "E 8\t: loss=1878.006, rmse=43.336, r2=0.426; v_loss=1301.530, v_rmse=36.077, v_r2=0.590; \n",
            "E 9\t: loss=1837.599, rmse=42.867, r2=0.439; v_loss=1193.741, v_rmse=34.551, v_r2=0.624; \n",
            "E 10\t: loss=1751.325, rmse=41.849, r2=0.465; v_loss=1513.923, v_rmse=38.909, v_r2=0.523; \n",
            "E 11\t: loss=1732.704, rmse=41.626, r2=0.471; v_loss=1190.908, v_rmse=34.510, v_r2=0.625; \n",
            "E 12\t: loss=1712.545, rmse=41.383, r2=0.477; v_loss=1084.618, v_rmse=32.934, v_r2=0.658; \n",
            "E 13\t: loss=1661.918, rmse=40.767, r2=0.492; v_loss=1123.525, v_rmse=33.519, v_r2=0.646; \n",
            "E 14\t: loss=1643.165, rmse=40.536, r2=0.498; v_loss=1181.776, v_rmse=34.377, v_r2=0.628; \n",
            "E 15\t: loss=1559.789, rmse=39.494, r2=0.523; v_loss=1146.717, v_rmse=33.863, v_r2=0.639; \n",
            "E 16\t: loss=1528.359, rmse=39.094, r2=0.533; v_loss=1563.743, v_rmse=39.544, v_r2=0.508; \n",
            "E 17\t: loss=1448.548, rmse=38.060, r2=0.557; v_loss=1046.775, v_rmse=32.354, v_r2=0.670; \n",
            "E 18\t: loss=1402.938, rmse=37.456, r2=0.571; v_loss=1115.131, v_rmse=33.394, v_r2=0.649; \n",
            "E 19\t: loss=1355.472, rmse=36.817, r2=0.586; v_loss=1053.757, v_rmse=32.462, v_r2=0.668; \n",
            "E 20\t: loss=1303.252, rmse=36.101, r2=0.602; v_loss=1089.233, v_rmse=33.004, v_r2=0.657; \n",
            "E 21\t: loss=1242.246, rmse=35.246, r2=0.620; v_loss=1019.638, v_rmse=31.932, v_r2=0.679; \n",
            "E 22\t: loss=1179.849, rmse=34.349, r2=0.640; v_loss=1193.350, v_rmse=34.545, v_r2=0.624; \n",
            "E 23\t: loss=1133.702, rmse=33.670, r2=0.654; v_loss=1076.874, v_rmse=32.816, v_r2=0.661; \n",
            "E 24\t: loss=1081.199, rmse=32.882, r2=0.670; v_loss=1090.557, v_rmse=33.024, v_r2=0.657; \n",
            "E 25\t: loss=1053.077, rmse=32.451, r2=0.678; v_loss=1100.234, v_rmse=33.170, v_r2=0.654; \n",
            "E 26\t: loss=1024.153, rmse=32.002, r2=0.687; v_loss=1215.071, v_rmse=34.858, v_r2=0.617; \n",
            "E 27\t: loss=997.367, rmse=31.581, r2=0.695; v_loss=1253.580, v_rmse=35.406, v_r2=0.605; \n",
            "E 28\t: loss=967.635, rmse=31.107, r2=0.704; v_loss=1176.399, v_rmse=34.299, v_r2=0.630; \n",
            "E 29\t: loss=909.357, rmse=30.156, r2=0.722; v_loss=1110.451, v_rmse=33.323, v_r2=0.650; \n",
            "E 30\t: loss=937.232, rmse=30.614, r2=0.714; v_loss=1109.833, v_rmse=33.314, v_r2=0.650; \n",
            "E 31\t: loss=877.705, rmse=29.626, r2=0.732; v_loss=1115.223, v_rmse=33.395, v_r2=0.649; \n",
            "E 32\t: loss=856.936, rmse=29.273, r2=0.738; v_loss=1098.097, v_rmse=33.138, v_r2=0.654; \n",
            "E 33\t: loss=866.449, rmse=29.436, r2=0.735; v_loss=1265.761, v_rmse=35.578, v_r2=0.601; \n",
            "E 34\t: loss=824.186, rmse=28.709, r2=0.748; v_loss=1145.572, v_rmse=33.846, v_r2=0.639; \n",
            "E 35\t: loss=797.298, rmse=28.236, r2=0.756; v_loss=1174.464, v_rmse=34.270, v_r2=0.630; \n",
            "E 36\t: loss=775.110, rmse=27.841, r2=0.763; v_loss=1098.753, v_rmse=33.147, v_r2=0.654; \n",
            "E 37\t: loss=752.430, rmse=27.430, r2=0.770; v_loss=1060.040, v_rmse=32.558, v_r2=0.666; \n",
            "E 38\t: loss=764.765, rmse=27.654, r2=0.766; v_loss=1145.904, v_rmse=33.851, v_r2=0.639; \n",
            "E 39\t: loss=755.433, rmse=27.485, r2=0.769; v_loss=1250.225, v_rmse=35.359, v_r2=0.606; \n",
            "E 40\t: loss=728.359, rmse=26.988, r2=0.777; v_loss=1118.288, v_rmse=33.441, v_r2=0.648; \n",
            "E 41\t: loss=710.628, rmse=26.658, r2=0.783; v_loss=1273.839, v_rmse=35.691, v_r2=0.599; \n",
            "E 42\t: loss=714.062, rmse=26.722, r2=0.782; v_loss=1181.100, v_rmse=34.367, v_r2=0.628; \n",
            "E 43\t: loss=686.102, rmse=26.194, r2=0.790; v_loss=1066.907, v_rmse=32.664, v_r2=0.664; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fd7e8fdd450>, <keras.callbacks.LambdaCallback object at 0x7fd7e8fdda90>], epochs=43, model=<function create_model at 0x7fd7e8f44560>, model__activation1='tanh', model__activation2='elu', model__dropout1=0.4523423204279986, model__dropout2=0.6519444578...ss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7fd7583cc0d0>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fd7583d36d0>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.22182563254238585, verbose=0),\n",
              "                     include_settings=True, seq_length=53)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ae74b2-d352-4c75-9dac-49d41d6ae978",
        "id": "svjWhd4FYvPD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.730,RMSE=-27.967\n",
            "Finished: 2022-10-25 20:21:55.227530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL (More Epochs)"
      ],
      "metadata": {
        "id": "6LznVkFxYvPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.7530758636321139  \n",
        "Test: 0.895\n",
        "```\n",
        "('basemodel__batch_size', 287),\n",
        "('basemodel__epochs', 28),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'elu'),\n",
        "('basemodel__model__dropout1', 0.13678820565973349),\n",
        "('basemodel__model__dropout2', 0.9),\n",
        "('basemodel__model__layer1', 336),\n",
        "('basemodel__model__layer2', 77),\n",
        "('basemodel__model__learning_rate', 0.0040050838967013785),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.1494847733663106),\n",
        "('clip_y', 124),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 73)\n",
        "```\n"
      ],
      "metadata": {
        "id": "KiL-gZkZYvPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=73\n",
        "CLIP=124\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=287,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='elu',\n",
        "                           model__dropout1=0.13678820565973349, \n",
        "                           model__dropout2=0.9, \n",
        "                           model__layer1=336, \n",
        "                           model__layer2=77, \n",
        "                           model__learning_rate=0.0040050838967013785,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.1494847733663106, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "tEwHSsUCYvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd691158-b7d8-4222-fd7b-fc0c0c3d1022",
        "id": "AMEzooPSYvPF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_5 (Masking)         (None, 73, 25)            0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 336)               486528    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 336)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 77)                25949     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 77)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 78        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 512,555\n",
            "Trainable params: 512,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2121.321, rmse=46.058, r2=-0.325; v_loss=1434.515, v_rmse=37.875, v_r2=0.149; \n",
            "E 2\t: loss=1710.618, rmse=41.360, r2=-0.069; v_loss=1388.748, v_rmse=37.266, v_r2=0.176; \n",
            "E 3\t: loss=1624.482, rmse=40.305, r2=-0.015; v_loss=1369.694, v_rmse=37.009, v_r2=0.187; \n",
            "E 4\t: loss=1573.453, rmse=39.667, r2=0.017; v_loss=1141.218, v_rmse=33.782, v_r2=0.323; \n",
            "E 5\t: loss=1473.414, rmse=38.385, r2=0.080; v_loss=1065.825, v_rmse=32.647, v_r2=0.368; \n",
            "E 6\t: loss=1368.537, rmse=36.994, r2=0.145; v_loss=1156.886, v_rmse=34.013, v_r2=0.313; \n",
            "E 7\t: loss=1297.190, rmse=36.017, r2=0.190; v_loss=913.823, v_rmse=30.230, v_r2=0.458; \n",
            "E 8\t: loss=1183.597, rmse=34.403, r2=0.261; v_loss=730.363, v_rmse=27.025, v_r2=0.567; \n",
            "E 9\t: loss=1137.115, rmse=33.721, r2=0.290; v_loss=534.779, v_rmse=23.125, v_r2=0.683; \n",
            "E 10\t: loss=1120.553, rmse=33.475, r2=0.300; v_loss=486.831, v_rmse=22.064, v_r2=0.711; \n",
            "E 11\t: loss=1070.256, rmse=32.715, r2=0.331; v_loss=447.935, v_rmse=21.164, v_r2=0.734; \n",
            "E 12\t: loss=1010.580, rmse=31.790, r2=0.369; v_loss=698.507, v_rmse=26.429, v_r2=0.585; \n",
            "E 13\t: loss=1000.448, rmse=31.630, r2=0.375; v_loss=445.802, v_rmse=21.114, v_r2=0.735; \n",
            "E 14\t: loss=1004.167, rmse=31.689, r2=0.373; v_loss=385.398, v_rmse=19.632, v_r2=0.771; \n",
            "E 15\t: loss=942.477, rmse=30.700, r2=0.411; v_loss=453.489, v_rmse=21.295, v_r2=0.731; \n",
            "E 16\t: loss=911.243, rmse=30.187, r2=0.431; v_loss=317.767, v_rmse=17.826, v_r2=0.811; \n",
            "E 17\t: loss=880.057, rmse=29.666, r2=0.450; v_loss=367.404, v_rmse=19.168, v_r2=0.782; \n",
            "E 18\t: loss=891.872, rmse=29.864, r2=0.443; v_loss=489.997, v_rmse=22.136, v_r2=0.709; \n",
            "E 19\t: loss=831.669, rmse=28.839, r2=0.480; v_loss=300.630, v_rmse=17.339, v_r2=0.822; \n",
            "E 20\t: loss=826.929, rmse=28.756, r2=0.483; v_loss=221.223, v_rmse=14.874, v_r2=0.869; \n",
            "E 21\t: loss=842.727, rmse=29.030, r2=0.474; v_loss=338.446, v_rmse=18.397, v_r2=0.799; \n",
            "E 22\t: loss=795.966, rmse=28.213, r2=0.503; v_loss=230.496, v_rmse=15.182, v_r2=0.863; \n",
            "E 23\t: loss=845.498, rmse=29.077, r2=0.472; v_loss=325.727, v_rmse=18.048, v_r2=0.807; \n",
            "E 24\t: loss=795.473, rmse=28.204, r2=0.503; v_loss=336.775, v_rmse=18.351, v_r2=0.800; \n",
            "E 25\t: loss=776.315, rmse=27.862, r2=0.515; v_loss=234.076, v_rmse=15.300, v_r2=0.861; \n",
            "E 26\t: loss=772.012, rmse=27.785, r2=0.518; v_loss=186.145, v_rmse=13.644, v_r2=0.890; \n",
            "E 27\t: loss=772.697, rmse=27.797, r2=0.517; v_loss=306.834, v_rmse=17.517, v_r2=0.818; \n",
            "E 28\t: loss=742.982, rmse=27.258, r2=0.536; v_loss=259.909, v_rmse=16.122, v_r2=0.846; \n",
            "E 29\t: loss=743.422, rmse=27.266, r2=0.536; v_loss=186.321, v_rmse=13.650, v_r2=0.889; \n",
            "E 30\t: loss=746.315, rmse=27.319, r2=0.534; v_loss=266.234, v_rmse=16.317, v_r2=0.842; \n",
            "E 31\t: loss=756.549, rmse=27.505, r2=0.527; v_loss=223.695, v_rmse=14.956, v_r2=0.867; \n",
            "E 32\t: loss=731.422, rmse=27.045, r2=0.543; v_loss=291.703, v_rmse=17.079, v_r2=0.827; \n",
            "E 33\t: loss=724.112, rmse=26.909, r2=0.548; v_loss=313.733, v_rmse=17.712, v_r2=0.814; \n",
            "E 34\t: loss=725.754, rmse=26.940, r2=0.547; v_loss=434.812, v_rmse=20.852, v_r2=0.742; \n",
            "E 35\t: loss=747.185, rmse=27.335, r2=0.533; v_loss=443.798, v_rmse=21.067, v_r2=0.737; \n",
            "E 36\t: loss=700.709, rmse=26.471, r2=0.562; v_loss=296.974, v_rmse=17.233, v_r2=0.824; \n",
            "E 37\t: loss=707.859, rmse=26.606, r2=0.558; v_loss=288.329, v_rmse=16.980, v_r2=0.829; \n",
            "E 38\t: loss=706.803, rmse=26.586, r2=0.558; v_loss=201.057, v_rmse=14.179, v_r2=0.881; \n",
            "E 39\t: loss=682.695, rmse=26.128, r2=0.574; v_loss=260.240, v_rmse=16.132, v_r2=0.846; \n",
            "E 40\t: loss=702.416, rmse=26.503, r2=0.561; v_loss=329.325, v_rmse=18.147, v_r2=0.805; \n",
            "E 41\t: loss=696.241, rmse=26.386, r2=0.565; v_loss=228.093, v_rmse=15.103, v_r2=0.865; \n",
            "E 42\t: loss=672.523, rmse=25.933, r2=0.580; v_loss=204.412, v_rmse=14.297, v_r2=0.879; \n",
            "E 43\t: loss=672.295, rmse=25.929, r2=0.580; v_loss=201.801, v_rmse=14.206, v_r2=0.880; \n",
            "E 44\t: loss=666.820, rmse=25.823, r2=0.583; v_loss=199.196, v_rmse=14.114, v_r2=0.882; \n",
            "E 45\t: loss=656.582, rmse=25.624, r2=0.590; v_loss=190.514, v_rmse=13.803, v_r2=0.887; \n",
            "E 46\t: loss=656.107, rmse=25.615, r2=0.590; v_loss=182.929, v_rmse=13.525, v_r2=0.891; \n",
            "E 47\t: loss=648.895, rmse=25.473, r2=0.595; v_loss=254.943, v_rmse=15.967, v_r2=0.849; \n",
            "E 48\t: loss=639.681, rmse=25.292, r2=0.600; v_loss=205.077, v_rmse=14.321, v_r2=0.878; \n",
            "E 49\t: loss=634.865, rmse=25.197, r2=0.603; v_loss=325.146, v_rmse=18.032, v_r2=0.807; \n",
            "E 50\t: loss=647.532, rmse=25.447, r2=0.596; v_loss=217.073, v_rmse=14.733, v_r2=0.871; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=287, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fd7e8fdd450>, <keras.callbacks.LambdaCallback object at 0x7fd7e8fdda90>], epochs=50, model=<function create_model at 0x7fd7e8f44560>, model__activation1='tanh', model__activation2='elu', model__dropout1=0.13678820565973349, model__dropout2=0.9, model_...odel__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7fd7583c7450>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fd6a1101050>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.1494847733663106, verbose=0),\n",
              "                     clip_y=124, include_settings=True, seq_length=73)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb0caba-da02-4b07-b5c3-790733b3e9ea",
        "id": "WU1dYRTwYvPG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.895,RMSE=-13.821\n",
            "Finished: 2022-10-25 20:30:14.001723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2"
      ],
      "metadata": {
        "id": "y28M-FK8zDq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL (More Epochs, ES)"
      ],
      "metadata": {
        "id": "9Zl5AM1czDq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.5860971746607238  \n",
        "Test: 0.754\n",
        "```\n",
        "('basemodel__batch_size', 264),\n",
        "('basemodel__epochs', 23),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'sigmoid'),\n",
        "('basemodel__model__activation3', 'relu'),\n",
        "('basemodel__model__dropout1', 0.21534955706280656),\n",
        "('basemodel__model__dropout2', 0.7741992560602),\n",
        "('basemodel__model__dropout3', 0.4418655267370424),\n",
        "('basemodel__model__layer1', 395),\n",
        "('basemodel__model__layer2', 330),\n",
        "('basemodel__model__layer3', 145),\n",
        "('basemodel__model__learning_rate', 0.009202704024775169),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.20435450812720612),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 70)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y5_j9VhBzDq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=70\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=264,\n",
        "                           epochs=50,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='sigmoid',\n",
        "                           model__activation3='relu',\n",
        "                           model__dropout1=0.21534955706280656, \n",
        "                           model__dropout2=0.7741992560602,\n",
        "                           model__dropout3=0.4418655267370424, \n",
        "                           model__layer1=395, \n",
        "                           model__layer2=330, \n",
        "                           model__layer3=145, \n",
        "                           model__learning_rate=0.009202704024775169,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.20435450812720612, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "yP84kQK2zDq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15720ae4-e633-4acf-a127-eb51c6eca3e8",
        "id": "dpx_rNVCzDq6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_7 (Masking)         (None, 70, 25)            0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 395)               665180    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 395)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 330)               130680    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 330)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 145)               47995     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 145)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 146       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 844,001\n",
            "Trainable params: 844,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=2563.990, rmse=50.636, r2=0.106; v_loss=1977.422, v_rmse=44.468, v_r2=0.288; \n",
            "E 2\t: loss=2142.876, rmse=46.291, r2=0.253; v_loss=1920.237, v_rmse=43.821, v_r2=0.309; \n",
            "E 3\t: loss=2138.773, rmse=46.247, r2=0.254; v_loss=1867.078, v_rmse=43.210, v_r2=0.328; \n",
            "E 4\t: loss=2094.055, rmse=45.761, r2=0.270; v_loss=1842.660, v_rmse=42.926, v_r2=0.337; \n",
            "E 5\t: loss=2071.494, rmse=45.514, r2=0.278; v_loss=1767.616, v_rmse=42.043, v_r2=0.364; \n",
            "E 6\t: loss=1952.422, rmse=44.186, r2=0.319; v_loss=1632.956, v_rmse=40.410, v_r2=0.412; \n",
            "E 7\t: loss=1849.409, rmse=43.005, r2=0.355; v_loss=1464.281, v_rmse=38.266, v_r2=0.473; \n",
            "E 8\t: loss=1722.049, rmse=41.498, r2=0.400; v_loss=1225.107, v_rmse=35.002, v_r2=0.559; \n",
            "E 9\t: loss=1616.358, rmse=40.204, r2=0.437; v_loss=1937.757, v_rmse=44.020, v_r2=0.302; \n",
            "E 10\t: loss=1636.528, rmse=40.454, r2=0.430; v_loss=1152.434, v_rmse=33.948, v_r2=0.585; \n",
            "E 11\t: loss=1510.006, rmse=38.859, r2=0.474; v_loss=1086.643, v_rmse=32.964, v_r2=0.609; \n",
            "E 12\t: loss=1378.591, rmse=37.129, r2=0.519; v_loss=1514.238, v_rmse=38.913, v_r2=0.455; \n",
            "E 13\t: loss=1398.117, rmse=37.391, r2=0.513; v_loss=1146.511, v_rmse=33.860, v_r2=0.587; \n",
            "E 14\t: loss=1443.322, rmse=37.991, r2=0.497; v_loss=944.055, v_rmse=30.725, v_r2=0.660; \n",
            "E 15\t: loss=1297.752, rmse=36.024, r2=0.548; v_loss=912.310, v_rmse=30.204, v_r2=0.672; \n",
            "E 16\t: loss=1300.221, rmse=36.059, r2=0.547; v_loss=1026.710, v_rmse=32.042, v_r2=0.630; \n",
            "E 17\t: loss=1214.747, rmse=34.853, r2=0.577; v_loss=923.094, v_rmse=30.382, v_r2=0.668; \n",
            "E 18\t: loss=1190.491, rmse=34.503, r2=0.585; v_loss=851.746, v_rmse=29.185, v_r2=0.693; \n",
            "E 19\t: loss=1177.974, rmse=34.322, r2=0.589; v_loss=914.670, v_rmse=30.244, v_r2=0.671; \n",
            "E 20\t: loss=1155.701, rmse=33.996, r2=0.597; v_loss=1093.845, v_rmse=33.073, v_r2=0.606; \n",
            "E 21\t: loss=1126.945, rmse=33.570, r2=0.607; v_loss=877.215, v_rmse=29.618, v_r2=0.684; \n",
            "E 22\t: loss=1162.982, rmse=34.103, r2=0.595; v_loss=1159.207, v_rmse=34.047, v_r2=0.583; \n",
            "E 23\t: loss=1060.773, rmse=32.570, r2=0.630; v_loss=722.501, v_rmse=26.879, v_r2=0.740; \n",
            "E 24\t: loss=1022.528, rmse=31.977, r2=0.644; v_loss=731.648, v_rmse=27.049, v_r2=0.737; \n",
            "E 25\t: loss=1017.724, rmse=31.902, r2=0.645; v_loss=934.634, v_rmse=30.572, v_r2=0.664; \n",
            "E 26\t: loss=1041.319, rmse=32.269, r2=0.637; v_loss=902.704, v_rmse=30.045, v_r2=0.675; \n",
            "E 27\t: loss=960.838, rmse=30.997, r2=0.665; v_loss=758.173, v_rmse=27.535, v_r2=0.727; \n",
            "E 28\t: loss=1024.262, rmse=32.004, r2=0.643; v_loss=657.469, v_rmse=25.641, v_r2=0.763; \n",
            "E 29\t: loss=922.586, rmse=30.374, r2=0.678; v_loss=943.963, v_rmse=30.724, v_r2=0.660; \n",
            "E 30\t: loss=1000.492, rmse=31.631, r2=0.651; v_loss=1072.529, v_rmse=32.749, v_r2=0.614; \n",
            "E 31\t: loss=931.168, rmse=30.515, r2=0.675; v_loss=727.752, v_rmse=26.977, v_r2=0.738; \n",
            "E 32\t: loss=888.461, rmse=29.807, r2=0.690; v_loss=668.216, v_rmse=25.850, v_r2=0.759; \n",
            "E 33\t: loss=905.523, rmse=30.092, r2=0.684; v_loss=729.132, v_rmse=27.002, v_r2=0.738; \n",
            "E 34\t: loss=886.090, rmse=29.767, r2=0.691; v_loss=1393.715, v_rmse=37.332, v_r2=0.498; \n",
            "E 35\t: loss=924.586, rmse=30.407, r2=0.678; v_loss=827.694, v_rmse=28.770, v_r2=0.702; \n",
            "E 36\t: loss=876.115, rmse=29.599, r2=0.695; v_loss=665.645, v_rmse=25.800, v_r2=0.760; \n",
            "E 37\t: loss=893.151, rmse=29.886, r2=0.689; v_loss=844.572, v_rmse=29.062, v_r2=0.696; \n",
            "E 38\t: loss=808.534, rmse=28.435, r2=0.718; v_loss=729.815, v_rmse=27.015, v_r2=0.737; \n",
            "E 39\t: loss=815.068, rmse=28.549, r2=0.716; v_loss=655.582, v_rmse=25.604, v_r2=0.764; \n",
            "E 40\t: loss=785.274, rmse=28.023, r2=0.726; v_loss=775.917, v_rmse=27.855, v_r2=0.721; \n",
            "E 41\t: loss=841.390, rmse=29.007, r2=0.707; v_loss=683.490, v_rmse=26.144, v_r2=0.754; \n",
            "E 42\t: loss=728.207, rmse=26.985, r2=0.746; v_loss=805.302, v_rmse=28.378, v_r2=0.710; \n",
            "E 43\t: loss=795.838, rmse=28.211, r2=0.723; v_loss=742.171, v_rmse=27.243, v_r2=0.733; \n",
            "E 44\t: loss=866.343, rmse=29.434, r2=0.698; v_loss=837.504, v_rmse=28.940, v_r2=0.699; \n",
            "E 45\t: loss=837.936, rmse=28.947, r2=0.708; v_loss=730.225, v_rmse=27.023, v_r2=0.737; \n",
            "E 46\t: loss=753.823, rmse=27.456, r2=0.737; v_loss=826.004, v_rmse=28.740, v_r2=0.703; \n",
            "E 47\t: loss=792.253, rmse=28.147, r2=0.724; v_loss=771.538, v_rmse=27.777, v_r2=0.722; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=264, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fd7e8fdd450>, <keras.callbacks.LambdaCallback object at 0x7fd7e8fdda90>], epochs=50, model=<function create_model at 0x7fd7e8f44560>, model__activation1='tanh', model__activation2='sigmoid', model__activation3='relu', model__dropout1=0.21534955706280...ss='mse', model__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7fd69be60f10>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fd69be61110>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.20435450812720612, verbose=0),\n",
              "                     include_settings=True, seq_length=70)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e954f5b-cfbe-4885-a106-05ba9583a934",
        "id": "qzoIZZmlzDq7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd696a36200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.754,RMSE=-26.654\n",
            "Finished: 2022-10-25 20:43:38.876189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL \n"
      ],
      "metadata": {
        "id": "wrpte1WXzDq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.8114717682301014  \n",
        "Test: 0.890\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "('basemodel__epochs', 47),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'sigmoid'),\n",
        "('basemodel__model__dropout1', 0.1),\n",
        "('basemodel__model__dropout2', 0.2141175093000496),\n",
        "('basemodel__model__dropout3', 0.7714899358963251),\n",
        "('basemodel__model__layer1', 16),\n",
        "('basemodel__model__layer2', 16),\n",
        "('basemodel__model__layer3', 100),\n",
        "('basemodel__model__learning_rate', 0.000567080109365328),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', True),\n",
        "('basemodel__validation_split', 0.11371723233432361),\n",
        "('clip_y', 106),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 44)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-RCr6qz8zDq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=44\n",
        "CLIP=106\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=47,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='sigmoid',\n",
        "                           model__dropout1=0.1, \n",
        "                           model__dropout2=0.2141175093000496,\n",
        "                           model__dropout3=0.7714899358963251, \n",
        "                           model__layer1=16, \n",
        "                           model__layer2=16, \n",
        "                           model__layer3=100, \n",
        "                           model__learning_rate=0.000567080109365328,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=True,\n",
        "                           validation_split=0.11371723233432361, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "TCGZ2Pr4zDq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea1bdae-dbe2-4c2f-f640-b1c6f5ecd8a0",
        "id": "Fd65WHLTzDq9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_11 (Masking)        (None, 44, 25)            0         \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 16)                2688      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 100)               1700      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,761\n",
            "Trainable params: 4,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3352.102, rmse=57.897, r2=-1.662; v_loss=1846.970, v_rmse=42.976, v_r2=-0.457; \n",
            "E 2\t: loss=1572.063, rmse=39.649, r2=-0.248; v_loss=1307.167, v_rmse=36.155, v_r2=-0.031; \n",
            "E 3\t: loss=1098.251, rmse=33.140, r2=0.128; v_loss=870.397, v_rmse=29.502, v_r2=0.314; \n",
            "E 4\t: loss=858.687, rmse=29.303, r2=0.318; v_loss=669.029, v_rmse=25.866, v_r2=0.472; \n",
            "E 5\t: loss=757.468, rmse=27.522, r2=0.399; v_loss=550.534, v_rmse=23.463, v_r2=0.566; \n",
            "E 6\t: loss=720.848, rmse=26.849, r2=0.428; v_loss=556.460, v_rmse=23.589, v_r2=0.561; \n",
            "E 7\t: loss=693.259, rmse=26.330, r2=0.450; v_loss=459.256, v_rmse=21.430, v_r2=0.638; \n",
            "E 8\t: loss=663.191, rmse=25.752, r2=0.473; v_loss=493.386, v_rmse=22.212, v_r2=0.611; \n",
            "E 9\t: loss=619.344, rmse=24.887, r2=0.508; v_loss=388.206, v_rmse=19.703, v_r2=0.694; \n",
            "E 10\t: loss=572.917, rmse=23.936, r2=0.545; v_loss=338.563, v_rmse=18.400, v_r2=0.733; \n",
            "E 11\t: loss=556.308, rmse=23.586, r2=0.558; v_loss=346.591, v_rmse=18.617, v_r2=0.727; \n",
            "E 12\t: loss=537.985, rmse=23.194, r2=0.573; v_loss=383.222, v_rmse=19.576, v_r2=0.698; \n",
            "E 13\t: loss=522.316, rmse=22.854, r2=0.585; v_loss=447.538, v_rmse=21.155, v_r2=0.647; \n",
            "E 14\t: loss=520.780, rmse=22.821, r2=0.586; v_loss=299.514, v_rmse=17.306, v_r2=0.764; \n",
            "E 15\t: loss=512.292, rmse=22.634, r2=0.593; v_loss=323.844, v_rmse=17.996, v_r2=0.745; \n",
            "E 16\t: loss=499.935, rmse=22.359, r2=0.603; v_loss=319.683, v_rmse=17.880, v_r2=0.748; \n",
            "E 17\t: loss=495.698, rmse=22.264, r2=0.606; v_loss=323.265, v_rmse=17.980, v_r2=0.745; \n",
            "E 18\t: loss=493.621, rmse=22.218, r2=0.608; v_loss=413.058, v_rmse=20.324, v_r2=0.674; \n",
            "E 19\t: loss=484.359, rmse=22.008, r2=0.615; v_loss=534.347, v_rmse=23.116, v_r2=0.579; \n",
            "E 20\t: loss=480.299, rmse=21.916, r2=0.619; v_loss=342.618, v_rmse=18.510, v_r2=0.730; \n",
            "E 21\t: loss=472.813, rmse=21.744, r2=0.625; v_loss=309.904, v_rmse=17.604, v_r2=0.756; \n",
            "E 22\t: loss=471.214, rmse=21.707, r2=0.626; v_loss=287.107, v_rmse=16.944, v_r2=0.774; \n",
            "E 23\t: loss=465.076, rmse=21.566, r2=0.631; v_loss=307.710, v_rmse=17.542, v_r2=0.757; \n",
            "E 24\t: loss=454.908, rmse=21.329, r2=0.639; v_loss=284.684, v_rmse=16.873, v_r2=0.775; \n",
            "E 25\t: loss=447.618, rmse=21.157, r2=0.645; v_loss=293.253, v_rmse=17.125, v_r2=0.769; \n",
            "E 26\t: loss=440.738, rmse=20.994, r2=0.650; v_loss=310.295, v_rmse=17.615, v_r2=0.755; \n",
            "E 27\t: loss=429.796, rmse=20.732, r2=0.659; v_loss=262.803, v_rmse=16.211, v_r2=0.793; \n",
            "E 28\t: loss=440.359, rmse=20.985, r2=0.650; v_loss=280.018, v_rmse=16.734, v_r2=0.779; \n",
            "E 29\t: loss=427.295, rmse=20.671, r2=0.661; v_loss=306.468, v_rmse=17.506, v_r2=0.758; \n",
            "E 30\t: loss=419.527, rmse=20.482, r2=0.667; v_loss=262.756, v_rmse=16.210, v_r2=0.793; \n",
            "E 31\t: loss=412.167, rmse=20.302, r2=0.673; v_loss=312.242, v_rmse=17.670, v_r2=0.754; \n",
            "E 32\t: loss=400.479, rmse=20.012, r2=0.682; v_loss=321.880, v_rmse=17.941, v_r2=0.746; \n",
            "E 33\t: loss=401.902, rmse=20.048, r2=0.681; v_loss=262.202, v_rmse=16.193, v_r2=0.793; \n",
            "E 34\t: loss=390.585, rmse=19.763, r2=0.690; v_loss=233.090, v_rmse=15.267, v_r2=0.816; \n",
            "E 35\t: loss=383.257, rmse=19.577, r2=0.696; v_loss=218.957, v_rmse=14.797, v_r2=0.827; \n",
            "E 36\t: loss=380.451, rmse=19.505, r2=0.698; v_loss=243.534, v_rmse=15.606, v_r2=0.808; \n",
            "E 37\t: loss=371.431, rmse=19.273, r2=0.705; v_loss=210.741, v_rmse=14.517, v_r2=0.834; \n",
            "E 38\t: loss=365.884, rmse=19.128, r2=0.709; v_loss=247.581, v_rmse=15.735, v_r2=0.805; \n",
            "E 39\t: loss=362.776, rmse=19.047, r2=0.712; v_loss=388.278, v_rmse=19.705, v_r2=0.694; \n",
            "E 40\t: loss=350.041, rmse=18.709, r2=0.722; v_loss=257.213, v_rmse=16.038, v_r2=0.797; \n",
            "E 41\t: loss=348.268, rmse=18.662, r2=0.723; v_loss=186.128, v_rmse=13.643, v_r2=0.853; \n",
            "E 42\t: loss=346.317, rmse=18.610, r2=0.725; v_loss=294.694, v_rmse=17.167, v_r2=0.768; \n",
            "E 43\t: loss=339.388, rmse=18.422, r2=0.731; v_loss=225.700, v_rmse=15.023, v_r2=0.822; \n",
            "E 44\t: loss=342.014, rmse=18.494, r2=0.728; v_loss=230.250, v_rmse=15.174, v_r2=0.818; \n",
            "E 45\t: loss=335.170, rmse=18.308, r2=0.734; v_loss=190.639, v_rmse=13.807, v_r2=0.850; \n",
            "E 46\t: loss=325.478, rmse=18.041, r2=0.742; v_loss=188.495, v_rmse=13.729, v_r2=0.851; \n",
            "E 47\t: loss=323.552, rmse=17.988, r2=0.743; v_loss=212.104, v_rmse=14.564, v_r2=0.833; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=32, callbacks=[<keras.callbacks.EarlyStopping object at 0x7fd7e8fdd450>, <keras.callbacks.LambdaCallback object at 0x7fd7e8fdda90>], epochs=47, model=<function create_model at 0x7fd7e8f44560>, model__activation1='tanh', model__activation2='tanh', model__activation3='sigmoid', model__dropout1=0.1, model__dropou...del__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7fd6937c4810>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7fd6937c4a10>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, model__second_dense=True, print_summary=True, validation_split=0.11371723233432361, verbose=0),\n",
              "                     clip_y=106, include_settings=True, seq_length=44)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049d8840-103e-48ca-d652-87f920fb8abb",
        "id": "O8csd7JVzDq-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.901,RMSE=-11.743\n",
            "Finished: 2022-10-25 21:24:24.591407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense "
      ],
      "metadata": {
        "id": "5z_LZWx32lXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear RUL"
      ],
      "metadata": {
        "id": "Pu0gM_uE2lXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Score: 0.4572066088840683  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 413),\n",
        "('basemodel__epochs', 39),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'elu'),\n",
        "('basemodel__model__dropout1', 0.8027344701984965),\n",
        "('basemodel__model__dropout2', 0.7569408037894426),\n",
        "('basemodel__model__dropout3', 0.12896783869092998),\n",
        "('basemodel__model__layer1', 367),\n",
        "('basemodel__model__layer2', 478),\n",
        "('basemodel__model__layer3', 22),\n",
        "('basemodel__model__learning_rate', 0.0068513804632596),\n",
        "('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "('basemodel__model__second_dense', False),\n",
        "('basemodel__validation_split', 0.6070472478342536),\n",
        "('include_settings', True),\n",
        "('scaler', MinMaxScaler()),\n",
        "('seq_length', 32)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRabKU0p2lXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=32\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=413,\n",
        "                           epochs=39,\n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='elu',\n",
        "                           model__dropout1=0.8027344701984965, \n",
        "                           model__dropout2=0.7569408037894426,\n",
        "                           model__dropout3=0.12896783869092998, \n",
        "                           model__layer1=367, \n",
        "                           model__layer2=478, \n",
        "                           model__layer3=22, \n",
        "                           model__learning_rate=0.0068513804632596,\n",
        "                           model__optim=RMSprop,\n",
        "                           model__second_dense=False,\n",
        "                           validation_split=0.6070472478342536, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "6BGiwksX2lXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2b6a00-fb52-4e41-e41c-9dba2fd43f50",
        "id": "Yert7PMH2lXI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 32, 25)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32, 367)           576924    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 367)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 478)               1617552   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 478)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 22)                10538     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 22)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 23        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,205,037\n",
            "Trainable params: 2,205,037\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=3683.127, rmse=60.689, r2=0.015; v_loss=2235.089, v_rmse=47.277, v_r2=0.421; \n",
            "E 2\t: loss=2481.200, rmse=49.812, r2=0.336; v_loss=3066.714, v_rmse=55.378, v_r2=0.206; \n",
            "E 3\t: loss=2451.697, rmse=49.515, r2=0.344; v_loss=2255.836, v_rmse=47.496, v_r2=0.416; \n",
            "E 4\t: loss=2359.735, rmse=48.577, r2=0.369; v_loss=2013.957, v_rmse=44.877, v_r2=0.479; \n",
            "E 5\t: loss=2378.891, rmse=48.774, r2=0.364; v_loss=2258.279, v_rmse=47.521, v_r2=0.415; \n",
            "E 6\t: loss=2335.442, rmse=48.326, r2=0.375; v_loss=2325.924, v_rmse=48.228, v_r2=0.398; \n",
            "E 7\t: loss=2295.228, rmse=47.909, r2=0.386; v_loss=2183.754, v_rmse=46.731, v_r2=0.435; \n",
            "E 8\t: loss=2314.764, rmse=48.112, r2=0.381; v_loss=2163.403, v_rmse=46.512, v_r2=0.440; \n",
            "E 9\t: loss=2275.799, rmse=47.705, r2=0.391; v_loss=2104.926, v_rmse=45.879, v_r2=0.455; \n",
            "E 10\t: loss=2279.761, rmse=47.747, r2=0.390; v_loss=2060.720, v_rmse=45.395, v_r2=0.466; \n",
            "E 11\t: loss=2267.487, rmse=47.618, r2=0.394; v_loss=2118.405, v_rmse=46.026, v_r2=0.451; \n",
            "E 12\t: loss=2289.483, rmse=47.849, r2=0.388; v_loss=2084.828, v_rmse=45.660, v_r2=0.460; \n",
            "E 13\t: loss=2245.711, rmse=47.389, r2=0.399; v_loss=2107.153, v_rmse=45.904, v_r2=0.454; \n",
            "E 14\t: loss=2262.814, rmse=47.569, r2=0.395; v_loss=2231.274, v_rmse=47.236, v_r2=0.422; \n",
            "E 15\t: loss=2237.426, rmse=47.301, r2=0.402; v_loss=2003.012, v_rmse=44.755, v_r2=0.481; \n",
            "E 16\t: loss=2238.235, rmse=47.310, r2=0.401; v_loss=2088.337, v_rmse=45.698, v_r2=0.459; \n",
            "E 17\t: loss=2244.197, rmse=47.373, r2=0.400; v_loss=2097.091, v_rmse=45.794, v_r2=0.457; \n",
            "E 18\t: loss=2227.592, rmse=47.197, r2=0.404; v_loss=2140.553, v_rmse=46.266, v_r2=0.446; \n",
            "E 19\t: loss=2179.865, rmse=46.689, r2=0.417; v_loss=2101.824, v_rmse=45.846, v_r2=0.456; \n",
            "E 20\t: loss=2236.026, rmse=47.287, r2=0.402; v_loss=2199.315, v_rmse=46.897, v_r2=0.431; \n",
            "E 21\t: loss=2217.426, rmse=47.090, r2=0.407; v_loss=2071.041, v_rmse=45.509, v_r2=0.464; \n",
            "E 22\t: loss=2229.016, rmse=47.212, r2=0.404; v_loss=2115.823, v_rmse=45.998, v_r2=0.452; \n",
            "E 23\t: loss=2189.738, rmse=46.795, r2=0.414; v_loss=2052.501, v_rmse=45.305, v_r2=0.469; \n",
            "E 24\t: loss=2215.525, rmse=47.069, r2=0.407; v_loss=2059.498, v_rmse=45.382, v_r2=0.467; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=413, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f8d0c16a590>, <keras.callbacks.LambdaCallback object at 0x7f8d0c16e690>], epochs=39, model=<function create_model at 0x7f8d0c17cf80>, model__activation1='tanh', model__activation2='tanh', model__activation3='elu', model__dropout1=0.8027344701984965, m...ras.metrics.metrics.RootMeanSquaredError object at 0x7f8d0c16d210>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f8d66adb410>], model__optim=<class 'keras.optimizers.optimizer_v2.rmsprop.RMSprop'>, model__second_dense=False, print_summary=True, validation_split=0.6070472478342536, verbose=0),\n",
              "                     include_settings=True, scaler=MinMaxScaler(),\n",
              "                     seq_length=32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60f7f3a-ca0f-4613-e073-256fc2a29400",
        "id": "rqyVHO5n2lXK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.488,RMSE=-38.494\n",
            "Finished: 2022-10-30 10:58:37.479329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "DZEmsy2m2lXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.5770400313627971  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 475),\n",
        "('basemodel__epochs', 38),\n",
        "('basemodel__model__activation1', 'tanh'),\n",
        "('basemodel__model__activation2', 'tanh'),\n",
        "('basemodel__model__activation3', 'selu'),\n",
        "('basemodel__model__dropout1', 0.41871805965088293),\n",
        "('basemodel__model__dropout2', 0.3421999536441197),\n",
        "('basemodel__model__dropout3', 0.6177826332606998),\n",
        "('basemodel__model__layer1', 440),\n",
        "('basemodel__model__layer2', 184),\n",
        "('basemodel__model__layer3', 376),\n",
        "('basemodel__model__learning_rate', 0.0038903406569891345),\n",
        "('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "('basemodel__model__second_dense', False),\n",
        "('basemodel__validation_split', 0.7313863245835751),\n",
        "('clip_y', 100),\n",
        "('include_settings', True),\n",
        "('scaler', StandardScaler()),\n",
        "('seq_length', 44)\n",
        "```\n"
      ],
      "metadata": {
        "id": "5340ZcMG2lXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=44\n",
        "CLIP=100\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=StandardScaler(),\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=475,\n",
        "                           epochs=38,     \n",
        "                           model__activation1='tanh',\n",
        "                           model__activation2='tanh',\n",
        "                           model__activation3='selu',\n",
        "                           model__dropout1=0.41871805965088293, \n",
        "                           model__dropout2=0.3421999536441197,\n",
        "                           model__dropout3=0.6177826332606998, \n",
        "                           model__layer1=440, \n",
        "                           model__layer2=184, \n",
        "                           model__layer3=376, \n",
        "                           model__learning_rate=0.0038903406569891345,\n",
        "                           model__optim=Adam,\n",
        "                           model__second_dense=False,\n",
        "                           validation_split=0.7313863245835751, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "njy3V5mz2lXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8013869-5b41-4d76-8a20-4aa6a540775a",
        "id": "0ZDq9Rf-2lXM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 44, 25)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 44, 440)           820160    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 44, 440)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 184)               460000    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 184)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 376)               69560     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 376)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 377       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,350,097\n",
            "Trainable params: 1,350,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=1740.681, rmse=41.721, r2=-0.552; v_loss=1202.417, v_rmse=34.676, v_r2=-0.082; \n",
            "E 2\t: loss=1174.578, rmse=34.272, r2=-0.047; v_loss=1134.278, v_rmse=33.679, v_r2=-0.020; \n",
            "E 3\t: loss=1155.567, rmse=33.994, r2=-0.030; v_loss=1090.261, v_rmse=33.019, v_r2=0.019; \n",
            "E 4\t: loss=1078.451, rmse=32.840, r2=0.039; v_loss=983.504, v_rmse=31.361, v_r2=0.115; \n",
            "E 5\t: loss=908.117, rmse=30.135, r2=0.190; v_loss=784.702, v_rmse=28.013, v_r2=0.294; \n",
            "E 6\t: loss=699.579, rmse=26.450, r2=0.376; v_loss=796.262, v_rmse=28.218, v_r2=0.284; \n",
            "E 7\t: loss=644.282, rmse=25.383, r2=0.426; v_loss=723.805, v_rmse=26.904, v_r2=0.349; \n",
            "E 8\t: loss=648.028, rmse=25.456, r2=0.422; v_loss=651.066, v_rmse=25.516, v_r2=0.414; \n",
            "E 9\t: loss=635.263, rmse=25.204, r2=0.434; v_loss=671.137, v_rmse=25.906, v_r2=0.396; \n",
            "E 10\t: loss=632.032, rmse=25.140, r2=0.437; v_loss=644.992, v_rmse=25.397, v_r2=0.420; \n",
            "E 11\t: loss=634.565, rmse=25.191, r2=0.434; v_loss=755.890, v_rmse=27.493, v_r2=0.320; \n",
            "E 12\t: loss=615.265, rmse=24.805, r2=0.452; v_loss=687.951, v_rmse=26.229, v_r2=0.381; \n",
            "E 13\t: loss=611.139, rmse=24.721, r2=0.455; v_loss=660.046, v_rmse=25.691, v_r2=0.406; \n",
            "E 14\t: loss=607.495, rmse=24.647, r2=0.458; v_loss=722.764, v_rmse=26.884, v_r2=0.350; \n",
            "E 15\t: loss=608.445, rmse=24.667, r2=0.458; v_loss=639.689, v_rmse=25.292, v_r2=0.425; \n",
            "E 16\t: loss=591.814, rmse=24.327, r2=0.472; v_loss=693.917, v_rmse=26.342, v_r2=0.376; \n",
            "E 17\t: loss=587.651, rmse=24.242, r2=0.476; v_loss=709.983, v_rmse=26.645, v_r2=0.361; \n",
            "E 18\t: loss=584.170, rmse=24.170, r2=0.479; v_loss=657.931, v_rmse=25.650, v_r2=0.408; \n",
            "E 19\t: loss=576.620, rmse=24.013, r2=0.486; v_loss=718.761, v_rmse=26.810, v_r2=0.353; \n",
            "E 20\t: loss=599.877, rmse=24.492, r2=0.465; v_loss=662.373, v_rmse=25.737, v_r2=0.404; \n",
            "E 21\t: loss=572.116, rmse=23.919, r2=0.490; v_loss=676.381, v_rmse=26.007, v_r2=0.392; \n",
            "E 22\t: loss=575.040, rmse=23.980, r2=0.487; v_loss=611.438, v_rmse=24.727, v_r2=0.450; \n",
            "E 23\t: loss=549.933, rmse=23.451, r2=0.510; v_loss=748.847, v_rmse=27.365, v_r2=0.326; \n",
            "E 24\t: loss=544.946, rmse=23.344, r2=0.514; v_loss=687.843, v_rmse=26.227, v_r2=0.381; \n",
            "E 25\t: loss=552.483, rmse=23.505, r2=0.507; v_loss=748.199, v_rmse=27.353, v_r2=0.327; \n",
            "E 26\t: loss=563.661, rmse=23.742, r2=0.498; v_loss=587.263, v_rmse=24.234, v_r2=0.472; \n",
            "E 27\t: loss=531.950, rmse=23.064, r2=0.526; v_loss=488.949, v_rmse=22.112, v_r2=0.560; \n",
            "E 28\t: loss=556.847, rmse=23.598, r2=0.504; v_loss=692.369, v_rmse=26.313, v_r2=0.377; \n",
            "E 29\t: loss=591.728, rmse=24.325, r2=0.472; v_loss=780.625, v_rmse=27.940, v_r2=0.298; \n",
            "E 30\t: loss=599.548, rmse=24.486, r2=0.466; v_loss=676.829, v_rmse=26.016, v_r2=0.391; \n",
            "E 31\t: loss=575.759, rmse=23.995, r2=0.487; v_loss=695.523, v_rmse=26.373, v_r2=0.374; \n",
            "E 32\t: loss=561.364, rmse=23.693, r2=0.500; v_loss=648.718, v_rmse=25.470, v_r2=0.416; \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWrapperRegressor(basemodel=KerasRegressor(batch_size=475, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f8d0c16a590>, <keras.callbacks.LambdaCallback object at 0x7f8d0c16e690>], epochs=38, model=<function create_model at 0x7f8d0c17cf80>, model__activation1='tanh', model__activation2='tanh', model__activation3='selu', model__dropout1=0.41871805965088293...del__metrics=[<keras.metrics.metrics.RootMeanSquaredError object at 0x7f8c9f9c2410>, <tensorflow_addons.metrics.r_square.RSquare object at 0x7f8c9f9c2690>], model__optim=<class 'keras.optimizers.optimizer_v2.adam.Adam'>, model__second_dense=False, print_summary=True, validation_split=0.7313863245835751, verbose=0),\n",
              "                     clip_y=100, include_settings=True, seq_length=44)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "if(CLIP > 0): reclipped_y = reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=False)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cbb451-5ce1-426d-ed0c-1d2498004820",
        "id": "GsrsS-Ga2lXO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.582,RMSE=-22.862\n",
            "Finished: 2022-10-30 11:02:43.976159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pr8HlKjxjOvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}