{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iqDPLB2EDXSK",
        "AU6ipeRozJz-",
        "Q4QwyfhXs_hv",
        "n7MBDuPasy-s",
        "IIXnBTkfxpCf",
        "ppByl3wN_W05",
        "zSnh2UONQb4Y"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMLNb0pkrSLsGHQ5KPCSssI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthursl12/POC1/blob/main/POC2_FD002_LSTMv2_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iqDPLB2EDXSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikeras;\n",
        "%pip install -U tensorflow-addons;\n",
        "%pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObuYEARk28q",
        "outputId": "76a6c511-2292-4ee7-f2bb-23e105d56f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in h:\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in h:\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-addons in h:\\anaconda3\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in h:\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in h:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-optimize in h:\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.6.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in h:\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: PyYAML in h:\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in h:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "i0Z0Zs7YcgTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af019e7d-71ba-428d-c942-9cea63e8b598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "H:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "H:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from sklearn.base import BaseEstimator,RegressorMixin"
      ],
      "metadata": {
        "id": "wmJyWwoFHcFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "from skopt.space.space import Categorical, Integer, Real"
      ],
      "metadata": {
        "id": "b4AwhIPNHgzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking\n",
        "\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import RSquare as R2\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "LnMMh6xN33s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette('colorblind')"
      ],
      "metadata": {
        "id": "yIpSdBdJ-uWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oWUcQTaa3lth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "fwRwlCA7Yt4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove some tf warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "cJXVJecRHjMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "AU6ipeRozJz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    IN_COLAB = True\n",
        "    folder=\"/content/\"\n",
        "\n",
        "    # Dataset Download \n",
        "    os.system('git clone https://github.com/arthursl12/dataset_2')\n",
        "    os.system('mv /content/dataset_2/CMaps /content/CMaps')\n",
        "    os.system('mv /content/dataset_2/data_processing /content/data_processing')\n",
        "    os.system('rm -rf dataset_2')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    IN_COLAB = False\n",
        "    folder=\"CMaps/\"\n",
        "    %cd dataset_2/"
      ],
      "metadata": {
        "id": "tlp572nXopEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e882051a-3edd-4db8-c9cb-d98ea8f53fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on CoLab\n",
            "C:\\Users\\Arthur Lima\\POC\\dataset_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_processing.processing import DatasetProcessing\n",
        "from data_processing.training import HyperparameterSearch, reclipper_scorer\n",
        "from data_processing.eval import Evaluation"
      ],
      "metadata": {
        "id": "FUQ5tHe4Eu7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc = DatasetProcessing()"
      ],
      "metadata": {
        "id": "g1BmyudxzUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "Q4QwyfhXs_hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:  \n",
        "\n",
        "1) unit number   \n",
        "2) time, in cycles  \n",
        "3) operational setting 1  \n",
        "4) operational setting 2  \n",
        "5) operational setting 3    \n",
        "6) sensor measurement 1    \n",
        "7) sensor measurement 2  \n",
        "...  \n",
        "26) sensor measurement 20\n",
        "\n",
        "\n",
        "There are 6 conditions (or combinations) which the 3 operational settings can take.  \n",
        "Condition 1: Altitude = 0, Mach Number = 0, TRA = 100  \n",
        "Condition 2: Altitude = 10, Mach Number = 0.25, TRA = 100  \n",
        "Condition 3: Altitude = 20, Mach Number = 0.7 TRA = 100  \n",
        "Condition 4: Altitude = 25, Mach Number = 0.62, TRA = 60  \n",
        "Condition 5: Altitude = 35 Mach Number = 0.84, TRA = 100  \n",
        "Condition 6: Altitude = 42, Mach Number = 0.84, TRA = 100  \n",
        "  \n",
        "There is slight variation in all these conditions so you may get numbers like 24.453 instead of 25 exactly.\n",
        "\n",
        "FD001: Condition 1 only  \n",
        "FD002: Mix of all the conditions  \n",
        "FD003: Condition 1 only  \n",
        "FD004: Mix of all conditions  \n"
      ],
      "metadata": {
        "id": "PQe-SyeYc6Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_cols, settings_cols, sensors_cols, cols = proc.column_names()\n",
        "train, test, y_test = proc.read_dataset(2, folder='CMaps/')\n",
        "train"
      ],
      "metadata": {
        "id": "-yRYxz2hh4xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d2c366a7-fa7a-4629-a5b3-15118b4cb032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       unit_number  time     op_1    op_2   op_3     s_0     s_1      s_2  \\\n",
              "0                1     1  34.9983  0.8400  100.0  449.44  555.32  1358.61   \n",
              "1                1     2  41.9982  0.8408  100.0  445.00  549.90  1353.22   \n",
              "2                1     3  24.9988  0.6218   60.0  462.54  537.31  1256.76   \n",
              "3                1     4  42.0077  0.8416  100.0  445.00  549.51  1354.03   \n",
              "4                1     5  25.0005  0.6203   60.0  462.54  537.07  1257.71   \n",
              "...            ...   ...      ...     ...    ...     ...     ...      ...   \n",
              "53754          260   312  20.0037  0.7000  100.0  491.19  608.79  1495.60   \n",
              "53755          260   313  10.0022  0.2510  100.0  489.05  605.81  1514.32   \n",
              "53756          260   314  25.0041  0.6200   60.0  462.54  537.48  1276.24   \n",
              "53757          260   315  25.0033  0.6220   60.0  462.54  537.84  1272.95   \n",
              "53758          260   316  35.0036  0.8400  100.0  449.44  556.64  1374.61   \n",
              "\n",
              "           s_3    s_4  ...    s_11     s_12     s_13     s_14  s_15  s_16  \\\n",
              "0      1137.23   5.48  ...  183.06  2387.72  8048.56   9.3461  0.02   334   \n",
              "1      1125.78   3.91  ...  130.42  2387.66  8072.30   9.3774  0.02   330   \n",
              "2      1047.45   7.05  ...  164.22  2028.03  7864.87  10.8941  0.02   309   \n",
              "3      1126.38   3.91  ...  130.72  2387.61  8068.66   9.3528  0.02   329   \n",
              "4      1047.93   7.05  ...  164.31  2028.00  7861.23  10.8963  0.02   309   \n",
              "...        ...    ...  ...     ...      ...      ...      ...   ...   ...   \n",
              "53754  1269.51   9.35  ...  314.05  2389.02  8169.64   9.3035  0.03   369   \n",
              "53755  1324.12  10.52  ...  371.22  2388.42  8245.36   8.7586  0.03   374   \n",
              "53756  1057.92   7.05  ...  163.74  2030.33  7971.25  11.0657  0.02   310   \n",
              "53757  1066.30   7.05  ...  164.37  2030.35  7972.47  11.0537  0.02   311   \n",
              "53758  1145.52   5.48  ...  183.09  2390.38  8185.35   9.3998  0.02   338   \n",
              "\n",
              "       s_17    s_18   s_19     s_20  \n",
              "0      2223  100.00  14.73   8.8071  \n",
              "1      2212  100.00  10.41   6.2665  \n",
              "2      1915   84.93  14.08   8.6723  \n",
              "3      2212  100.00  10.59   6.4701  \n",
              "4      1915   84.93  14.13   8.5286  \n",
              "...     ...     ...    ...      ...  \n",
              "53754  2324  100.00  24.36  14.5189  \n",
              "53755  2319  100.00  28.10  16.9454  \n",
              "53756  1915   84.93  14.19   8.5503  \n",
              "53757  1915   84.93  14.05   8.3729  \n",
              "53758  2223  100.00  14.75   8.8446  \n",
              "\n",
              "[53759 rows x 26 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>183.06</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>130.42</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.22</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>130.72</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.31</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53754</th>\n",
              "      <td>260</td>\n",
              "      <td>312</td>\n",
              "      <td>20.0037</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>608.79</td>\n",
              "      <td>1495.60</td>\n",
              "      <td>1269.51</td>\n",
              "      <td>9.35</td>\n",
              "      <td>...</td>\n",
              "      <td>314.05</td>\n",
              "      <td>2389.02</td>\n",
              "      <td>8169.64</td>\n",
              "      <td>9.3035</td>\n",
              "      <td>0.03</td>\n",
              "      <td>369</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.00</td>\n",
              "      <td>24.36</td>\n",
              "      <td>14.5189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53755</th>\n",
              "      <td>260</td>\n",
              "      <td>313</td>\n",
              "      <td>10.0022</td>\n",
              "      <td>0.2510</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.81</td>\n",
              "      <td>1514.32</td>\n",
              "      <td>1324.12</td>\n",
              "      <td>10.52</td>\n",
              "      <td>...</td>\n",
              "      <td>371.22</td>\n",
              "      <td>2388.42</td>\n",
              "      <td>8245.36</td>\n",
              "      <td>8.7586</td>\n",
              "      <td>0.03</td>\n",
              "      <td>374</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.00</td>\n",
              "      <td>28.10</td>\n",
              "      <td>16.9454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53756</th>\n",
              "      <td>260</td>\n",
              "      <td>314</td>\n",
              "      <td>25.0041</td>\n",
              "      <td>0.6200</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.48</td>\n",
              "      <td>1276.24</td>\n",
              "      <td>1057.92</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>163.74</td>\n",
              "      <td>2030.33</td>\n",
              "      <td>7971.25</td>\n",
              "      <td>11.0657</td>\n",
              "      <td>0.02</td>\n",
              "      <td>310</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.19</td>\n",
              "      <td>8.5503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53757</th>\n",
              "      <td>260</td>\n",
              "      <td>315</td>\n",
              "      <td>25.0033</td>\n",
              "      <td>0.6220</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.84</td>\n",
              "      <td>1272.95</td>\n",
              "      <td>1066.30</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.37</td>\n",
              "      <td>2030.35</td>\n",
              "      <td>7972.47</td>\n",
              "      <td>11.0537</td>\n",
              "      <td>0.02</td>\n",
              "      <td>311</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.05</td>\n",
              "      <td>8.3729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53758</th>\n",
              "      <td>260</td>\n",
              "      <td>316</td>\n",
              "      <td>35.0036</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>556.64</td>\n",
              "      <td>1374.61</td>\n",
              "      <td>1145.52</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>183.09</td>\n",
              "      <td>2390.38</td>\n",
              "      <td>8185.35</td>\n",
              "      <td>9.3998</td>\n",
              "      <td>0.02</td>\n",
              "      <td>338</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8.8446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53759 rows × 26 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "n7MBDuPasy-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set Transformation \n",
        "Test set has samples for all cycles, but has annotations only for last one"
      ],
      "metadata": {
        "id": "QinQ4hWStzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "4wtvRNsfuUwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f532f503-4ef2-4e48-e6b7-6f74197242a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33991, 26), (259, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_last = proc.transform_test_keep_setting(test)\n",
        "test_last.head()"
      ],
      "metadata": {
        "id": "onw4pCwZy-1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "5d4da397-eb4e-42ea-9686-32fe137a6f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3    s_4    s_5  \\\n",
              "0  10.0076  0.2501  100.0  489.05  605.42  1515.00  1325.07  10.52  15.50   \n",
              "1   0.0018  0.0000  100.0  518.67  642.67  1591.67  1418.17  14.62  21.61   \n",
              "2  35.0015  0.8412  100.0  449.44  555.86  1370.62  1135.59   5.48   8.00   \n",
              "3  20.0032  0.7000  100.0  491.19  607.99  1487.94  1257.49   9.35  13.66   \n",
              "4  42.0055  0.8400  100.0  445.00  550.81  1358.95  1140.34   3.91   5.72   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13    s_14  s_15  s_16  s_17   s_18  \\\n",
              "0  393.58  ...  370.87  2388.32  8167.06  8.7456  0.03   371  2319  100.0   \n",
              "1  553.36  ...  521.10  2388.12  8138.12  8.4248  0.03   393  2388  100.0   \n",
              "2  194.58  ...  183.11  2388.07  8071.23  9.3094  0.02   332  2223  100.0   \n",
              "3  334.39  ...  314.88  2388.12  8062.39  9.2349  0.02   365  2324  100.0   \n",
              "4  138.42  ...  130.82  2389.06  8140.94  9.3964  0.02   333  2212  100.0   \n",
              "\n",
              "    s_19     s_20  \n",
              "0  28.30  17.0934  \n",
              "1  38.82  23.3463  \n",
              "2  14.75   8.9589  \n",
              "3  24.22  14.6814  \n",
              "4  10.34   6.3601  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0076</td>\n",
              "      <td>0.2501</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.42</td>\n",
              "      <td>1515.00</td>\n",
              "      <td>1325.07</td>\n",
              "      <td>10.52</td>\n",
              "      <td>15.50</td>\n",
              "      <td>393.58</td>\n",
              "      <td>...</td>\n",
              "      <td>370.87</td>\n",
              "      <td>2388.32</td>\n",
              "      <td>8167.06</td>\n",
              "      <td>8.7456</td>\n",
              "      <td>0.03</td>\n",
              "      <td>371</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.0</td>\n",
              "      <td>28.30</td>\n",
              "      <td>17.0934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0018</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.67</td>\n",
              "      <td>1591.67</td>\n",
              "      <td>1418.17</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.36</td>\n",
              "      <td>...</td>\n",
              "      <td>521.10</td>\n",
              "      <td>2388.12</td>\n",
              "      <td>8138.12</td>\n",
              "      <td>8.4248</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.82</td>\n",
              "      <td>23.3463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.0015</td>\n",
              "      <td>0.8412</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.86</td>\n",
              "      <td>1370.62</td>\n",
              "      <td>1135.59</td>\n",
              "      <td>5.48</td>\n",
              "      <td>8.00</td>\n",
              "      <td>194.58</td>\n",
              "      <td>...</td>\n",
              "      <td>183.11</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8071.23</td>\n",
              "      <td>9.3094</td>\n",
              "      <td>0.02</td>\n",
              "      <td>332</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.0</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8.9589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0032</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>491.19</td>\n",
              "      <td>607.99</td>\n",
              "      <td>1487.94</td>\n",
              "      <td>1257.49</td>\n",
              "      <td>9.35</td>\n",
              "      <td>13.66</td>\n",
              "      <td>334.39</td>\n",
              "      <td>...</td>\n",
              "      <td>314.88</td>\n",
              "      <td>2388.12</td>\n",
              "      <td>8062.39</td>\n",
              "      <td>9.2349</td>\n",
              "      <td>0.02</td>\n",
              "      <td>365</td>\n",
              "      <td>2324</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.22</td>\n",
              "      <td>14.6814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.0055</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>550.81</td>\n",
              "      <td>1358.95</td>\n",
              "      <td>1140.34</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.72</td>\n",
              "      <td>138.42</td>\n",
              "      <td>...</td>\n",
              "      <td>130.82</td>\n",
              "      <td>2389.06</td>\n",
              "      <td>8140.94</td>\n",
              "      <td>9.3964</td>\n",
              "      <td>0.02</td>\n",
              "      <td>333</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.34</td>\n",
              "      <td>6.3601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_last"
      ],
      "metadata": {
        "id": "ar3xxOQvIbHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remaining Useful Life (RUL)"
      ],
      "metadata": {
        "id": "boZqFQNlraCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = proc.add_remaining_useful_life_linear(train)\n",
        "train[index_cols+['RUL']].head()"
      ],
      "metadata": {
        "id": "lmFKjQaeip1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "1fde76db-2b38-42ec-8c82-f3fc9165a77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unit_number  time  RUL\n",
              "0            1     1  148\n",
              "1            1     2  147\n",
              "2            1     3  146\n",
              "3            1     4  145\n",
              "4            1     5  144"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes and target separation"
      ],
      "metadata": {
        "id": "IIXnBTkfxpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = proc.X_y_train_divide_with_settings(train)"
      ],
      "metadata": {
        "id": "4SzUk6ZLxv6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "fuAnHn4GxzwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "8e270a7b-0190-4a20-fc26-dade5b98268b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RUL\n",
              "0  148\n",
              "1  147\n",
              "2  146\n",
              "3  145\n",
              "4  144"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "26hK4VWkx1R7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "e0a52510-b2d3-46aa-ec8e-f0b8e0901ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      op_1    op_2   op_3     s_0     s_1      s_2      s_3   s_4   s_5  \\\n",
              "0  34.9983  0.8400  100.0  449.44  555.32  1358.61  1137.23  5.48  8.00   \n",
              "1  41.9982  0.8408  100.0  445.00  549.90  1353.22  1125.78  3.91  5.71   \n",
              "2  24.9988  0.6218   60.0  462.54  537.31  1256.76  1047.45  7.05  9.02   \n",
              "3  42.0077  0.8416  100.0  445.00  549.51  1354.03  1126.38  3.91  5.71   \n",
              "4  25.0005  0.6203   60.0  462.54  537.07  1257.71  1047.93  7.05  9.03   \n",
              "\n",
              "      s_6  ...    s_11     s_12     s_13     s_14  s_15  s_16  s_17    s_18  \\\n",
              "0  194.64  ...  183.06  2387.72  8048.56   9.3461  0.02   334  2223  100.00   \n",
              "1  138.51  ...  130.42  2387.66  8072.30   9.3774  0.02   330  2212  100.00   \n",
              "2  175.71  ...  164.22  2028.03  7864.87  10.8941  0.02   309  1915   84.93   \n",
              "3  138.46  ...  130.72  2387.61  8068.66   9.3528  0.02   329  2212  100.00   \n",
              "4  175.05  ...  164.31  2028.00  7861.23  10.8963  0.02   309  1915   84.93   \n",
              "\n",
              "    s_19    s_20  \n",
              "0  14.73  8.8071  \n",
              "1  10.41  6.2665  \n",
              "2  14.08  8.6723  \n",
              "3  10.59  6.4701  \n",
              "4  14.13  8.5286  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op_1</th>\n",
              "      <th>op_2</th>\n",
              "      <th>op_3</th>\n",
              "      <th>s_0</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>s_6</th>\n",
              "      <th>...</th>\n",
              "      <th>s_11</th>\n",
              "      <th>s_12</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>8.00</td>\n",
              "      <td>194.64</td>\n",
              "      <td>...</td>\n",
              "      <td>183.06</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.71</td>\n",
              "      <td>138.51</td>\n",
              "      <td>...</td>\n",
              "      <td>130.42</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.02</td>\n",
              "      <td>175.71</td>\n",
              "      <td>...</td>\n",
              "      <td>164.22</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.71</td>\n",
              "      <td>138.46</td>\n",
              "      <td>...</td>\n",
              "      <td>130.72</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>9.03</td>\n",
              "      <td>175.05</td>\n",
              "      <td>...</td>\n",
              "      <td>164.31</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "fQA-YtFMM81M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()"
      ],
      "metadata": {
        "id": "u88P6scrNTRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = HyperparameterSearch()"
      ],
      "metadata": {
        "id": "OUcS61OqPFhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Construction"
      ],
      "metadata": {
        "id": "nTPBH5fg_sFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "f3Or3dZbB5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                      patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "E_f33CIB-13t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Callback\n",
        "def printLog(epoch, logs):\n",
        "    print(\n",
        "        f\"E {epoch+1}\\t: loss={logs['loss']:.3f}, \"+\n",
        "        f\"rmse={logs['root_mean_squared_error']:.3f}, \"+\n",
        "        f\"r2={logs['r_square']:.3f}; \"+\n",
        "        f\"v_loss={logs['val_loss']:.3f}, \"+\n",
        "        f\"v_rmse={logs['val_root_mean_squared_error']:.3f}, \"+\n",
        "        f\"v_r2={logs['val_r_square']:.3f}; \"\n",
        "    )\n",
        "\n",
        "printerCallback = LambdaCallback(on_epoch_end=printLog)"
      ],
      "metadata": {
        "id": "07NuyHHfWLZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "DvHTMj_9_xss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train must include indices\n",
        "train3 = train.copy()\n",
        "X_train_ = train3.drop(columns=[\"RUL\"])"
      ],
      "metadata": {
        "id": "MmsURACM-Wkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 0"
      ],
      "metadata": {
        "id": "xKy2t3QS8gss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper"
      ],
      "metadata": {
        "id": "9mjReYMmM08s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LSTMWrapperRegressor(BaseEstimator,RegressorMixin):\n",
        "    def __init__(self, basemodel=None, clip_y=-1, seq_length=40,\n",
        "                 include_settings=False, poly_degree=1,\n",
        "                 scaler=StandardScaler()):\n",
        "        # Base parameters\n",
        "        self.basemodel = basemodel\n",
        "        self.clip_y = clip_y\n",
        "        self.seq_length = seq_length\n",
        "        self.poly_degree = poly_degree\n",
        "        self.include_settings = include_settings\n",
        "\n",
        "        # Column indexers\n",
        "        self.feature_cols = sensors_cols\n",
        "        if(include_settings):\n",
        "            # self.seq_cols = settings_cols + self.cols\n",
        "            self.feature_cols = settings_cols + self.feature_cols\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        self.base_feature_cols = self.feature_cols\n",
        "\n",
        "        # Scaler and PolyFeatures transformers\n",
        "        self.scaler = scaler\n",
        "        self.polyft = PolynomialFeatures(degree=self.poly_degree, \n",
        "                                         include_bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features and add them to the dataframe\n",
        "        transf = self.polyft.fit_transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, columns=\n",
        "                              self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        self.feature_cols = list(self.polyft.get_feature_names_out())\n",
        "        self.seq_cols = [\"time\"] + self.feature_cols\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data\n",
        "        data[self.feature_cols] = \\\n",
        "                            self.scaler.fit_transform(data[self.feature_cols])\n",
        "\n",
        "        # Transform into time series\n",
        "        X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_train.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_train = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Update input shape for future use\n",
        "        global INPUT_SHAPE\n",
        "        # print(INPUT_SHAPE, X_train.shape)\n",
        "        INPUT_SHAPE = (X_train.shape[1],X_train.shape[2])\n",
        "\n",
        "        # Fit model\n",
        "        # print(X_train.shape, y_train.shape)\n",
        "        self.basemodel.fit(X_train,y_train)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X=None):\n",
        "        # Perform transformation, if not done\n",
        "        if (len(X.shape) < 3):\n",
        "            data = X.copy()\n",
        "\n",
        "            # Apply polynomial features\n",
        "            transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "            transf = pd.DataFrame(transf, \n",
        "                                  columns=self.polyft.get_feature_names_out(),\n",
        "                                  index=data.index)\n",
        "            # data = pd.concat([data,transf], axis=1)\n",
        "            data[self.feature_cols] = transf\n",
        "\n",
        "            # Scale the data\n",
        "            data[self.feature_cols] = \\\n",
        "                            self.scaler.transform(data[self.feature_cols])\n",
        "            \n",
        "            # Transform into time series\n",
        "            X_train = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        else:\n",
        "            X_train = X\n",
        "        return self.basemodel.predict(X_train)\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        # Merge features and target again\n",
        "        data = X.copy()\n",
        "        data[\"RUL\"] = y\n",
        "\n",
        "        # Apply polynomial features\n",
        "        transf = self.polyft.transform(data[self.base_feature_cols])\n",
        "        transf = pd.DataFrame(transf, \n",
        "                              columns=self.polyft.get_feature_names_out(),\n",
        "                              index=data.index)\n",
        "        # data = pd.concat([data,transf], axis=1)\n",
        "        data[self.feature_cols] = transf\n",
        "\n",
        "        # Scale the data (with train data parameters)\n",
        "        data[self.feature_cols] = \\\n",
        "                        self.scaler.transform(data[self.feature_cols])\n",
        "        \n",
        "        # Transform into time series\n",
        "        X_test = self.gen_X_wrapper(data,self.seq_length,self.seq_cols)\n",
        "        # print(data.shape,X_test.shape, X.shape)\n",
        "\n",
        "        # Clip and transform labels\n",
        "        data2 = data.copy()\n",
        "        if (self.clip_y > 0):\n",
        "            data2[\"RUL\"].clip(upper=self.clip_y, inplace=True)\n",
        "        y_test = self.gen_y_wrapper(data2,self.seq_length,[\"RUL\"])\n",
        "\n",
        "        # Predict on test data\n",
        "        y_pred = self.predict(X_test)\n",
        "        return r2_score(y_test, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    def gen_X_data(self, df, sequence_length, columns, mask_value=-99.):\n",
        "        if df.shape[0] < sequence_length:\n",
        "            # print(\"\\t Not enough sequence:\",df.shape[0],\" < \",sequence_length)\n",
        "            data = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "            idx = data.shape[0] - df.shape[0]\n",
        "            data[idx:,:] = df[columns].values  # fill with available data\n",
        "        else:\n",
        "            data = df[columns].values\n",
        "            \n",
        "        # # specifically yield the last possible sequence\n",
        "        # stop = num_elements = data_matrix.shape[0]\n",
        "        # start = stop - sequence_length\n",
        "        # for i in list(range(1)):\n",
        "        #     yield data_matrix[start:stop, :]\n",
        "\n",
        "\n",
        "\n",
        "        # data = df[columns].values\n",
        "        num_elements = data.shape[0]\n",
        "\n",
        "        # -1 and +1 because of Python indexing\n",
        "        for start, stop in zip(range(0, num_elements-(sequence_length-1)), \n",
        "                               range(sequence_length, num_elements+1)):\n",
        "            yield data[start:stop, :]\n",
        "\n",
        "    def gen_X_wrapper(self, df, sequence_length, columns, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        data_gen = (list(self.gen_X_data(df[df[idx_col]==unit_nr], \n",
        "                                         sequence_length, columns))\n",
        "                for unit_nr in unit_nrs)\n",
        "        # print(\"\\tdatagen len:\",len(data_gen))\n",
        "        data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "        # print(\"\\tdata_array.shape:\",data_array.shape)\n",
        "        return data_array\n",
        "\n",
        "    def gen_y(self, df, sequence_length, label):\n",
        "        data_matrix = df[label].values\n",
        "        num_elements = data_matrix.shape[0]\n",
        "\n",
        "        # -1 because I want to predict the rul of that last row in the sequence, \n",
        "        # not the next row\n",
        "        return data_matrix[sequence_length-1:num_elements, :]  \n",
        "\n",
        "    def gen_y_wrapper(self, df, sequence_length, label, \n",
        "                      unit_nrs=np.array([]), idx_col=\"unit_number\"):\n",
        "        # print(\">> Y Wrapper called. df shape:\",df.shape)\n",
        "        if unit_nrs.size <= 0:\n",
        "            unit_nrs = df[idx_col].unique()\n",
        "            \n",
        "        label_gen = [self.gen_y(df[df[idx_col]==unit_nr], \n",
        "                                sequence_length, label) \n",
        "                    for unit_nr in unit_nrs]\n",
        "        # print(\"\\tlabelgen len:\",len(label_gen))\n",
        "        label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "        # print(\"\\tlabel_array.shape:\",label_array.shape)\n",
        "        return label_array"
      ],
      "metadata": {
        "id": "VhrwfNvEM0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "Z7Z5u9Bu_Q4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "        \n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]"
      ],
      "metadata": {
        "id": "npYlhD17_STQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_test_wrapper(X_test_scaled, sequence_length, cols, idx_col=\"unit_number\"): \n",
        "    data_gen = (\n",
        "        list(gen_test_data(X_test_scaled[X_test_scaled[idx_col]==unit_nr], \n",
        "                           sequence_length, cols, -99.))\n",
        "            for unit_nr in X_test_scaled[idx_col].unique())\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array"
      ],
      "metadata": {
        "id": "dHLgOufSAcAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_test(test,model):\n",
        "    test2 = test.copy()\n",
        "\n",
        "    # Apply polynomial features\n",
        "    transf = model.polyft.transform(test2[model.base_feature_cols])\n",
        "    transf = pd.DataFrame(transf, \n",
        "                          columns=model.polyft.get_feature_names_out(),\n",
        "                          index=test2.index)\n",
        "    newcols = model.polyft.get_feature_names_out()\n",
        "    test2[newcols] = transf \n",
        "\n",
        "    # Scale the data (with train data parameters)\n",
        "    test2[model.feature_cols] = \\\n",
        "                    model.scaler.transform(test2[model.feature_cols])\n",
        "    return test2"
      ],
      "metadata": {
        "id": "OFW6XKjG5kCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructor"
      ],
      "metadata": {
        "id": "Ha2fY8VlWD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optim=Adam, learning_rate=1e-3, \n",
        "                 layer1=32  , activation1=\"tanh\"    , dropout1=0.1,\n",
        "                 layer2=None, activation2=\"tanh\"    , dropout2=0.1,\n",
        "                 layer3=None, activation3=\"tanh\"    , dropout3=0.1,\n",
        "                 second_dense=True,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==False):\n",
        "        # LSTM-LSTM-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1, return_sequences=True))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(LSTM(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "    elif (layer2 is not None and layer3 is not None and second_dense==True):\n",
        "        # LSTM-Dense-Dense\n",
        "        model.add(LSTM(layer1, activation=activation1))\n",
        "        model.add(Dropout(dropout1))\n",
        "        model.add(Dense(layer2, activation=activation2))\n",
        "        model.add(Dropout(dropout2))\n",
        "        model.add(Dense(layer3, activation=activation3))\n",
        "        model.add(Dropout(dropout3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YR28IpUT5cm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "Jowfppg9HG3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=-1\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "                           model__layer3=64,\n",
        "                           model__activation3='tanh',\n",
        "                           model__dropout3=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__second_dense=False,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "Oau6_Lt-sRnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~2h LSTM-1\n",
        "# ~?min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"include_settings\": Categorical([True]),\n",
        "        \"basemodel__model__second_dense\": Categorical([False]),\n",
        "        # \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        # \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__activation2\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer3\": Integer(16,512),\n",
        "        \"basemodel__model__activation3\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da37173-14d1-4b8b-c559-c709dee95baa",
        "id": "gu7Q5lAvsRnY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=147, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.22229231511562592, basemodel__model__dropout2=0.2645489937800392, basemodel__model__dropout3=0.20116064246007348, basemodel__model__layer1=249, basemodel__model__layer2=146, basemodel__model__layer3=383, basemodel__model__learning_rate=0.008548684122521974, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4885347783656473, include_settings=True, scaler=StandardScaler(), seq_length=68;, score=-0.005 total time=  46.0s\n",
            "[CV 2/3] END basemodel__batch_size=147, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.22229231511562592, basemodel__model__dropout2=0.2645489937800392, basemodel__model__dropout3=0.20116064246007348, basemodel__model__layer1=249, basemodel__model__layer2=146, basemodel__model__layer3=383, basemodel__model__learning_rate=0.008548684122521974, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4885347783656473, include_settings=True, scaler=StandardScaler(), seq_length=68;, score=-0.019 total time= 1.0min\n",
            "[CV 3/3] END basemodel__batch_size=147, basemodel__epochs=22, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.22229231511562592, basemodel__model__dropout2=0.2645489937800392, basemodel__model__dropout3=0.20116064246007348, basemodel__model__layer1=249, basemodel__model__layer2=146, basemodel__model__layer3=383, basemodel__model__learning_rate=0.008548684122521974, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4885347783656473, include_settings=True, scaler=StandardScaler(), seq_length=68;, score=0.331 total time= 2.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=203, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.16695399224428525, basemodel__model__dropout2=0.8005051109819826, basemodel__model__dropout3=0.7063744679034039, basemodel__model__layer1=431, basemodel__model__layer2=424, basemodel__model__layer3=477, basemodel__model__learning_rate=0.0006390437530283336, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5979350042540882, include_settings=True, scaler=MinMaxScaler(), seq_length=63;, score=0.330 total time= 3.9min\n",
            "[CV 2/3] END basemodel__batch_size=203, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.16695399224428525, basemodel__model__dropout2=0.8005051109819826, basemodel__model__dropout3=0.7063744679034039, basemodel__model__layer1=431, basemodel__model__layer2=424, basemodel__model__layer3=477, basemodel__model__learning_rate=0.0006390437530283336, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5979350042540882, include_settings=True, scaler=MinMaxScaler(), seq_length=63;, score=0.355 total time= 3.8min\n",
            "[CV 3/3] END basemodel__batch_size=203, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.16695399224428525, basemodel__model__dropout2=0.8005051109819826, basemodel__model__dropout3=0.7063744679034039, basemodel__model__layer1=431, basemodel__model__layer2=424, basemodel__model__layer3=477, basemodel__model__learning_rate=0.0006390437530283336, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5979350042540882, include_settings=True, scaler=MinMaxScaler(), seq_length=63;, score=0.332 total time= 3.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=199, basemodel__epochs=43, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.26186988850170867, basemodel__model__dropout2=0.673314241483544, basemodel__model__dropout3=0.2508930467643141, basemodel__model__layer1=451, basemodel__model__layer2=329, basemodel__model__layer3=148, basemodel__model__learning_rate=0.009060275453561265, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.15066022386643435, include_settings=True, scaler=MinMaxScaler(), seq_length=52;, score=-0.002 total time= 1.7min\n",
            "[CV 2/3] END basemodel__batch_size=199, basemodel__epochs=43, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.26186988850170867, basemodel__model__dropout2=0.673314241483544, basemodel__model__dropout3=0.2508930467643141, basemodel__model__layer1=451, basemodel__model__layer2=329, basemodel__model__layer3=148, basemodel__model__learning_rate=0.009060275453561265, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.15066022386643435, include_settings=True, scaler=MinMaxScaler(), seq_length=52;, score=0.403 total time= 6.6min\n",
            "[CV 3/3] END basemodel__batch_size=199, basemodel__epochs=43, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.26186988850170867, basemodel__model__dropout2=0.673314241483544, basemodel__model__dropout3=0.2508930467643141, basemodel__model__layer1=451, basemodel__model__layer2=329, basemodel__model__layer3=148, basemodel__model__learning_rate=0.009060275453561265, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.15066022386643435, include_settings=True, scaler=MinMaxScaler(), seq_length=52;, score=-0.007 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=318, basemodel__epochs=27, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.31258994670524654, basemodel__model__dropout2=0.4571245022030752, basemodel__model__dropout3=0.1506508156431501, basemodel__model__layer1=354, basemodel__model__layer2=121, basemodel__model__layer3=328, basemodel__model__learning_rate=0.008132362508960366, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6309267786220827, include_settings=True, scaler=StandardScaler(), seq_length=40;, score=0.308 total time= 1.5min\n",
            "[CV 2/3] END basemodel__batch_size=318, basemodel__epochs=27, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.31258994670524654, basemodel__model__dropout2=0.4571245022030752, basemodel__model__dropout3=0.1506508156431501, basemodel__model__layer1=354, basemodel__model__layer2=121, basemodel__model__layer3=328, basemodel__model__learning_rate=0.008132362508960366, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6309267786220827, include_settings=True, scaler=StandardScaler(), seq_length=40;, score=0.388 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=318, basemodel__epochs=27, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.31258994670524654, basemodel__model__dropout2=0.4571245022030752, basemodel__model__dropout3=0.1506508156431501, basemodel__model__layer1=354, basemodel__model__layer2=121, basemodel__model__layer3=328, basemodel__model__learning_rate=0.008132362508960366, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6309267786220827, include_settings=True, scaler=StandardScaler(), seq_length=40;, score=0.385 total time= 1.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=263, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.1667247187134688, basemodel__model__dropout2=0.17866707633550274, basemodel__model__dropout3=0.5672479319025548, basemodel__model__layer1=103, basemodel__model__layer2=116, basemodel__model__layer3=396, basemodel__model__learning_rate=0.009296623824628748, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5598371636162577, include_settings=True, scaler=StandardScaler(), seq_length=56;, score=0.323 total time=  31.5s\n",
            "[CV 2/3] END basemodel__batch_size=263, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.1667247187134688, basemodel__model__dropout2=0.17866707633550274, basemodel__model__dropout3=0.5672479319025548, basemodel__model__layer1=103, basemodel__model__layer2=116, basemodel__model__layer3=396, basemodel__model__learning_rate=0.009296623824628748, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5598371636162577, include_settings=True, scaler=StandardScaler(), seq_length=56;, score=0.324 total time=  31.9s\n",
            "[CV 3/3] END basemodel__batch_size=263, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.1667247187134688, basemodel__model__dropout2=0.17866707633550274, basemodel__model__dropout3=0.5672479319025548, basemodel__model__layer1=103, basemodel__model__layer2=116, basemodel__model__layer3=396, basemodel__model__learning_rate=0.009296623824628748, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5598371636162577, include_settings=True, scaler=StandardScaler(), seq_length=56;, score=0.352 total time=  31.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=165, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8261376144698483, basemodel__model__dropout2=0.15636986250454862, basemodel__model__dropout3=0.4339578525311556, basemodel__model__layer1=275, basemodel__model__layer2=462, basemodel__model__layer3=425, basemodel__model__learning_rate=0.004688889062525143, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8341748787504925, include_settings=True, scaler=MinMaxScaler(), seq_length=89;, score=-1.134 total time= 1.4min\n",
            "[CV 2/3] END basemodel__batch_size=165, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8261376144698483, basemodel__model__dropout2=0.15636986250454862, basemodel__model__dropout3=0.4339578525311556, basemodel__model__layer1=275, basemodel__model__layer2=462, basemodel__model__layer3=425, basemodel__model__learning_rate=0.004688889062525143, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8341748787504925, include_settings=True, scaler=MinMaxScaler(), seq_length=89;, score=0.139 total time= 2.5min\n",
            "[CV 3/3] END basemodel__batch_size=165, basemodel__epochs=36, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8261376144698483, basemodel__model__dropout2=0.15636986250454862, basemodel__model__dropout3=0.4339578525311556, basemodel__model__layer1=275, basemodel__model__layer2=462, basemodel__model__layer3=425, basemodel__model__learning_rate=0.004688889062525143, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8341748787504925, include_settings=True, scaler=MinMaxScaler(), seq_length=89;, score=0.076 total time= 3.8min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=45, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5863143098935141, basemodel__model__dropout2=0.33978808091592333, basemodel__model__dropout3=0.11444223811524089, basemodel__model__layer1=61, basemodel__model__layer2=379, basemodel__model__layer3=376, basemodel__model__learning_rate=0.00022312080419824716, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5772397436920965, include_settings=True, scaler=StandardScaler(), seq_length=85;, score=0.324 total time= 5.9min\n",
            "[CV 2/3] END basemodel__batch_size=45, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5863143098935141, basemodel__model__dropout2=0.33978808091592333, basemodel__model__dropout3=0.11444223811524089, basemodel__model__layer1=61, basemodel__model__layer2=379, basemodel__model__layer3=376, basemodel__model__learning_rate=0.00022312080419824716, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5772397436920965, include_settings=True, scaler=StandardScaler(), seq_length=85;, score=0.450 total time= 5.9min\n",
            "[CV 3/3] END basemodel__batch_size=45, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5863143098935141, basemodel__model__dropout2=0.33978808091592333, basemodel__model__dropout3=0.11444223811524089, basemodel__model__layer1=61, basemodel__model__layer2=379, basemodel__model__layer3=376, basemodel__model__learning_rate=0.00022312080419824716, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5772397436920965, include_settings=True, scaler=StandardScaler(), seq_length=85;, score=0.490 total time= 5.9min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=413, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8027344701984965, basemodel__model__dropout2=0.7569408037894426, basemodel__model__dropout3=0.12896783869092998, basemodel__model__layer1=367, basemodel__model__layer2=478, basemodel__model__layer3=22, basemodel__model__learning_rate=0.0068513804632596, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6070472478342536, include_settings=True, scaler=MinMaxScaler(), seq_length=32;, score=0.448 total time= 1.6min\n",
            "[CV 2/3] END basemodel__batch_size=413, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8027344701984965, basemodel__model__dropout2=0.7569408037894426, basemodel__model__dropout3=0.12896783869092998, basemodel__model__layer1=367, basemodel__model__layer2=478, basemodel__model__layer3=22, basemodel__model__learning_rate=0.0068513804632596, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6070472478342536, include_settings=True, scaler=MinMaxScaler(), seq_length=32;, score=0.442 total time= 3.0min\n",
            "[CV 3/3] END basemodel__batch_size=413, basemodel__epochs=39, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8027344701984965, basemodel__model__dropout2=0.7569408037894426, basemodel__model__dropout3=0.12896783869092998, basemodel__model__layer1=367, basemodel__model__layer2=478, basemodel__model__layer3=22, basemodel__model__learning_rate=0.0068513804632596, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6070472478342536, include_settings=True, scaler=MinMaxScaler(), seq_length=32;, score=0.482 total time= 3.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=41, basemodel__epochs=44, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.13971001522772195, basemodel__model__dropout2=0.2519788092712689, basemodel__model__dropout3=0.16415718503178606, basemodel__model__layer1=237, basemodel__model__layer2=390, basemodel__model__layer3=499, basemodel__model__learning_rate=0.005895744762859025, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8273186258952614, include_settings=True, scaler=MinMaxScaler(), seq_length=70;, score=0.296 total time= 2.2min\n",
            "[CV 2/3] END basemodel__batch_size=41, basemodel__epochs=44, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.13971001522772195, basemodel__model__dropout2=0.2519788092712689, basemodel__model__dropout3=0.16415718503178606, basemodel__model__layer1=237, basemodel__model__layer2=390, basemodel__model__layer3=499, basemodel__model__learning_rate=0.005895744762859025, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8273186258952614, include_settings=True, scaler=MinMaxScaler(), seq_length=70;, score=0.160 total time= 7.3min\n",
            "[CV 3/3] END basemodel__batch_size=41, basemodel__epochs=44, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.13971001522772195, basemodel__model__dropout2=0.2519788092712689, basemodel__model__dropout3=0.16415718503178606, basemodel__model__layer1=237, basemodel__model__layer2=390, basemodel__model__layer3=499, basemodel__model__learning_rate=0.005895744762859025, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8273186258952614, include_settings=True, scaler=MinMaxScaler(), seq_length=70;, score=0.094 total time= 7.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=433, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4710220808283482, basemodel__model__dropout2=0.3291628634812217, basemodel__model__dropout3=0.4544817375383813, basemodel__model__layer1=220, basemodel__model__layer2=164, basemodel__model__layer3=299, basemodel__model__learning_rate=0.0032590878746683893, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5389024295199419, include_settings=True, scaler=MinMaxScaler(), seq_length=73;, score=0.234 total time=  52.9s\n",
            "[CV 2/3] END basemodel__batch_size=433, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4710220808283482, basemodel__model__dropout2=0.3291628634812217, basemodel__model__dropout3=0.4544817375383813, basemodel__model__layer1=220, basemodel__model__layer2=164, basemodel__model__layer3=299, basemodel__model__learning_rate=0.0032590878746683893, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5389024295199419, include_settings=True, scaler=MinMaxScaler(), seq_length=73;, score=0.318 total time= 1.3min\n",
            "[CV 3/3] END basemodel__batch_size=433, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.4710220808283482, basemodel__model__dropout2=0.3291628634812217, basemodel__model__dropout3=0.4544817375383813, basemodel__model__layer1=220, basemodel__model__layer2=164, basemodel__model__layer3=299, basemodel__model__learning_rate=0.0032590878746683893, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5389024295199419, include_settings=True, scaler=MinMaxScaler(), seq_length=73;, score=0.310 total time= 1.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=379, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6907116323562346, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.9, basemodel__model__layer1=201, basemodel__model__layer2=475, basemodel__model__layer3=54, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6087661677017705, include_settings=True, scaler=StandardScaler(), seq_length=100;, score=0.021 total time= 2.5min\n",
            "[CV 2/3] END basemodel__batch_size=379, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6907116323562346, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.9, basemodel__model__layer1=201, basemodel__model__layer2=475, basemodel__model__layer3=54, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6087661677017705, include_settings=True, scaler=StandardScaler(), seq_length=100;, score=-0.035 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=379, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6907116323562346, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.9, basemodel__model__layer1=201, basemodel__model__layer2=475, basemodel__model__layer3=54, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6087661677017705, include_settings=True, scaler=StandardScaler(), seq_length=100;, score=-0.062 total time= 2.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=435, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.6377515173963777, basemodel__model__dropout3=0.1, basemodel__model__layer1=100, basemodel__model__layer2=151, basemodel__model__layer3=269, basemodel__model__learning_rate=0.00010816512708135676, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5517249488578739, include_settings=True, scaler=MinMaxScaler(), seq_length=92;, score=-0.657 total time=  29.9s\n",
            "[CV 2/3] END basemodel__batch_size=435, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.6377515173963777, basemodel__model__dropout3=0.1, basemodel__model__layer1=100, basemodel__model__layer2=151, basemodel__model__layer3=269, basemodel__model__learning_rate=0.00010816512708135676, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5517249488578739, include_settings=True, scaler=MinMaxScaler(), seq_length=92;, score=-0.713 total time=  29.9s\n",
            "[CV 3/3] END basemodel__batch_size=435, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.6377515173963777, basemodel__model__dropout3=0.1, basemodel__model__layer1=100, basemodel__model__layer2=151, basemodel__model__layer3=269, basemodel__model__learning_rate=0.00010816512708135676, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5517249488578739, include_settings=True, scaler=MinMaxScaler(), seq_length=92;, score=-0.666 total time=  29.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=367, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7895220285828466, basemodel__model__dropout2=0.7867889457704101, basemodel__model__dropout3=0.1, basemodel__model__layer1=339, basemodel__model__layer2=504, basemodel__model__layer3=34, basemodel__model__learning_rate=0.006423917907836377, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6036691725307168, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=0.468 total time= 2.5min\n",
            "[CV 2/3] END basemodel__batch_size=367, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7895220285828466, basemodel__model__dropout2=0.7867889457704101, basemodel__model__dropout3=0.1, basemodel__model__layer1=339, basemodel__model__layer2=504, basemodel__model__layer3=34, basemodel__model__learning_rate=0.006423917907836377, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6036691725307168, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=0.412 total time= 1.5min\n",
            "[CV 3/3] END basemodel__batch_size=367, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7895220285828466, basemodel__model__dropout2=0.7867889457704101, basemodel__model__dropout3=0.1, basemodel__model__layer1=339, basemodel__model__layer2=504, basemodel__model__layer3=34, basemodel__model__learning_rate=0.006423917907836377, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6036691725307168, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=0.424 total time= 1.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=-1.782 total time= 8.8min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=-1.773 total time= 9.0min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=50, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.9, basemodel__model__layer1=512, basemodel__model__layer2=512, basemodel__model__layer3=16, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=-1.788 total time= 9.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=34, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.1826658623766309, basemodel__model__dropout2=0.20624705643222147, basemodel__model__dropout3=0.21865143549244148, basemodel__model__layer1=231, basemodel__model__layer2=309, basemodel__model__layer3=469, basemodel__model__learning_rate=0.005628781746410525, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6191634960614492, include_settings=True, scaler=StandardScaler(), seq_length=63;, score=0.448 total time= 8.6min\n",
            "[CV 2/3] END basemodel__batch_size=34, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.1826658623766309, basemodel__model__dropout2=0.20624705643222147, basemodel__model__dropout3=0.21865143549244148, basemodel__model__layer1=231, basemodel__model__layer2=309, basemodel__model__layer3=469, basemodel__model__learning_rate=0.005628781746410525, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6191634960614492, include_settings=True, scaler=StandardScaler(), seq_length=63;, score=0.249 total time= 8.6min\n",
            "[CV 3/3] END basemodel__batch_size=34, basemodel__epochs=37, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.1826658623766309, basemodel__model__dropout2=0.20624705643222147, basemodel__model__dropout3=0.21865143549244148, basemodel__model__layer1=231, basemodel__model__layer2=309, basemodel__model__layer3=469, basemodel__model__learning_rate=0.005628781746410525, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6191634960614492, include_settings=True, scaler=StandardScaler(), seq_length=63;, score=0.337 total time= 7.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=146, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.3460729258452969, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=77, basemodel__model__layer2=32, basemodel__model__layer3=456, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6592638346639539, include_settings=True, scaler=StandardScaler(), seq_length=45;, score=0.373 total time= 2.2min\n",
            "[CV 2/3] END basemodel__batch_size=146, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.3460729258452969, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=77, basemodel__model__layer2=32, basemodel__model__layer3=456, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6592638346639539, include_settings=True, scaler=StandardScaler(), seq_length=45;, score=0.365 total time= 2.1min\n",
            "[CV 3/3] END basemodel__batch_size=146, basemodel__epochs=41, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.3460729258452969, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=77, basemodel__model__layer2=32, basemodel__model__layer3=456, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6592638346639539, include_settings=True, scaler=StandardScaler(), seq_length=45;, score=0.424 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8615260004330325, basemodel__model__dropout2=0.4717781587002726, basemodel__model__dropout3=0.41365635818969215, basemodel__model__layer1=496, basemodel__model__layer2=300, basemodel__model__layer3=16, basemodel__model__learning_rate=0.009323943697835927, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6236499790029116, include_settings=True, scaler=MinMaxScaler(), seq_length=56;, score=0.353 total time= 2.5min\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8615260004330325, basemodel__model__dropout2=0.4717781587002726, basemodel__model__dropout3=0.41365635818969215, basemodel__model__layer1=496, basemodel__model__layer2=300, basemodel__model__layer3=16, basemodel__model__learning_rate=0.009323943697835927, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6236499790029116, include_settings=True, scaler=MinMaxScaler(), seq_length=56;, score=0.298 total time= 2.4min\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=24, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.8615260004330325, basemodel__model__dropout2=0.4717781587002726, basemodel__model__dropout3=0.41365635818969215, basemodel__model__layer1=496, basemodel__model__layer2=300, basemodel__model__layer3=16, basemodel__model__learning_rate=0.009323943697835927, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6236499790029116, include_settings=True, scaler=MinMaxScaler(), seq_length=56;, score=-0.267 total time= 2.4min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.2072782311497492, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=167, basemodel__model__layer3=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7432563412380805, include_settings=True, scaler=StandardScaler(), seq_length=54;, score=0.382 total time= 8.6min\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.2072782311497492, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=167, basemodel__model__layer3=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7432563412380805, include_settings=True, scaler=StandardScaler(), seq_length=54;, score=0.387 total time= 8.1min\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.2072782311497492, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=167, basemodel__model__layer3=512, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7432563412380805, include_settings=True, scaler=StandardScaler(), seq_length=54;, score=0.238 total time= 8.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=288, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.17478594087538507, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.600812682365264, basemodel__model__layer1=16, basemodel__model__layer2=52, basemodel__model__layer3=439, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6096244594708046, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.418 total time=  15.3s\n",
            "[CV 2/3] END basemodel__batch_size=288, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.17478594087538507, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.600812682365264, basemodel__model__layer1=16, basemodel__model__layer2=52, basemodel__model__layer3=439, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6096244594708046, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.272 total time=  15.2s\n",
            "[CV 3/3] END basemodel__batch_size=288, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.17478594087538507, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.600812682365264, basemodel__model__layer1=16, basemodel__model__layer2=52, basemodel__model__layer3=439, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.6096244594708046, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.382 total time=  15.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.3524012977561545, basemodel__model__dropout2=0.8242701834530637, basemodel__model__dropout3=0.9, basemodel__model__layer1=124, basemodel__model__layer2=16, basemodel__model__layer3=238, basemodel__model__learning_rate=0.009333167746000116, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5588682192621625, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=-0.027 total time=  14.6s\n",
            "[CV 2/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.3524012977561545, basemodel__model__dropout2=0.8242701834530637, basemodel__model__dropout3=0.9, basemodel__model__layer1=124, basemodel__model__layer2=16, basemodel__model__layer3=238, basemodel__model__learning_rate=0.009333167746000116, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5588682192621625, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=-0.037 total time=  14.8s\n",
            "[CV 3/3] END basemodel__batch_size=512, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.3524012977561545, basemodel__model__dropout2=0.8242701834530637, basemodel__model__dropout3=0.9, basemodel__model__layer1=124, basemodel__model__layer2=16, basemodel__model__layer3=238, basemodel__model__learning_rate=0.009333167746000116, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5588682192621625, include_settings=True, scaler=MinMaxScaler(), seq_length=30;, score=-0.033 total time=  14.6s\n",
            "Finished: 2022-10-21 18:09:16.817938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5d5c0a-30ea-4727-b443-0c461c134a48",
        "id": "II2XZ3bisRna"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4572066088840683\n",
            "OrderedDict([('basemodel__batch_size', 413), ('basemodel__epochs', 39), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'tanh'), ('basemodel__model__activation3', 'elu'), ('basemodel__model__dropout1', 0.8027344701984965), ('basemodel__model__dropout2', 0.7569408037894426), ('basemodel__model__dropout3', 0.12896783869092998), ('basemodel__model__layer1', 367), ('basemodel__model__layer2', 478), ('basemodel__model__layer3', 22), ('basemodel__model__learning_rate', 0.0068513804632596), ('basemodel__model__optim', <class 'keras.optimizer_v2.rmsprop.RMSprop'>), ('basemodel__model__second_dense', False), ('basemodel__validation_split', 0.6070472478342536), ('include_settings', True), ('scaler', MinMaxScaler()), ('seq_length', 32)])\n",
            "Finished: 2022-10-21 18:09:16.830803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "eb532d03-6661-4744-a794-dc7019fda8d8",
        "id": "yYjDwPh4sRnb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-21 18:09:16.863829\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0275b9-5b66-415b-99b1-a79d20b55f90",
        "id": "zi1RfQy-sRnc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 413),\n",
              "             ('basemodel__epochs', 39),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'tanh'),\n",
              "             ('basemodel__model__activation3', 'elu'),\n",
              "             ('basemodel__model__dropout1', 0.8027344701984965),\n",
              "             ('basemodel__model__dropout2', 0.7569408037894426),\n",
              "             ('basemodel__model__dropout3', 0.12896783869092998),\n",
              "             ('basemodel__model__layer1', 367),\n",
              "             ('basemodel__model__layer2', 478),\n",
              "             ('basemodel__model__layer3', 22),\n",
              "             ('basemodel__model__learning_rate', 0.0068513804632596),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
              "             ('basemodel__model__second_dense', False),\n",
              "             ('basemodel__validation_split', 0.6070472478342536),\n",
              "             ('include_settings', True),\n",
              "             ('scaler', MinMaxScaler()),\n",
              "             ('seq_length', 32)])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=126\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH,\n",
        "        include_settings=True,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer1=512, \n",
        "                           model__layer2=64,\n",
        "                           model__activation2='tanh',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "                           model__layer3=64,\n",
        "                           model__activation3='tanh',\n",
        "                           model__dropout3=0.30649418903936865,\n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__second_dense=False,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=False\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "KqsQV_ZrTjhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~2h LSTM-1\n",
        "# ~?min LSTM-2\n",
        "GRID_SEARCH = True\n",
        "if (GRID_SEARCH):\n",
        "    param_distributions = {\n",
        "        \"seq_length\": Integer(30,100),\n",
        "        \"include_settings\": Categorical([True]),\n",
        "        \"basemodel__model__second_dense\": Categorical([False]),\n",
        "        \"clip_y\": Integer(80,140),\n",
        "        # \"poly_degree\": Categorical([2,3]),\n",
        "        \"scaler\": Categorical([MinMaxScaler(),StandardScaler()]),\n",
        "        \"basemodel__epochs\": Integer(1,50),\n",
        "        \"basemodel__validation_split\":Real(0.1,0.9),\n",
        "        \"basemodel__batch_size\": Integer(32,512),\n",
        "        \"basemodel__model__optim\":Categorical([Adam,RMSprop]),\n",
        "        \"basemodel__model__learning_rate\": Real(1e-4, 1e-2),\n",
        "\n",
        "        \"basemodel__model__layer1\": Integer(16,512),\n",
        "        \"basemodel__model__activation1\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout1\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer2\": Integer(16,512),\n",
        "        # \"basemodel__model__activation2\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__activation2\": Categorical([\"tanh\"]),\n",
        "        \"basemodel__model__dropout2\": Real(0.1,0.9),\n",
        "\n",
        "        \"basemodel__model__layer3\": Integer(16,512),\n",
        "        \"basemodel__model__activation3\": Categorical([\"relu\",\"elu\",\"selu\",\"tanh\", \"sigmoid\"]),\n",
        "        \"basemodel__model__dropout3\": Real(0.1,0.9),\n",
        "    }\n",
        "    gcv = GroupKFold(n_splits=3)\n",
        "    groups=X_train_['unit_number']\n",
        "    bss = BayesSearchCV(model, param_distributions, \n",
        "                        verbose=3, n_jobs=1, refit=False,\n",
        "                        cv=gcv.split(X_train_, groups=groups), n_iter=20)\n",
        "                        # cv=gcv.split(X_train_, groups=groups), n_iter=2)\n",
        "    \n",
        "    model = bss.fit(X_train_, y_train)\n",
        "    \n",
        "    # print(bss.best_estimator_)\n",
        "    print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013d65d1-c698-4fb7-da8b-9d3ce49e9167",
        "id": "AEzlJhmrTjhS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=383, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7446662207095487, basemodel__model__dropout2=0.5661418853373179, basemodel__model__dropout3=0.5112642627081574, basemodel__model__layer1=488, basemodel__model__layer2=319, basemodel__model__layer3=444, basemodel__model__learning_rate=0.0067147626567922065, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5824998290472077, clip_y=139, include_settings=True, scaler=StandardScaler(), seq_length=62;, score=0.391 total time= 2.2min\n",
            "[CV 2/3] END basemodel__batch_size=383, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7446662207095487, basemodel__model__dropout2=0.5661418853373179, basemodel__model__dropout3=0.5112642627081574, basemodel__model__layer1=488, basemodel__model__layer2=319, basemodel__model__layer3=444, basemodel__model__learning_rate=0.0067147626567922065, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5824998290472077, clip_y=139, include_settings=True, scaler=StandardScaler(), seq_length=62;, score=0.345 total time= 2.3min\n",
            "[CV 3/3] END basemodel__batch_size=383, basemodel__epochs=20, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.7446662207095487, basemodel__model__dropout2=0.5661418853373179, basemodel__model__dropout3=0.5112642627081574, basemodel__model__layer1=488, basemodel__model__layer2=319, basemodel__model__layer3=444, basemodel__model__learning_rate=0.0067147626567922065, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5824998290472077, clip_y=139, include_settings=True, scaler=StandardScaler(), seq_length=62;, score=0.384 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=110, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.5046783344476454, basemodel__model__dropout2=0.5604520404176939, basemodel__model__dropout3=0.6246802656675159, basemodel__model__layer1=445, basemodel__model__layer2=193, basemodel__model__layer3=105, basemodel__model__learning_rate=0.003750958730200658, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.2353448581188973, clip_y=103, include_settings=True, scaler=MinMaxScaler(), seq_length=81;, score=0.374 total time= 4.1min\n",
            "[CV 2/3] END basemodel__batch_size=110, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.5046783344476454, basemodel__model__dropout2=0.5604520404176939, basemodel__model__dropout3=0.6246802656675159, basemodel__model__layer1=445, basemodel__model__layer2=193, basemodel__model__layer3=105, basemodel__model__learning_rate=0.003750958730200658, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.2353448581188973, clip_y=103, include_settings=True, scaler=MinMaxScaler(), seq_length=81;, score=0.578 total time= 6.2min\n",
            "[CV 3/3] END basemodel__batch_size=110, basemodel__epochs=34, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.5046783344476454, basemodel__model__dropout2=0.5604520404176939, basemodel__model__dropout3=0.6246802656675159, basemodel__model__layer1=445, basemodel__model__layer2=193, basemodel__model__layer3=105, basemodel__model__learning_rate=0.003750958730200658, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.2353448581188973, clip_y=103, include_settings=True, scaler=MinMaxScaler(), seq_length=81;, score=0.496 total time= 6.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=154, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.15537813774103856, basemodel__model__dropout2=0.21691145842551926, basemodel__model__dropout3=0.24287496227531621, basemodel__model__layer1=21, basemodel__model__layer2=257, basemodel__model__layer3=126, basemodel__model__learning_rate=0.0006107309294389157, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5127159941689349, clip_y=136, include_settings=True, scaler=StandardScaler(), seq_length=53;, score=0.414 total time=  44.4s\n",
            "[CV 2/3] END basemodel__batch_size=154, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.15537813774103856, basemodel__model__dropout2=0.21691145842551926, basemodel__model__dropout3=0.24287496227531621, basemodel__model__layer1=21, basemodel__model__layer2=257, basemodel__model__layer3=126, basemodel__model__learning_rate=0.0006107309294389157, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5127159941689349, clip_y=136, include_settings=True, scaler=StandardScaler(), seq_length=53;, score=0.367 total time=  44.5s\n",
            "[CV 3/3] END basemodel__batch_size=154, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.15537813774103856, basemodel__model__dropout2=0.21691145842551926, basemodel__model__dropout3=0.24287496227531621, basemodel__model__layer1=21, basemodel__model__layer2=257, basemodel__model__layer3=126, basemodel__model__learning_rate=0.0006107309294389157, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5127159941689349, clip_y=136, include_settings=True, scaler=StandardScaler(), seq_length=53;, score=0.431 total time=  44.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=90, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.15330573620797205, basemodel__model__dropout2=0.7949934607956608, basemodel__model__dropout3=0.4371136740985019, basemodel__model__layer1=70, basemodel__model__layer2=27, basemodel__model__layer3=406, basemodel__model__learning_rate=0.0008730011634820979, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3619254355373066, clip_y=112, include_settings=True, scaler=MinMaxScaler(), seq_length=92;, score=0.284 total time= 3.5min\n",
            "[CV 2/3] END basemodel__batch_size=90, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.15330573620797205, basemodel__model__dropout2=0.7949934607956608, basemodel__model__dropout3=0.4371136740985019, basemodel__model__layer1=70, basemodel__model__layer2=27, basemodel__model__layer3=406, basemodel__model__learning_rate=0.0008730011634820979, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3619254355373066, clip_y=112, include_settings=True, scaler=MinMaxScaler(), seq_length=92;, score=0.362 total time= 3.5min\n",
            "[CV 3/3] END basemodel__batch_size=90, basemodel__epochs=42, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.15330573620797205, basemodel__model__dropout2=0.7949934607956608, basemodel__model__dropout3=0.4371136740985019, basemodel__model__layer1=70, basemodel__model__layer2=27, basemodel__model__layer3=406, basemodel__model__learning_rate=0.0008730011634820979, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.3619254355373066, clip_y=112, include_settings=True, scaler=MinMaxScaler(), seq_length=92;, score=0.298 total time= 3.5min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=454, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.3959908039097356, basemodel__model__dropout2=0.5114409996479388, basemodel__model__dropout3=0.5600094429171198, basemodel__model__layer1=421, basemodel__model__layer2=136, basemodel__model__layer3=363, basemodel__model__learning_rate=0.0003799790707842783, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8573260149953116, clip_y=128, include_settings=True, scaler=StandardScaler(), seq_length=31;, score=0.516 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=454, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.3959908039097356, basemodel__model__dropout2=0.5114409996479388, basemodel__model__dropout3=0.5600094429171198, basemodel__model__layer1=421, basemodel__model__layer2=136, basemodel__model__layer3=363, basemodel__model__learning_rate=0.0003799790707842783, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8573260149953116, clip_y=128, include_settings=True, scaler=StandardScaler(), seq_length=31;, score=0.509 total time= 1.1min\n",
            "[CV 3/3] END basemodel__batch_size=454, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.3959908039097356, basemodel__model__dropout2=0.5114409996479388, basemodel__model__dropout3=0.5600094429171198, basemodel__model__layer1=421, basemodel__model__layer2=136, basemodel__model__layer3=363, basemodel__model__learning_rate=0.0003799790707842783, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8573260149953116, clip_y=128, include_settings=True, scaler=StandardScaler(), seq_length=31;, score=0.510 total time= 1.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=342, basemodel__epochs=43, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.16658441749251704, basemodel__model__dropout2=0.7778022385771737, basemodel__model__dropout3=0.5639649111469681, basemodel__model__layer1=389, basemodel__model__layer2=346, basemodel__model__layer3=91, basemodel__model__learning_rate=0.007927263298020201, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.39740049034856273, clip_y=81, include_settings=True, scaler=MinMaxScaler(), seq_length=98;, score=-0.000 total time= 1.9min\n",
            "[CV 2/3] END basemodel__batch_size=342, basemodel__epochs=43, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.16658441749251704, basemodel__model__dropout2=0.7778022385771737, basemodel__model__dropout3=0.5639649111469681, basemodel__model__layer1=389, basemodel__model__layer2=346, basemodel__model__layer3=91, basemodel__model__learning_rate=0.007927263298020201, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.39740049034856273, clip_y=81, include_settings=True, scaler=MinMaxScaler(), seq_length=98;, score=-0.003 total time= 2.3min\n",
            "[CV 3/3] END basemodel__batch_size=342, basemodel__epochs=43, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.16658441749251704, basemodel__model__dropout2=0.7778022385771737, basemodel__model__dropout3=0.5639649111469681, basemodel__model__layer1=389, basemodel__model__layer2=346, basemodel__model__layer3=91, basemodel__model__learning_rate=0.007927263298020201, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.39740049034856273, clip_y=81, include_settings=True, scaler=MinMaxScaler(), seq_length=98;, score=-0.002 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=35, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.11144419468424092, basemodel__model__dropout2=0.6962707507071817, basemodel__model__dropout3=0.2096926425505646, basemodel__model__layer1=271, basemodel__model__layer2=62, basemodel__model__layer3=59, basemodel__model__learning_rate=0.007722256783538624, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5816181716132146, clip_y=127, include_settings=True, scaler=StandardScaler(), seq_length=38;, score=0.470 total time= 1.7min\n",
            "[CV 2/3] END basemodel__batch_size=35, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.11144419468424092, basemodel__model__dropout2=0.6962707507071817, basemodel__model__dropout3=0.2096926425505646, basemodel__model__layer1=271, basemodel__model__layer2=62, basemodel__model__layer3=59, basemodel__model__learning_rate=0.007722256783538624, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5816181716132146, clip_y=127, include_settings=True, scaler=StandardScaler(), seq_length=38;, score=0.498 total time= 1.6min\n",
            "[CV 3/3] END basemodel__batch_size=35, basemodel__epochs=7, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=sigmoid, basemodel__model__dropout1=0.11144419468424092, basemodel__model__dropout2=0.6962707507071817, basemodel__model__dropout3=0.2096926425505646, basemodel__model__layer1=271, basemodel__model__layer2=62, basemodel__model__layer3=59, basemodel__model__learning_rate=0.007722256783538624, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5816181716132146, clip_y=127, include_settings=True, scaler=StandardScaler(), seq_length=38;, score=0.485 total time= 1.7min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=352, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6620164591928618, basemodel__model__dropout2=0.7463001742895797, basemodel__model__dropout3=0.2079242405320063, basemodel__model__layer1=198, basemodel__model__layer2=486, basemodel__model__layer3=38, basemodel__model__learning_rate=0.005774951053979504, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.11789252854799549, clip_y=133, include_settings=True, scaler=MinMaxScaler(), seq_length=70;, score=0.333 total time= 3.6min\n",
            "[CV 2/3] END basemodel__batch_size=352, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6620164591928618, basemodel__model__dropout2=0.7463001742895797, basemodel__model__dropout3=0.2079242405320063, basemodel__model__layer1=198, basemodel__model__layer2=486, basemodel__model__layer3=38, basemodel__model__learning_rate=0.005774951053979504, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.11789252854799549, clip_y=133, include_settings=True, scaler=MinMaxScaler(), seq_length=70;, score=0.347 total time= 3.6min\n",
            "[CV 3/3] END basemodel__batch_size=352, basemodel__epochs=28, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.6620164591928618, basemodel__model__dropout2=0.7463001742895797, basemodel__model__dropout3=0.2079242405320063, basemodel__model__layer1=198, basemodel__model__layer2=486, basemodel__model__layer3=38, basemodel__model__learning_rate=0.005774951053979504, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.11789252854799549, clip_y=133, include_settings=True, scaler=MinMaxScaler(), seq_length=70;, score=-0.001 total time= 2.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=166, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5741635408397163, basemodel__model__dropout2=0.2848535829132991, basemodel__model__dropout3=0.42742672155010986, basemodel__model__layer1=28, basemodel__model__layer2=106, basemodel__model__layer3=282, basemodel__model__learning_rate=0.0029901326564183172, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4354878833667518, clip_y=116, include_settings=True, scaler=MinMaxScaler(), seq_length=64;, score=0.426 total time= 2.3min\n",
            "[CV 2/3] END basemodel__batch_size=166, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5741635408397163, basemodel__model__dropout2=0.2848535829132991, basemodel__model__dropout3=0.42742672155010986, basemodel__model__layer1=28, basemodel__model__layer2=106, basemodel__model__layer3=282, basemodel__model__learning_rate=0.0029901326564183172, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4354878833667518, clip_y=116, include_settings=True, scaler=MinMaxScaler(), seq_length=64;, score=0.343 total time= 2.3min\n",
            "[CV 3/3] END basemodel__batch_size=166, basemodel__epochs=46, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5741635408397163, basemodel__model__dropout2=0.2848535829132991, basemodel__model__dropout3=0.42742672155010986, basemodel__model__layer1=28, basemodel__model__layer2=106, basemodel__model__layer3=282, basemodel__model__learning_rate=0.0029901326564183172, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.4354878833667518, clip_y=116, include_settings=True, scaler=MinMaxScaler(), seq_length=64;, score=0.565 total time= 2.3min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=132, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.4236668671921673, basemodel__model__dropout2=0.37375594428601244, basemodel__model__dropout3=0.5463094771481084, basemodel__model__layer1=208, basemodel__model__layer2=239, basemodel__model__layer3=407, basemodel__model__learning_rate=0.00955602369681923, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23791902573749638, clip_y=86, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.603 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=132, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.4236668671921673, basemodel__model__dropout2=0.37375594428601244, basemodel__model__dropout3=0.5463094771481084, basemodel__model__layer1=208, basemodel__model__layer2=239, basemodel__model__layer3=407, basemodel__model__learning_rate=0.00955602369681923, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23791902573749638, clip_y=86, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.621 total time= 1.1min\n",
            "[CV 3/3] END basemodel__batch_size=132, basemodel__epochs=9, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.4236668671921673, basemodel__model__dropout2=0.37375594428601244, basemodel__model__dropout3=0.5463094771481084, basemodel__model__layer1=208, basemodel__model__layer2=239, basemodel__model__layer3=407, basemodel__model__learning_rate=0.00955602369681923, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23791902573749638, clip_y=86, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.471 total time= 1.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=325, basemodel__epochs=4, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.45408693776401365, basemodel__model__dropout3=0.19673176401876696, basemodel__model__layer1=363, basemodel__model__layer2=16, basemodel__model__layer3=199, basemodel__model__learning_rate=0.000801952359004921, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23358104714171202, clip_y=103, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.456 total time=  25.9s\n",
            "[CV 2/3] END basemodel__batch_size=325, basemodel__epochs=4, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.45408693776401365, basemodel__model__dropout3=0.19673176401876696, basemodel__model__layer1=363, basemodel__model__layer2=16, basemodel__model__layer3=199, basemodel__model__learning_rate=0.000801952359004921, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23358104714171202, clip_y=103, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.515 total time=  25.8s\n",
            "[CV 3/3] END basemodel__batch_size=325, basemodel__epochs=4, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.45408693776401365, basemodel__model__dropout3=0.19673176401876696, basemodel__model__layer1=363, basemodel__model__layer2=16, basemodel__model__layer3=199, basemodel__model__learning_rate=0.000801952359004921, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23358104714171202, clip_y=103, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.500 total time=  25.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=442, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.45179604838939647, basemodel__model__dropout3=0.9, basemodel__model__layer1=384, basemodel__model__layer2=490, basemodel__model__layer3=512, basemodel__model__learning_rate=0.008354405178314265, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=129, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.388 total time= 1.6min\n",
            "[CV 2/3] END basemodel__batch_size=442, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.45179604838939647, basemodel__model__dropout3=0.9, basemodel__model__layer1=384, basemodel__model__layer2=490, basemodel__model__layer3=512, basemodel__model__learning_rate=0.008354405178314265, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=129, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.351 total time= 1.7min\n",
            "[CV 3/3] END basemodel__batch_size=442, basemodel__epochs=49, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.45179604838939647, basemodel__model__dropout3=0.9, basemodel__model__layer1=384, basemodel__model__layer2=490, basemodel__model__layer3=512, basemodel__model__learning_rate=0.008354405178314265, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.9, clip_y=129, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.402 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=147, basemodel__epochs=5, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5014770524563225, basemodel__model__dropout2=0.6086475513454409, basemodel__model__dropout3=0.8088523076738845, basemodel__model__layer1=89, basemodel__model__layer2=147, basemodel__model__layer3=505, basemodel__model__learning_rate=0.008446877795078226, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7324148058379806, clip_y=119, include_settings=True, scaler=StandardScaler(), seq_length=45;, score=0.402 total time=  28.6s\n",
            "[CV 2/3] END basemodel__batch_size=147, basemodel__epochs=5, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5014770524563225, basemodel__model__dropout2=0.6086475513454409, basemodel__model__dropout3=0.8088523076738845, basemodel__model__layer1=89, basemodel__model__layer2=147, basemodel__model__layer3=505, basemodel__model__learning_rate=0.008446877795078226, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7324148058379806, clip_y=119, include_settings=True, scaler=StandardScaler(), seq_length=45;, score=0.462 total time=  28.6s\n",
            "[CV 3/3] END basemodel__batch_size=147, basemodel__epochs=5, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.5014770524563225, basemodel__model__dropout2=0.6086475513454409, basemodel__model__dropout3=0.8088523076738845, basemodel__model__layer1=89, basemodel__model__layer2=147, basemodel__model__layer3=505, basemodel__model__learning_rate=0.008446877795078226, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7324148058379806, clip_y=119, include_settings=True, scaler=StandardScaler(), seq_length=45;, score=0.431 total time=  28.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.503 total time=  36.0s\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.516 total time=  36.4s\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=elu, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.1, basemodel__model__layer1=16, basemodel__model__layer2=512, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0001, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.449 total time=  35.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.48047631957844494, basemodel__model__dropout3=0.1, basemodel__model__layer1=46, basemodel__model__layer2=16, basemodel__model__layer3=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=0.324 total time=  35.9s\n",
            "[CV 2/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.48047631957844494, basemodel__model__dropout3=0.1, basemodel__model__layer1=46, basemodel__model__layer2=16, basemodel__model__layer3=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=-0.000 total time=  37.0s\n",
            "[CV 3/3] END basemodel__batch_size=32, basemodel__epochs=1, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=tanh, basemodel__model__dropout1=0.1, basemodel__model__dropout2=0.48047631957844494, basemodel__model__dropout3=0.1, basemodel__model__layer1=46, basemodel__model__layer2=16, basemodel__model__layer3=16, basemodel__model__learning_rate=0.01, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.1, clip_y=80, include_settings=True, scaler=StandardScaler(), seq_length=30;, score=-0.001 total time=  36.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=386, basemodel__epochs=40, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.569781652937638, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.39340387608577554, basemodel__model__layer1=301, basemodel__model__layer2=220, basemodel__model__layer3=198, basemodel__model__learning_rate=0.007362139922624056, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23709213478483587, clip_y=140, include_settings=True, scaler=MinMaxScaler(), seq_length=78;, score=0.303 total time= 2.6min\n",
            "[CV 2/3] END basemodel__batch_size=386, basemodel__epochs=40, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.569781652937638, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.39340387608577554, basemodel__model__layer1=301, basemodel__model__layer2=220, basemodel__model__layer3=198, basemodel__model__learning_rate=0.007362139922624056, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23709213478483587, clip_y=140, include_settings=True, scaler=MinMaxScaler(), seq_length=78;, score=0.311 total time= 1.7min\n",
            "[CV 3/3] END basemodel__batch_size=386, basemodel__epochs=40, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.569781652937638, basemodel__model__dropout2=0.1, basemodel__model__dropout3=0.39340387608577554, basemodel__model__layer1=301, basemodel__model__layer2=220, basemodel__model__layer3=198, basemodel__model__learning_rate=0.007362139922624056, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.23709213478483587, clip_y=140, include_settings=True, scaler=MinMaxScaler(), seq_length=78;, score=-0.000 total time= 1.6min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=276, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.9, basemodel__model__layer1=357, basemodel__model__layer2=452, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0005974780463255199, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5657504932820226, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=55;, score=0.481 total time= 3.0min\n",
            "[CV 2/3] END basemodel__batch_size=276, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.9, basemodel__model__layer1=357, basemodel__model__layer2=452, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0005974780463255199, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5657504932820226, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=55;, score=0.491 total time= 3.0min\n",
            "[CV 3/3] END basemodel__batch_size=276, basemodel__epochs=25, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=relu, basemodel__model__dropout1=0.9, basemodel__model__dropout2=0.9, basemodel__model__dropout3=0.9, basemodel__model__layer1=357, basemodel__model__layer2=452, basemodel__model__layer3=512, basemodel__model__learning_rate=0.0005974780463255199, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5657504932820226, clip_y=140, include_settings=True, scaler=StandardScaler(), seq_length=55;, score=0.411 total time= 3.0min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=405, basemodel__epochs=31, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.29944981559871114, basemodel__model__dropout2=0.4026483666395597, basemodel__model__dropout3=0.7167433539915277, basemodel__model__layer1=219, basemodel__model__layer2=16, basemodel__model__layer3=354, basemodel__model__learning_rate=0.00850025463243397, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5921265755999453, clip_y=84, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.514 total time= 1.1min\n",
            "[CV 2/3] END basemodel__batch_size=405, basemodel__epochs=31, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.29944981559871114, basemodel__model__dropout2=0.4026483666395597, basemodel__model__dropout3=0.7167433539915277, basemodel__model__layer1=219, basemodel__model__layer2=16, basemodel__model__layer3=354, basemodel__model__learning_rate=0.00850025463243397, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5921265755999453, clip_y=84, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.509 total time= 1.1min\n",
            "[CV 3/3] END basemodel__batch_size=405, basemodel__epochs=31, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.29944981559871114, basemodel__model__dropout2=0.4026483666395597, basemodel__model__dropout3=0.7167433539915277, basemodel__model__layer1=219, basemodel__model__layer2=16, basemodel__model__layer3=354, basemodel__model__learning_rate=0.00850025463243397, basemodel__model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>, basemodel__model__second_dense=False, basemodel__validation_split=0.5921265755999453, clip_y=84, include_settings=True, scaler=StandardScaler(), seq_length=52;, score=0.508 total time= 1.1min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=475, basemodel__epochs=38, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.41871805965088293, basemodel__model__dropout2=0.3421999536441197, basemodel__model__dropout3=0.6177826332606998, basemodel__model__layer1=440, basemodel__model__layer2=184, basemodel__model__layer3=376, basemodel__model__learning_rate=0.0038903406569891345, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7313863245835751, clip_y=100, include_settings=True, scaler=StandardScaler(), seq_length=44;, score=0.619 total time= 2.2min\n",
            "[CV 2/3] END basemodel__batch_size=475, basemodel__epochs=38, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.41871805965088293, basemodel__model__dropout2=0.3421999536441197, basemodel__model__dropout3=0.6177826332606998, basemodel__model__layer1=440, basemodel__model__layer2=184, basemodel__model__layer3=376, basemodel__model__learning_rate=0.0038903406569891345, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7313863245835751, clip_y=100, include_settings=True, scaler=StandardScaler(), seq_length=44;, score=0.612 total time= 2.2min\n",
            "[CV 3/3] END basemodel__batch_size=475, basemodel__epochs=38, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.41871805965088293, basemodel__model__dropout2=0.3421999536441197, basemodel__model__dropout3=0.6177826332606998, basemodel__model__layer1=440, basemodel__model__layer2=184, basemodel__model__layer3=376, basemodel__model__learning_rate=0.0038903406569891345, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.7313863245835751, clip_y=100, include_settings=True, scaler=StandardScaler(), seq_length=44;, score=0.500 total time= 2.2min\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END basemodel__batch_size=470, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.8037215169400213, basemodel__model__dropout2=0.32060253053788235, basemodel__model__dropout3=0.3733228816851921, basemodel__model__layer1=507, basemodel__model__layer2=177, basemodel__model__layer3=490, basemodel__model__learning_rate=0.005139193540599123, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8711842550025372, clip_y=132, include_settings=True, scaler=StandardScaler(), seq_length=98;, score=0.155 total time= 2.5min\n",
            "[CV 2/3] END basemodel__batch_size=470, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.8037215169400213, basemodel__model__dropout2=0.32060253053788235, basemodel__model__dropout3=0.3733228816851921, basemodel__model__layer1=507, basemodel__model__layer2=177, basemodel__model__layer3=490, basemodel__model__learning_rate=0.005139193540599123, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8711842550025372, clip_y=132, include_settings=True, scaler=StandardScaler(), seq_length=98;, score=0.158 total time= 1.8min\n",
            "[CV 3/3] END basemodel__batch_size=470, basemodel__epochs=33, basemodel__model__activation1=tanh, basemodel__model__activation2=tanh, basemodel__model__activation3=selu, basemodel__model__dropout1=0.8037215169400213, basemodel__model__dropout2=0.32060253053788235, basemodel__model__dropout3=0.3733228816851921, basemodel__model__layer1=507, basemodel__model__layer2=177, basemodel__model__layer3=490, basemodel__model__learning_rate=0.005139193540599123, basemodel__model__optim=<class 'keras.optimizer_v2.adam.Adam'>, basemodel__model__second_dense=False, basemodel__validation_split=0.8711842550025372, clip_y=132, include_settings=True, scaler=StandardScaler(), seq_length=98;, score=-0.000 total time= 1.1min\n",
            "Finished: 2022-10-21 20:01:58.468950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bss.best_estimator_)\n",
        "print(bss.best_score_)\n",
        "print(bss.best_params_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNpN6avkTjhT",
        "outputId": "c537dba0-68bf-40da-d2b9-b693dcac3499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5770400313627971\n",
            "OrderedDict([('basemodel__batch_size', 475), ('basemodel__epochs', 38), ('basemodel__model__activation1', 'tanh'), ('basemodel__model__activation2', 'tanh'), ('basemodel__model__activation3', 'selu'), ('basemodel__model__dropout1', 0.41871805965088293), ('basemodel__model__dropout2', 0.3421999536441197), ('basemodel__model__dropout3', 0.6177826332606998), ('basemodel__model__layer1', 440), ('basemodel__model__layer2', 184), ('basemodel__model__layer3', 376), ('basemodel__model__learning_rate', 0.0038903406569891345), ('basemodel__model__optim', <class 'keras.optimizer_v2.adam.Adam'>), ('basemodel__model__second_dense', False), ('basemodel__validation_split', 0.7313863245835751), ('clip_y', 100), ('include_settings', True), ('scaler', StandardScaler()), ('seq_length', 44)])\n",
            "Finished: 2022-10-21 20:01:58.477925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt.plots import plot_convergence\n",
        "\n",
        "plot_convergence(bss.optimizer_results_)\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "ot_dDcRKTjhU",
        "outputId": "42287ecc-5f19-4cc0-de9b-02f5240b50f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: 2022-10-21 20:01:58.512924\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VCjkODvTjhV",
        "outputId": "7322b174-2813-4462-a211-d60845326386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('basemodel__batch_size', 475),\n",
              "             ('basemodel__epochs', 38),\n",
              "             ('basemodel__model__activation1', 'tanh'),\n",
              "             ('basemodel__model__activation2', 'tanh'),\n",
              "             ('basemodel__model__activation3', 'selu'),\n",
              "             ('basemodel__model__dropout1', 0.41871805965088293),\n",
              "             ('basemodel__model__dropout2', 0.3421999536441197),\n",
              "             ('basemodel__model__dropout3', 0.6177826332606998),\n",
              "             ('basemodel__model__layer1', 440),\n",
              "             ('basemodel__model__layer2', 184),\n",
              "             ('basemodel__model__layer3', 376),\n",
              "             ('basemodel__model__learning_rate', 0.0038903406569891345),\n",
              "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
              "             ('basemodel__model__second_dense', False),\n",
              "             ('basemodel__validation_split', 0.7313863245835751),\n",
              "             ('clip_y', 100),\n",
              "             ('include_settings', True),\n",
              "             ('scaler', StandardScaler()),\n",
              "             ('seq_length', 44)])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 1-layer\n"
      ],
      "metadata": {
        "id": "ppByl3wN_W05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.5816177553633815  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 35),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.9),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__learning_rate', 0.0001),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.1),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 100)\n",
        "```\n"
      ],
      "metadata": {
        "id": "O3mGfle45Bp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.6487511063058244  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 262),\n",
        "             ('basemodel__epochs', 50),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__dropout1', 0.9),\n",
        "             ('basemodel__model__layer1', 512),\n",
        "             ('basemodel__model__learning_rate', 0.0001),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__validation_split', 0.13191782981852057),\n",
        "             ('clip_y', 140),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 75)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ESr-SWV1Dy3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-1\n"
      ],
      "metadata": {
        "id": "zSnh2UONQb4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.5709418653283571  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 43),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.4523423204279986),\n",
        "             ('basemodel__model__dropout2', 0.6519444578987227),\n",
        "             ('basemodel__model__layer1', 492),\n",
        "             ('basemodel__model__layer2', 53),\n",
        "             ('basemodel__model__learning_rate', 0.0001),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.22182563254238585),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 53)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vL2GlZ8KQb4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.7530758636321139  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 287),\n",
        "             ('basemodel__epochs', 28),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.13678820565973349),\n",
        "             ('basemodel__model__dropout2', 0.9),\n",
        "             ('basemodel__model__layer1', 336),\n",
        "             ('basemodel__model__layer2', 77),\n",
        "             ('basemodel__model__learning_rate', 0.0040050838967013785),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.1494847733663106),\n",
        "             ('clip_y', 124),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 73)\n",
        "```\n"
      ],
      "metadata": {
        "id": "B3F5zD55D9Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Dense-2\n"
      ],
      "metadata": {
        "id": "Jygcz0fjrzEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to change the argument: 'second_dense=True'"
      ],
      "metadata": {
        "id": "puLVKoxXEXb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.5860971746607238  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 264),\n",
        "             ('basemodel__epochs', 23),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'sigmoid'),\n",
        "             ('basemodel__model__activation3', 'relu'),\n",
        "             ('basemodel__model__dropout1', 0.21534955706280656),\n",
        "             ('basemodel__model__dropout2', 0.7741992560602),\n",
        "             ('basemodel__model__dropout3', 0.4418655267370424),\n",
        "             ('basemodel__model__layer1', 395),\n",
        "             ('basemodel__model__layer2', 330),\n",
        "             ('basemodel__model__layer3', 145),\n",
        "             ('basemodel__model__learning_rate', 0.009202704024775169),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.20435450812720612),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 70)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ywnov-HvrzEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.8114717682301014  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 32),\n",
        "             ('basemodel__epochs', 47),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'sigmoid'),\n",
        "             ('basemodel__model__dropout1', 0.1),\n",
        "             ('basemodel__model__dropout2', 0.2141175093000496),\n",
        "             ('basemodel__model__dropout3', 0.7714899358963251),\n",
        "             ('basemodel__model__layer1', 16),\n",
        "             ('basemodel__model__layer2', 16),\n",
        "             ('basemodel__model__layer3', 100),\n",
        "             ('basemodel__model__learning_rate', 0.000567080109365328),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', True),\n",
        "             ('basemodel__validation_split', 0.11371723233432361),\n",
        "             ('clip_y', 106),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 44)\n",
        "```\n"
      ],
      "metadata": {
        "id": "W98etTHQrzEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-LSTM-Dense\n"
      ],
      "metadata": {
        "id": "z2vaL6nDDYF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Linear RUL\n",
        "\n",
        "Score: 0.4572066088840683  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 413),\n",
        "             ('basemodel__epochs', 39),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'elu'),\n",
        "             ('basemodel__model__dropout1', 0.8027344701984965),\n",
        "             ('basemodel__model__dropout2', 0.7569408037894426),\n",
        "             ('basemodel__model__dropout3', 0.12896783869092998),\n",
        "             ('basemodel__model__layer1', 367),\n",
        "             ('basemodel__model__layer2', 478),\n",
        "             ('basemodel__model__layer3', 22),\n",
        "             ('basemodel__model__learning_rate', 0.0068513804632596),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.rmsprop.RMSprop),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.6070472478342536),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', MinMaxScaler()),\n",
        "             ('seq_length', 32)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YD0XcCDuDYF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Non-Linear RUL\n",
        "Score: 0.5770400313627971  \n",
        "Test: 0.\n",
        "```\n",
        "('basemodel__batch_size', 475),\n",
        "             ('basemodel__epochs', 38),\n",
        "             ('basemodel__model__activation1', 'tanh'),\n",
        "             ('basemodel__model__activation2', 'tanh'),\n",
        "             ('basemodel__model__activation3', 'selu'),\n",
        "             ('basemodel__model__dropout1', 0.41871805965088293),\n",
        "             ('basemodel__model__dropout2', 0.3421999536441197),\n",
        "             ('basemodel__model__dropout3', 0.6177826332606998),\n",
        "             ('basemodel__model__layer1', 440),\n",
        "             ('basemodel__model__layer2', 184),\n",
        "             ('basemodel__model__layer3', 376),\n",
        "             ('basemodel__model__learning_rate', 0.0038903406569891345),\n",
        "             ('basemodel__model__optim', keras.optimizer_v2.adam.Adam),\n",
        "             ('basemodel__model__second_dense', False),\n",
        "             ('basemodel__validation_split', 0.7313863245835751),\n",
        "             ('clip_y', 100),\n",
        "             ('include_settings', True),\n",
        "             ('scaler', StandardScaler()),\n",
        "             ('seq_length', 44)\n",
        "```\n"
      ],
      "metadata": {
        "id": "L5Sg97mcDYF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Tester"
      ],
      "metadata": {
        "id": "HcbbxDGAmi21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=68\n",
        "CLIP=105\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, scaler=MinMaxScaler(),\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=50,\n",
        "                           model__activation='tanh',\n",
        "                           model__dropout=0.1, \n",
        "                           model__layer1=512, \n",
        "                           model__learning_rate=0.0001,\n",
        "                           model__optim=Adam,\n",
        "                           validation_split=0.1, \n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "5p5GYkfQFKtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "outputId": "10771aed-b881-4a8f-84bc-279c86183fd4",
        "id": "wmkoVA33FKtl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-58-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# Data checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfeature_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_build_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_build_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: create_model() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "# reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aabf85-7117-4fc6-ec26-dd6768f621fb",
        "id": "RXnrciV-FKtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.857,RMSE=-15.701\n",
            "Finished: 2022-10-10 12:37:52.380820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFF\n",
        "## Non-Linear RUL"
      ],
      "metadata": {
        "id": "WVSMJWsLFDx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LSTMWrapperRegressor(\n",
        "    basemodel=KerasRegressor(\n",
        "        batch_size=32, \n",
        "        epochs=23, \n",
        "        model__activation='tanh',\n",
        "        model__dropout=0.30649418903936865, \n",
        "        model__layer_nodes=512, \n",
        "        model__learning_rate=0.0010472789501880123,\n",
        "        model__optim=<class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
        "        validation_split=0.23542211183603107,\n",
        "    clip_y=99, \n",
        "    seq_length=79)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZtOjUBNDKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(optim=Adam, dropout=0.1, activation=\"tanh\", \n",
        "                 learning_rate=1e-3, layer1=32, layer2=None, layer3=None,\n",
        "                 print_summary=False, loss='mean_squared_error',\n",
        "                 metrics=[tf.keras.metrics.MeanSquaredError()]):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input-masked layer\n",
        "    model.add(Masking(mask_value=-99., input_shape=INPUT_SHAPE))\n",
        "    \n",
        "    if (layer2 is None and layer3 is None):\n",
        "        # Single LSTM layer\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is None):\n",
        "        # 2 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "    elif (layer2 is not None and layer3 is not None):\n",
        "        # 3 stacked LSTM layers\n",
        "        model.add(LSTM(layer1, return_sequences=True, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer2, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Dense(layer3, activation=activation))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optim(learning_rate=learning_rate), \n",
        "                  metrics=metrics)\n",
        "    \n",
        "    if(print_summary): model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "QFBtaiz2Ckgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH=79\n",
        "CLIP=99\n",
        "\n",
        "model = LSTMWrapperRegressor(\n",
        "        clip_y=CLIP, seq_length=SEQ_LENGTH, poly_degree=1,\n",
        "        basemodel=\n",
        "            KerasRegressor(model=create_model,\n",
        "                           batch_size=32,\n",
        "                           epochs=23,\n",
        "                           validation_split=0.23542211183603107, \n",
        "                           \n",
        "                           \n",
        "                           model__layer1=512, \n",
        "                           model__activation1='tanh',\n",
        "                           model__dropout1=0.30649418903936865, \n",
        "                           model__layer2=400,\n",
        "                           model__activation2='selu',\n",
        "                           model__dropout2=0.30649418903936865,\n",
        "\n",
        "                        \n",
        "                           \n",
        "                           model__learning_rate=0.0010472789501880123,\n",
        "                           model__optim=RMSprop,\n",
        "                           verbose=0, callbacks=[es, printerCallback],\n",
        "                           model__metrics=[RMSE(), R2()],\n",
        "                           model__loss='mse',\n",
        "                           print_summary=True\n",
        "                           )\n",
        "    )"
      ],
      "metadata": {
        "id": "rqEuUKLF0CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_36P-gmRD6QM",
        "outputId": "04f7f7d7-28d1-40ba-97ee-4fd9aa120787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_65 (Masking)        (None, 79, 22)            0         \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 512)               1095680   \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 400)               205200    \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 400)               0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301,281\n",
            "Trainable params: 1,301,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "E 1\t: loss=288.566, rmse=16.987, r2=0.735; v_loss=171.738, v_rmse=13.105, v_r2=0.847; \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-62-2ad527791c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-30-ac15c1524480>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print(X_train.shape, y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         self._fit(\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         self._fit_keras_model(\n\u001b[0m\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m   1222\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling and formatting test data\n",
        "test_sc = scale_test(test,model)\n",
        "test_wr = gen_test_wrapper(test_sc, SEQ_LENGTH, cols=model.seq_cols)\n",
        "\n",
        "# Clipping test labels\n",
        "reclipped_y = y_test.copy()\n",
        "reclipped_y[\"RUL\"].clip(upper=CLIP, inplace=True)\n",
        "\n",
        "# Evaluation\n",
        "eval.show_result(reclipped_y, model.basemodel.predict(test_wr))\n",
        "print(\"Finished:\", datetime.datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5L88ftEB7C",
        "outputId": "83699a7e-1744-455e-c836-906b8dc33bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2=0.918,RMSE=-9.668\n",
            "Finished: 2022-10-13 13:15:58.111062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee8uwFhF-E6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}